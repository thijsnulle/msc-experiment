{"outputs": [{"text": " re.split(r'\\.', text)", "tokens": [" re", ".", "split", "(", "r", "'\\", ".", "'", ",", " text", ")", "\n"], "logprobs": [-0.18768629431724548, -0.0001081169830285944, -0.19452351331710815, -0.23465465009212494, -0.20437006652355194, -2.533712387084961, -0.07155780494213104, -0.7111724615097046, -0.0002851079625543207, -0.02923419512808323, -0.0723942220211029, -0.10369212925434113], "finish_reason": "stop"}, {"text": " [s for s in sentences if s]", "tokens": [" [", "s", " for", " s", " in", " sentences", " if", " s", "]", "\n"], "logprobs": [-0.1708301156759262, -0.8741267919540405, -1.5035552978515625, -0.000486970558995381, -4.076874756719917e-05, -0.001122321467846632, -0.0029673613607883453, -0.3881792724132538, -0.8704869747161865, -0.12672968208789825], "finish_reason": "stop"}, {"text": " CountVectorizer(strip_accents=None)", "tokens": [" Count", "Vector", "izer", "(", "strip", "_", "acc", "ents", "=", "None", ")", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -1.0655977725982666, -3.373816967010498, -0.000648883986286819, -0.001746677909977734, -0.0008772339206188917, -0.08950316160917282, -1.2601118087768555, -0.7554683685302734, -0.02978767640888691], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform(sentences).toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-1.9051625728607178, -0.0008831891464069486, -0.016007130965590477, -0.0415533110499382, -0.0827103853225708, -1.07287787614041e-05, -5.94836674281396e-05, -0.0054380581714212894, -0.00022289653134066612, -6.913899414939806e-05, -0.12960854172706604, -0.0033246977254748344, -5.960462772236497e-07, -0.06267751008272171, -0.016150010749697685, -0.07248470187187195, -0.01831875555217266, -0.3051387071609497, -0.016884975135326385, -0.696926474571228, -0.04256291687488556, -0.010154962539672852, -9.560128091834486e-05, -5.006664650863968e-05, -0.018518297001719475, -6.079655122448457e-06, -6.758938252460212e-05, -6.318072337307967e-06, -0.001804986852221191, -0.2327488362789154, -0.03970817103981972], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.053216371685266495, -0.0017819016939029098, -0.016764473170042038, -0.01210580300539732, -0.06857752054929733, -0.00016723664884921163, -0.01276171114295721, -0.1384403109550476, -0.018320979550480843, -0.014636406674981117, -0.004090039525181055, -0.2761584520339966, -0.026658829301595688, -0.006340624764561653, -2.932505594799295e-05, -1.4543427823809907e-05, -0.0076685803942382336, -1.1801649634435307e-05, -6.365573790390044e-05, -6.9141146923357155e-06, -0.0009204680100083351, -0.18079563975334167, -0.008497391827404499], "finish_reason": "stop"}, {"text": " df", "tokens": [" df", "\n"], "logprobs": [-0.011449581943452358, -0.8055678606033325], "finish_reason": "stop"}], "metrics": {"energy": 148.55379481697076, "energy_per_token": 1.650597720188564, "time": 5.4607015, "time_per_token": 0.06067446111111111}}
{"outputs": [{"text": " re.split(r\"\\.\", text)", "tokens": [" re", ".", "split", "(", "r", "\"", "\\", ".", "\"", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -0.5187638401985168, -0.1950531154870987, -0.06564738601446152, -0.8228386640548706, -0.0003868784988299012, -0.02319338358938694, -0.06789029389619827, -0.11168789863586426], "finish_reason": "stop"}, {"text": " [sentence for sentence in sentences if sentence]", "tokens": [" [", "sentence", " for", " sentence", " in", " sentences", " if", " sentence", "]", "\n"], "logprobs": [-0.1708301156759262, -0.9143050909042358, -1.3256704807281494, -0.00047052756417542696, -0.00010382589971413836, -0.000788139586802572, -0.006003798451274633, -0.3932245671749115, -0.8903968334197998, -0.11479271948337555], "finish_reason": "stop"}, {"text": " CountVectorizer(analyzer='word')", "tokens": [" Count", "Vector", "izer", "(", "analy", "zer", "='", "word", "')", "\n"], "logprobs": [-0.000399033073335886, -9.298280929215252e-06, -2.3007127310847864e-05, -1.010318398475647, -1.0332813262939453, -0.02766978181898594, -0.8784961700439453, -0.13043296337127686, -0.5531978607177734, -0.009336145594716072], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences).toarray()", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", ".", "to", "array", "()", "\n"], "logprobs": [-0.1275787204504013, -6.639736966462806e-05, -4.3748852476710454e-05, -0.0015438791597262025, -0.0002649671514518559, -7.545663538621739e-05, -0.03556574136018753, -0.001191144809126854, -5.960462772236497e-07, -0.0019357530400156975, -2.4912045001983643, -0.14065755903720856, -0.5459451079368591, -0.0026022878009825945, -0.03703504055738449], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names(), dtype=int)", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " dtype", "=", "int", ")", "\n"], "logprobs": [-0.03895723447203636, -0.0017459639348089695, -0.01815335638821125, -0.014458413235843182, -0.10171449184417725, -0.00020621081057470292, -0.0147114722058177, -0.13782107830047607, -0.018917029723525047, -0.014543477445840836, -0.004349533934146166, -0.2757498323917389, -0.027523433789610863, -0.005765237845480442, -4.076874756719917e-05, -1.680836794548668e-05, -0.010805311612784863, -8.583032467868179e-06, -6.09140915912576e-05, -6.437280717364047e-06, -0.001212338567711413, -2.7297303676605225, -0.015918435528874397, -1.270368218421936, -0.043856553733348846, -0.14979897439479828, -0.012876695021986961, -0.018316179513931274], "finish_reason": "stop"}, {"text": " df", "tokens": [" df"], "logprobs": [-0.012526288628578186], "finish_reason": "stop"}], "metrics": {"energy": 77.14832654380798, "energy_per_token": 1.001926318750753, "time": 3.9718437, "time_per_token": 0.051582385714285715}}
{"outputs": [{"text": " text.split(\". \")", "tokens": [" text", ".", "split", "(", "\"", ".", " \"", ")", "\n"], "logprobs": [-2.9960718154907227, -0.008470677770674229, -0.09857099503278732, -0.595751941204071, -0.03654348477721214, -0.020107129588723183, -2.0055301189422607, -0.0021771318279206753, -0.09632253646850586], "finish_reason": "stop"}, {"text": " [s.lower().strip() for s in sentences if s.strip()]", "tokens": [" [", "s", ".", "lower", "()", ".", "strip", "()", " for", " s", " in", " sentences", " if", " s", ".", "strip", "()", "]", "\n"], "logprobs": [-0.1708301156759262, -0.8741267919540405, -0.273036926984787, -2.9834253787994385, -0.00043418517452664673, -1.3158910274505615, -0.05607074126601219, -0.020482689142227173, -0.0157108623534441, -0.00017987063620239496, -5.2689116273541003e-05, -0.0008800924406386912, -0.28177401423454285, -0.2771879732608795, -0.4679693579673767, -0.014467342756688595, -0.0031163957901299, -0.11996002495288849, -0.030841592699289322], "finish_reason": "stop"}, {"text": " CountVectorizer(tokenizer=lambda x: x.split())", "tokens": [" Count", "Vector", "izer", "(", "token", "izer", "=", "lambda", " x", ":", " x", ".", "split", "())", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -1.0655977725982666, -1.9773612022399902, -0.35805580019950867, -0.03708914667367935, -0.25949645042419434, -0.24050289392471313, -0.00308585399761796, -0.10418624430894852, -0.04485848546028137, -0.226227268576622, -0.34204554557800293, -0.009777157567441463], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16751833260059357, -6.05564855504781e-05, -4.23184028477408e-05, -0.001926591619849205, -0.00023624490131624043, -7.784063927829266e-05, -0.03274422138929367, -0.0012705596163868904, -5.960462772236497e-07, -0.001416633022017777, -0.07310684770345688], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03827664256095886, -0.002274071332067251, -0.019564863294363022, -0.01376704964786768, -0.07013684511184692, -0.00018082413589581847, -0.013408721424639225, -0.13627171516418457, -0.020992357283830643, -0.016209715977311134, -0.0046304380521178246, -0.22598308324813843, -0.02613671123981476, -0.007026249077171087, -3.8980677345534787e-05, -1.4781842764932662e-05, -0.010650577954947948, -9.179073458653875e-06, -6.770858453819528e-05, -6.079655122448457e-06, -0.0010099078062921762, -0.1486474722623825, -0.011710825376212597], "finish_reason": "stop"}, {"text": " df<|endoftext|>import pandas as pd", "tokens": [" df", "<", "|", "end", "of", "text", "|>", "import", " pandas", " as", " pd", "\n"], "logprobs": [-0.011720840819180012, -1.2492297887802124, -2.50339189733495e-06, -1.5497195136049413e-06, -2.4437606043647975e-05, -0.0002195594133809209, -0.04185207933187485, -0.9950740933418274, -1.8180558681488037, -0.008627640083432198, -0.001878165639936924, -0.002737467410042882], "finish_reason": "stop"}], "metrics": {"energy": 90.01578138351442, "energy_per_token": 1.0114132739720723, "time": 4.430779, "time_per_token": 0.049784033707865175}}
{"outputs": [{"text": " re.split(r\"\\.(?![^()]*\\))\", text)", "tokens": [" re", ".", "split", "(", "r", "\"", "\\", ".", "(", "?", "!", "[", "^", "()", "]", "*\\", "))", "\"", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -0.5187638401985168, -0.1950531154870987, -0.06564738601446152, -3.2743139266967773, -0.022872205823659897, -0.9748919606208801, -1.0242068767547607, -0.6236003637313843, -0.5353644490242004, -0.01764949969947338, -0.031658586114645004, -0.03845859318971634, -0.050799328833818436, -0.0005041282274760306, -0.02075512707233429, -0.09707175195217133, -0.14802825450897217], "finish_reason": "stop"}, {"text": " [s.strip() for s in sentences]", "tokens": [" [", "s", ".", "strip", "()", " for", " s", " in", " sentences", "]", "\n"], "logprobs": [-0.1708301156759262, -0.8741267919540405, -0.273036926984787, -0.11037475615739822, -0.017111873254179955, -0.018640577793121338, -0.00010966652916977182, -3.6000557884108275e-05, -0.0005480932886712253, -1.5229861736297607, -0.02392854355275631], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -0.4238341450691223, -0.007598308380693197], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences).toarray()", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", ".", "to", "array", "()", "\n"], "logprobs": [-0.16751833260059357, -6.05564855504781e-05, -4.23184028477408e-05, -0.001926591619849205, -0.00023624490131624043, -7.784063927829266e-05, -0.03274422138929367, -0.0012705596163868904, -5.960462772236497e-07, -0.001416633022017777, -2.7058067321777344, -0.14080430567264557, -0.41908591985702515, -0.0026780238840729, -0.04692428559064865], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03827664256095886, -0.002274071332067251, -0.019564863294363022, -0.01376704964786768, -0.07013684511184692, -0.00018082413589581847, -0.013408721424639225, -0.13627171516418457, -0.020992357283830643, -0.016209715977311134, -0.0046304380521178246, -0.22598308324813843, -0.02613671123981476, -0.007026249077171087, -3.8980677345534787e-05, -1.4781842764932662e-05, -0.010650577954947948, -9.179073458653875e-06, -6.770858453819528e-05, -6.079655122448457e-06, -0.0010099078062921762, -0.1486474722623825, -0.011710825376212597], "finish_reason": "stop"}, {"text": " df", "tokens": [" df"], "logprobs": [-0.011720840819180012], "finish_reason": "stop"}], "metrics": {"energy": 78.36657627677916, "energy_per_token": 1.0177477438542748, "time": 4.01161, "time_per_token": 0.05209883116883117}}
{"outputs": [{"text": " [sentence for sentence in re.split(r\"\\.(?=\\s)\", text) if sentence]", "tokens": [" [", "sentence", " for", " sentence", " in", " re", ".", "split", "(", "r", "\"", "\\", ".", "(", "?", "=\\", "s", ")\"", ",", " text", ")", " if", " sentence", "]", "\n"], "logprobs": [-3.0538816452026367, -1.030453085899353, -0.5156927108764648, -0.0021802245173603296, -0.0012562725460156798, -0.2164919227361679, -0.00018439977429807186, -0.10708138346672058, -0.3201233446598053, -0.19876587390899658, -0.6721397638320923, -0.30169782042503357, -0.09415949881076813, -3.336850166320801, -0.04501644894480705, -2.1614885330200195, -0.0646146759390831, -0.39351728558540344, -0.0005159238935448229, -0.024695612490177155, -0.2005004733800888, -0.03716219961643219, -0.2478758990764618, -0.6947868466377258, -0.07990474253892899], "finish_reason": "stop"}, {"text": " [s.strip() for s in sentences if s.strip()]", "tokens": [" [", "s", ".", "strip", "()", " for", " s", " in", " sentences", " if", " s", ".", "strip", "()", "]", "\n"], "logprobs": [-0.1708301156759262, -0.8741267919540405, -0.273036926984787, -0.11037475615739822, -0.017111873254179955, -0.018640577793121338, -0.00010966652916977182, -3.6000557884108275e-05, -0.0005480932886712253, -0.25047188997268677, -0.2596908211708069, -0.4068619906902313, -0.0030548356007784605, -0.002044612541794777, -0.212433859705925, -0.035269804298877716], "finish_reason": "stop"}, {"text": " CountVectorizer(analyzer=\"word\")", "tokens": [" Count", "Vector", "izer", "(", "analy", "zer", "=", "\"", "word", "\"", ")", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -1.0655977725982666, -1.1910223960876465, -0.0346544086933136, -0.493262380361557, -0.005521285813301802, -0.14749537408351898, -0.0017879704246297479, -0.28809866309165955, -0.02771882899105549], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16751833260059357, -6.05564855504781e-05, -4.23184028477408e-05, -0.001926591619849205, -0.00023624490131624043, -7.784063927829266e-05, -0.03274422138929367, -0.0012705596163868904, -5.960462772236497e-07, -0.001416633022017777, -0.07310684770345688], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03827664256095886, -0.002274071332067251, -0.019564863294363022, -0.01376704964786768, -0.07013684511184692, -0.00018082413589581847, -0.013408721424639225, -0.13627171516418457, -0.020992357283830643, -0.016209715977311134, -0.0046304380521178246, -0.22598308324813843, -0.02613671123981476, -0.007026249077171087, -3.8980677345534787e-05, -1.4781842764932662e-05, -0.010650577954947948, -9.179073458653875e-06, -6.770858453819528e-05, -6.079655122448457e-06, -0.0010099078062921762, -0.1486474722623825, -0.011710825376212597], "finish_reason": "stop"}, {"text": " df", "tokens": [" df"], "logprobs": [-0.011720840819180012], "finish_reason": "stop"}], "metrics": {"energy": 114.11226890754703, "energy_per_token": 1.2967303284948526, "time": 4.431742, "time_per_token": 0.05036070454545454}}
{"outputs": [{"text": " re.split('\\.', text)", "tokens": [" re", ".", "split", "('", "\\", ".", "'", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -1.4033715724945068, -0.3178728520870209, -0.08021791279315948, -0.521751880645752, -0.0005211663665249944, -0.052563853561878204, -0.08190013468265533, -0.10703328996896744], "finish_reason": "stop"}, {"text": " list(filter(lambda x: len(x) > 0, sentences))", "tokens": [" list", "(", "filter", "(", "lambda", " x", ":", " len", "(", "x", ")", " >", " ", "0", ",", " sentences", "))", "\n"], "logprobs": [-2.1585638523101807, -0.0052846260368824005, -0.7251476645469666, -0.001534238108433783, -0.43233609199523926, -0.6116184592247009, -0.005370237864553928, -0.581660270690918, -0.000105375460407231, -0.009000799618661404, -0.4803943634033203, -0.12118429690599442, -0.0013760393485426903, -0.045980896800756454, -0.004065345041453838, -0.0048406790010631084, -0.0010848119854927063, -0.047634709626436234], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=\"english\")", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "\"", "eng", "lish", "\"", ")", "\n"], "logprobs": [-0.0004077318590134382, -8.22540732769994e-06, -2.4437606043647975e-05, -0.9930575489997864, -1.8743505477905273, -5.769562994828448e-05, -0.00011467275908216834, -0.504368782043457, -0.048355989158153534, -0.009220045059919357, -6.437280717364047e-06, -5.972207145532593e-05, -0.1552119255065918, -0.015445027500391006], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16059574484825134, -5.566918844124302e-05, -4.935142715112306e-05, -0.0012465096078813076, -0.00020430385484360158, -6.782778655178845e-05, -0.039935678243637085, -0.0012321030953899026, -7.152555099310121e-07, -0.0016690860502421856, -0.12780345976352692], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.041124261915683746, -0.0015031717484816909, -0.0160312969237566, -0.013411779887974262, -0.0725608691573143, -0.00019858295854646713, -0.01096568163484335, -0.12710170447826385, -0.02176191471517086, -0.013578199781477451, -0.0037544730585068464, -0.2785536050796509, -0.026191988959908485, -0.005984957329928875, -3.135155202471651e-05, -1.5139465176616795e-05, -0.010463261976838112, -9.536697689327411e-06, -6.282132380874828e-05, -6.9141146923357155e-06, -0.0010830257087945938, -0.18131496012210846, -0.010843166150152683], "finish_reason": "stop"}, {"text": " df", "tokens": [" df", "\n"], "logprobs": [-0.011715184897184372, -0.8584194183349609], "finish_reason": "stop"}], "metrics": {"energy": 105.60509364700319, "energy_per_token": 1.3367733373038377, "time": 3.9257517, "time_per_token": 0.04969305949367089}}
{"outputs": [{"text": " re.split(r'[.?!]+', text)", "tokens": [" re", ".", "split", "(", "r", "'", "[", ".", "?", "!", "]+", "'", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -1.2205135822296143, -0.520754873752594, -0.13972388207912445, -1.7658270597457886, -0.09245985746383667, -1.73740553855896, -0.029587477445602417, -0.0001740304142003879, -0.015650659799575806, -0.05887472629547119, -0.13077567517757416], "finish_reason": "stop"}, {"text": " [sentence.strip() for sentence in sentences if sentence.strip()]", "tokens": [" [", "sentence", ".", "strip", "()", " for", " sentence", " in", " sentences", " if", " sentence", ".", "strip", "()", "]", "\n"], "logprobs": [-0.1708301156759262, -0.9143050909042358, -0.3255273699760437, -0.08968070894479752, -0.013650286942720413, -0.02439795434474945, -0.0002307625545654446, -0.00011336160969221964, -0.00036042393185198307, -0.44355931878089905, -0.2625086307525635, -0.4732871651649475, -0.0023055896162986755, -0.0011264891363680363, -0.14373375475406647, -0.030333450064063072], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=[\".\"])", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=[", "\"", ".", "\"", "])", "\n"], "logprobs": [-0.0004032037395518273, -8.4638240878121e-06, -2.52720492426306e-05, -0.9782846570014954, -1.6909493207931519, -7.879423355916515e-05, -0.00010442188795423135, -3.2113513946533203, -0.0765412226319313, -1.8076719045639038, -0.03730829060077667, -1.3776345252990723, -0.01978437602519989], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16921454668045044, -5.638440416078083e-05, -4.684815212385729e-05, -0.0016221948899328709, -0.00021371940965764225, -7.521823135903105e-05, -0.04531361535191536, -0.001134705264121294, -7.152555099310121e-07, -0.0016657537780702114, -0.08831246197223663], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.05256928130984306, -0.0020882722456008196, -0.021449262276291847, -0.016418004408478737, -0.06307480484247208, -0.00016151554882526398, -0.010400736704468727, -0.12300483882427216, -0.01410914771258831, -0.015865519642829895, -0.004352263640612364, -0.2418835610151291, -0.02767151966691017, -0.005188215058296919, -3.93382906622719e-05, -1.5020257706055418e-05, -0.010420556180179119, -8.583032467868179e-06, -6.258291978156194e-05, -8.34461570775602e-06, -0.0010202685371041298, -0.14341382682323456, -0.009956695139408112], "finish_reason": "stop"}, {"text": " df", "tokens": [" df", "\n"], "logprobs": [-0.013903080485761166, -0.8035694360733032], "finish_reason": "stop"}], "metrics": {"energy": 112.62990126037597, "energy_per_token": 1.3904926081527897, "time": 4.1093307, "time_per_token": 0.05073247777777778}}
{"outputs": [{"text": " re.split(r'[.!?]+', text)", "tokens": [" re", ".", "split", "(", "r", "'", "[", ".", "!", "?", "]+", "'", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -1.2205135822296143, -0.520754873752594, -0.13972388207912445, -1.725620150566101, -0.04497895389795303, -0.9313570857048035, -0.01810207962989807, -0.00016497205069754273, -0.015655940398573875, -0.05224812775850296, -0.10331527143716812], "finish_reason": "stop"}, {"text": " [s for s in sentences if len(s.strip()) > 0]", "tokens": [" [", "s", " for", " s", " in", " sentences", " if", " len", "(", "s", ".", "strip", "())", " >", " ", "0", "]", "\n"], "logprobs": [-0.1708301156759262, -0.8741267919540405, -1.5035552978515625, -0.000486970558995381, -4.076874756719917e-05, -0.001122321467846632, -0.0029673613607883453, -1.193711757659912, -0.00010311071673640981, -0.01557648740708828, -0.6998918056488037, -0.0748259499669075, -0.0523407869040966, -0.05093302205204964, -0.000750736624468118, -0.007150179706513882, -0.0026246407069265842, -0.045068297535181046], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -0.4238341450691223, -0.007598308380693197], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences).tocsr()", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", ".", "to", "cs", "r", "()", "\n"], "logprobs": [-0.16751833260059357, -6.05564855504781e-05, -4.23184028477408e-05, -0.001926591619849205, -0.00023624490131624043, -7.784063927829266e-05, -0.03274422138929367, -0.0012705596163868904, -5.960462772236497e-07, -0.001416633022017777, -2.7058067321777344, -0.14080430567264557, -1.1568331718444824, -0.005626318044960499, -0.008961339481174946, -0.07821794599294662], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03827664256095886, -0.002274071332067251, -0.019564863294363022, -0.01376704964786768, -0.07013684511184692, -0.00018082413589581847, -0.013408721424639225, -2.1234371662139893, -9.870042413240299e-05, -0.032997310161590576, -0.03027527779340744, -0.007106740493327379, -0.3981553912162781, -0.01815405860543251, -0.007227347232401371, -2.288792165927589e-05, -1.5616295058862306e-05, -0.012507452629506588, -1.3351351299206726e-05, -7.486063259420916e-05, -2.9802276912960224e-06, -0.0009569118265062571, -0.16424310207366943, -0.010648809373378754], "finish_reason": "stop"}, {"text": " df<|endoftext|>import os", "tokens": [" df", "<", "|", "end", "of", "text", "|>", "import", " os", "\n"], "logprobs": [-0.01234144251793623, -1.12785005569458, -2.861018856492592e-06, -1.5497195136049413e-06, -3.075552376685664e-05, -0.00018880968855228275, -0.04206344112753868, -1.120876669883728, -2.8019630908966064, -0.058355558663606644], "finish_reason": "stop"}], "metrics": {"energy": 119.67760921859742, "energy_per_token": 1.344692238411207, "time": 4.514805, "time_per_token": 0.05072814606741573}}
{"outputs": [{"text": " re.split(r'[\\.\\!\\?]', text)", "tokens": [" re", ".", "split", "(", "r", "'", "[\\", ".", "\\", "!", "\\", "?", "]", "'", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -1.2205135822296143, -1.5630216598510742, -0.1475309580564499, -1.5985432863235474, -2.186246871948242, -0.07653194665908813, -0.005371542181819677, -0.7734326720237732, -0.021124957129359245, -0.00017033556650858372, -0.022791460156440735, -0.04462548345327377, -0.10882030427455902], "finish_reason": "stop"}, {"text": " list(filter(lambda sentence: len(sentence.strip()) > 0, sentences))", "tokens": [" list", "(", "filter", "(", "lambda", " sentence", ":", " len", "(", "sentence", ".", "strip", "())", " >", " ", "0", ",", " sentences", "))", "\n"], "logprobs": [-2.1585638523101807, -0.0052846260368824005, -0.7251476645469666, -0.001534238108433783, -0.43233609199523926, -1.8755784034729004, -0.003958248998969793, -0.5738344788551331, -0.00012766500003635883, -0.0073216683231294155, -0.4652382433414459, -0.029067927971482277, -0.009134526364505291, -0.08685655146837234, -0.0009916870621964335, -0.009224534034729004, -0.0014843647368252277, -0.0034392275847494602, -0.0007487116381525993, -0.041777998208999634], "finish_reason": "stop"}, {"text": " CountVectorizer(analyzer='word')", "tokens": [" Count", "Vector", "izer", "(", "analy", "zer", "='", "word", "')", "\n"], "logprobs": [-0.0004077318590134382, -8.22540732769994e-06, -2.4437606043647975e-05, -0.9930575489997864, -0.960598886013031, -0.026268746703863144, -0.9376075863838196, -0.10914058238267899, -0.6552518606185913, -0.009938164614140987], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16059574484825134, -5.566918844124302e-05, -4.935142715112306e-05, -0.0012465096078813076, -0.00020430385484360158, -6.782778655178845e-05, -0.039935678243637085, -0.0012321030953899026, -7.152555099310121e-07, -0.0016690860502421856, -0.12780345976352692], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.041124261915683746, -0.0015031717484816909, -0.0160312969237566, -0.013411779887974262, -0.0725608691573143, -0.00019858295854646713, -0.01096568163484335, -0.12710170447826385, -0.02176191471517086, -0.013578199781477451, -0.0037544730585068464, -0.2785536050796509, -0.026191988959908485, -0.005984957329928875, -3.135155202471651e-05, -1.5139465176616795e-05, -0.010463261976838112, -9.536697689327411e-06, -6.282132380874828e-05, -6.9141146923357155e-06, -0.0010830257087945938, -0.18131496012210846, -0.010843166150152683], "finish_reason": "stop"}, {"text": " df<|endoftext|>#!/usr/bin/env python3", "tokens": [" df", "<", "|", "end", "of", "text", "|>", "#", "!", "/", "usr", "/", "bin", "/", "env", " python", "3", "\n"], "logprobs": [-0.011715184897184372, -1.0715351104736328, -2.0265558760002023e-06, -1.7881377516459906e-06, -2.3245540432981215e-05, -0.0002337421028641984, -0.04273403808474541, -1.3989368677139282, -1.1366214752197266, -0.040565576404333115, -0.07832818478345871, -0.0002686616498976946, -0.002794410800561309, -0.00022682955022901297, -0.04106396809220314, -0.004537524189800024, -0.8347522616386414, -0.015903769060969353], "finish_reason": "stop"}], "metrics": {"energy": 101.40886880683897, "energy_per_token": 1.0140886880683897, "time": 4.9428697, "time_per_token": 0.049428697}}
{"outputs": [{"text": " re.split('\\.\\s*', text)", "tokens": [" re", ".", "split", "('", "\\", ".", "\\", "s", "*", "'", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -1.4033715724945068, -0.3178728520870209, -0.08021791279315948, -2.2080788612365723, -0.0440908782184124, -0.8472971320152283, -0.018101027235388756, -0.0004151197790633887, -0.037399012595415115, -0.12529461085796356, -0.14213944971561432], "finish_reason": "stop"}, {"text": " [s.strip() for s in sentences if s.strip()]", "tokens": [" [", "s", ".", "strip", "()", " for", " s", " in", " sentences", " if", " s", ".", "strip", "()", "]", "\n"], "logprobs": [-0.1708301156759262, -0.8741267919540405, -0.273036926984787, -0.11037475615739822, -0.017111873254179955, -0.018640577793121338, -0.00010966652916977182, -3.6000557884108275e-05, -0.0005480932886712253, -0.25047188997268677, -0.2596908211708069, -0.4068619906902313, -0.0030548356007784605, -0.002044612541794777, -0.212433859705925, -0.035269804298877716], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -0.4238341450691223, -0.007598308380693197], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16751833260059357, -6.05564855504781e-05, -4.23184028477408e-05, -0.001926591619849205, -0.00023624490131624043, -7.784063927829266e-05, -0.03274422138929367, -0.0012705596163868904, -5.960462772236497e-07, -0.001416633022017777, -0.07310684770345688], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03827664256095886, -0.002274071332067251, -0.019564863294363022, -0.01376704964786768, -0.07013684511184692, -0.00018082413589581847, -0.013408721424639225, -0.13627171516418457, -0.020992357283830643, -0.016209715977311134, -0.0046304380521178246, -0.22598308324813843, -0.02613671123981476, -0.007026249077171087, -3.8980677345534787e-05, -1.4781842764932662e-05, -0.010650577954947948, -9.179073458653875e-06, -6.770858453819528e-05, -6.079655122448457e-06, -0.0010099078062921762, -0.1486474722623825, -0.011710825376212597], "finish_reason": "stop"}, {"text": " df", "tokens": [" df"], "logprobs": [-0.011720840819180012], "finish_reason": "stop"}], "metrics": {"energy": 79.51324198150635, "energy_per_token": 1.1359034568786621, "time": 3.71071, "time_per_token": 0.05301014285714286}}
{"outputs": [{"text": " re.split(\"\\.\", text)  # Split the text into sentences", "tokens": [" re", ".", "split", "(", "\"", "\\", ".", "\"", ",", " text", ")", "  ", "#", " Split", " the", " text", " into", " sentences", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -1.6646298170089722, -0.4133495092391968, -0.1065467894077301, -0.5060225129127502, -0.0007709868368692696, -0.03945963829755783, -0.04330144822597504, -2.741987943649292, -0.003163692308589816, -0.5977847576141357, -0.4798692464828491, -0.05228421837091446, -0.13218098878860474, -0.045204922556877136, -0.5614025592803955], "finish_reason": "stop"}, {"text": " [sentence for sentence in sentences if sentence]", "tokens": [" [", "sentence", " for", " sentence", " in", " sentences", " if", " sentence", "]", "\n"], "logprobs": [-0.1708301156759262, -0.9143050909042358, -1.3256704807281494, -0.00047052756417542696, -0.00010382589971413836, -0.000788139586802572, -0.006003798451274633, -0.3932245671749115, -0.8903968334197998, -0.11479271948337555], "finish_reason": "stop"}, {"text": " CountVectorizer(analyzer='word', tokenizer=None, ngram_range=(1, 1), preprocessor=None, stop_words=None,", "tokens": [" Count", "Vector", "izer", "(", "analy", "zer", "='", "word", "'", ",", " token", "izer", "=", "None", ",", " n", "gram", "_", "range", "=(", "1", ",", " ", "1", ")", ",", " pre", "processor", "=", "None", ",", " stop", "_", "words", "=", "None", ",", "\n"], "logprobs": [-0.000399033073335886, -9.298280929215252e-06, -2.3007127310847864e-05, -1.010318398475647, -1.0332813262939453, -0.02766978181898594, -0.8784961700439453, -0.13043296337127686, -0.9201393127441406, -0.0013617537915706635, -1.0472670793533325, -1.2307406663894653, -0.005883992183953524, -0.2657349109649658, -0.164541557431221, -1.5654155015945435, -0.13697341084480286, -0.00018988236843142658, -0.0006347072194330394, -0.007743342313915491, -0.08847516775131226, -0.0004567056894302368, -0.06258726119995117, -0.35668522119522095, -0.5616993308067322, -0.0010893370490521193, -3.0220260620117188, -0.12478040158748627, -0.004977928940206766, -0.011586751788854599, -0.09283767640590668, -0.7140461206436157, -1.2397689715726301e-05, -0.0031519278418272734, -0.07432939112186432, -0.011665934696793556, -0.41254866123199463, -0.7600399851799011], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.1275787204504013, -6.639736966462806e-05, -4.3748852476710454e-05, -0.0015438791597262025, -0.0002649671514518559, -7.545663538621739e-05, -0.03556574136018753, -0.001191144809126854, -5.960462772236497e-07, -0.0019357530400156975, -0.09100083261728287], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03895723447203636, -0.0017459639348089695, -0.01815335638821125, -0.014458413235843182, -0.10171449184417725, -0.00020621081057470292, -0.0147114722058177, -2.1245155334472656, -9.202533692587167e-05, -0.04164547845721245, -0.03478728234767914, -0.007610966917127371, -0.3770081102848053, -0.021528134122490883, -0.007942640222609043, -2.372236667724792e-05, -1.7762025890988298e-05, -0.015392908826470375, -1.0967194612021558e-05, -6.675497570540756e-05, -2.3841830625315197e-06, -0.0010353925172239542, -0.16608573496341705, -0.011722254566848278], "finish_reason": "stop"}, {"text": " df<|endoftext|>#!/usr/bin/env python3", "tokens": [" df", "<", "|", "end", "of", "text", "|>", "#", "!", "/", "usr", "/", "bin", "/", "env", " python", "3", "\n"], "logprobs": [-0.013053441420197487, -1.116438388824463, -2.3841830625315197e-06, -1.6689286894688848e-06, -1.9907753085135482e-05, -0.00023850933939684182, -0.047064751386642456, -1.3204479217529297, -1.1458773612976074, -0.0379786379635334, -0.07711946219205856, -0.0002648479712661356, -0.003157037775963545, -0.00029059001826681197, -0.03438849374651909, -0.003907308913767338, -0.8106284737586975, -0.016348110511898994], "finish_reason": "stop"}], "metrics": {"energy": 145.0263420066833, "energy_per_token": 1.2085528500556941, "time": 5.7612667, "time_per_token": 0.048010555833333336}}
{"outputs": [{"text": " re.split(r'[.]\\s', text)", "tokens": [" re", ".", "split", "(", "r", "'", "[", ".", "]\\", "s", "'", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -1.2205135822296143, -0.520754873752594, -0.13972388207912445, -2.212596893310547, -0.005025493446737528, -0.7757611870765686, -0.00031251792097464204, -0.03952541574835777, -0.08452043682336807, -0.13566279411315918], "finish_reason": "stop"}, {"text": " [sentence for sentence in sentences if sentence != \"\"]", "tokens": [" [", "sentence", " for", " sentence", " in", " sentences", " if", " sentence", " ", "!", "=", " \"", "\"", "]", "\n"], "logprobs": [-0.1708301156759262, -0.9143050909042358, -1.3256704807281494, -0.00047052756417542696, -0.00010382589971413836, -0.000788139586802572, -0.006003798451274633, -0.3932245671749115, -1.516472578048706, -8.583032467868179e-06, -2.729855441430118e-05, -0.28149858117103577, -0.045544520020484924, -0.00575468922033906, -0.028084121644496918], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.000399033073335886, -9.298280929215252e-06, -2.3007127310847864e-05, -0.4541584253311157, -0.007267467677593231], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.1275787204504013, -6.639736966462806e-05, -4.3748852476710454e-05, -0.0015438791597262025, -0.0002649671514518559, -7.545663538621739e-05, -0.03556574136018753, -0.001191144809126854, -5.960462772236497e-07, -0.0019357530400156975, -0.09100083261728287], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names(), index=range(1, 1 + len(sentences)))", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " index", "=", "range", "(", "1", ",", " ", "1", " +", " len", "(", "sent", "ences", ")))", "\n"], "logprobs": [-0.03895723447203636, -0.0017459639348089695, -0.01815335638821125, -0.014458413235843182, -0.10171449184417725, -0.00020621081057470292, -0.0147114722058177, -0.13782107830047607, -0.018917029723525047, -0.014543477445840836, -0.004349533934146166, -0.2757498323917389, -0.027523433789610863, -0.005765237845480442, -4.076874756719917e-05, -1.680836794548668e-05, -0.010805311612784863, -8.583032467868179e-06, -6.09140915912576e-05, -6.437280717364047e-06, -0.001212338567711413, -2.7297303676605225, -0.015918435528874397, -0.349734902381897, -0.18902181088924408, -1.0716493129730225, -0.0002711643755901605, -0.3458413779735565, -0.008820027112960815, -2.944793462753296, -0.44220614433288574, -0.3269284963607788, -0.07829037308692932, -0.00015555603022221476, -0.0786491185426712, -4.172316494077677e-06, -0.005991948768496513, -0.009421884082257748], "finish_reason": "stop"}, {"text": " df", "tokens": [" df", "\n"], "logprobs": [-0.012526288628578186, -0.8052845597267151], "finish_reason": "stop"}], "metrics": {"energy": 119.60535869789118, "energy_per_token": 1.3907599848591998, "time": 4.3239794, "time_per_token": 0.050278830232558136}}
{"outputs": [{"text": " text.split(\".\")", "tokens": [" text", ".", "split", "(", "\"", ".", "\"", ")", "\n"], "logprobs": [-2.9960718154907227, -0.008470677770674229, -0.09857099503278732, -0.595751941204071, -0.03654348477721214, -0.020107129588723183, -0.14649464190006256, -0.0077855708077549934, -0.0738520622253418], "finish_reason": "stop"}, {"text": " [s.strip() for s in sentences if s.strip() != \"\"]", "tokens": [" [", "s", ".", "strip", "()", " for", " s", " in", " sentences", " if", " s", ".", "strip", "()", " ", "!", "=", " \"", "\"", "]", "\n"], "logprobs": [-0.1708301156759262, -0.8741267919540405, -0.273036926984787, -0.11037475615739822, -0.017111873254179955, -0.018640577793121338, -0.00010966652916977182, -3.6000557884108275e-05, -0.0005480932886712253, -0.25047188997268677, -0.2596908211708069, -0.4068619906902313, -0.0030548356007784605, -0.002044612541794777, -1.736830711364746, -1.9192511899746023e-05, -2.0503786799963564e-05, -0.34469306468963623, -0.0033593906555324793, -0.0034448110964149237, -0.023160303011536598], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -0.4238341450691223, -0.007598308380693197], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16751833260059357, -6.05564855504781e-05, -4.23184028477408e-05, -0.001926591619849205, -0.00023624490131624043, -7.784063927829266e-05, -0.03274422138929367, -0.0012705596163868904, -5.960462772236497e-07, -0.001416633022017777, -0.07310684770345688], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03827664256095886, -0.002274071332067251, -0.019564863294363022, -0.01376704964786768, -0.07013684511184692, -0.00018082413589581847, -0.013408721424639225, -0.13627171516418457, -0.020992357283830643, -0.016209715977311134, -0.0046304380521178246, -0.22598308324813843, -0.02613671123981476, -0.007026249077171087, -3.8980677345534787e-05, -1.4781842764932662e-05, -0.010650577954947948, -9.179073458653875e-06, -6.770858453819528e-05, -6.079655122448457e-06, -0.0010099078062921762, -0.1486474722623825, -0.011710825376212597], "finish_reason": "stop"}, {"text": " df<|endoftext|>#!/usr/bin/env python", "tokens": [" df", "<", "|", "end", "of", "text", "|>", "#", "!", "/", "usr", "/", "bin", "/", "env", " python", "\n"], "logprobs": [-0.011720840819180012, -1.2492297887802124, -2.50339189733495e-06, -1.5497195136049413e-06, -2.4437606043647975e-05, -0.0002195594133809209, -0.04185207933187485, -1.3674876689910889, -1.214948058128357, -0.03658244386315346, -0.06681429594755173, -0.0002037079248111695, -0.002619171282276511, -0.00034278715611435473, -0.0402442067861557, -0.0036728798877447844, -0.6143624186515808], "finish_reason": "stop"}], "metrics": {"energy": 99.09807584857937, "energy_per_token": 1.1523032075416206, "time": 4.3217607, "time_per_token": 0.050253031395348834}}
{"outputs": [{"text": " re.split('\\.', text)", "tokens": [" re", ".", "split", "('", "\\", ".", "'", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -1.4033715724945068, -0.3178728520870209, -0.08021791279315948, -0.521751880645752, -0.0005211663665249944, -0.052563853561878204, -0.08190013468265533, -0.10703328996896744], "finish_reason": "stop"}, {"text": " [x.strip() for x in sentences if x.strip()]", "tokens": [" [", "x", ".", "strip", "()", " for", " x", " in", " sentences", " if", " x", ".", "strip", "()", "]", "\n"], "logprobs": [-0.1708301156759262, -3.139835834503174, -0.29689928889274597, -0.09464902430772781, -0.013690267689526081, -0.021493833512067795, -0.00011383838864276186, -9.738924563862383e-05, -0.0005172345554456115, -0.24354791641235352, -0.3961101174354553, -0.31241855025291443, -0.0026247594505548477, -0.0016279076226055622, -0.2749066650867462, -0.03085257299244404], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -0.4238341450691223, -0.007598308380693197], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16751833260059357, -6.05564855504781e-05, -4.23184028477408e-05, -0.001926591619849205, -0.00023624490131624043, -7.784063927829266e-05, -0.03274422138929367, -0.0012705596163868904, -5.960462772236497e-07, -0.001416633022017777, -0.07310684770345688], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03827664256095886, -0.002274071332067251, -0.019564863294363022, -0.01376704964786768, -0.07013684511184692, -0.00018082413589581847, -0.013408721424639225, -0.13627171516418457, -0.020992357283830643, -0.016209715977311134, -0.0046304380521178246, -0.22598308324813843, -0.02613671123981476, -0.007026249077171087, -3.8980677345534787e-05, -1.4781842764932662e-05, -0.010650577954947948, -9.179073458653875e-06, -6.770858453819528e-05, -6.079655122448457e-06, -0.0010099078062921762, -0.1486474722623825, -0.011710825376212597], "finish_reason": "stop"}, {"text": " df<|endoftext|>import re", "tokens": [" df", "<", "|", "end", "of", "text", "|>", "import", " re", "\n"], "logprobs": [-0.011720840819180012, -1.2492297887802124, -2.50339189733495e-06, -1.5497195136049413e-06, -2.4437606043647975e-05, -0.0002195594133809209, -0.04185207933187485, -0.9950740933418274, -2.457263708114624, -0.01441129483282566], "finish_reason": "stop"}], "metrics": {"energy": 77.41997804450989, "energy_per_token": 1.018683921638288, "time": 3.9139, "time_per_token": 0.051498684210526315}}
{"outputs": [{"text": " re.split(r'[\\.]', text)", "tokens": [" re", ".", "split", "(", "r", "'", "[\\", ".", "]", "'", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -1.2205135822296143, -1.5630216598510742, -0.1475309580564499, -1.3560391664505005, -0.026146117597818375, -0.00023278864682652056, -0.028944021090865135, -0.07144682854413986, -0.10727757960557938], "finish_reason": "stop"}, {"text": " [s.strip() for s in sentences]", "tokens": [" [", "s", ".", "strip", "()", " for", " s", " in", " sentences", "]", "\n"], "logprobs": [-0.1708301156759262, -0.8741267919540405, -0.273036926984787, -0.11037475615739822, -0.017111873254179955, -0.018640577793121338, -0.00010966652916977182, -3.6000557884108275e-05, -0.0005480932886712253, -1.5229861736297607, -0.02392854355275631], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -0.4238341450691223, -0.007598308380693197], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16751833260059357, -6.05564855504781e-05, -4.23184028477408e-05, -0.001926591619849205, -0.00023624490131624043, -7.784063927829266e-05, -0.03274422138929367, -0.0012705596163868904, -5.960462772236497e-07, -0.001416633022017777, -0.07310684770345688], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), index=sentences, columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " index", "=", "sent", "ences", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03827664256095886, -0.002274071332067251, -0.019564863294363022, -0.01376704964786768, -0.07013684511184692, -0.00018082413589581847, -0.013408721424639225, -0.13627171516418457, -0.020992357283830643, -0.016209715977311134, -0.0046304380521178246, -1.8675198554992676, -0.05961298942565918, -0.20596188306808472, -0.0013260389678180218, -0.059587832540273666, -0.010569663718342781, -0.02533390372991562, -0.005619798321276903, -4.076874756719917e-05, -4.51792984677013e-05, -0.006189819425344467, -5.245195097813848e-06, -9.30981186684221e-05, -2.622600959512056e-06, -0.0011469698511064053, -0.22270752489566803, -0.01310132909566164], "finish_reason": "stop"}, {"text": " df", "tokens": [" df", "\n"], "logprobs": [-0.011570490896701813, -0.7844842672348022], "finish_reason": "stop"}], "metrics": {"energy": 78.7571588420868, "energy_per_token": 1.1092557583392506, "time": 3.7081594, "time_per_token": 0.05222759718309859}}
{"outputs": [{"text": " re.split(r\"\\.\\s*\", text)", "tokens": [" re", ".", "split", "(", "r", "\"", "\\", ".", "\\", "s", "*", "\"", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -0.5187638401985168, -0.1950531154870987, -0.06564738601446152, -1.296894907951355, -0.01728224940598011, -0.45532089471817017, -0.010129119269549847, -0.0003499372396618128, -0.015518623404204845, -0.10391563177108765, -0.1446336805820465], "finish_reason": "stop"}, {"text": " [s.lower() for s in sentences if s]", "tokens": [" [", "s", ".", "lower", "()", " for", " s", " in", " sentences", " if", " s", "]", "\n"], "logprobs": [-0.1708301156759262, -0.8741267919540405, -0.273036926984787, -2.9834253787994385, -0.00043418517452664673, -0.32733896374702454, -0.00022516099852509797, -5.185469490243122e-05, -0.0018785225693136454, -0.3785038888454437, -0.33902233839035034, -1.8709502220153809, -0.09918791800737381], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -0.4238341450691223, -0.007598308380693197], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16751833260059357, -6.05564855504781e-05, -4.23184028477408e-05, -0.001926591619849205, -0.00023624490131624043, -7.784063927829266e-05, -0.03274422138929367, -0.0012705596163868904, -5.960462772236497e-07, -0.001416633022017777, -0.07310684770345688], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03827664256095886, -0.002274071332067251, -0.019564863294363022, -0.01376704964786768, -0.07013684511184692, -0.00018082413589581847, -0.013408721424639225, -0.13627171516418457, -0.020992357283830643, -0.016209715977311134, -0.0046304380521178246, -0.22598308324813843, -0.02613671123981476, -0.007026249077171087, -3.8980677345534787e-05, -1.4781842764932662e-05, -0.010650577954947948, -9.179073458653875e-06, -6.770858453819528e-05, -6.079655122448457e-06, -0.0010099078062921762, -0.1486474722623825, -0.011710825376212597], "finish_reason": "stop"}, {"text": " df", "tokens": [" df"], "logprobs": [-0.011720840819180012], "finish_reason": "stop"}], "metrics": {"energy": 70.35282557487487, "energy_per_token": 1.0196061677518098, "time": 3.7108536, "time_per_token": 0.05378048695652174}}
{"outputs": [{"text": " re.split(r\"\\.\", text)", "tokens": [" re", ".", "split", "(", "r", "\"", "\\", ".", "\"", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -0.5187638401985168, -0.1950531154870987, -0.06564738601446152, -0.8228386640548706, -0.0003868784988299012, -0.02319338358938694, -0.06789029389619827, -0.11168789863586426], "finish_reason": "stop"}, {"text": " [sentence for sentence in sentences if sentence.strip()]", "tokens": [" [", "sentence", " for", " sentence", " in", " sentences", " if", " sentence", ".", "strip", "()", "]", "\n"], "logprobs": [-0.1708301156759262, -0.9143050909042358, -1.3256704807281494, -0.00047052756417542696, -0.00010382589971413836, -0.000788139586802572, -0.006003798451274633, -0.3932245671749115, -1.0516040325164795, -0.006205694749951363, -0.0068799271248281, -0.1884492188692093, -0.06788171827793121], "finish_reason": "stop"}, {"text": " CountVectorizer(analyzer='word')", "tokens": [" Count", "Vector", "izer", "(", "analy", "zer", "='", "word", "')", "\n"], "logprobs": [-0.000399033073335886, -9.298280929215252e-06, -2.3007127310847864e-05, -1.010318398475647, -1.0332813262939453, -0.02766978181898594, -0.8784961700439453, -0.13043296337127686, -0.5531978607177734, -0.009336145594716072], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.1275787204504013, -6.639736966462806e-05, -4.3748852476710454e-05, -0.0015438791597262025, -0.0002649671514518559, -7.545663538621739e-05, -0.03556574136018753, -0.001191144809126854, -5.960462772236497e-07, -0.0019357530400156975, -0.09100083261728287], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03895723447203636, -0.0017459639348089695, -0.01815335638821125, -0.014458413235843182, -0.10171449184417725, -0.00020621081057470292, -0.0147114722058177, -0.13782107830047607, -0.018917029723525047, -0.014543477445840836, -0.004349533934146166, -0.2757498323917389, -0.027523433789610863, -0.005765237845480442, -4.076874756719917e-05, -1.680836794548668e-05, -0.010805311612784863, -8.583032467868179e-06, -6.09140915912576e-05, -6.437280717364047e-06, -0.001212338567711413, -0.17135211825370789, -0.010013583116233349], "finish_reason": "stop"}, {"text": " df", "tokens": [" df", "\n"], "logprobs": [-0.012526288628578186, -0.8052845597267151], "finish_reason": "stop"}], "metrics": {"energy": 100.67389548301698, "energy_per_token": 1.3982485483752358, "time": 3.7117033, "time_per_token": 0.05155143472222222}}
{"outputs": [{"text": " re.split('\\.\\s', text)  # split text into sentences", "tokens": [" re", ".", "split", "('", "\\", ".", "\\", "s", "'", ",", " text", ")", "  ", "#", " split", " text", " into", " sentences", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -1.4033715724945068, -0.3178728520870209, -0.08021791279315948, -2.2080788612365723, -0.0440908782184124, -1.5039725303649902, -0.0006061147432774305, -0.07078500092029572, -0.08724227547645569, -2.5901050567626953, -0.0023888403084129095, -1.669327735900879, -0.9748822450637817, -0.4298054277896881, -0.04781541973352432, -0.3666161000728607], "finish_reason": "stop"}, {"text": " [x.strip() for x in sentences]", "tokens": [" [", "x", ".", "strip", "()", " for", " x", " in", " sentences", "]", "\n"], "logprobs": [-0.1708301156759262, -3.139835834503174, -0.29689928889274597, -0.09464902430772781, -0.013690267689526081, -0.021493833512067795, -0.00011383838864276186, -9.738924563862383e-05, -0.0005172345554456115, -1.5489792823791504, -0.02508956380188465], "finish_reason": "stop"}, {"text": " CountVectorizer(", "tokens": [" Count", "Vector", "izer", "(", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -1.0655977725982666, -2.445739269256592], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16751833260059357, -6.05564855504781e-05, -4.23184028477408e-05, -0.001926591619849205, -0.00023624490131624043, -7.784063927829266e-05, -0.03274422138929367, -0.0012705596163868904, -5.960462772236497e-07, -0.001416633022017777, -0.07310684770345688], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(),", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", "\n"], "logprobs": [-0.03827664256095886, -0.002274071332067251, -0.019564863294363022, -0.01376704964786768, -0.07013684511184692, -0.00018082413589581847, -0.013408721424639225, -2.1234371662139893, -9.870042413240299e-05, -0.032997310161590576, -0.03027527779340744, -0.007106740493327379, -2.8970606327056885], "finish_reason": "stop"}, {"text": " df", "tokens": [" df"], "logprobs": [-0.01234144251793623], "finish_reason": "stop"}], "metrics": {"energy": 90.0712862014771, "energy_per_token": 1.5011881033579515, "time": 3.3087597, "time_per_token": 0.055145994999999996}}
{"outputs": [{"text": " re.split(r\"\\.\\s*\", text)", "tokens": [" re", ".", "split", "(", "r", "\"", "\\", ".", "\\", "s", "*", "\"", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -0.5187638401985168, -0.1950531154870987, -0.06564738601446152, -1.296894907951355, -0.01728224940598011, -0.45532089471817017, -0.010129119269549847, -0.0003499372396618128, -0.015518623404204845, -0.10391563177108765, -0.1446336805820465], "finish_reason": "stop"}, {"text": " [s.strip() for s in sentences]", "tokens": [" [", "s", ".", "strip", "()", " for", " s", " in", " sentences", "]", "\n"], "logprobs": [-0.1708301156759262, -0.8741267919540405, -0.273036926984787, -0.11037475615739822, -0.017111873254179955, -0.018640577793121338, -0.00010966652916977182, -3.6000557884108275e-05, -0.0005480932886712253, -1.5229861736297607, -0.02392854355275631], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -0.4238341450691223, -0.007598308380693197], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16751833260059357, -6.05564855504781e-05, -4.23184028477408e-05, -0.001926591619849205, -0.00023624490131624043, -7.784063927829266e-05, -0.03274422138929367, -0.0012705596163868904, -5.960462772236497e-07, -0.001416633022017777, -0.07310684770345688], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03827664256095886, -0.002274071332067251, -0.019564863294363022, -0.01376704964786768, -0.07013684511184692, -0.00018082413589581847, -0.013408721424639225, -2.1234371662139893, -9.870042413240299e-05, -0.032997310161590576, -0.03027527779340744, -0.007106740493327379, -0.3981553912162781, -0.01815405860543251, -0.007227347232401371, -2.288792165927589e-05, -1.5616295058862306e-05, -0.012507452629506588, -1.3351351299206726e-05, -7.486063259420916e-05, -2.9802276912960224e-06, -0.0009569118265062571, -0.16424310207366943, -0.010648809373378754], "finish_reason": "stop"}, {"text": " df<|endoftext|>import regex as re", "tokens": [" df", "<", "|", "end", "of", "text", "|>", "import", " regex", " as", " re", "\n"], "logprobs": [-0.01234144251793623, -1.12785005569458, -2.861018856492592e-06, -1.5497195136049413e-06, -3.075552376685664e-05, -0.00018880968855228275, -0.04206344112753868, -1.120876669883728, -2.68705677986145, -0.030402952805161476, -0.010440965183079243, -0.0027416283264756203], "finish_reason": "stop"}], "metrics": {"energy": 104.87881995773317, "energy_per_token": 1.3275799994649768, "time": 3.9103842, "time_per_token": 0.04949853417721519}}
{"outputs": [{"text": " re.split(\"[.!?]\", text)", "tokens": [" re", ".", "split", "(", "\"", "[", ".", "!", "?", "]\"", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -1.6646298170089722, -1.7218250036239624, -0.0982700064778328, -1.6069456338882446, -0.03447717800736427, -0.6697584390640259, -0.0004349001101218164, -0.017131326720118523, -0.0352574922144413, -0.11179929971694946], "finish_reason": "stop"}, {"text": " [sentence.strip() for sentence in sentences]", "tokens": [" [", "sentence", ".", "strip", "()", " for", " sentence", " in", " sentences", "]", "\n"], "logprobs": [-0.1708301156759262, -0.9143050909042358, -0.3255273699760437, -0.08968070894479752, -0.013650286942720413, -0.02439795434474945, -0.0002307625545654446, -0.00011336160969221964, -0.00036042393185198307, -1.0475326776504517, -0.015031874179840088], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0004032037395518273, -8.4638240878121e-06, -2.52720492426306e-05, -0.472856342792511, -0.008020929992198944], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16921454668045044, -5.638440416078083e-05, -4.684815212385729e-05, -0.0016221948899328709, -0.00021371940965764225, -7.521823135903105e-05, -0.04531361535191536, -0.001134705264121294, -7.152555099310121e-07, -0.0016657537780702114, -0.08831246197223663], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.05256928130984306, -0.0020882722456008196, -0.021449262276291847, -0.016418004408478737, -0.06307480484247208, -0.00016151554882526398, -0.010400736704468727, -0.12300483882427216, -0.01410914771258831, -0.015865519642829895, -0.004352263640612364, -0.2418835610151291, -0.02767151966691017, -0.005188215058296919, -3.93382906622719e-05, -1.5020257706055418e-05, -0.010420556180179119, -8.583032467868179e-06, -6.258291978156194e-05, -8.34461570775602e-06, -0.0010202685371041298, -0.14341382682323456, -0.009956695139408112], "finish_reason": "stop"}, {"text": " df<|endoftext|>def task_func(text, k=2):", "tokens": [" df", "<", "|", "end", "of", "text", "|>", "def", " task", "_", "func", "(", "text", ",", " k", "=", "2", "):", "\n"], "logprobs": [-0.013903080485761166, -1.1408230066299438, -2.9802276912960224e-06, -1.5497195136049413e-06, -2.4676019165781327e-05, -0.00018952481332235038, -0.04635836184024811, -2.948573589324951, -0.7766087055206299, -0.027861321344971657, -0.04931313917040825, -0.14964421093463898, -1.3495012521743774, -2.1942062377929688, -4.194721221923828, -1.8812053203582764, -1.2490456104278564, -0.23212778568267822, -0.002406560117378831], "finish_reason": "stop"}], "metrics": {"energy": 79.35464055633544, "energy_per_token": 0.9560800067028367, "time": 4.1207395, "time_per_token": 0.04964746385542169}}
{"outputs": [{"text": " re.split(\"\\. \", text)", "tokens": [" re", ".", "split", "(", "\"", "\\", ".", " \"", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -1.6646298170089722, -0.4133495092391968, -0.1065467894077301, -1.7477788925170898, -0.0006996329175308347, -0.029551714658737183, -0.05882785841822624, -0.12706568837165833], "finish_reason": "stop"}, {"text": " [s.strip() for s in sentences if s]", "tokens": [" [", "s", ".", "strip", "()", " for", " s", " in", " sentences", " if", " s", "]", "\n"], "logprobs": [-0.1708301156759262, -0.8741267919540405, -0.273036926984787, -0.11037475615739822, -0.017111873254179955, -0.018640577793121338, -0.00010966652916977182, -3.6000557884108275e-05, -0.0005480932886712253, -0.25047188997268677, -0.2596908211708069, -1.6907422542572021, -0.10350049287080765], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -0.4238341450691223, -0.007598308380693197], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16751833260059357, -6.05564855504781e-05, -4.23184028477408e-05, -0.001926591619849205, -0.00023624490131624043, -7.784063927829266e-05, -0.03274422138929367, -0.0012705596163868904, -5.960462772236497e-07, -0.001416633022017777, -0.07310684770345688], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), index=sentences, columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " index", "=", "sent", "ences", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03827664256095886, -0.002274071332067251, -0.019564863294363022, -0.01376704964786768, -0.07013684511184692, -0.00018082413589581847, -0.013408721424639225, -0.13627171516418457, -0.020992357283830643, -0.016209715977311134, -0.0046304380521178246, -1.8675198554992676, -0.05961298942565918, -0.20596188306808472, -0.0013260389678180218, -0.059587832540273666, -0.010569663718342781, -0.02533390372991562, -0.005619798321276903, -4.076874756719917e-05, -4.51792984677013e-05, -0.006189819425344467, -5.245195097813848e-06, -9.30981186684221e-05, -2.622600959512056e-06, -0.0011469698511064053, -0.22270752489566803, -0.01310132909566164], "finish_reason": "stop"}, {"text": " df<|endoftext|>import pandas as pd", "tokens": [" df", "<", "|", "end", "of", "text", "|>", "import", " pandas", " as", " pd", "\n"], "logprobs": [-0.011570490896701813, -1.1942895650863647, -2.145764938177308e-06, -1.6689286894688848e-06, -2.2172682292875834e-05, -0.00024136967840604484, -0.047977689653635025, -1.0212560892105103, -1.9148964881896973, -0.00918531883507967, -0.001582085620611906, -0.0027941730804741383], "finish_reason": "stop"}], "metrics": {"energy": 88.8093487548828, "energy_per_token": 1.0964117130232445, "time": 4.2222404, "time_per_token": 0.05212642469135802}}
{"outputs": [{"text": " re.split(r\"\\.\\s*\", text)", "tokens": [" re", ".", "split", "(", "r", "\"", "\\", ".", "\\", "s", "*", "\"", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -0.5187638401985168, -0.1950531154870987, -0.06564738601446152, -1.296894907951355, -0.01728224940598011, -0.45532089471817017, -0.010129119269549847, -0.0003499372396618128, -0.015518623404204845, -0.10391563177108765, -0.1446336805820465], "finish_reason": "stop"}, {"text": " [sent.strip() for sent in sentences]", "tokens": [" [", "sent", ".", "strip", "()", " for", " sent", " in", " sentences", "]", "\n"], "logprobs": [-0.1708301156759262, -3.146507740020752, -0.9396789073944092, -0.16206593811511993, -0.015269643627107143, -0.02509828470647335, -0.0014872215688228607, -0.00011824862303910777, -0.0004472924047149718, -1.4627364873886108, -0.03507265821099281], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -0.4238341450691223, -0.007598308380693197], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform(sentences).toarray(),", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", ".", "to", "array", "()", ",", "\n"], "logprobs": [-1.9051625728607178, -0.0008831891464069486, -0.016007130965590477, -0.0415533110499382, -0.0827103853225708, -1.07287787614041e-05, -5.94836674281396e-05, -0.0054380581714212894, -0.00022289653134066612, -6.913899414939806e-05, -0.12960854172706604, -0.0033246977254748344, -5.960462772236497e-07, -0.06267751008272171, -0.016150010749697685, -0.07248470187187195, -0.01831875555217266, -0.3051387071609497, -0.016884975135326385, -1.0616916418075562], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), index=sentences, columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " index", "=", "sent", "ences", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.053216371685266495, -0.0017819016939029098, -0.016764473170042038, -0.01210580300539732, -0.06857752054929733, -0.00016723664884921163, -0.01276171114295721, -0.1384403109550476, -0.018320979550480843, -0.014636406674981117, -0.004090039525181055, -1.7231436967849731, -0.06790733337402344, -0.19669575989246368, -0.0013897294411435723, -0.046734996140003204, -0.009840548038482666, -0.022437050938606262, -0.006663957145065069, -3.886147169396281e-05, -5.030505417380482e-05, -0.004894656129181385, -5.125986263010418e-06, -8.582700684200972e-05, -4.291525328881107e-06, -0.0011861439561471343, -0.15363164246082306, -0.014343963004648685], "finish_reason": "stop"}, {"text": " df<|endoftext|>from functools import wraps", "tokens": [" df", "<", "|", "end", "of", "text", "|>", "from", " fun", "ct", "ools", " import", " wraps", "\n"], "logprobs": [-0.011474094353616238, -1.1782763004302979, -2.3841830625315197e-06, -1.6689286894688848e-06, -2.4199192921514623e-05, -0.00021586472576018423, -0.03908460959792137, -1.3467895984649658, -3.5002918243408203, -0.03335652872920036, -0.0014910305617377162, -0.00017510310863144696, -1.543033242225647, -0.013347556814551353], "finish_reason": "stop"}], "metrics": {"energy": 122.73407992362978, "energy_per_token": 1.3056817013152104, "time": 4.6330194, "time_per_token": 0.04928744042553192}}
{"outputs": [{"text": " re.split(r\"\\.+\", text)  # Split text into sentences", "tokens": [" re", ".", "split", "(", "r", "\"", "\\", ".", "+", "\"", ",", " text", ")", "  ", "#", " Split", " text", " into", " sentences", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -0.5187638401985168, -0.1950531154870987, -0.06564738601446152, -2.8505468368530273, -0.07872481644153595, -0.00039760314393788576, -0.02081887796521187, -0.04480593651533127, -2.6788346767425537, -0.0024732735473662615, -0.48955237865448, -1.3220460414886475, -0.1613806188106537, -0.039112236350774765, -0.5626317858695984], "finish_reason": "stop"}, {"text": " [s.strip() for s in sentences if len(s.strip()) > 0]", "tokens": [" [", "s", ".", "strip", "()", " for", " s", " in", " sentences", " if", " len", "(", "s", ".", "strip", "())", " >", " ", "0", "]", "\n"], "logprobs": [-0.1708301156759262, -0.8741267919540405, -0.273036926984787, -0.11037475615739822, -0.017111873254179955, -0.018640577793121338, -0.00010966652916977182, -3.6000557884108275e-05, -0.0005480932886712253, -0.25047188997268677, -1.5174059867858887, -4.5060096454108134e-05, -0.0032895284239202738, -0.46204036474227905, -0.028811875730752945, -0.019161244854331017, -0.05078120157122612, -0.000979539705440402, -0.01080201007425785, -0.0031424211338162422, -0.032681919634342194], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -0.4238341450691223, -0.007598308380693197], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16751833260059357, -6.05564855504781e-05, -4.23184028477408e-05, -0.001926591619849205, -0.00023624490131624043, -7.784063927829266e-05, -0.03274422138929367, -0.0012705596163868904, -5.960462772236497e-07, -0.001416633022017777, -0.07310684770345688], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03827664256095886, -0.002274071332067251, -0.019564863294363022, -0.01376704964786768, -0.07013684511184692, -0.00018082413589581847, -0.013408721424639225, -0.13627171516418457, -0.020992357283830643, -0.016209715977311134, -0.0046304380521178246, -0.22598308324813843, -0.02613671123981476, -0.007026249077171087, -3.8980677345534787e-05, -1.4781842764932662e-05, -0.010650577954947948, -9.179073458653875e-06, -6.770858453819528e-05, -6.079655122448457e-06, -0.0010099078062921762, -0.1486474722623825, -0.011710825376212597], "finish_reason": "stop"}, {"text": " df<|endoftext|>from django.urls import path", "tokens": [" df", "<", "|", "end", "of", "text", "|>", "from", " django", ".", "urls", " import", " path", "\n"], "logprobs": [-0.011720840819180012, -1.2492297887802124, -2.50339189733495e-06, -1.5497195136049413e-06, -2.4437606043647975e-05, -0.0002195594133809209, -0.04185207933187485, -1.3067615032196045, -4.417130470275879, -0.10676676779985428, -2.176936149597168, -0.0024926564656198025, -0.1074942871928215, -0.046689946204423904], "finish_reason": "stop"}], "metrics": {"energy": 127.29811771774294, "energy_per_token": 1.3542352948696057, "time": 4.641111, "time_per_token": 0.04937352127659575}}
{"outputs": [{"text": " re.split(r\"\\.\\s+\", text)", "tokens": [" re", ".", "split", "(", "r", "\"", "\\", ".", "\\", "s", "+", "\"", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -0.5187638401985168, -0.1950531154870987, -0.06564738601446152, -1.296894907951355, -0.01728224940598011, -2.442984104156494, -0.01784859038889408, -0.000276765669696033, -0.01667138934135437, -0.11461978405714035, -0.13396359980106354], "finish_reason": "stop"}, {"text": " list(map(lambda s: s.strip(), sentences))", "tokens": [" list", "(", "map", "(", "lambda", " s", ":", " s", ".", "strip", "()", ",", " sentences", "))", "\n"], "logprobs": [-2.1585638523101807, -0.0052846260368824005, -0.7414440512657166, -0.0010372978867962956, -0.12703493237495422, -1.126157522201538, -0.00298542738892138, -0.09226182103157043, -0.046534862369298935, -0.11923865973949432, -0.014286498539149761, -0.031893473118543625, -0.016455646604299545, -0.002514536026865244, -0.04451010003685951], "finish_reason": "stop"}, {"text": " CountVectorizer(vocabulary={\"contains\": 0, \"is\": 1, \"sample\": 2, \"sentence\": 3, \"this\": 4, \"words\": 5})", "tokens": [" Count", "Vector", "izer", "(", "voc", "abulary", "=", "{\"", "contains", "\":", " ", "0", ",", " \"", "is", "\":", " ", "1", ",", " \"", "sample", "\":", " ", "2", ",", " \"", "sentence", "\":", " ", "3", ",", " \"", "this", "\":", " ", "4", ",", " \"", "words", "\":", " ", "5", "})", "\n"], "logprobs": [-0.0004077318590134382, -8.22540732769994e-06, -2.4437606043647975e-05, -0.9930575489997864, -3.000882148742676, -0.02790757827460766, -0.9289918541908264, -0.4570062756538391, -0.8718833923339844, -0.036712877452373505, -0.42450496554374695, -1.019948959350586, -0.040864527225494385, -0.025339948013424873, -0.052721962332725525, -0.002752922009676695, -0.007279420271515846, -0.07261962443590164, -0.01160690188407898, -0.00901450403034687, -0.01629873551428318, -0.0014356792671605945, -0.002245049923658371, -0.7379171848297119, -0.007124968804419041, -0.03155047819018364, -0.0012025751639157534, -0.000416907190810889, -0.002529875375330448, -0.025644414126873016, -0.006359932944178581, -0.01936190389096737, -0.001567802974022925, -0.0004563482361845672, -0.0030166853684931993, -0.008086678571999073, -0.002031288342550397, -0.015328577719628811, -0.0009831124916672707, -0.0005984899471513927, -0.004126011859625578, -0.011495896615087986, -0.0630016028881073, -0.007320011965930462], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16059574484825134, -5.566918844124302e-05, -4.935142715112306e-05, -0.0012465096078813076, -0.00020430385484360158, -6.782778655178845e-05, -0.039935678243637085, -0.0012321030953899026, -7.152555099310121e-07, -0.0016690860502421856, -0.12780345976352692], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), index=sentences, columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " index", "=", "sent", "ences", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.041124261915683746, -0.0015031717484816909, -0.0160312969237566, -0.013411779887974262, -0.0725608691573143, -0.00019858295854646713, -0.01096568163484335, -2.1932122707366943, -0.00011276562872808427, -0.04545419290661812, -0.03166690096259117, -0.007648232858628035, -1.3574671745300293, -0.0491110235452652, -0.3994572162628174, -0.0021157516166567802, -0.052582740783691406, -0.012895642779767513, -0.020902352407574654, -0.006807350553572178, -4.029192859889008e-05, -4.649054244509898e-05, -0.006163280922919512, -5.483612312673358e-06, -9.059495641849935e-05, -3.4570634852570947e-06, -0.0010825494537129998, -0.1778336465358734, -0.012645655311644077], "finish_reason": "stop"}, {"text": " df", "tokens": [" df", "\n"], "logprobs": [-0.011572140268981457, -0.8360328078269958], "finish_reason": "stop"}], "metrics": {"energy": 121.07683501243591, "energy_per_token": 1.0348447436960333, "time": 5.688516, "time_per_token": 0.04861979487179487}}
{"outputs": [{"text": " re.split(\"\\.\", text)", "tokens": [" re", ".", "split", "(", "\"", "\\", ".", "\"", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -1.6646298170089722, -0.4133495092391968, -0.1065467894077301, -0.5060225129127502, -0.0007709868368692696, -0.03945963829755783, -0.04330144822597504, -0.09615980088710785], "finish_reason": "stop"}, {"text": " [sentence.strip() for sentence in sentences]", "tokens": [" [", "sentence", ".", "strip", "()", " for", " sentence", " in", " sentences", "]", "\n"], "logprobs": [-0.1708301156759262, -0.9143050909042358, -0.3255273699760437, -0.08968070894479752, -0.013650286942720413, -0.02439795434474945, -0.0002307625545654446, -0.00011336160969221964, -0.00036042393185198307, -1.0475326776504517, -0.015031874179840088], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0004032037395518273, -8.4638240878121e-06, -2.52720492426306e-05, -0.472856342792511, -0.008020929992198944], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform([sentences]).toarray(),", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "([", "sent", "ences", "])", ".", "to", "array", "()", ",", "\n"], "logprobs": [-1.893068552017212, -0.0011037455406039953, -0.01404073741286993, -0.047857239842414856, -0.07829897105693817, -1.07287787614041e-05, -5.1020273531321436e-05, -0.004816596396267414, -0.00023123928986024112, -6.949660019017756e-05, -2.0010597705841064, -2.662814140319824, -0.12149884551763535, -0.09777133166790009, -0.10872012376785278, -0.05453164130449295, -0.008306006900966167, -0.3520556390285492, -0.01772410422563553, -1.2983689308166504], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.04517894610762596, -0.002044731518253684, -0.017549587413668633, -0.012583030387759209, -0.07644116878509521, -0.00016068121476564556, -0.012633060105144978, -0.11724671721458435, -0.023924820125102997, -0.01263070572167635, -0.004056559409946203, -0.25802284479141235, -0.025834020227193832, -0.00731385825201869, -3.516612196108326e-05, -1.4305012882687151e-05, -0.009706679731607437, -1.1086402082582936e-05, -6.258291978156194e-05, -6.198863957251888e-06, -0.0010475391754880548, -0.16644884645938873, -0.010010160505771637], "finish_reason": "stop"}, {"text": " df", "tokens": [" df", "\n"], "logprobs": [-0.01194373145699501, -0.8457512855529785], "finish_reason": "stop"}], "metrics": {"energy": 74.586659075737, "energy_per_token": 1.0217350558320137, "time": 3.7992177, "time_per_token": 0.052044078082191775}}
{"outputs": [{"text": " re.split(r\"\\.\\s*\", text)", "tokens": [" re", ".", "split", "(", "r", "\"", "\\", ".", "\\", "s", "*", "\"", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -0.5187638401985168, -0.1950531154870987, -0.06564738601446152, -1.296894907951355, -0.01728224940598011, -0.45532089471817017, -0.010129119269549847, -0.0003499372396618128, -0.015518623404204845, -0.10391563177108765, -0.1446336805820465], "finish_reason": "stop"}, {"text": " list(filter(None, sentences))", "tokens": [" list", "(", "filter", "(", "None", ",", " sentences", "))", "\n"], "logprobs": [-2.1585638523101807, -0.0052846260368824005, -0.7251476645469666, -0.001534238108433783, -1.2865269184112549, -0.000271879427600652, -0.008904391899704933, -0.0010346779599785805, -0.09973789751529694], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0004077318590134382, -8.22540732769994e-06, -2.4437606043647975e-05, -0.4642375111579895, -0.008504129014909267], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform(sentences).toarray())", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", ".", "to", "array", "())", "\n"], "logprobs": [-1.9417084455490112, -0.0010489681735634804, -0.014380273409187794, -0.038378406316041946, -0.09257222712039948, -1.1801649634435307e-05, -5.543078441405669e-05, -0.0048182569444179535, -0.0002739054325502366, -6.69933797325939e-05, -0.16517549753189087, -0.0036541137378662825, -5.960462772236497e-07, -0.060710225254297256, -0.01742119900882244, -0.0711456686258316, -0.016896579414606094, -1.4875577688217163, -0.05919432267546654], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03536669537425041, -0.00177107285708189, -0.017799172550439835, -0.014162274077534676, -0.07115532457828522, -0.00018773700867313892, -0.012983429245650768, -0.13858531415462494, -0.02046084776520729, -0.018417419865727425, -0.004231665749102831, -0.24869661033153534, -0.023801786825060844, -0.00584891252219677, -3.2543604902457446e-05, -1.585470999998506e-05, -0.012188360095024109, -1.156323378381785e-05, -6.639736966462806e-05, -6.198863957251888e-06, -0.0008974815136753023, -0.17652685940265656, -0.011114117689430714], "finish_reason": "stop"}, {"text": " df", "tokens": [" df"], "logprobs": [-0.011189683340489864], "finish_reason": "stop"}], "metrics": {"energy": 77.64191602706907, "energy_per_token": 1.0635878907817682, "time": 3.8020813, "time_per_token": 0.05208330547945206}}
{"outputs": [{"text": " re.split(r\"\\.\", text)  # Split text into sentences by .", "tokens": [" re", ".", "split", "(", "r", "\"", "\\", ".", "\"", ",", " text", ")", "  ", "#", " Split", " text", " into", " sentences", " by", " ", ".", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -0.5187638401985168, -0.1950531154870987, -0.06564738601446152, -0.8228386640548706, -0.0003868784988299012, -0.02319338358938694, -0.06789029389619827, -2.5732033252716064, -0.0021946171764284372, -0.5406476259231567, -1.4828726053237915, -0.20817555487155914, -0.03335537761449814, -3.215280532836914, -1.593630313873291, -0.014120666310191154, -0.07099533081054688], "finish_reason": "stop"}, {"text": " [sentence.strip() for sentence in sentences if sentence != \"\"]", "tokens": [" [", "sentence", ".", "strip", "()", " for", " sentence", " in", " sentences", " if", " sentence", " ", "!", "=", " \"", "\"", "]", "\n"], "logprobs": [-0.1708301156759262, -0.9143050909042358, -0.3255273699760437, -0.08968070894479752, -0.013650286942720413, -0.02439795434474945, -0.0002307625545654446, -0.00011336160969221964, -0.00036042393185198307, -0.44355931878089905, -0.2625086307525635, -2.089585781097412, -8.106198947643861e-06, -1.7165990357170813e-05, -0.2316155731678009, -0.029296480119228363, -0.006059845443814993, -0.0256204791367054], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=\"english\")", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "\"", "eng", "lish", "\"", ")", "\n"], "logprobs": [-0.0004032037395518273, -8.4638240878121e-06, -2.52720492426306e-05, -0.9782846570014954, -1.6909493207931519, -7.879423355916515e-05, -0.00010442188795423135, -0.5313435792922974, -0.04900262877345085, -0.009422946721315384, -6.318072337307967e-06, -7.188061863416806e-05, -0.1607244610786438, -0.01336861215531826], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform(sentences).toarray(),", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", ".", "to", "array", "()", ",", "\n"], "logprobs": [-1.893068552017212, -0.0011037455406039953, -0.01404073741286993, -0.047857239842414856, -0.07829897105693817, -1.07287787614041e-05, -5.1020273531321436e-05, -0.004816596396267414, -0.00023123928986024112, -6.949660019017756e-05, -0.1482822597026825, -0.004148924257606268, -3.576278118089249e-07, -0.05754321441054344, -0.018134158104658127, -0.08247242867946625, -0.016766346991062164, -0.23429539799690247, -0.01628079265356064, -0.9904330968856812], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.04517894610762596, -0.002044731518253684, -0.017549587413668633, -0.012583030387759209, -0.07644116878509521, -0.00016068121476564556, -0.012633060105144978, -2.277151107788086, -0.00010489867418073118, -0.04348453879356384, -0.03394702821969986, -0.006143494974821806, -0.3937053084373474, -0.02003387175500393, -0.006400324869900942, -3.111314072157256e-05, -1.8000440832111053e-05, -0.010834085755050182, -1.1324817933200393e-05, -7.64102369430475e-05, -3.099436753473128e-06, -0.0009816833771765232, -0.15215247869491577, -0.010649280622601509], "finish_reason": "stop"}, {"text": " df<|endoftext|>import numpy as np", "tokens": [" df", "<", "|", "end", "of", "text", "|>", "import", " numpy", " as", " np", "\n"], "logprobs": [-0.010937382467091084, -1.2368528842926025, -2.9802276912960224e-06, -1.9073468138230965e-06, -2.1457441107486375e-05, -0.00020919041708111763, -0.044093500822782516, -1.0107436180114746, -1.6928914785385132, -0.013236861675977707, -0.0012055517872795463, -0.002782404189929366], "finish_reason": "stop"}], "metrics": {"energy": 137.40641768646242, "energy_per_token": 1.2491492516951128, "time": 5.483462, "time_per_token": 0.04984965454545455}}
{"outputs": [{"text": " re.split(r\"\\.\", text)", "tokens": [" re", ".", "split", "(", "r", "\"", "\\", ".", "\"", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -0.5187638401985168, -0.1950531154870987, -0.06564738601446152, -0.8228386640548706, -0.0003868784988299012, -0.02319338358938694, -0.06789029389619827, -0.11168789863586426], "finish_reason": "stop"}, {"text": " [sentence.strip() for sentence in sentences]", "tokens": [" [", "sentence", ".", "strip", "()", " for", " sentence", " in", " sentences", "]", "\n"], "logprobs": [-0.1708301156759262, -0.9143050909042358, -0.3255273699760437, -0.08968070894479752, -0.013650286942720413, -0.02439795434474945, -0.0002307625545654446, -0.00011336160969221964, -0.00036042393185198307, -1.0475326776504517, -0.015031874179840088], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0004032037395518273, -8.4638240878121e-06, -2.52720492426306e-05, -0.472856342792511, -0.008020929992198944], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16921454668045044, -5.638440416078083e-05, -4.684815212385729e-05, -0.0016221948899328709, -0.00021371940965764225, -7.521823135903105e-05, -0.04531361535191536, -0.001134705264121294, -7.152555099310121e-07, -0.0016657537780702114, -0.08831246197223663], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.05256928130984306, -0.0020882722456008196, -0.021449262276291847, -0.016418004408478737, -0.06307480484247208, -0.00016151554882526398, -0.010400736704468727, -0.12300483882427216, -0.01410914771258831, -0.015865519642829895, -0.004352263640612364, -0.2418835610151291, -0.02767151966691017, -0.005188215058296919, -3.93382906622719e-05, -1.5020257706055418e-05, -0.010420556180179119, -8.583032467868179e-06, -6.258291978156194e-05, -8.34461570775602e-06, -0.0010202685371041298, -0.14341382682323456, -0.009956695139408112], "finish_reason": "stop"}, {"text": " df", "tokens": [" df"], "logprobs": [-0.013903080485761166], "finish_reason": "stop"}], "metrics": {"energy": 62.40182856178283, "energy_per_token": 0.9750285712778567, "time": 3.3810384, "time_per_token": 0.052828725}}
{"outputs": [{"text": " re.split('\\.', text)", "tokens": [" re", ".", "split", "('", "\\", ".", "'", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -1.4033715724945068, -0.3178728520870209, -0.08021791279315948, -0.521751880645752, -0.0005211663665249944, -0.052563853561878204, -0.08190013468265533, -0.10703328996896744], "finish_reason": "stop"}, {"text": " [s.strip() for s in sentences if s.strip() != '']", "tokens": [" [", "s", ".", "strip", "()", " for", " s", " in", " sentences", " if", " s", ".", "strip", "()", " ", "!", "=", " '", "']", "\n"], "logprobs": [-0.1708301156759262, -0.8741267919540405, -0.273036926984787, -0.11037475615739822, -0.017111873254179955, -0.018640577793121338, -0.00010966652916977182, -3.6000557884108275e-05, -0.0005480932886712253, -0.25047188997268677, -0.2596908211708069, -0.4068619906902313, -0.0030548356007784605, -0.002044612541794777, -1.736830711364746, -1.9192511899746023e-05, -2.0503786799963564e-05, -1.251351237297058, -0.0020404488313943148, -0.03708558529615402], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.0003953390696551651, -8.34461570775602e-06, -2.8609820219571702e-05, -0.4238341450691223, -0.007598308380693197], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16751833260059357, -6.05564855504781e-05, -4.23184028477408e-05, -0.001926591619849205, -0.00023624490131624043, -7.784063927829266e-05, -0.03274422138929367, -0.0012705596163868904, -5.960462772236497e-07, -0.001416633022017777, -0.07310684770345688], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.03827664256095886, -0.002274071332067251, -0.019564863294363022, -0.01376704964786768, -0.07013684511184692, -0.00018082413589581847, -0.013408721424639225, -0.13627171516418457, -0.020992357283830643, -0.016209715977311134, -0.0046304380521178246, -0.22598308324813843, -0.02613671123981476, -0.007026249077171087, -3.8980677345534787e-05, -1.4781842764932662e-05, -0.010650577954947948, -9.179073458653875e-06, -6.770858453819528e-05, -6.079655122448457e-06, -0.0010099078062921762, -0.1486474722623825, -0.011710825376212597], "finish_reason": "stop"}, {"text": " df", "tokens": [" df", "\n"], "logprobs": [-0.011720840819180012, -0.8416351079940796], "finish_reason": "stop"}], "metrics": {"energy": 62.814204174041755, "energy_per_token": 0.8724195024172466, "time": 3.5814295, "time_per_token": 0.04974207638888889}}
{"outputs": [{"text": " re.split(r\"\\.(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\", text)", "tokens": [" re", ".", "split", "(", "r", "\"", "\\", ".", "(", "?", "=(", "?", ":[", "^", "\\\"]", "*", "\\\"[", "^", "\\\"]", "*", "\\\")", "*[", "^", "\\\"]", "*", "$)", "\"", ",", " text", ")", "\n"], "logprobs": [-0.17184554040431976, -0.00011562632425921038, -0.17382071912288666, -0.28708434104919434, -0.2276218831539154, -0.5187638401985168, -0.1950531154870987, -0.06564738601446152, -3.2743139266967773, -0.022872205823659897, -1.6878416538238525, -0.14221058785915375, -0.30869507789611816, -0.17983408272266388, -0.8369985222816467, -0.12147413939237595, -0.12852789461612701, -6.687417771900073e-05, -0.0017404898535460234, -0.006686100736260414, -0.004930717870593071, -0.19311682879924774, -0.020086800679564476, -0.0015224544331431389, -0.050625279545784, -0.0012413900112733245, -0.08113648742437363, -0.00056429672986269, -0.02263367548584938, -0.07607842981815338, -0.09897501766681671], "finish_reason": "stop"}, {"text": " [sentence.strip() for sentence in sentences if len(sentence.strip()) > 0]", "tokens": [" [", "sentence", ".", "strip", "()", " for", " sentence", " in", " sentences", " if", " len", "(", "sentence", ".", "strip", "())", " >", " ", "0", "]", "\n"], "logprobs": [-0.1708301156759262, -0.9143050909042358, -0.3255273699760437, -0.08968070894479752, -0.013650286942720413, -0.02439795434474945, -0.0002307625545654446, -0.00011336160969221964, -0.00036042393185198307, -0.44355931878089905, -1.5131800174713135, -2.9801878554280847e-05, -0.00392345804721117, -0.19792336225509644, -0.0106643782928586, -0.0367036871612072, -0.04239976778626442, -0.0012762743281200528, -0.009599595330655575, -0.002640453865751624, -0.023319635540246964], "finish_reason": "stop"}, {"text": " CountVectorizer(token_pattern=\"\\\\w+\")", "tokens": [" Count", "Vector", "izer", "(", "token", "_", "pattern", "=", "\"", "\\\\", "w", "+", "\"", ")", "\n"], "logprobs": [-0.0004032037395518273, -8.4638240878121e-06, -2.52720492426306e-05, -0.9782846570014954, -2.234776496887207, -1.1228855848312378, -0.09139236062765121, -0.0894327461719513, -1.7552223205566406, -0.16925813257694244, -0.738614559173584, -0.017327357083559036, -0.010460784658789635, -0.13200914859771729, -0.013281211256980896], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(sentences)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "sent", "ences", ")", "\n"], "logprobs": [-0.16921454668045044, -5.638440416078083e-05, -4.684815212385729e-05, -0.0016221948899328709, -0.00021371940965764225, -7.521823135903105e-05, -0.04531361535191536, -0.001134705264121294, -7.152555099310121e-07, -0.0016657537780702114, -0.08831246197223663], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), index=sentences, columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " index", "=", "sent", "ences", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.05256928130984306, -0.0020882722456008196, -0.021449262276291847, -0.016418004408478737, -0.06307480484247208, -0.00016151554882526398, -0.010400736704468727, -0.12300483882427216, -0.01410914771258831, -0.015865519642829895, -0.004352263640612364, -1.793290376663208, -0.04573483392596245, -0.137104794383049, -0.001334848813712597, -0.055869195610284805, -0.008776779286563396, -0.02164456434547901, -0.006049181334674358, -4.351044481154531e-05, -4.51792984677013e-05, -0.005136626306921244, -4.768360213347478e-06, -8.237022848334163e-05, -3.6954811548639555e-06, -0.001176023157313466, -0.14661026000976562, -0.018692996352910995], "finish_reason": "stop"}, {"text": " df<|endoftext|>from collections import defaultdict", "tokens": [" df", "<", "|", "end", "of", "text", "|>", "from", " collections", " import", " default", "dict", "\n"], "logprobs": [-0.009727812372148037, -1.0467681884765625, -2.0265558760002023e-06, -1.9073468138230965e-06, -2.6702524337451905e-05, -0.00019405389321036637, -0.048586875200271606, -1.3654236793518066, -2.536583185195923, -0.021779760718345642, -0.9611404538154602, -7.748573807475623e-06, -0.08014364540576935], "finish_reason": "stop"}], "metrics": {"energy": 150.51538219261172, "energy_per_token": 1.2648351444757289, "time": 5.6808596, "time_per_token": 0.04773831596638655}}
