{"outputs": [{"text": " [ALPHANUMERIC.sub('', text).lower() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", "'", ",", " text", ")", ".", "lower", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.36279451847076416, -0.09351514279842377, -3.814689989667386e-06, -0.00010680581908673048, -2.6702524337451905e-05, -7.390948667307384e-06, -0.00011395759065635502, -0.0002746204845607281, -0.0003319427778478712, -0.04210321605205536, -0.8465220332145691, -0.00014101465058047324, -0.34863749146461487, -0.4953864514827728, -0.04071849584579468, -0.018423739820718765, -0.001670038211159408, -0.42500463128089905, -0.0008469808381050825, -0.00011181206355104223, -0.0006444760947488248, -0.02139698900282383, -0.015793122351169586], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -0.961950421333313, -0.014658844098448753, -0.057944800704717636, -0.055783968418836594, -0.0006480501033365726, -0.0004295380203984678, -3.766942609217949e-05, -0.04413753002882004, -7.438383181579411e-05, -2.0265558760002023e-06, -1.2516897186287679e-05, -0.0032663585152477026, -0.0015555436257272959], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform(tokenized_texts).toarray(), columns=vectorizer.get_feature_names(), index=texts)", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " index", "=", "text", "s", ")", "\n"], "logprobs": [-1.9018622636795044, -1.6689160474925302e-05, -0.007498452439904213, -0.02244695834815502, -0.03257957845926285, -7.033323527139146e-06, -2.95634672511369e-05, -0.0026763593778014183, -0.0001382732152706012, -0.00010442188795423135, -0.006943383254110813, -0.013187568634748459, -8.702239938429557e-06, -5.030505417380482e-05, -3.4570634852570947e-06, -2.5510462364763953e-05, -0.11155803501605988, -0.006090888753533363, -0.0887315571308136, -0.0145249143242836, -0.10225436091423035, -0.004305498208850622, -0.8696419596672058, -0.01642856001853943, -0.006376634817570448, -3.135155202471651e-05, -1.597391747054644e-05, -0.007723232731223106, -5.960462772236497e-07, -0.0001811817055568099, -1.4305104514278355e-06, -0.0023462644312530756, -0.939881443977356, -0.007114079315215349, -0.14075377583503723, -0.05607885494828224, -0.8141103982925415, -0.001100887660868466, -0.020153513178229332, -0.02483353763818741], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.01139301061630249, -0.00016616393986623734, -0.0041642384603619576, -0.011126496829092503, -0.05456686019897461, -5.960446742392378e-06, -0.001142087858170271, -0.20451104640960693, -0.006021216977387667, -0.004727852065116167, -0.0009677494526840746, -0.4257713854312897, -0.023752428591251373, -0.004288168158382177, -9.65590606938349e-06, -9.65590606938349e-06, -0.004881369415670633, -1.0728830375228426e-06, -0.00017176583060063422, -1.1920928244535389e-07, -0.000894146622158587, -0.14723335206508636, -0.015751700848340988], "finish_reason": "stop"}, {"text": " else None)", "tokens": [" else", " None", ")", "\n"], "logprobs": [-0.01996142417192459, -1.6337916851043701, -0.3097115159034729, -0.029286755248904228], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.05485951155424118, -6.16293036728166e-05, -0.0012840130366384983, -5.030505417380482e-05, -1.1036642789840698, -3.6954811548639555e-06, -1.1920922133867862e-06, -1.645074735279195e-05, -0.00031859567388892174, -0.053711775690317154], "finish_reason": "stop"}], "metrics": {"energy": 212.77170864868165, "energy_per_token": 1.7879975516695936, "time": 9.019912, "time_per_token": 0.07579757983193278}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', t.lower()) for t in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " t", ".", "lower", "())", " for", " t", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -2.1090197563171387, -1.0902228355407715, -0.08709336072206497, -0.020923249423503876, -1.3654282093048096, -0.0002097863471135497, -5.9602869441732764e-05, -0.00104301399551332, -0.007970196194946766, -0.028989648446440697], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -1.073909878730774, -0.00020144341397099197, -0.00028951745480298996, -0.044072624295949936, -0.00865234062075615, -0.0012244831304997206, -0.00035065223346464336, -0.002056628232821822, -0.02010420896112919, -0.01904475875198841, -0.0014748420799151063, -0.000797311426140368, -5.590759246842936e-05, -0.026396585628390312, -7.211902266135439e-05, -7.152555099310121e-07, -1.4305012882687151e-05, -0.0052262828685343266, -0.0011199399596080184], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform(tokenized_texts).toarray(), index=tokenized_texts, columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", ".", "to", "array", "()", ",", " index", "=", "token", "ized", "_", "text", "s", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-1.9018622636795044, -1.6689160474925302e-05, -0.007498452439904213, -0.02244695834815502, -0.03257957845926285, -7.033323527139146e-06, -2.95634672511369e-05, -0.0026763593778014183, -0.0001382732152706012, -0.00010442188795423135, -0.006943383254110813, -0.013187568634748459, -8.702239938429557e-06, -5.030505417380482e-05, -3.4570634852570947e-06, -2.5510462364763953e-05, -0.11155803501605988, -0.006090888753533363, -0.0887315571308136, -0.0145249143242836, -0.10225436091423035, -0.004305498208850622, -1.57328200340271, -0.03525162115693092, -2.111968994140625, -0.0021211046259850264, -0.004620945546776056, -5.471556869451888e-05, -8.34461570775602e-06, -0.0574718602001667, -0.07540695369243622, -0.0258179884403944, -0.005794513039290905, -2.7417760065873154e-05, -2.52720492426306e-05, -0.0037187249399721622, -5.960462772236497e-07, -0.00033563701435923576, -3.576278118089249e-07, -0.0022198338992893696, -0.09410253167152405, -0.0520961694419384], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), index=cleaned_texts, columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " index", "=", "cleaned", "_", "text", "s", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.01139301061630249, -0.00016616393986623734, -0.0041642384603619576, -0.011126496829092503, -0.05456686019897461, -5.960446742392378e-06, -0.001142087858170271, -0.20451104640960693, -0.006021216977387667, -0.004727852065116167, -0.0009677494526840746, -1.2132869958877563, -0.02962983399629593, -3.106938123703003, -1.156323378381785e-05, -8.904537389753386e-05, -9.298280929215252e-06, -0.032762449234724045, -0.007617118768393993, -0.03705583140254021, -0.007060340140014887, -2.002696055569686e-05, -1.6689160474925302e-05, -0.007475143298506737, -5.960462772236497e-07, -0.00021205084340181202, -1.1920928244535389e-07, -0.0027957186102867126, -0.07164270430803299, -0.01670069806277752], "finish_reason": "stop"}, {"text": " else None, index=range(dtm.shape[0]))", "tokens": [" else", " None", ",", " index", "=", "range", "(", "dt", "m", ".", "shape", "[", "0", "]))", "\n"], "logprobs": [-0.02004976198077202, -1.7343487739562988, -1.375806450843811, -0.24173247814178467, -0.19747649133205414, -1.4771567583084106, -0.000595034915022552, -1.954781413078308, -1.2993727978027891e-05, -0.00369437737390399, -0.01501766499131918, -0.003336697816848755, -0.033477701246738434, -0.14149227738380432, -0.019860107451677322], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.04483705386519432, -6.532455881824717e-05, -0.0018168861279264092, -3.528532761265524e-05, -0.9706307649612427], "finish_reason": "stop"}], "metrics": {"energy": 193.99209591007227, "energy_per_token": 1.3956265892810955, "time": 8.631918, "time_per_token": 0.06210012949640288}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text).lower() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ")", ".", "lower", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -0.3058427572250366, -0.3795720636844635, -0.033408068120479584, -0.06999747455120087, -0.001383539172820747, -0.5623471736907959, -0.0006177900941111147, -9.250213042832911e-05, -0.0006170752458274364, -0.010922761633992195, -0.016307415440678596], "finish_reason": "stop"}, {"text": " [ALPHANUMERIC.sub(' ', text).lower().split() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ")", ".", "lower", "()", ".", "split", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.05564460903406143, -2.454538345336914, -6.222531374078244e-05, -4.8397800128441304e-05, -0.00031609306461177766, -1.585470999998506e-05, -0.0006093314150348306, -9.07141511561349e-05, -0.006861221045255661, -0.004506669472903013, -0.036930497735738754, -0.00026901919045485556, -0.008954014629125595, -0.011055760085582733, -0.08316551148891449, -0.4057275652885437, -0.00027700403006747365, -0.12078176438808441, -0.045460574328899384, -0.021055158227682114, -0.014426805078983307, -0.0002493547508493066, -4.9470632802695036e-05, -0.6016818284988403, -0.0013036570744588971, -0.003975347150117159], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -0.25154757499694824, -0.006177972070872784, -0.006157593801617622, -0.001101244823075831, -0.360628604888916, -0.02248215861618519, -0.00347213470377028, -7.152531907195225e-06, -1.0013530300057027e-05, -0.005828527733683586, -1.1920922133867862e-06, -0.0001454247540095821, -1.1920928244535389e-07, -0.0009485750924795866, -0.1305103898048401, -0.016259564086794853], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.019529208540916443, -0.5104995369911194, -0.00011777184408856556, -0.001111961784772575, -0.12247985601425171, -9.77468371274881e-05, -0.0027870405465364456, -8.296622399939224e-05, -0.001416871091350913, -0.5013384222984314, -0.022062107920646667], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.05894036218523979, -7.211902266135439e-05, -0.0018090326339006424, -3.838465272565372e-05, -0.9325190186500549], "finish_reason": "stop"}], "metrics": {"energy": 180.93533922004707, "energy_per_token": 1.6909844786920287, "time": 7.793268, "time_per_token": 0.07283428037383177}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', doc.lower()).strip() for doc in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " doc", ".", "lower", "())", ".", "strip", "()", " for", " doc", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -2.9532809257507324, -1.1287593841552734, -0.07320523262023926, -0.03146996721625328, -0.46976444125175476, -0.22095543146133423, -0.005609959363937378, -0.06450370699167252, -0.00019834458362311125, -9.023735765367746e-05, -0.0015067425556480885, -0.0098600247874856, -0.01756657287478447], "finish_reason": "stop"}, {"text": " [ALPHANUMERIC.sub(' ', text).lower().split() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ")", ".", "lower", "()", ".", "split", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.05564460903406143, -2.454538345336914, -6.222531374078244e-05, -4.8397800128441304e-05, -0.00031609306461177766, -1.585470999998506e-05, -0.0006093314150348306, -9.07141511561349e-05, -0.006861221045255661, -0.004506669472903013, -0.036930497735738754, -0.00026901919045485556, -0.008954014629125595, -0.011055760085582733, -0.08316551148891449, -0.4057275652885437, -0.00027700403006747365, -0.12078176438808441, -0.045460574328899384, -0.021055158227682114, -0.014426805078983307, -0.0002493547508493066, -4.9470632802695036e-05, -0.6016818284988403, -0.0013036570744588971, -0.003975347150117159], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names(), index=range(1, len(texts) + 1))", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " index", "=", "range", "(", "1", ",", " len", "(", "text", "s", ")", " +", " ", "1", "))", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -0.25154757499694824, -0.006177972070872784, -0.006157593801617622, -0.001101244823075831, -0.360628604888916, -0.02248215861618519, -0.00347213470377028, -7.152531907195225e-06, -1.0013530300057027e-05, -0.005828527733683586, -1.1920922133867862e-06, -0.0001454247540095821, -1.1920928244535389e-07, -0.0009485750924795866, -2.395101547241211, -0.006437635514885187, -0.09684281796216965, -0.0860135555267334, -0.6343652009963989, -0.00013243274588603526, -0.47811347246170044, -0.000497336674015969, -0.15895622968673706, -5.924526340095326e-05, -1.2046027183532715, -0.0008135108510032296, -0.441893607378006, -0.00030894274823367596, -0.003229523543268442, -0.0024465173482894897, -0.0021275284234434366, -0.02194199524819851], "finish_reason": "stop"}, {"text": " else [],", "tokens": [" else", " []", ",", "\n"], "logprobs": [-0.019529208540916443, -2.6530699729919434, -0.06608501076698303, -2.279475450515747], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.051002804189920425, -6.90197994117625e-05, -0.0018931577214971185, -3.909988299710676e-05, -1.110565423965454, -3.099436753473128e-06, -1.1920922133867862e-06, -1.549708758830093e-05, -0.0004051103023812175, -0.05643821507692337], "finish_reason": "stop"}], "metrics": {"energy": 179.79585915184018, "energy_per_token": 1.4617549524539852, "time": 7.9994454, "time_per_token": 0.06503614146341463}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', t.lower()).split() for t in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " t", ".", "lower", "())", ".", "split", "()", " for", " t", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -2.1090197563171387, -1.0902228355407715, -0.08709336072206497, -0.020923249423503876, -0.29976582527160645, -2.024271011352539, -0.033517125993967056, -0.012710041366517544, -0.00015114595589693636, -5.924526340095326e-05, -0.001026103738695383, -0.006074300967156887, -0.022645678371191025], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -0.961950421333313, -0.014658844098448753, -0.057944800704717636, -0.055783968418836594, -0.0006480501033365726, -0.0004295380203984678, -3.766942609217949e-05, -0.04413753002882004, -7.438383181579411e-05, -2.0265558760002023e-06, -1.2516897186287679e-05, -0.0032663585152477026, -0.0015555436257272959], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform(tokenized_texts))", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", "))", "\n"], "logprobs": [-1.9018622636795044, -1.6689160474925302e-05, -0.007498452439904213, -0.02244695834815502, -0.03257957845926285, -7.033323527139146e-06, -2.95634672511369e-05, -0.0026763593778014183, -0.0001382732152706012, -0.00010442188795423135, -0.006943383254110813, -0.013187568634748459, -8.702239938429557e-06, -5.030505417380482e-05, -3.4570634852570947e-06, -2.5510462364763953e-05, -2.2561120986938477, -0.05034816265106201], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.01139301061630249, -0.00016616393986623734, -0.0041642384603619576, -0.011126496829092503, -0.05456686019897461, -5.960446742392378e-06, -0.001142087858170271, -0.20451104640960693, -0.006021216977387667, -0.004727852065116167, -0.0009677494526840746, -0.4257713854312897, -0.023752428591251373, -0.004288168158382177, -9.65590606938349e-06, -9.65590606938349e-06, -0.004881369415670633, -1.0728830375228426e-06, -0.00017176583060063422, -1.1920928244535389e-07, -0.000894146622158587, -0.14723335206508636, -0.015751700848340988], "finish_reason": "stop"}, {"text": " else None)", "tokens": [" else", " None", ")", "\n"], "logprobs": [-0.01996142417192459, -1.6337916851043701, -0.3097115159034729, -0.029286755248904228], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.05485951155424118, -6.16293036728166e-05, -0.0012840130366384983, -5.030505417380482e-05, -1.0461024045944214], "finish_reason": "stop"}], "metrics": {"energy": 150.1319139213562, "energy_per_token": 1.5971480204399595, "time": 6.7279224, "time_per_token": 0.07157364255319149}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text).strip() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ")", ".", "strip", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -0.3058427572250366, -0.3795720636844635, -0.033408068120479584, -2.896209478378296, -0.0030625606887042522, -1.4278348684310913, -0.0005202132160775363, -7.450303382938728e-05, -0.0005492847412824631, -0.01116186287254095, -0.018779456615447998], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -0.961950421333313, -0.014658844098448753, -0.057944800704717636, -0.055783968418836594, -0.0006480501033365726, -0.0004295380203984678, -3.766942609217949e-05, -0.04413753002882004, -7.438383181579411e-05, -2.0265558760002023e-06, -1.2516897186287679e-05, -0.0032663585152477026, -0.0015555436257272959], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -0.25154757499694824, -0.006177972070872784, -0.006157593801617622, -0.001101244823075831, -0.360628604888916, -0.02248215861618519, -0.00347213470377028, -7.152531907195225e-06, -1.0013530300057027e-05, -0.005828527733683586, -1.1920922133867862e-06, -0.0001454247540095821, -1.1920928244535389e-07, -0.0009485750924795866, -0.1305103898048401, -0.016259564086794853], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.019529208540916443, -0.5104995369911194, -0.00011777184408856556, -0.001111961784772575, -0.12247985601425171, -9.77468371274881e-05, -0.0027870405465364456, -8.296622399939224e-05, -0.001416871091350913, -0.5013384222984314, -0.022062107920646667], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.05894036218523979, -7.211902266135439e-05, -0.0018090326339006424, -3.838465272565372e-05, -0.9325190186500549], "finish_reason": "stop"}], "metrics": {"energy": 137.55671688270573, "energy_per_token": 1.4479654408705867, "time": 6.2997518, "time_per_token": 0.06631317684210526}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(\"\", text).lower().strip() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "(", "\"", "\"", ",", " text", ")", ".", "lower", "()", ".", "strip", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -2.9615564346313477, -0.5181592106819153, -0.5574883222579956, -0.006017306819558144, -0.32042190432548523, -0.37466832995414734, -0.03525553643703461, -0.017931492999196053, -0.0010171722387894988, -1.2435245513916016, -1.4031448364257812, -0.010189301334321499, -0.14167003333568573, -0.0007448997348546982, -0.00011586471373448148, -0.0006993946735747159, -0.03054702840745449, -0.01811249926686287], "finish_reason": "stop"}, {"text": " [word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -2.4775466918945312, -1.4737722873687744, -0.007397639565169811, -0.0017849955474957824, -0.0023575627710670233, -0.049335721880197525, -0.015973811969161034, -0.0018184330547228456, -0.0013915151357650757, -7.450303382938728e-05, -0.016950378194451332, -8.248942322097719e-05, -1.4305104514278355e-06, -1.5020257706055418e-05, -0.007542820647358894, -0.001259963377378881], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(),", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -1.5738017559051514, -9.77468371274881e-05, -0.016980381682515144, -0.03800400346517563, -0.0018600797047838569, -3.2764480113983154], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.019877053797245026, -0.5352551937103271, -0.00012170527770649642, -0.0009548871894367039, -0.13353998959064484, -9.595887240720913e-05, -0.003407863900065422, -7.855583680793643e-05, -0.0014466306893154979, -0.49523645639419556, -0.023712266236543655], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.055180732160806656, -6.592056161025539e-05, -0.0019966682884842157, -4.2676016164477915e-05, -1.1839791536331177, -2.861018856492592e-06, -1.311301275563892e-06, -1.645074735279195e-05, -0.000248401309363544, -0.0591496042907238], "finish_reason": "stop"}], "metrics": {"energy": 145.57294784927367, "energy_per_token": 1.5007520396832337, "time": 6.7574635, "time_per_token": 0.06966457216494845}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-1.2304216623306274, -0.014714173972606659], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -0.961950421333313, -0.014658844098448753, -0.057944800704717636, -0.055783968418836594, -0.0006480501033365726, -0.0004295380203984678, -3.766942609217949e-05, -0.04413753002882004, -7.438383181579411e-05, -2.0265558760002023e-06, -1.2516897186287679e-05, -0.0032663585152477026, -0.0015555436257272959], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), index=tokenized_texts, columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " index", "=", "token", "ized", "_", "text", "s", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -1.5738017559051514, -9.77468371274881e-05, -0.016980381682515144, -0.03800400346517563, -0.0018600797047838569, -1.163374662399292, -0.013533863238990307, -1.9045939445495605, -0.00036030475166626275, -0.0005326044629327953, -5.209310256759636e-05, -9.179073458653875e-06, -0.023185230791568756, -0.00788054894655943, -0.047061000019311905, -0.005760852713137865, -2.0861407392658293e-05, -1.4305012882687151e-05, -0.007018436212092638, -5.960462772236497e-07, -0.00021360022947192192, -1.1920928244535389e-07, -0.003440653206780553, -0.07639699429273605, -0.019642364233732224], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.019877053797245026, -0.5352551937103271, -0.00012170527770649642, -0.0009548871894367039, -0.13353998959064484, -9.595887240720913e-05, -0.003407863900065422, -7.855583680793643e-05, -0.0014466306893154979, -0.49523645639419556, -0.023712266236543655], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.055180732160806656, -6.592056161025539e-05, -0.0019966682884842157, -4.2676016164477915e-05, -0.885574460029602], "finish_reason": "stop"}], "metrics": {"energy": 186.83136668968197, "energy_per_token": 2.2509803215624333, "time": 6.917811, "time_per_token": 0.08334712048192772}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text).lower() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ")", ".", "lower", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -0.3058427572250366, -0.3795720636844635, -0.033408068120479584, -0.06999747455120087, -0.001383539172820747, -0.5623471736907959, -0.0006177900941111147, -9.250213042832911e-05, -0.0006170752458274364, -0.010922761633992195, -0.016307415440678596], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -0.961950421333313, -0.014658844098448753, -0.057944800704717636, -0.055783968418836594, -0.0006480501033365726, -0.0004295380203984678, -3.766942609217949e-05, -0.04413753002882004, -7.438383181579411e-05, -2.0265558760002023e-06, -1.2516897186287679e-05, -0.0032663585152477026, -0.0015555436257272959], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -1.5738017559051514, -9.77468371274881e-05, -0.016980381682515144, -0.03800400346517563, -0.0018600797047838569, -0.45992356538772583, -0.020647352561354637, -0.00367881846614182, -8.22540732769994e-06, -9.179073458653875e-06, -0.012659779749810696, -1.0728830375228426e-06, -0.00017474555352237076, -1.1920928244535389e-07, -0.0011612584348767996, -0.16146694123744965, -0.028514975681900978], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names(), index= texts)", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " index", "=", " texts", ")", "\n"], "logprobs": [-0.019877053797245026, -0.5352551937103271, -0.00012170527770649642, -0.0009548871894367039, -0.13353998959064484, -9.595887240720913e-05, -0.003407863900065422, -7.855583680793643e-05, -0.0014466306893154979, -0.9684935212135315, -0.11315305531024933, -0.2590566575527191, -0.2245658040046692, -1.8764984607696533, -0.04378444328904152, -0.02335958182811737], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df"], "logprobs": [-0.055180732160806656, -6.592056161025539e-05, -0.0019966682884842157, -4.2676016164477915e-05], "finish_reason": "stop"}], "metrics": {"energy": 182.05373530006403, "energy_per_token": 1.8205373530006403, "time": 6.7310195, "time_per_token": 0.067310195}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-1.2304216623306274, -0.014714173972606659], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -0.961950421333313, -0.014658844098448753, -0.057944800704717636, -0.055783968418836594, -0.0006480501033365726, -0.0004295380203984678, -3.766942609217949e-05, -0.04413753002882004, -7.438383181579411e-05, -2.0265558760002023e-06, -1.2516897186287679e-05, -0.0032663585152477026, -0.0015555436257272959], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), columns=vectorizer.get_feature_names(), index=[\"document_1\", \"document_2\", \"document_3\"])", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " index", "=[", "\"", "document", "_", "1", "\"", ",", " \"", "document", "_", "2", "\"", ",", " \"", "document", "_", "3", "\"", "])", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -1.5738017559051514, -9.77468371274881e-05, -0.016980381682515144, -0.03800400346517563, -0.0018600797047838569, -0.45992356538772583, -0.020647352561354637, -0.00367881846614182, -8.22540732769994e-06, -9.179073458653875e-06, -0.012659779749810696, -1.0728830375228426e-06, -0.00017474555352237076, -1.1920928244535389e-07, -0.0011612584348767996, -2.366377115249634, -0.005697676911950111, -0.11642026156187057, -2.8843257427215576, -0.9948583841323853, -1.655816674232483, -2.0224766731262207, -2.0813562870025635, -0.00216535571962595, -0.003579401643946767, -0.05040223151445389, -0.0005253365379758179, -0.0001998939987970516, -0.0005639393348246813, -0.0001248043408850208, -0.013792093843221664, -0.004687036853283644, -0.001209838199429214, -0.000491021724883467, -0.0008298290777020156, -0.0004609952447935939, -0.007044005207717419, -0.019544990733265877], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.019877053797245026, -0.5352551937103271, -0.00012170527770649642, -0.0009548871894367039, -0.13353998959064484, -9.595887240720913e-05, -0.003407863900065422, -7.855583680793643e-05, -0.0014466306893154979, -0.49523645639419556, -0.023712266236543655], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.055180732160806656, -6.592056161025539e-05, -0.0019966682884842157, -4.2676016164477915e-05, -0.885574460029602], "finish_reason": "stop"}], "metrics": {"energy": 152.37745458698276, "energy_per_token": 1.5872651519477372, "time": 6.716659, "time_per_token": 0.06996519791666667}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text.lower()) for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ".", "lower", "())", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -0.3058427572250366, -1.1567574739456177, -0.06783348321914673, -0.01909586787223816, -1.053930640220642, -0.0009302341495640576, -7.784063927829266e-05, -0.0006509092636406422, -0.012613166123628616, -0.029514214023947716], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -1.073909878730774, -0.00020144341397099197, -0.00028951745480298996, -0.044072624295949936, -0.00865234062075615, -0.0012244831304997206, -0.00035065223346464336, -0.002056628232821822, -0.02010420896112919, -0.01904475875198841, -0.0014748420799151063, -0.000797311426140368, -5.590759246842936e-05, -0.026396585628390312, -7.211902266135439e-05, -7.152555099310121e-07, -1.4305012882687151e-05, -0.0052262828685343266, -0.0011199399596080184], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -1.5738017559051514, -9.77468371274881e-05, -0.016980381682515144, -0.03800400346517563, -0.0018600797047838569, -0.45992356538772583, -0.020647352561354637, -0.00367881846614182, -8.22540732769994e-06, -9.179073458653875e-06, -0.012659779749810696, -1.0728830375228426e-06, -0.00017474555352237076, -1.1920928244535389e-07, -0.0011612584348767996, -0.16146694123744965, -0.028514975681900978], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.019877053797245026, -0.5352551937103271, -0.00012170527770649642, -0.0009548871894367039, -0.13353998959064484, -9.595887240720913e-05, -0.003407863900065422, -7.855583680793643e-05, -0.0014466306893154979, -0.49523645639419556, -0.023712266236543655], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.055180732160806656, -6.592056161025539e-05, -0.0019966682884842157, -4.2676016164477915e-05, -1.1839791536331177, -2.861018856492592e-06, -1.311301275563892e-06, -1.645074735279195e-05, -0.000248401309363544, -0.0591496042907238], "finish_reason": "stop"}], "metrics": {"energy": 153.06780544090267, "energy_per_token": 1.4440359003858743, "time": 6.9343605, "time_per_token": 0.06541849528301887}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text).lower() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ")", ".", "lower", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -0.3058427572250366, -0.3795720636844635, -0.033408068120479584, -0.06999747455120087, -0.001383539172820747, -0.5623471736907959, -0.0006177900941111147, -9.250213042832911e-05, -0.0006170752458274364, -0.010922761633992195, -0.016307415440678596], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -1.073909878730774, -0.00020144341397099197, -0.00028951745480298996, -0.044072624295949936, -0.00865234062075615, -0.0012244831304997206, -0.00035065223346464336, -0.002056628232821822, -0.02010420896112919, -0.01904475875198841, -0.0014748420799151063, -0.000797311426140368, -5.590759246842936e-05, -0.026396585628390312, -7.211902266135439e-05, -7.152555099310121e-07, -1.4305012882687151e-05, -0.0052262828685343266, -0.0011199399596080184], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), index=texts, columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " index", "=", "text", "s", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -0.25154757499694824, -0.006177972070872784, -0.006157593801617622, -0.001101244823075831, -1.3944039344787598, -0.02731083333492279, -0.9184310436248779, -0.0015447123441845179, -0.0372893400490284, -0.0020478246733546257, -0.016540424898266792, -0.004469405394047499, -1.537788011773955e-05, -1.2159273865108844e-05, -0.006336953025311232, -4.768370445162873e-07, -0.00020382710499688983, -1.1920928244535389e-07, -0.0022033003624528646, -0.10056035220623016, -0.019421299919486046], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.019712261855602264, -0.5717103481292725, -8.928377064876258e-05, -0.0010484919184818864, -0.1334025114774704, -0.00010823617776622996, -0.0030411682091653347, -8.21318244561553e-05, -0.0017560789128765464, -0.49872148036956787, -0.021349262446165085], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df"], "logprobs": [-0.05735839903354645, -7.331102824537084e-05, -0.0015018623089417815, -4.8636207793606445e-05], "finish_reason": "stop"}], "metrics": {"energy": 171.19700344848633, "energy_per_token": 1.630447651890346, "time": 7.347072, "time_per_token": 0.06997211428571429}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-1.2304216623306274, -0.014714173972606659], "finish_reason": "stop"}, {"text": " [ALPHANUMERIC.sub(' ', text).lower().split() for text in cleaned_texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ")", ".", "lower", "()", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -2.454538345336914, -6.222531374078244e-05, -4.8397800128441304e-05, -0.00031609306461177766, -1.585470999998506e-05, -0.0006093314150348306, -9.07141511561349e-05, -0.006861221045255661, -0.004506669472903013, -0.036930497735738754, -0.00026901919045485556, -0.008954014629125595, -0.011055760085582733, -0.08316551148891449, -0.4057275652885437, -0.00027700403006747365, -0.12078176438808441, -0.045460574328899384, -0.021055158227682114, -0.014426805078983307, -0.0002493547508493066, -4.9470632802695036e-05, -0.8065139055252075, -0.00010775939153973013, -2.861018856492592e-06, -8.702239938429557e-06, -0.006845356430858374, -0.0037606486584991217], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), index=vectorizer.get_feature_names(), columns=['count'])", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " index", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " columns", "=['", "count", "'])", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -1.5738017559051514, -9.77468371274881e-05, -0.016980381682515144, -0.03800400346517563, -0.0018600797047838569, -1.163374662399292, -0.013533863238990307, -0.7877669334411621, -0.32168129086494446, -0.00017093151109293103, -0.0835469588637352, -2.622600959512056e-06, -0.000285227142740041, -1.1920928244535389e-07, -0.0013406822690740228, -0.11856050789356232, -0.0006777135422453284, -0.011904976330697536, -1.793568730354309, -0.7068870663642883, -0.008979888632893562, -0.05906824767589569], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names(), index= texts)", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " index", "=", " texts", ")", "\n"], "logprobs": [-0.019877053797245026, -0.5352551937103271, -0.00012170527770649642, -0.0009548871894367039, -0.13353998959064484, -9.595887240720913e-05, -0.003407863900065422, -7.855583680793643e-05, -0.0014466306893154979, -0.9684935212135315, -0.11315305531024933, -0.2590566575527191, -0.2245658040046692, -1.8764984607696533, -0.04378444328904152, -0.02335958182811737], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df"], "logprobs": [-0.055180732160806656, -6.592056161025539e-05, -0.0019966682884842157, -4.2676016164477915e-05], "finish_reason": "stop"}], "metrics": {"energy": 174.7112783279419, "energy_per_token": 1.7647603871509283, "time": 6.521182, "time_per_token": 0.06587052525252525}}
{"outputs": [{"text": " [ALPHANUMERIC.sub('', text).lower() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", "'", ",", " text", ")", ".", "lower", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.8775860071182251, -0.00014435203047469258, -0.3691330552101135, -0.46504664421081543, -0.04510852321982384, -0.018077027052640915, -0.0015046000480651855, -0.5547010898590088, -0.0007022537174634635, -0.00011407678539399058, -0.0006098079611547291, -0.01842888817191124, -0.015234891325235367], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -1.073909878730774, -0.00020144341397099197, -0.00028951745480298996, -0.044072624295949936, -0.00865234062075615, -0.0012244831304997206, -0.00035065223346464336, -0.002056628232821822, -0.02010420896112919, -0.01904475875198841, -0.0014748420799151063, -0.000797311426140368, -5.590759246842936e-05, -0.026396585628390312, -7.211902266135439e-05, -7.152555099310121e-07, -1.4305012882687151e-05, -0.0052262828685343266, -0.0011199399596080184], "finish_reason": "stop"}, {"text": " CountVectorizer(analyzer='word')", "tokens": [" Count", "Vector", "izer", "(", "analy", "zer", "='", "word", "')", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -1.2911405563354492, -1.1791411638259888, -0.010012520477175713, -0.05519066005945206, -0.15062148869037628, -0.685238778591156, -0.014313291758298874], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -0.25154757499694824, -0.006177972070872784, -0.006157593801617622, -0.001101244823075831, -0.360628604888916, -0.02248215861618519, -0.00347213470377028, -7.152531907195225e-06, -1.0013530300057027e-05, -0.005828527733683586, -1.1920922133867862e-06, -0.0001454247540095821, -1.1920928244535389e-07, -0.0009485750924795866, -0.1305103898048401, -0.016259564086794853], "finish_reason": "stop"}, {"text": " else [])", "tokens": [" else", " [", "])", "\n"], "logprobs": [-0.019529208540916443, -3.0583319664001465, -2.173452377319336, -0.023804929107427597], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df"], "logprobs": [-0.051002804189920425, -6.90197994117625e-05, -0.0018931577214971185, -3.909988299710676e-05], "finish_reason": "stop"}], "metrics": {"energy": 146.1116775112152, "energy_per_token": 1.4909354848083183, "time": 6.721199, "time_per_token": 0.06858366326530613}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text.lower()).strip() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ".", "lower", "())", ".", "strip", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -0.3058427572250366, -1.1567574739456177, -0.06783348321914673, -0.01909586787223816, -0.43795621395111084, -0.2285831719636917, -0.0044964635744690895, -0.08017048984766006, -0.00041345154750160873, -8.201262971851975e-05, -0.0007540719816461205, -0.017260339111089706, -0.014919133856892586], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -1.073909878730774, -0.00020144341397099197, -0.00028951745480298996, -0.044072624295949936, -0.00865234062075615, -0.0012244831304997206, -0.00035065223346464336, -0.002056628232821822, -0.02010420896112919, -0.01904475875198841, -0.0014748420799151063, -0.000797311426140368, -5.590759246842936e-05, -0.026396585628390312, -7.211902266135439e-05, -7.152555099310121e-07, -1.4305012882687151e-05, -0.0052262828685343266, -0.0011199399596080184], "finish_reason": "stop"}, {"text": " CountVectorizer(analyzer='char_wb')", "tokens": [" Count", "Vector", "izer", "(", "analy", "zer", "='", "char", "_", "wb", "')", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -1.2911405563354492, -1.1791411638259888, -0.010012520477175713, -0.05519066005945206, -2.060697555541992, -0.24811403453350067, -0.4761708080768585, -0.7081551551818848, -0.04550784453749657], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -0.25154757499694824, -0.006177972070872784, -0.006157593801617622, -0.001101244823075831, -0.360628604888916, -0.02248215861618519, -0.00347213470377028, -7.152531907195225e-06, -1.0013530300057027e-05, -0.005828527733683586, -1.1920922133867862e-06, -0.0001454247540095821, -1.1920928244535389e-07, -0.0009485750924795866, -0.1305103898048401, -0.016259564086794853], "finish_reason": "stop"}, {"text": " else None, index=np.arange(dtm.shape[0]))", "tokens": [" else", " None", ",", " index", "=", "np", ".", "ar", "ange", "(", "dt", "m", ".", "shape", "[", "0", "]))", "\n"], "logprobs": [-0.019529208540916443, -1.8714900016784668, -1.3404541015625, -0.2615930140018463, -0.17216631770133972, -4.385919570922852, -7.331102824537084e-05, -0.038130924105644226, -9.179073458653875e-06, -0.0016330252401530743, -1.051809549331665, -1.2636104656849056e-05, -0.004177771974354982, -0.021064845845103264, -0.0037675369530916214, -0.02841324731707573, -0.23428143560886383, -0.019981756806373596], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df"], "logprobs": [-0.051002804189920425, -6.90197994117625e-05, -0.0018931577214971185, -3.909988299710676e-05], "finish_reason": "stop"}], "metrics": {"energy": 161.8521038389205, "energy_per_token": 1.3952767572320732, "time": 7.3516917, "time_per_token": 0.0633766525862069}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text).lower().split() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ")", ".", "lower", "()", ".", "split", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -0.3058427572250366, -0.3795720636844635, -0.033408068120479584, -0.06999747455120087, -0.001383539172820747, -0.8996007442474365, -0.725610613822937, -0.03749719262123108, -0.034088753163814545, -0.0004558716027531773, -7.402622577501461e-05, -0.0007539528887718916, -0.006388598587363958, -0.016405340284109116], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -1.073909878730774, -0.00020144341397099197, -0.00028951745480298996, -0.044072624295949936, -0.00865234062075615, -0.0012244831304997206, -0.00035065223346464336, -0.002056628232821822, -0.02010420896112919, -0.01904475875198841, -0.0014748420799151063, -0.000797311426140368, -5.590759246842936e-05, -0.026396585628390312, -7.211902266135439e-05, -7.152555099310121e-07, -1.4305012882687151e-05, -0.0052262828685343266, -0.0011199399596080184], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), index=texts, columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " index", "=", "text", "s", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -0.25154757499694824, -0.006177972070872784, -0.006157593801617622, -0.001101244823075831, -1.3944039344787598, -0.02731083333492279, -0.9184310436248779, -0.0015447123441845179, -0.0372893400490284, -0.0020478246733546257, -0.016540424898266792, -0.004469405394047499, -1.537788011773955e-05, -1.2159273865108844e-05, -0.006336953025311232, -4.768370445162873e-07, -0.00020382710499688983, -1.1920928244535389e-07, -0.0022033003624528646, -0.10056035220623016, -0.019421299919486046], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names(), index= text for text in texts)", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " index", "=", " text", " for", " text", " in", " texts", ")", "\n"], "logprobs": [-0.019712261855602264, -0.5717103481292725, -8.928377064876258e-05, -0.0010484919184818864, -0.1334025114774704, -0.00010823617776622996, -0.0030411682091653347, -8.21318244561553e-05, -0.0017560789128765464, -0.9660505056381226, -0.09981503337621689, -0.22391030192375183, -0.21299828588962555, -4.115907669067383, -1.6326706409454346, -0.017845194786787033, -0.011169171892106533, -0.6563549637794495, -0.04927671328186989, -0.022848786786198616], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.05735839903354645, -7.331102824537084e-05, -0.0015018623089417815, -4.8636207793606445e-05, -0.9541107416152954], "finish_reason": "stop"}], "metrics": {"energy": 156.9834180631637, "energy_per_token": 1.330367949687828, "time": 7.36019, "time_per_token": 0.06237449152542373}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-1.2304216623306274, -0.014714173972606659], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -0.961950421333313, -0.014658844098448753, -0.057944800704717636, -0.055783968418836594, -0.0006480501033365726, -0.0004295380203984678, -3.766942609217949e-05, -0.04413753002882004, -7.438383181579411e-05, -2.0265558760002023e-06, -1.2516897186287679e-05, -0.0032663585152477026, -0.0015555436257272959], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), index=vectorized_texts)", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " index", "=", "vector", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -0.25154757499694824, -0.006177972070872784, -0.006157593801617622, -0.001101244823075831, -1.3944039344787598, -0.02731083333492279, -1.2141215801239014, -1.0209912061691284, -3.8742269680369645e-05, -0.0025142983067780733, -0.22358644008636475, -2.6768810749053955, -0.05770886316895485], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.019712261855602264, -0.5717103481292725, -8.928377064876258e-05, -0.0010484919184818864, -0.1334025114774704, -0.00010823617776622996, -0.0030411682091653347, -8.21318244561553e-05, -0.0017560789128765464, -0.49872148036956787, -0.021349262446165085], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df"], "logprobs": [-0.05735839903354645, -7.331102824537084e-05, -0.0015018623089417815, -4.8636207793606445e-05], "finish_reason": "stop"}], "metrics": {"energy": 143.33190218544007, "energy_per_token": 2.0475986026491437, "time": 5.4735193, "time_per_token": 0.07819313285714287}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text).lower().strip().split() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ")", ".", "lower", "()", ".", "strip", "()", ".", "split", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -0.3058427572250366, -0.3795720636844635, -0.033408068120479584, -0.06999747455120087, -0.001383539172820747, -0.8996007442474365, -0.710809588432312, -0.006883479189127684, -2.6737937927246094, -0.035970039665699005, -0.10120610892772675, -0.06707607209682465, -0.00040284625720232725, -7.950943836476654e-05, -0.0007388246012851596, -0.011172355152666569, -0.014474979601800442], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -0.961950421333313, -0.014658844098448753, -0.057944800704717636, -0.055783968418836594, -0.0006480501033365726, -0.0004295380203984678, -3.766942609217949e-05, -0.04413753002882004, -7.438383181579411e-05, -2.0265558760002023e-06, -1.2516897186287679e-05, -0.0032663585152477026, -0.0015555436257272959], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform(tokenized_texts).toarray(), index=texts, columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", ".", "to", "array", "()", ",", " index", "=", "text", "s", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-1.9018622636795044, -1.6689160474925302e-05, -0.007498452439904213, -0.02244695834815502, -0.03257957845926285, -7.033323527139146e-06, -2.95634672511369e-05, -0.0026763593778014183, -0.0001382732152706012, -0.00010442188795423135, -0.006943383254110813, -0.013187568634748459, -8.702239938429557e-06, -5.030505417380482e-05, -3.4570634852570947e-06, -2.5510462364763953e-05, -0.11155803501605988, -0.006090888753533363, -0.0887315571308136, -0.0145249143242836, -0.10225436091423035, -0.004305498208850622, -1.57328200340271, -0.03525162115693092, -0.7674960494041443, -0.0011337526375427842, -0.04343169182538986, -0.021778594702482224, -0.017842968925833702, -0.007083422504365444, -2.610649426060263e-05, -1.966933996300213e-05, -0.005212052259594202, -4.768370445162873e-07, -0.0002694958820939064, -4.768370445162873e-07, -0.0023557788226753473, -0.13252758979797363, -0.03628186509013176], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.01139301061630249, -0.00016616393986623734, -0.0041642384603619576, -0.011126496829092503, -0.05456686019897461, -5.960446742392378e-06, -0.001142087858170271, -1.7665170431137085, -9.107174992095679e-05, -0.014169207774102688, -0.04185139387845993, -0.0020077326335012913, -0.415169894695282, -0.021555902436375618, -0.003999212756752968, -9.417489309271332e-06, -1.1444026313256472e-05, -0.01045028492808342, -1.1920922133867862e-06, -0.00016711745411157608, -1.1920928244535389e-07, -0.001158996019512415, -0.18502388894557953, -0.026246335357427597], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names(), index= [str(text) for text in texts])", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " index", "=", " [", "str", "(", "text", ")", " for", " text", " in", " texts", "])", "\n"], "logprobs": [-0.020104091614484787, -0.49390485882759094, -0.00014041867689229548, -0.0010452766437083483, -0.13518856465816498, -9.953480184776708e-05, -0.002796669490635395, -9.297892393078655e-05, -0.0021328814327716827, -0.9307152032852173, -0.10501814633607864, -0.25621268153190613, -0.21260562539100647, -2.4266161918640137, -3.836848735809326, -0.011155614629387856, -2.089176654815674, -0.13417553901672363, -0.07122582197189331, -0.023346422240138054, -0.0025840960443019867, -0.4436326026916504, -0.030843442305922508, -0.024279749020934105], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.06023320183157921, -6.09140915912576e-05, -0.0019945267122238874, -4.589452510117553e-05, -0.8309428095817566], "finish_reason": "stop"}], "metrics": {"energy": 207.24046471786488, "energy_per_token": 1.4802890336990349, "time": 9.041057, "time_per_token": 0.06457897857142858}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-1.2304216623306274, -0.014714173972606659], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -0.961950421333313, -0.014658844098448753, -0.057944800704717636, -0.055783968418836594, -0.0006480501033365726, -0.0004295380203984678, -3.766942609217949e-05, -0.04413753002882004, -7.438383181579411e-05, -2.0265558760002023e-06, -1.2516897186287679e-05, -0.0032663585152477026, -0.0015555436257272959], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -0.25154757499694824, -0.006177972070872784, -0.006157593801617622, -0.001101244823075831, -0.360628604888916, -0.02248215861618519, -0.00347213470377028, -7.152531907195225e-06, -1.0013530300057027e-05, -0.005828527733683586, -1.1920922133867862e-06, -0.0001454247540095821, -1.1920928244535389e-07, -0.0009485750924795866, -0.1305103898048401, -0.016259564086794853], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names(), index=texts)", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " index", "=", "text", "s", ")", "\n"], "logprobs": [-0.019529208540916443, -0.5104995369911194, -0.00011777184408856556, -0.001111961784772575, -0.12247985601425171, -9.77468371274881e-05, -0.0027870405465364456, -8.296622399939224e-05, -0.001416871091350913, -0.9596876502037048, -0.10307077318429947, -0.21706613898277283, -0.19589874148368835, -1.323935627937317, -0.0018964892951771617, -0.029378091916441917, -0.02621207945048809], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.05894036218523979, -7.211902266135439e-05, -0.0018090326339006424, -3.838465272565372e-05, -0.9325190186500549], "finish_reason": "stop"}], "metrics": {"energy": 137.85733009624477, "energy_per_token": 1.7232166262030595, "time": 6.135869, "time_per_token": 0.07669836249999999}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-1.2304216623306274, -0.014714173972606659], "finish_reason": "stop"}, {"text": " [token.split() for token in cleaned_texts]", "tokens": [" [", "token", ".", "split", "()", " for", " token", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -3.309324264526367, -1.347630500793457, -0.06939419358968735, -0.10235992819070816, -0.0018398514948785305, -0.08481278270483017, -0.00024089295766316354, -0.03280409798026085, -8.082063141046092e-05, -3.2186455882765586e-06, -4.887569048150908e-06, -0.015880538150668144, -0.002244930947199464], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts).toarray()", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", ".", "to", "array", "()", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -2.6309847831726074, -0.20709559321403503, -0.2260572612285614, -0.0007744412287138402, -0.025891872122883797], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), index=texts, columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " index", "=", "text", "s", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -0.25154757499694824, -0.006177972070872784, -0.006157593801617622, -0.001101244823075831, -1.3944039344787598, -0.02731083333492279, -0.9184310436248779, -0.0015447123441845179, -0.0372893400490284, -0.0020478246733546257, -0.016540424898266792, -0.004469405394047499, -1.537788011773955e-05, -1.2159273865108844e-05, -0.006336953025311232, -4.768370445162873e-07, -0.00020382710499688983, -1.1920928244535389e-07, -0.0022033003624528646, -0.10056035220623016, -0.019421299919486046], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.019712261855602264, -0.5717103481292725, -8.928377064876258e-05, -0.0010484919184818864, -0.1334025114774704, -0.00010823617776622996, -0.0030411682091653347, -8.21318244561553e-05, -0.0017560789128765464, -0.49872148036956787, -0.021349262446165085], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df"], "logprobs": [-0.05735839903354645, -7.331102824537084e-05, -0.0015018623089417815, -4.8636207793606445e-05], "finish_reason": "stop"}], "metrics": {"energy": 125.87864640808104, "energy_per_token": 1.5351054440009884, "time": 5.882097, "time_per_token": 0.07173289024390243}}
{"outputs": [{"text": " [ALPHANUMERIC.sub('', text).lower() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", "'", ",", " text", ")", ".", "lower", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.8775860071182251, -0.00014435203047469258, -0.3691330552101135, -0.46504664421081543, -0.04510852321982384, -0.018077027052640915, -0.0015046000480651855, -0.5547010898590088, -0.0007022537174634635, -0.00011407678539399058, -0.0006098079611547291, -0.01842888817191124, -0.015234891325235367], "finish_reason": "stop"}, {"text": " [word.split() for text in cleaned_texts for word in text.split(',')]", "tokens": [" [", "word", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", " for", " word", " in", " text", ".", "split", "('", ",", "')", "]", "\n"], "logprobs": [-0.05564460903406143, -2.4775466918945312, -0.7969019412994385, -0.08336590975522995, -0.1096985712647438, -0.001921832445077598, -1.0815225839614868, -0.000805053801741451, -0.1275676041841507, -9.643566590966657e-05, -3.2186455882765586e-06, -7.629365427419543e-06, -0.3339983820915222, -0.000726197671610862, -0.00019536493346095085, -0.04197874292731285, -0.025371793657541275, -0.05431770533323288, -0.8598238825798035, -1.6761939525604248, -0.0328819639980793, -0.12497704476118088, -0.00984562374651432], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform(tokenized_texts).toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-1.9018622636795044, -1.6689160474925302e-05, -0.007498452439904213, -0.02244695834815502, -0.03257957845926285, -7.033323527139146e-06, -2.95634672511369e-05, -0.0026763593778014183, -0.0001382732152706012, -0.00010442188795423135, -0.006943383254110813, -0.013187568634748459, -8.702239938429557e-06, -5.030505417380482e-05, -3.4570634852570947e-06, -2.5510462364763953e-05, -0.11155803501605988, -0.006090888753533363, -0.0887315571308136, -0.0145249143242836, -0.10225436091423035, -0.004305498208850622, -0.8696419596672058, -0.01642856001853943, -0.006376634817570448, -3.135155202471651e-05, -1.597391747054644e-05, -0.007723232731223106, -5.960462772236497e-07, -0.0001811817055568099, -1.4305104514278355e-06, -0.0023462644312530756, -0.6033183336257935, -0.04052596911787987], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.01139301061630249, -0.00016616393986623734, -0.0041642384603619576, -0.011126496829092503, -0.05456686019897461, -5.960446742392378e-06, -0.001142087858170271, -0.20451104640960693, -0.006021216977387667, -0.004727852065116167, -0.0009677494526840746, -0.4257713854312897, -0.023752428591251373, -0.004288168158382177, -9.65590606938349e-06, -9.65590606938349e-06, -0.004881369415670633, -1.0728830375228426e-06, -0.00017176583060063422, -1.1920928244535389e-07, -0.000894146622158587, -0.14723335206508636, -0.015751700848340988], "finish_reason": "stop"}, {"text": " else None, index=texts)", "tokens": [" else", " None", ",", " index", "=", "text", "s", ")", "\n"], "logprobs": [-0.01996142417192459, -1.6337916851043701, -1.4349212646484375, -0.23282977938652039, -0.1907302290201187, -1.4952367544174194, -0.0015714927576482296, -0.06038516387343407, -0.021527433767914772], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df"], "logprobs": [-0.05485951155424118, -6.16293036728166e-05, -0.0012840130366384983, -5.030505417380482e-05], "finish_reason": "stop"}], "metrics": {"energy": 183.90593104267123, "energy_per_token": 1.519883727625382, "time": 7.9978733, "time_per_token": 0.06609812644628099}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-1.2304216623306274, -0.014714173972606659], "finish_reason": "stop"}, {"text": " [ALPHANUMERIC.sub(' ', text).lower().split() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ")", ".", "lower", "()", ".", "split", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.05564460903406143, -2.454538345336914, -6.222531374078244e-05, -4.8397800128441304e-05, -0.00031609306461177766, -1.585470999998506e-05, -0.0006093314150348306, -9.07141511561349e-05, -0.006861221045255661, -0.004506669472903013, -0.036930497735738754, -0.00026901919045485556, -0.008954014629125595, -0.011055760085582733, -0.08316551148891449, -0.4057275652885437, -0.00027700403006747365, -0.12078176438808441, -0.045460574328899384, -0.021055158227682114, -0.014426805078983307, -0.0002493547508493066, -4.9470632802695036e-05, -0.6016818284988403, -0.0013036570744588971, -0.003975347150117159], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), index=tokenized_texts, columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " index", "=", "token", "ized", "_", "text", "s", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -1.5738017559051514, -9.77468371274881e-05, -0.016980381682515144, -0.03800400346517563, -0.0018600797047838569, -1.163374662399292, -0.013533863238990307, -1.9045939445495605, -0.00036030475166626275, -0.0005326044629327953, -5.209310256759636e-05, -9.179073458653875e-06, -0.023185230791568756, -0.00788054894655943, -0.047061000019311905, -0.005760852713137865, -2.0861407392658293e-05, -1.4305012882687151e-05, -0.007018436212092638, -5.960462772236497e-07, -0.00021360022947192192, -1.1920928244535389e-07, -0.003440653206780553, -0.07639699429273605, -0.019642364233732224], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.019877053797245026, -0.5352551937103271, -0.00012170527770649642, -0.0009548871894367039, -0.13353998959064484, -9.595887240720913e-05, -0.003407863900065422, -7.855583680793643e-05, -0.0014466306893154979, -0.49523645639419556, -0.023712266236543655], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.055180732160806656, -6.592056161025539e-05, -0.0019966682884842157, -4.2676016164477915e-05, -1.1839791536331177, -2.861018856492592e-06, -1.311301275563892e-06, -1.645074735279195e-05, -0.000248401309363544, -0.0591496042907238], "finish_reason": "stop"}], "metrics": {"energy": 166.59285428142547, "energy_per_token": 1.6659285428142547, "time": 6.939019, "time_per_token": 0.06939019}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text.lower()).strip() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ".", "lower", "())", ".", "strip", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -0.3058427572250366, -1.1567574739456177, -0.06783348321914673, -0.01909586787223816, -0.43795621395111084, -0.2285831719636917, -0.0044964635744690895, -0.08017048984766006, -0.00041345154750160873, -8.201262971851975e-05, -0.0007540719816461205, -0.017260339111089706, -0.014919133856892586], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -0.961950421333313, -0.014658844098448753, -0.057944800704717636, -0.055783968418836594, -0.0006480501033365726, -0.0004295380203984678, -3.766942609217949e-05, -0.04413753002882004, -7.438383181579411e-05, -2.0265558760002023e-06, -1.2516897186287679e-05, -0.0032663585152477026, -0.0015555436257272959], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform(tokenized_texts).todense())", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", ".", "t", "od", "ense", "())", "\n"], "logprobs": [-1.9018622636795044, -1.6689160474925302e-05, -0.007498452439904213, -0.02244695834815502, -0.03257957845926285, -7.033323527139146e-06, -2.95634672511369e-05, -0.0026763593778014183, -0.0001382732152706012, -0.00010442188795423135, -0.006943383254110813, -0.013187568634748459, -8.702239938429557e-06, -5.030505417380482e-05, -3.4570634852570947e-06, -2.5510462364763953e-05, -0.11155803501605988, -0.006090888753533363, -2.548400640487671, -0.00017569905321579427, -0.0390600748360157, -0.576485276222229, -0.071193628013134], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), index=vectorizer.get_feature_names(), columns=range(dtm.shape[1]))", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " index", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " columns", "=", "range", "(", "dt", "m", ".", "shape", "[", "1", "]))", "\n"], "logprobs": [-0.01139301061630249, -0.00016616393986623734, -0.0041642384603619576, -0.011126496829092503, -0.05456686019897461, -5.960446742392378e-06, -0.001142087858170271, -0.20451104640960693, -0.006021216977387667, -0.004727852065116167, -0.0009677494526840746, -1.2132869958877563, -0.02962983399629593, -1.264916181564331, -0.5530866980552673, -0.00021038226259406656, -0.12897783517837524, -2.264974000354414e-06, -0.0002728328399825841, -2.3841855067985307e-07, -0.0008783058729022741, -0.1055247038602829, -0.0006020640721544623, -0.008026961237192154, -0.37541690468788147, -0.4401281177997589, -0.00017855956684798002, -1.5552581548690796, -0.0001720042055239901, -0.001525192055851221, -0.01972348242998123, -0.006499224808067083, -0.02914249710738659, -0.009993873536586761, -0.021355681121349335], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.02004976198077202, -0.5740742087364197, -0.00012265883560758084, -0.0010677833342924714, -0.15850746631622314, -0.00010895135346800089, -0.0024233281146734953, -7.724463648628443e-05, -0.0015908931382000446, -0.446201354265213, -0.02652173675596714], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.055203065276145935, -7.223821739898995e-05, -0.0015399513067677617, -4.088794958079234e-05, -0.9702907204627991], "finish_reason": "stop"}], "metrics": {"energy": 227.6412622518539, "energy_per_token": 1.9291632394224907, "time": 8.4137335, "time_per_token": 0.07130282627118643}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-1.2304216623306274, -0.014714173972606659], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -0.961950421333313, -0.014658844098448753, -0.057944800704717636, -0.055783968418836594, -0.0006480501033365726, -0.0004295380203984678, -3.766942609217949e-05, -0.04413753002882004, -7.438383181579411e-05, -2.0265558760002023e-06, -1.2516897186287679e-05, -0.0032663585152477026, -0.0015555436257272959], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), index=vectorizer.get_feature_names(), columns=range(dtm.shape[1]))", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " index", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " columns", "=", "range", "(", "dt", "m", ".", "shape", "[", "1", "]))", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -1.5738017559051514, -9.77468371274881e-05, -0.016980381682515144, -0.03800400346517563, -0.0018600797047838569, -1.163374662399292, -0.013533863238990307, -0.7877669334411621, -0.32168129086494446, -0.00017093151109293103, -0.0835469588637352, -2.622600959512056e-06, -0.000285227142740041, -1.1920928244535389e-07, -0.0013406822690740228, -0.11856050789356232, -0.0006777135422453284, -0.011904976330697536, -0.38997185230255127, -0.726691484451294, -0.00018130090029444546, -1.142963171005249, -5.9960475482512265e-05, -0.0007064230740070343, -0.013176157139241695, -0.004517469089478254, -0.014542537741363049, -0.00409882515668869, -0.02549196034669876], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.019877053797245026, -0.5352551937103271, -0.00012170527770649642, -0.0009548871894367039, -0.13353998959064484, -9.595887240720913e-05, -0.003407863900065422, -7.855583680793643e-05, -0.0014466306893154979, -0.49523645639419556, -0.023712266236543655], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df"], "logprobs": [-0.055180732160806656, -6.592056161025539e-05, -0.0019966682884842157, -4.2676016164477915e-05], "finish_reason": "stop"}], "metrics": {"energy": 145.27646750450134, "energy_per_token": 1.6892612500523412, "time": 5.881647, "time_per_token": 0.06839124418604652}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-1.2304216623306274, -0.014714173972606659], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -0.961950421333313, -0.014658844098448753, -0.057944800704717636, -0.055783968418836594, -0.0006480501033365726, -0.0004295380203984678, -3.766942609217949e-05, -0.04413753002882004, -7.438383181579411e-05, -2.0265558760002023e-06, -1.2516897186287679e-05, -0.0032663585152477026, -0.0015555436257272959], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), index=texts, columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " index", "=", "text", "s", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -0.25154757499694824, -0.006177972070872784, -0.006157593801617622, -0.001101244823075831, -1.3944039344787598, -0.02731083333492279, -0.9184310436248779, -0.0015447123441845179, -0.0372893400490284, -0.0020478246733546257, -0.016540424898266792, -0.004469405394047499, -1.537788011773955e-05, -1.2159273865108844e-05, -0.006336953025311232, -4.768370445162873e-07, -0.00020382710499688983, -1.1920928244535389e-07, -0.0022033003624528646, -0.10056035220623016, -0.019421299919486046], "finish_reason": "stop"}, {"text": " else [], index= [", "tokens": [" else", " []", ",", " index", "=", " [", "\n"], "logprobs": [-0.019712261855602264, -2.477285146713257, -0.05557052418589592, -0.2005130499601364, -0.23122277855873108, -2.324192523956299, -3.5986328125], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df"], "logprobs": [-0.057951997965574265, -6.675497570540756e-05, -0.002261820714920759, -4.303362584323622e-05], "finish_reason": "stop"}], "metrics": {"energy": 127.07834056472781, "energy_per_token": 1.7172748724963218, "time": 5.861367, "time_per_token": 0.07920766216216217}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text.lower()).strip() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ".", "lower", "())", ".", "strip", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -0.3058427572250366, -1.1567574739456177, -0.06783348321914673, -0.01909586787223816, -0.43795621395111084, -0.2285831719636917, -0.0044964635744690895, -0.08017048984766006, -0.00041345154750160873, -8.201262971851975e-05, -0.0007540719816461205, -0.017260339111089706, -0.014919133856892586], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -0.961950421333313, -0.014658844098448753, -0.057944800704717636, -0.055783968418836594, -0.0006480501033365726, -0.0004295380203984678, -3.766942609217949e-05, -0.04413753002882004, -7.438383181579411e-05, -2.0265558760002023e-06, -1.2516897186287679e-05, -0.0032663585152477026, -0.0015555436257272959], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -0.25154757499694824, -0.006177972070872784, -0.006157593801617622, -0.001101244823075831, -0.360628604888916, -0.02248215861618519, -0.00347213470377028, -7.152531907195225e-06, -1.0013530300057027e-05, -0.005828527733683586, -1.1920922133867862e-06, -0.0001454247540095821, -1.1920928244535389e-07, -0.0009485750924795866, -0.1305103898048401, -0.016259564086794853], "finish_reason": "stop"}, {"text": " else [], index=['Doc-1', 'Doc-2', 'Doc-3'])", "tokens": [" else", " []", ",", " index", "=['", "Doc", "-", "1", "'", ",", " '", "Doc", "-", "2", "'", ",", " '", "Doc", "-", "3", "'])", "\n"], "logprobs": [-0.019529208540916443, -2.6530699729919434, -0.06608501076698303, -0.21961340308189392, -2.7548327445983887, -4.136898994445801, -3.3409645557403564, -1.4200892448425293, -0.5574636459350586, -0.001733468729071319, -0.32587915658950806, -0.004212554078549147, -0.002126814564689994, -0.0019132657907903194, -0.015450427308678627, -0.00043394684325903654, -0.11427361518144608, -0.0026953816413879395, -0.0018202179344370961, -0.0011818574275821447, -0.02813616394996643, -0.01943182200193405], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df"], "logprobs": [-0.051002804189920425, -6.90197994117625e-05, -0.0018931577214971185, -3.909988299710676e-05], "finish_reason": "stop"}], "metrics": {"energy": 174.67614893722538, "energy_per_token": 1.632487373245097, "time": 7.560875, "time_per_token": 0.07066238317757009}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text).lower() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ")", ".", "lower", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -0.3058427572250366, -0.3795720636844635, -0.033408068120479584, -0.06999747455120087, -0.001383539172820747, -0.5623471736907959, -0.0006177900941111147, -9.250213042832911e-05, -0.0006170752458274364, -0.010922761633992195, -0.016307415440678596], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -0.961950421333313, -0.014658844098448753, -0.057944800704717636, -0.055783968418836594, -0.0006480501033365726, -0.0004295380203984678, -3.766942609217949e-05, -0.04413753002882004, -7.438383181579411e-05, -2.0265558760002023e-06, -1.2516897186287679e-05, -0.0032663585152477026, -0.0015555436257272959], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), index=range(1, dtm.shape[0] + 1), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " index", "=", "range", "(", "1", ",", " d", "tm", ".", "shape", "[", "0", "]", " +", " ", "1", ")", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -1.5738017559051514, -9.77468371274881e-05, -0.016980381682515144, -0.03800400346517563, -0.0018600797047838569, -1.163374662399292, -0.013533863238990307, -3.268123149871826, -0.00016366096679121256, -1.0550676584243774, -0.0029362207278609276, -1.6254605054855347, -5.376194530981593e-05, -0.0018160531762987375, -0.030959833413362503, -0.001479484373703599, -0.023062689229846, -0.39402833580970764, -0.0005383234238252044, -0.00396727304905653, -0.0003293210465926677, -0.017221789807081223, -0.00016783259343355894, -0.035946235060691833, -0.05380780249834061, -0.02503259852528572, -1.8954096958623268e-05, -1.7404405298293568e-05, -0.006962798070162535, -7.152555099310121e-07, -0.0002388668799540028, -1.1920928244535389e-07, -0.0024700628127902746, -0.1089395135641098, -0.01914229802787304], "finish_reason": "stop"}, {"text": " else None)", "tokens": [" else", " None", ")", "\n"], "logprobs": [-0.019877053797245026, -1.8114221096038818, -0.27375394105911255, -0.032587308436632156], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.06330052763223648, -6.580135959666222e-05, -0.0018841149285435677, -4.708655978902243e-05, -1.0798332691192627], "finish_reason": "stop"}], "metrics": {"energy": 188.47576822090153, "energy_per_token": 1.761455777765435, "time": 7.5478764, "time_per_token": 0.07054090093457943}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text.lower()) for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ".", "lower", "())", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -0.3058427572250366, -1.1567574739456177, -0.06783348321914673, -0.01909586787223816, -1.053930640220642, -0.0009302341495640576, -7.784063927829266e-05, -0.0006509092636406422, -0.012613166123628616, -0.029514214023947716], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -0.961950421333313, -0.014658844098448753, -0.057944800704717636, -0.055783968418836594, -0.0006480501033365726, -0.0004295380203984678, -3.766942609217949e-05, -0.04413753002882004, -7.438383181579411e-05, -2.0265558760002023e-06, -1.2516897186287679e-05, -0.0032663585152477026, -0.0015555436257272959], "finish_reason": "stop"}, {"text": " CountVectorizer(min_df=0.001, max_features=0.25, stop_words=STOPWORDS)", "tokens": [" Count", "Vector", "izer", "(", "min", "_", "df", "=", "0", ".", "0", "0", "1", ",", " max", "_", "features", "=", "0", ".", "2", "5", ",", " stop", "_", "words", "=", "ST", "OP", "W", "OR", "DS", ")", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -1.2911405563354492, -3.43257999420166, -3.6954811548639555e-06, -0.008734592236578465, -0.011094076558947563, -1.4855661392211914, -0.03988837078213692, -0.693595290184021, -1.1483620405197144, -0.8023359775543213, -0.18018387258052826, -0.235049769282341, -0.00017510310863144696, -2.4745917320251465, -0.002272168407216668, -3.4405393600463867, -0.16978275775909424, -1.5295923948287964, -1.1149181127548218, -0.7860308289527893, -0.5905942320823669, -3.1709168979432434e-05, -0.0004702892620116472, -0.5682553052902222, -0.23442034423351288, -1.311301275563892e-06, -8.201262971851975e-05, -0.00021228920377325267, -1.3947389561508317e-05, -0.13716351985931396, -0.03558909520506859], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -0.25154757499694824, -0.006177972070872784, -0.006157593801617622, -0.001101244823075831, -0.360628604888916, -0.02248215861618519, -0.00347213470377028, -7.152531907195225e-06, -1.0013530300057027e-05, -0.005828527733683586, -1.1920922133867862e-06, -0.0001454247540095821, -1.1920928244535389e-07, -0.0009485750924795866, -0.1305103898048401, -0.016259564086794853], "finish_reason": "stop"}, {"text": " else [f\"c{i}\" for i in range(dtm.shape[1])])", "tokens": [" else", " [", "f", "\"", "c", "{", "i", "}\"", " for", " i", " in", " range", "(", "dt", "m", ".", "shape", "[", "1", "]", ")]", ")", "\n"], "logprobs": [-0.019529208540916443, -3.0583319664001465, -1.6881541013717651, -1.5126290321350098, -4.615880489349365, -0.2893756330013275, -0.2037559300661087, -0.056926850229501724, -0.15722733736038208, -0.005643150769174099, -0.05342071130871773, -0.07984509319067001, -0.003951480612158775, -0.32279548048973083, -4.589452510117553e-05, -0.003665278432890773, -0.04283306375145912, -0.015648312866687775, -0.01929537206888199, -0.0021570289973169565, -0.0010443239007145166, -0.2593538761138916, -0.04872642457485199], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.051002804189920425, -6.90197994117625e-05, -0.0018931577214971185, -3.909988299710676e-05, -0.9726603031158447], "finish_reason": "stop"}], "metrics": {"energy": 179.91537991333007, "energy_per_token": 1.332706517876519, "time": 8.17542, "time_per_token": 0.06055866666666667}}
{"outputs": [{"text": " [ALPHANUMERIC.sub('', text.lower()) for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", "'", ",", " text", ".", "lower", "())", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.8775860071182251, -0.00014435203047469258, -0.3691330552101135, -0.9939277172088623, -0.0379500612616539, -0.02182454988360405, -0.37766948342323303, -0.0006974886637181044, -8.987976616481319e-05, -0.0006615119054913521, -0.02000723034143448, -0.03498229756951332], "finish_reason": "stop"}, {"text": " [word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -2.4775466918945312, -1.4737722873687744, -0.007397639565169811, -0.0017849955474957824, -0.0023575627710670233, -0.049335721880197525, -0.015973811969161034, -0.0018184330547228456, -0.0013915151357650757, -7.450303382938728e-05, -0.016950378194451332, -8.248942322097719e-05, -1.4305104514278355e-06, -1.5020257706055418e-05, -0.007542820647358894, -0.001259963377378881], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -0.32204729318618774, -0.007081055082380772], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -0.25154757499694824, -0.006177972070872784, -0.006157593801617622, -0.001101244823075831, -0.360628604888916, -0.02248215861618519, -0.00347213470377028, -7.152531907195225e-06, -1.0013530300057027e-05, -0.005828527733683586, -1.1920922133867862e-06, -0.0001454247540095821, -1.1920928244535389e-07, -0.0009485750924795866, -0.1305103898048401, -0.016259564086794853], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names(), index= texts)", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " index", "=", " texts", ")", "\n"], "logprobs": [-0.019529208540916443, -0.5104995369911194, -0.00011777184408856556, -0.001111961784772575, -0.12247985601425171, -9.77468371274881e-05, -0.0027870405465364456, -8.296622399939224e-05, -0.001416871091350913, -0.9596876502037048, -0.10307077318429947, -0.21706613898277283, -0.19589874148368835, -1.7958956956863403, -0.041414812207221985, -0.02497539483010769], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.05894036218523979, -7.211902266135439e-05, -0.0018090326339006424, -3.838465272565372e-05, -1.0506982803344727, -2.7418097943154862e-06, -1.1920922133867862e-06, -1.4543427823809907e-05, -0.00024327656137757003, -0.05091104283928871], "finish_reason": "stop"}], "metrics": {"energy": 151.70123552513124, "energy_per_token": 1.4177685563096378, "time": 6.920245, "time_per_token": 0.06467518691588786}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text.lower()).strip() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ".", "lower", "())", ".", "strip", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-0.4037958085536957, -0.08559660613536835, -3.3378546504536644e-06, -0.0001113352773245424, -2.7417760065873154e-05, -7.867782187531702e-06, -0.00011789103882620111, -0.00038580605178140104, -0.00036864637513644993, -0.053412459790706635, -0.5389457941055298, -0.0019945267122238874, -0.3058427572250366, -1.1567574739456177, -0.06783348321914673, -0.01909586787223816, -0.43795621395111084, -0.2285831719636917, -0.0044964635744690895, -0.08017048984766006, -0.00041345154750160873, -8.201262971851975e-05, -0.0007540719816461205, -0.017260339111089706, -0.014919133856892586], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.05564460903406143, -1.073909878730774, -0.00020144341397099197, -0.00028951745480298996, -0.044072624295949936, -0.00865234062075615, -0.0012244831304997206, -0.00035065223346464336, -0.002056628232821822, -0.02010420896112919, -0.01904475875198841, -0.0014748420799151063, -0.000797311426140368, -5.590759246842936e-05, -0.026396585628390312, -7.211902266135439e-05, -7.152555099310121e-07, -1.4305012882687151e-05, -0.0052262828685343266, -0.0011199399596080184], "finish_reason": "stop"}, {"text": " CountVectorizer(tokenizer=lambda s: s.split())", "tokens": [" Count", "Vector", "izer", "(", "token", "izer", "=", "lambda", " s", ":", " s", ".", "split", "())", "\n"], "logprobs": [-0.00024232311989180744, -1.3112935448589269e-05, -5.280832192511298e-05, -1.2911405563354492, -1.8886595964431763, -0.03511996194720268, -0.04818446561694145, -0.2539448142051697, -2.553325891494751, -0.001992385368794203, -0.05949034169316292, -0.06418949365615845, -0.013758349232375622, -0.17757755517959595, -0.0121897729113698], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.16664423048496246, -1.823885577323381e-05, -2.8609820219571702e-05, -0.0007434703293256462, -7.354942499659956e-05, -9.60780744208023e-05, -0.0022878681775182486, -0.0032428319100290537, -1.0847986231965479e-05, -2.2172682292875834e-05, -2.3841830625315197e-06, -2.50339189733495e-06, -0.003575719427317381, -0.08568906784057617], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), index=vectorized_texts, columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " index", "=", "vector", "ized", "_", "text", "s", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.010729127563536167, -0.00014220656885299832, -0.0029922020621597767, -0.011129207909107208, -0.054519787430763245, -4.887569048150908e-06, -0.0013778250431641936, -0.25154757499694824, -0.006177972070872784, -0.006157593801617622, -0.001101244823075831, -1.3944039344787598, -0.02731083333492279, -1.2141215801239014, -1.0209912061691284, -3.8742269680369645e-05, -0.0025142983067780733, -0.22358644008636475, -0.07461288571357727, -0.00697783287614584, -0.02879508025944233, -0.00505455257371068, -0.00025912740966305137, -2.4914430468925275e-05, -0.009958701208233833, -4.768370445162873e-07, -0.00019560330838430673, -1.1920928244535389e-07, -0.00305031961761415, -0.08470030128955841, -0.020076168701052666], "finish_reason": "stop"}, {"text": " else None)", "tokens": [" else", " None", ")", "\n"], "logprobs": [-0.019712261855602264, -1.7170865535736084, -0.33802253007888794, -0.029333988204598427], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df"], "logprobs": [-0.057951997965574265, -6.675497570540756e-05, -0.002261820714920759, -4.303362584323622e-05], "finish_reason": "stop"}], "metrics": {"energy": 194.58838241004946, "energy_per_token": 1.722021083274774, "time": 7.590772, "time_per_token": 0.06717497345132743}}
