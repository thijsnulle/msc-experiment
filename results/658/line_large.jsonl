{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -1.678538203239441, -0.0016780118457973003, -0.004253388848155737, -0.012610340490937233, -0.00034397884155623615, -2.6225699912174605e-05, -1.6093124941107817e-05, -0.0007512131123803556, -8.344646857949556e-07, -3.3378546504536644e-06, -7.83174327807501e-05, -0.0015584002248942852, -0.014433620497584343], "finish_reason": "stop"}, {"text": " CountVectorizer(lowercase=False)", "tokens": [" Count", "Vector", "izer", "(", "low", "erc", "ase", "=", "False", ")", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -1.0701202154159546, -2.354997158050537, -0.00029392691794782877, -3.802703940891661e-05, -0.0028140253853052855, -0.21449342370033264, -0.24213652312755585, -0.26485946774482727], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -0.3088756799697876], "finish_reason": "stop"}], "metrics": {"energy": 512.6362747116091, "energy_per_token": 6.25166188672694, "time": 15.537491, "time_per_token": 0.1894815975609756}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [[word for word in text.split() if word not in STOPWORDS] for text in cleaned_texts]", "tokens": [" [[", "word", " for", " word", " in", " text", ".", "split", "()", " if", " word", " not", " in", " ST", "OP", "W", "OR", "DS", "]", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-2.1259605884552, -0.24680855870246887, -0.003709461074322462, -0.00014733182615600526, -9.798523387871683e-05, -0.3390404284000397, -0.0032480601221323013, -0.0052490513771772385, -0.07372085005044937, -0.00859064795076847, -0.0034006168134510517, -0.015855547040700912, -4.31528314948082e-05, -0.002035690238699317, 0.0, -6.437280717364047e-06, 0.0, 0.0, -0.0037108862306922674, -0.11522508412599564, -0.0002949994814116508, -7.915183232398704e-05, -0.0009831124916672707, -5.960462772236497e-07, -1.4305104514278355e-06, -3.4450891689630225e-05, -0.0003843760641757399, -0.007495020981878042], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -0.4201759099960327, -0.02241327054798603], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": " else", "tokens": [" else", "\n"], "logprobs": [-0.14558722078800201, -1.8179439306259155], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.00597832165658474, -8.702239938429557e-06, -0.0018488947534933686, -0.0001209901092806831, -1.806975245475769, -1.6689160474925302e-05, -7.867782187531702e-06, -5.8412379075889476e-06, -1.5735502529423684e-05, -0.11834988743066788], "finish_reason": "stop"}], "metrics": {"energy": 525.0326810798643, "energy_per_token": 6.10503117534726, "time": 15.972933, "time_per_token": 0.18573177906976743}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [[token for token in text.split(' ') if token not in STOPWORDS] for text in cleaned_texts]", "tokens": [" [[", "token", " for", " token", " in", " text", ".", "split", "('", " '", ")", " if", " token", " not", " in", " ST", "OP", "W", "OR", "DS", "]", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-2.1259605884552, -2.0513663291931152, -0.012216034345328808, -0.00032669928623363376, -9.238292841473594e-05, -0.2854316234588623, -0.006453388370573521, -0.009531821124255657, -1.957546353340149, -0.0003864018653985113, -0.009573973715305328, -0.028607426211237907, -0.01200875174254179, -0.28381162881851196, -5.876845170860179e-05, -0.0009067714563570917, 0.0, -5.722029527532868e-06, 0.0, -2.3841855067985307e-07, -0.0341007336974144, -0.25871896743774414, -0.0007256020326167345, -0.00012242044613230973, -0.0025346316397190094, -4.768370445162873e-07, -1.311301275563892e-06, -3.766942609217949e-05, -0.00047434045700356364, -0.006478379480540752], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -0.4201759099960327, -0.02241327054798603], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -2.9358954429626465, -1.8000440832111053e-05, -0.00034433635300956666, -0.007598071824759245, -0.0034786683972924948, -0.008916798047721386, -0.002362676663324237, -0.0023401989601552486, -1.0728830375228426e-06, -5.245195097813848e-06, -0.000942977552767843, -4.768370445162873e-07, -7.748573807475623e-06, 0.0, -4.5060096454108134e-05, -0.4537903070449829, -0.005405453033745289, -0.0208175927400589, -0.0045211478136479855], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.1458633691072464, -0.2093726247549057, -0.0002044230350293219, -0.008356604725122452, -0.005107332020998001, -0.00019441144831944257, -5.781483559985645e-05, -1.3828182090946939e-05, -1.3232143828645349e-05, -0.01891644485294819, -0.004647287540137768], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.006538189947605133, -1.0013530300057027e-05, -0.002384559018537402, -0.00010644822759786621, -1.7195889949798584, -1.5735502529423684e-05, -8.106198947643861e-06, -9.65590606938349e-06, -3.075552376685664e-05, -0.0947481319308281], "finish_reason": "stop"}], "metrics": {"energy": 546.7553351516725, "energy_per_token": 5.57913607297625, "time": 16.381683, "time_per_token": 0.16716003061224488}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [nltk.tokenize.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "token", "ize", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -2.183624505996704, -7.152531907195225e-06, -0.00016950124700088054, -0.008658604696393013, -0.04936590418219566, -0.0001991788885788992, -5.960462772236497e-07, -0.0030448525212705135, -0.040741730481386185, -0.07512722164392471, -0.002049728063866496, -4.458328112377785e-05, -2.0146166207268834e-05, -0.0020320022013038397, -5.960462772236497e-07, -4.768370445162873e-07, -1.966933996300213e-05, -0.00028880240279249847, -0.011526417918503284], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -0.4201759099960327, -0.02241327054798603], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -1.7170177698135376, -2.074220174108632e-05, -8.940656698541716e-06, -6.9141146923357155e-06, -3.0517112463712692e-05, -0.10522022098302841], "finish_reason": "stop"}], "metrics": {"energy": 511.0233294277191, "energy_per_token": 5.6780369936413235, "time": 15.755522, "time_per_token": 0.17506135555555555}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -0.12287348508834839, -0.003407150972634554, -0.0001934579631779343, -1.311301275563892e-06, -0.00042763148667290807, -0.0264801774173975, -0.01235039159655571, -0.00126008247025311, -5.8053239627042785e-05, -1.2516897186287679e-05, -0.0016831292305141687, -3.576278118089249e-07, -4.768370445162873e-07, -3.3378546504536644e-06, -0.000668659748043865, -0.0129861356690526], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -0.4201759099960327, -0.02241327054798603], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts).todense()", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", ".", "t", "od", "ense", "()", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -2.476853132247925, -1.4176487922668457, -1.1086402082582936e-05, -0.0002520958660170436, -4.1960789531003684e-05, -0.02772103250026703], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -0.3088756799697876], "finish_reason": "stop"}], "metrics": {"energy": 517.8123175373076, "energy_per_token": 5.9518657188196284, "time": 15.330545, "time_per_token": 0.17621316091954023}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -0.12287348508834839, -0.003407150972634554, -0.0001934579631779343, -1.311301275563892e-06, -0.00042763148667290807, -0.0264801774173975, -0.01235039159655571, -0.00126008247025311, -5.8053239627042785e-05, -1.2516897186287679e-05, -0.0016831292305141687, -3.576278118089249e-07, -4.768370445162873e-07, -3.3378546504536644e-06, -0.000668659748043865, -0.0129861356690526], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -0.4201759099960327, -0.02241327054798603], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -1.3527753353118896, -0.0019468179671093822], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -1.7170177698135376, -2.074220174108632e-05, -8.940656698541716e-06, -6.9141146923357155e-06, -3.0517112463712692e-05, -0.10522022098302841], "finish_reason": "stop"}], "metrics": {"energy": 503.15544182586655, "energy_per_token": 5.919475786186665, "time": 15.35368, "time_per_token": 0.18063152941176472}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -0.12287348508834839, -0.003407150972634554, -0.0001934579631779343, -1.311301275563892e-06, -0.00042763148667290807, -0.0264801774173975, -0.01235039159655571, -0.00126008247025311, -5.8053239627042785e-05, -1.2516897186287679e-05, -0.0016831292305141687, -3.576278118089249e-07, -4.768370445162873e-07, -3.3378546504536644e-06, -0.000668659748043865, -0.0129861356690526], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -0.4201759099960327, -0.02241327054798603], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -1.3527753353118896, -0.0019468179671093822], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -0.3088756799697876], "finish_reason": "stop"}], "metrics": {"energy": 570.8827198667524, "energy_per_token": 7.136033998334405, "time": 17.225002, "time_per_token": 0.215312525}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text.lower()) for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ".", "lower", "())", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-1.0674796104431152, -0.6491523385047913, -7.867782187531702e-06, -1.8715683836489916e-05, -1.9073468138230965e-06, -7.152555099310121e-07, 0.0, -0.0005013877525925636, -3.099436753473128e-06, -0.017639191821217537, -0.3929665982723236, -0.0005068686441518366, -0.4038739800453186, -1.0032058954238892, -0.016907714307308197, -0.016824960708618164, -0.49278903007507324, -0.0002615109842736274, -5.9602869441732764e-05, -0.0011214879341423512, -0.009428614750504494, -0.17688271403312683], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -0.12287348508834839, -0.003407150972634554, -0.0001934579631779343, -1.311301275563892e-06, -0.00042763148667290807, -0.0264801774173975, -0.01235039159655571, -0.00126008247025311, -5.8053239627042785e-05, -1.2516897186287679e-05, -0.0016831292305141687, -3.576278118089249e-07, -4.768370445162873e-07, -3.3378546504536644e-06, -0.000668659748043865, -0.0129861356690526], "finish_reason": "stop"}, {"text": " CountVectorizer(token_pattern=r\"[^\\s]+\")", "tokens": [" Count", "Vector", "izer", "(", "token", "_", "pattern", "=", "r", "\"", "[", "^\\", "s", "]+", "\"", ")", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -1.0701202154159546, -0.48875391483306885, -0.14789830148220062, -0.0006962973857298493, -0.035741858184337616, -0.014566857367753983, -0.6532240509986877, -2.424513339996338, -0.9556220173835754, -0.008082776330411434, -0.010129237547516823, -0.0027381805703043938, -0.11121517419815063, -0.32704994082450867], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": " else", "tokens": [" else", "\n"], "logprobs": [-0.14558722078800201, -1.8179439306259155], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.00597832165658474, -8.702239938429557e-06, -0.0018488947534933686, -0.0001209901092806831, -0.29235732555389404], "finish_reason": "stop"}], "metrics": {"energy": 673.3326207561494, "energy_per_token": 6.412691626249042, "time": 19.117249, "time_per_token": 0.1820690380952381}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text.lower()) for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ".", "lower", "())", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-1.0674796104431152, -0.6491523385047913, -7.867782187531702e-06, -1.8715683836489916e-05, -1.9073468138230965e-06, -7.152555099310121e-07, 0.0, -0.0005013877525925636, -3.099436753473128e-06, -0.017639191821217537, -0.3929665982723236, -0.0005068686441518366, -0.4038739800453186, -1.0032058954238892, -0.016907714307308197, -0.016824960708618164, -0.49278903007507324, -0.0002615109842736274, -5.9602869441732764e-05, -0.0011214879341423512, -0.009428614750504494, -0.17688271403312683], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -0.12287348508834839, -0.003407150972634554, -0.0001934579631779343, -1.311301275563892e-06, -0.00042763148667290807, -0.0264801774173975, -0.01235039159655571, -0.00126008247025311, -5.8053239627042785e-05, -1.2516897186287679e-05, -0.0016831292305141687, -3.576278118089249e-07, -4.768370445162873e-07, -3.3378546504536644e-06, -0.000668659748043865, -0.0129861356690526], "finish_reason": "stop"}, {"text": " CountVectorizer(lowercase=True, token_pattern=r'\\b\\w+\\b', min_df=1, max_df=0.25)", "tokens": [" Count", "Vector", "izer", "(", "low", "erc", "ase", "=", "True", ",", " token", "_", "pattern", "=", "r", "'\\", "b", "\\", "w", "+\\", "b", "'", ",", " min", "_", "df", "=", "1", ",", " max", "_", "df", "=", "0", ".", "2", "5", ")", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -1.0701202154159546, -2.354997158050537, -0.00029392691794782877, -3.802703940891661e-05, -0.0028140253853052855, -1.645546555519104, -0.8685794472694397, -0.9142540693283081, -0.103249691426754, -0.00010632903286023065, -0.44105562567710876, -0.03748169168829918, -1.0106605291366577, -0.09336617588996887, -1.0354211330413818, -0.01747637614607811, -0.0049459016881883144, -1.6093124941107817e-05, -2.5579800605773926, -0.00020168177434243262, -2.7502853870391846, -1.0251946150674485e-05, -2.2053474822314456e-05, -0.001427227514795959, -0.16719907522201538, -1.6084219217300415, -0.4046041965484619, -2.3841830625315197e-06, -0.00801891926676035, -0.00038675934774801135, -2.7862696647644043, -0.0031061756890267134, -3.213761329650879, -0.9436770677566528, -0.26311880350112915, -0.03489745780825615], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform(tokenized_texts).todense(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", ".", "t", "od", "ense", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-2.0311920642852783, -1.5497195136049413e-06, -2.610649426060263e-05, -0.002193665597587824, -0.037120964378118515, -1.3589766240329482e-05, -8.606540359323844e-05, -0.0001045410826918669, -1.4305104514278355e-06, -4.291525328881107e-06, -0.00014745102089364082, -0.0034481375478208065, -2.264974000354414e-06, -1.6689286894688848e-06, -3.576278118089249e-07, -3.969590397900902e-05, -0.0013256819220259786, -0.005512275733053684, -0.4627883732318878, -3.58813522325363e-05, -0.00021908267808612436, -0.1694987416267395, -0.006701020989567041, -0.15262599289417267, -0.0051124319434165955, -0.0027295020408928394, -5.960462772236497e-07, -1.07287787614041e-05, -0.0008635367848910391, -3.576278118089249e-07, -6.794906312279636e-06, 0.0, -2.5152843591058627e-05, -0.5764312744140625, -0.03524598479270935, -0.007445917464792728, -0.0020926736760884523], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.0002294515579706058, -1.8954096958623268e-05, -1.3112935448589269e-05, -0.00405347254127264, -0.016089249402284622, -1.1920922133867862e-06, -0.0012807984603568912, -0.09981514513492584, -2.7418097943154862e-06, -0.0054270317777991295, -0.005959480069577694, -0.005923929158598185, -0.002050560899078846, -0.0006625840906053782, -3.576278118089249e-07, -5.602820692729438e-06, -0.00018737945356406271, -3.576278118089249e-07, -7.033323527139146e-06, 0.0, -6.472854875028133e-05, -0.24142660200595856, -0.015009562484920025, -0.0045368121936917305, -0.0021224133670330048], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.145936518907547, -0.23963433504104614, -0.00022265815641731024, -0.010296912863850594, -0.005741651635617018, -0.00023803261865396053, -3.7788631743751466e-05, -1.3828182090946939e-05, -1.168244216387393e-05, -0.02126687578856945, -0.004852898418903351], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.004876031540334225, -1.0013530300057027e-05, -0.0024160738103091717, -0.0001431601122021675, -0.2821747958660126], "finish_reason": "stop"}], "metrics": {"energy": 775.8457261466984, "energy_per_token": 4.87953286884716, "time": 21.629822, "time_per_token": 0.13603661635220127}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [[word for word in text.split() if word not in STOPWORDS] for text in cleaned_texts]", "tokens": [" [[", "word", " for", " word", " in", " text", ".", "split", "()", " if", " word", " not", " in", " ST", "OP", "W", "OR", "DS", "]", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-2.1259605884552, -0.24680855870246887, -0.003709461074322462, -0.00014733182615600526, -9.798523387871683e-05, -0.3390404284000397, -0.0032480601221323013, -0.0052490513771772385, -0.07372085005044937, -0.00859064795076847, -0.0034006168134510517, -0.015855547040700912, -4.31528314948082e-05, -0.002035690238699317, 0.0, -6.437280717364047e-06, 0.0, 0.0, -0.0037108862306922674, -0.11522508412599564, -0.0002949994814116508, -7.915183232398704e-05, -0.0009831124916672707, -5.960462772236497e-07, -1.4305104514278355e-06, -3.4450891689630225e-05, -0.0003843760641757399, -0.007495020981878042], "finish_reason": "stop"}, {"text": " CountVectorizer(min_df=0.5, max_df=0.9, token_pattern='(?u)\\\\b\\\\w+\\\\b')", "tokens": [" Count", "Vector", "izer", "(", "min", "_", "df", "=", "0", ".", "5", ",", " max", "_", "df", "=", "0", ".", "9", ",", " token", "_", "pattern", "='", "(", "?", "u", ")\\\\", "b", "\\\\", "w", "+\\\\", "b", "')", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -1.0701202154159546, -2.9091391563415527, -1.2755313036905136e-05, -1.1324817933200393e-05, -0.010544538497924805, -3.065919876098633, -0.3884744346141815, -2.667917490005493, -0.6373531222343445, -0.3397923707962036, -8.583032467868179e-06, -0.0030669579282402992, -0.0009910915978252888, -0.6884804964065552, -0.00025197668583132327, -0.5287283062934875, -1.5126278400421143, -1.7017970085144043, -0.017899760976433754, -3.683499380713329e-05, -0.5719953775405884, -3.01780104637146, -0.0059547401033341885, -0.020973095670342445, -0.02489493414759636, -0.0038247781340032816, -0.01152559369802475, -0.0008743754005990922, -0.5315365791320801, -0.00019262365822214633, -0.09686987102031708, -0.08153420686721802], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -1.3527753353118896, -0.0019468179671093822], "finish_reason": "stop"}, {"text": "", "tokens": ["\n"], "logprobs": [-2.1053497791290283], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005762985907495022, -8.821448318485636e-06, -0.0024468740448355675, -0.00012134769349358976, -0.2891768515110016], "finish_reason": "stop"}], "metrics": {"energy": 591.9742956581115, "energy_per_token": 5.4812434783158475, "time": 17.466238, "time_per_token": 0.16172442592592592}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text).lower() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ")", ".", "lower", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-1.0674796104431152, -0.6491523385047913, -7.867782187531702e-06, -1.8715683836489916e-05, -1.9073468138230965e-06, -7.152555099310121e-07, 0.0, -0.0005013877525925636, -3.099436753473128e-06, -0.017639191821217537, -0.3929665982723236, -0.0005068686441518366, -0.4038739800453186, -0.45941317081451416, -0.271437406539917, -0.018281299620866776, -0.0003507714136503637, -0.1953532099723816, -0.00028725311858579516, -8.308542601298541e-05, -0.0013675870141014457, -0.009983958676457405, -0.13813738524913788], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -1.678538203239441, -0.0016780118457973003, -0.004253388848155737, -0.012610340490937233, -0.00034397884155623615, -2.6225699912174605e-05, -1.6093124941107817e-05, -0.0007512131123803556, -8.344646857949556e-07, -3.3378546504536644e-06, -7.83174327807501e-05, -0.0015584002248942852, -0.014433620497584343], "finish_reason": "stop"}, {"text": " CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b')", "tokens": [" Count", "Vector", "izer", "(", "token", "_", "pattern", "=", "r", "'(", "?", "u", ")\\", "b", "\\", "w", "+\\", "b", "')", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -1.0701202154159546, -0.48875391483306885, -0.14789830148220062, -0.0006962973857298493, -0.035741858184337616, -0.014566857367753983, -1.570204734802246, -2.1457441107486375e-05, -0.001328301033936441, -0.02476341463625431, -0.0007312007946893573, -0.0245306845754385, -0.0001161031104857102, -0.18046528100967407, -1.3232143828645349e-05, -0.04480092227458954, -0.16672615706920624], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform(tokenized_texts).toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-2.0311920642852783, -1.5497195136049413e-06, -2.610649426060263e-05, -0.002193665597587824, -0.037120964378118515, -1.3589766240329482e-05, -8.606540359323844e-05, -0.0001045410826918669, -1.4305104514278355e-06, -4.291525328881107e-06, -0.00014745102089364082, -0.0034481375478208065, -2.264974000354414e-06, -1.6689286894688848e-06, -3.576278118089249e-07, -3.969590397900902e-05, -0.0013256819220259786, -0.005512275733053684, -1.0068175792694092, -1.9907753085135482e-05, -1.1865146160125732, -0.009472189471125603, -0.09292490780353546, -0.004884572699666023, -0.0027419847901910543, -2.3841855067985307e-07, -1.0490362910786644e-05, -0.0006409021443687379, -1.1920928244535389e-07, -5.8412379075889476e-06, 0.0, -1.2040065485052764e-05, -0.4594224989414215, -0.06544039398431778, -0.0016296928515657783, -0.0015290009323507547], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.0002294515579706058, -1.8954096958623268e-05, -1.3112935448589269e-05, -0.00405347254127264, -0.016089249402284622, -1.1920922133867862e-06, -0.0012807984603568912, -0.09981514513492584, -2.7418097943154862e-06, -0.0054270317777991295, -0.005959480069577694, -0.005923929158598185, -0.002050560899078846, -0.0006625840906053782, -3.576278118089249e-07, -5.602820692729438e-06, -0.00018737945356406271, -3.576278118089249e-07, -7.033323527139146e-06, 0.0, -6.472854875028133e-05, -0.24142660200595856, -0.015009562484920025, -0.0045368121936917305, -0.0021224133670330048], "finish_reason": "stop"}, {"text": " else", "tokens": [" else", "\n"], "logprobs": [-0.145936518907547, -1.6548945903778076], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005900938529521227, -6.318072337307967e-06, -0.0023091575130820274, -0.0001532914029667154, -0.29182860255241394], "finish_reason": "stop"}], "metrics": {"energy": 664.2689996366503, "energy_per_token": 5.3141519970932025, "time": 19.13468, "time_per_token": 0.15307744}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text).lower() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ")", ".", "lower", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-1.0674796104431152, -0.6491523385047913, -7.867782187531702e-06, -1.8715683836489916e-05, -1.9073468138230965e-06, -7.152555099310121e-07, 0.0, -0.0005013877525925636, -3.099436753473128e-06, -0.017639191821217537, -0.3929665982723236, -0.0005068686441518366, -0.4038739800453186, -0.45941317081451416, -0.271437406539917, -0.018281299620866776, -0.0003507714136503637, -0.1953532099723816, -0.00028725311858579516, -8.308542601298541e-05, -0.0013675870141014457, -0.009983958676457405, -0.13813738524913788], "finish_reason": "stop"}, {"text": " [[word for word in nltk.word_tokenize(text) if word not in STOPWORDS]", "tokens": [" [[", "word", " for", " word", " in", " n", "lt", "k", ".", "word", "_", "token", "ize", "(", "text", ")", " if", " word", " not", " in", " ST", "OP", "W", "OR", "DS", "]", "\n"], "logprobs": [-2.1259605884552, -0.24680855870246887, -0.003709461074322462, -0.00014733182615600526, -9.798523387871683e-05, -2.267873525619507, -0.000395815703086555, -4.0531076592742465e-06, -0.00023100091493688524, -0.08555972576141357, -0.007844238542020321, -4.482168878894299e-05, -7.152555099310121e-07, -0.00013672371278516948, -0.06377172470092773, -0.01349328737705946, -0.029645804315805435, -0.006259716581553221, -0.02321038953959942, -3.5523738915799186e-05, -0.0016336203552782536, 0.0, -6.318072337307967e-06, 0.0, 0.0, -0.007220246363431215, -1.3042912483215332], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -0.4201759099960327, -0.02241327054798603], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -0.3088756799697876], "finish_reason": "stop"}], "metrics": {"energy": 577.194395290375, "energy_per_token": 5.247221775367046, "time": 17.217009, "time_per_token": 0.15651826363636365}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text.lower()) for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ".", "lower", "())", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-1.0674796104431152, -0.6491523385047913, -7.867782187531702e-06, -1.8715683836489916e-05, -1.9073468138230965e-06, -7.152555099310121e-07, 0.0, -0.0005013877525925636, -3.099436753473128e-06, -0.017639191821217537, -0.3929665982723236, -0.0005068686441518366, -0.4038739800453186, -1.0032058954238892, -0.016907714307308197, -0.016824960708618164, -0.49278903007507324, -0.0002615109842736274, -5.9602869441732764e-05, -0.0011214879341423512, -0.009428614750504494, -0.17688271403312683], "finish_reason": "stop"}, {"text": " [nltk.tokenize.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "token", "ize", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -2.183624505996704, -7.152531907195225e-06, -0.00016950124700088054, -0.008658604696393013, -0.04936590418219566, -0.0001991788885788992, -5.960462772236497e-07, -0.0030448525212705135, -0.040741730481386185, -0.07512722164392471, -0.002049728063866496, -4.458328112377785e-05, -2.0146166207268834e-05, -0.0020320022013038397, -5.960462772236497e-07, -4.768370445162873e-07, -1.966933996300213e-05, -0.00028880240279249847, -0.011526417918503284], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -0.4201759099960327, -0.02241327054798603], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -0.3088756799697876], "finish_reason": "stop"}], "metrics": {"energy": 581.9431888866426, "energy_per_token": 5.542316084634692, "time": 16.603346, "time_per_token": 0.15812710476190475}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -0.12287348508834839, -0.003407150972634554, -0.0001934579631779343, -1.311301275563892e-06, -0.00042763148667290807, -0.0264801774173975, -0.01235039159655571, -0.00126008247025311, -5.8053239627042785e-05, -1.2516897186287679e-05, -0.0016831292305141687, -3.576278118089249e-07, -4.768370445162873e-07, -3.3378546504536644e-06, -0.000668659748043865, -0.0129861356690526], "finish_reason": "stop"}, {"text": " CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b')", "tokens": [" Count", "Vector", "izer", "(", "token", "_", "pattern", "=", "r", "'(", "?", "u", ")\\", "b", "\\", "w", "+\\", "b", "')", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -1.0701202154159546, -0.48875391483306885, -0.14789830148220062, -0.0006962973857298493, -0.035741858184337616, -0.014566857367753983, -1.570204734802246, -2.1457441107486375e-05, -0.001328301033936441, -0.02476341463625431, -0.0007312007946893573, -0.0245306845754385, -0.0001161031104857102, -0.18046528100967407, -1.3232143828645349e-05, -0.04480092227458954, -0.16672615706920624], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -0.3088756799697876], "finish_reason": "stop"}], "metrics": {"energy": 558.0582073593139, "energy_per_token": 5.753177395456844, "time": 16.385958, "time_per_token": 0.16892740206185566}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text).lower() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ")", ".", "lower", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-1.0674796104431152, -0.6491523385047913, -7.867782187531702e-06, -1.8715683836489916e-05, -1.9073468138230965e-06, -7.152555099310121e-07, 0.0, -0.0005013877525925636, -3.099436753473128e-06, -0.017639191821217537, -0.3929665982723236, -0.0005068686441518366, -0.4038739800453186, -0.45941317081451416, -0.271437406539917, -0.018281299620866776, -0.0003507714136503637, -0.1953532099723816, -0.00028725311858579516, -8.308542601298541e-05, -0.0013675870141014457, -0.009983958676457405, -0.13813738524913788], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -0.12287348508834839, -0.003407150972634554, -0.0001934579631779343, -1.311301275563892e-06, -0.00042763148667290807, -0.0264801774173975, -0.01235039159655571, -0.00126008247025311, -5.8053239627042785e-05, -1.2516897186287679e-05, -0.0016831292305141687, -3.576278118089249e-07, -4.768370445162873e-07, -3.3378546504536644e-06, -0.000668659748043865, -0.0129861356690526], "finish_reason": "stop"}, {"text": " CountVectorizer(ngram_range=(1, 2))", "tokens": [" Count", "Vector", "izer", "(", "ng", "ram", "_", "range", "=(", "1", ",", " ", "2", "))", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -1.0701202154159546, -2.164884090423584, -0.006167427636682987, -0.00018225439998786896, -6.556489552167477e-06, -0.006071101874113083, -0.1947547048330307, -6.496695277746767e-05, -0.15834905207157135, -0.8751389980316162, -0.31117120385169983, -0.1305030733346939], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts).toarray()", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", ".", "to", "array", "()", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -2.476853132247925, -0.32914403080940247, -9.929640509653836e-05, -1.4543427823809907e-05, -0.008256824687123299], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -1.3527753353118896, -0.0019468179671093822], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -0.3088756799697876], "finish_reason": "stop"}], "metrics": {"energy": 608.3855431699759, "energy_per_token": 5.290309071043269, "time": 17.863703, "time_per_token": 0.15533654782608697}}
{"outputs": [{"text": " [", "tokens": [" [", "\n"], "logprobs": [-1.0674796104431152, -2.430640697479248], "finish_reason": "stop"}, {"text": " [nltk.tokenize.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "token", "ize", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -2.183624505996704, -7.152531907195225e-06, -0.00016950124700088054, -0.008658604696393013, -0.04936590418219566, -0.0001991788885788992, -5.960462772236497e-07, -0.0030448525212705135, -0.040741730481386185, -0.07512722164392471, -0.002049728063866496, -4.458328112377785e-05, -2.0146166207268834e-05, -0.0020320022013038397, -5.960462772236497e-07, -4.768370445162873e-07, -1.966933996300213e-05, -0.00028880240279249847, -0.011526417918503284], "finish_reason": "stop"}, {"text": " CountVectorizer(ngram_range=(1, 2))", "tokens": [" Count", "Vector", "izer", "(", "ng", "ram", "_", "range", "=(", "1", ",", " ", "2", "))", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -1.0701202154159546, -2.164884090423584, -0.006167427636682987, -0.00018225439998786896, -6.556489552167477e-06, -0.006071101874113083, -0.1947547048330307, -6.496695277746767e-05, -0.15834905207157135, -0.8751389980316162, -0.31117120385169983, -0.1305030733346939], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -2.9358954429626465, -1.8000440832111053e-05, -0.00034433635300956666, -0.007598071824759245, -0.0034786683972924948, -0.008916798047721386, -0.002362676663324237, -0.0023401989601552486, -1.0728830375228426e-06, -5.245195097813848e-06, -0.000942977552767843, -4.768370445162873e-07, -7.748573807475623e-06, 0.0, -4.5060096454108134e-05, -0.4537903070449829, -0.005405453033745289, -0.0208175927400589, -0.0045211478136479855], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.1458633691072464, -0.2093726247549057, -0.0002044230350293219, -0.008356604725122452, -0.005107332020998001, -0.00019441144831944257, -5.781483559985645e-05, -1.3828182090946939e-05, -1.3232143828645349e-05, -0.01891644485294819, -0.004647287540137768], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.006538189947605133, -1.0013530300057027e-05, -0.002384559018537402, -0.00010644822759786621, -0.317149817943573], "finish_reason": "stop"}], "metrics": {"energy": 534.2163209400175, "energy_per_token": 5.564753343125182, "time": 15.979111, "time_per_token": 0.16644907291666666}}
{"outputs": [{"text": " [ALPHANUMERIC.sub('', text.lower()).strip() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", "'", ",", " text", ".", "lower", "())", ".", "strip", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-1.0674796104431152, -0.6491523385047913, -7.867782187531702e-06, -1.8715683836489916e-05, -1.9073468138230965e-06, -7.152555099310121e-07, 0.0, -0.0005013877525925636, -3.099436753473128e-06, -0.017639191821217537, -1.1275209188461304, -6.925819616299123e-05, -0.25307905673980713, -0.1257796436548233, -0.008840351365506649, -0.01607634499669075, -1.635617733001709, -1.1954227685928345, -0.004647050518542528, -0.07702255994081497, -0.00037925204378552735, -0.00012838016846217215, -0.0008535317610949278, -0.01188801322132349, -0.09247735887765884], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -0.12287348508834839, -0.003407150972634554, -0.0001934579631779343, -1.311301275563892e-06, -0.00042763148667290807, -0.0264801774173975, -0.01235039159655571, -0.00126008247025311, -5.8053239627042785e-05, -1.2516897186287679e-05, -0.0016831292305141687, -3.576278118089249e-07, -4.768370445162873e-07, -3.3378546504536644e-06, -0.000668659748043865, -0.0129861356690526], "finish_reason": "stop"}, {"text": " CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b')", "tokens": [" Count", "Vector", "izer", "(", "token", "_", "pattern", "=", "r", "'(", "?", "u", ")\\", "b", "\\", "w", "+\\", "b", "')", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -1.0701202154159546, -0.48875391483306885, -0.14789830148220062, -0.0006962973857298493, -0.035741858184337616, -0.014566857367753983, -1.570204734802246, -2.1457441107486375e-05, -0.001328301033936441, -0.02476341463625431, -0.0007312007946893573, -0.0245306845754385, -0.0001161031104857102, -0.18046528100967407, -1.3232143828645349e-05, -0.04480092227458954, -0.16672615706920624], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -0.3088756799697876], "finish_reason": "stop"}], "metrics": {"energy": 626.4229977493287, "energy_per_token": 5.220191647911073, "time": 18.521574, "time_per_token": 0.15434645}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [nltk.tokenize.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "token", "ize", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -2.183624505996704, -7.152531907195225e-06, -0.00016950124700088054, -0.008658604696393013, -0.04936590418219566, -0.0001991788885788992, -5.960462772236497e-07, -0.0030448525212705135, -0.040741730481386185, -0.07512722164392471, -0.002049728063866496, -4.458328112377785e-05, -2.0146166207268834e-05, -0.0020320022013038397, -5.960462772236497e-07, -4.768370445162873e-07, -1.966933996300213e-05, -0.00028880240279249847, -0.011526417918503284], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -0.4201759099960327, -0.02241327054798603], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.todense(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "t", "od", "ense", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -2.9358954429626465, -1.8000440832111053e-05, -0.00034433635300956666, -0.007598071824759245, -0.0034786683972924948, -0.008916798047721386, -0.002362676663324237, -0.0023401989601552486, -1.0728830375228426e-06, -5.245195097813848e-06, -0.000942977552767843, -4.768370445162873e-07, -7.748573807475623e-06, 0.0, -4.5060096454108134e-05, -1.0407692193984985, -0.004324252251535654], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.1458633691072464, -0.2093726247549057, -0.0002044230350293219, -0.008356604725122452, -0.005107332020998001, -0.00019441144831944257, -5.781483559985645e-05, -1.3828182090946939e-05, -1.3232143828645349e-05, -0.01891644485294819, -0.004647287540137768], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.006538189947605133, -1.0013530300057027e-05, -0.002384559018537402, -0.00010644822759786621, -0.317149817943573], "finish_reason": "stop"}], "metrics": {"energy": 500.31491375541685, "energy_per_token": 5.956129925659725, "time": 14.911373, "time_per_token": 0.17751634523809523}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -0.12287348508834839, -0.003407150972634554, -0.0001934579631779343, -1.311301275563892e-06, -0.00042763148667290807, -0.0264801774173975, -0.01235039159655571, -0.00126008247025311, -5.8053239627042785e-05, -1.2516897186287679e-05, -0.0016831292305141687, -3.576278118089249e-07, -4.768370445162873e-07, -3.3378546504536644e-06, -0.000668659748043865, -0.0129861356690526], "finish_reason": "stop"}, {"text": " CountVectorizer(ngram_range=(1, 1),", "tokens": [" Count", "Vector", "izer", "(", "ng", "ram", "_", "range", "=(", "1", ",", " ", "1", ")", ",", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -1.0701202154159546, -2.164884090423584, -0.006167427636682987, -0.00018225439998786896, -6.556489552167477e-06, -0.006071101874113083, -0.1947547048330307, -6.496695277746767e-05, -0.15834905207157135, -0.7106187343597412, -0.6802119612693787, -0.00013958434283267707, -4.241572380065918], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -0.3088756799697876], "finish_reason": "stop"}], "metrics": {"energy": 539.7919677200318, "energy_per_token": 5.804214706667009, "time": 15.982651, "time_per_token": 0.1718564623655914}}
{"outputs": [{"text": " [ALPHANUMERIC.sub('', text.lower()) for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", "'", ",", " text", ".", "lower", "())", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-1.0674796104431152, -0.6491523385047913, -7.867782187531702e-06, -1.8715683836489916e-05, -1.9073468138230965e-06, -7.152555099310121e-07, 0.0, -0.0005013877525925636, -3.099436753473128e-06, -0.017639191821217537, -1.1275209188461304, -6.925819616299123e-05, -0.25307905673980713, -0.1257796436548233, -0.008840351365506649, -0.01607634499669075, -0.26566070318222046, -0.00023326536756940186, -8.237022848334163e-05, -0.0007108307327143848, -0.0063236854039132595, -0.21161359548568726], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -0.12287348508834839, -0.003407150972634554, -0.0001934579631779343, -1.311301275563892e-06, -0.00042763148667290807, -0.0264801774173975, -0.01235039159655571, -0.00126008247025311, -5.8053239627042785e-05, -1.2516897186287679e-05, -0.0016831292305141687, -3.576278118089249e-07, -4.768370445162873e-07, -3.3378546504536644e-06, -0.000668659748043865, -0.0129861356690526], "finish_reason": "stop"}, {"text": " CountVectorizer(ngram_range=(1, 1), max_features=300)", "tokens": [" Count", "Vector", "izer", "(", "ng", "ram", "_", "range", "=(", "1", ",", " ", "1", ")", ",", " max", "_", "features", "=", "3", "0", "0", ")", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -1.0701202154159546, -2.164884090423584, -0.006167427636682987, -0.00018225439998786896, -6.556489552167477e-06, -0.006071101874113083, -0.1947547048330307, -6.496695277746767e-05, -0.15834905207157135, -0.7106187343597412, -0.6802119612693787, -0.00013958434283267707, -1.6443243026733398, -2.825220326485578e-05, -1.684751033782959, -0.004963694605976343, -2.980567693710327, -0.21887630224227905, -0.12374687194824219, -1.2338340282440186, -0.045410677790641785], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -0.3088756799697876], "finish_reason": "stop"}], "metrics": {"energy": 667.2456493797299, "energy_per_token": 5.514426854377933, "time": 18.916895, "time_per_token": 0.15633797520661158}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -1.678538203239441, -0.0016780118457973003, -0.004253388848155737, -0.012610340490937233, -0.00034397884155623615, -2.6225699912174605e-05, -1.6093124941107817e-05, -0.0007512131123803556, -8.344646857949556e-07, -3.3378546504536644e-06, -7.83174327807501e-05, -0.0015584002248942852, -0.014433620497584343], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -0.4201759099960327, -0.02241327054798603], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -0.3088756799697876], "finish_reason": "stop"}], "metrics": {"energy": 472.1863756980896, "energy_per_token": 6.212978627606442, "time": 14.707676, "time_per_token": 0.19352205263157893}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', t).lower() for t in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " t", ")", ".", "lower", "()", " for", " t", " in", " texts", "]", "\n"], "logprobs": [-1.0674796104431152, -0.6491523385047913, -7.867782187531702e-06, -1.8715683836489916e-05, -1.9073468138230965e-06, -7.152555099310121e-07, 0.0, -0.0005013877525925636, -3.099436753473128e-06, -0.017639191821217537, -0.3929665982723236, -0.0005068686441518366, -1.4121613502502441, -0.7770355343818665, -0.3958103060722351, -0.027038201689720154, -0.00032062159152701497, -0.20734432339668274, -0.0003698380314745009, -5.531158240046352e-05, -0.0010367024224251509, -0.012579263187944889, -0.17077845335006714], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -1.678538203239441, -0.0016780118457973003, -0.004253388848155737, -0.012610340490937233, -0.00034397884155623615, -2.6225699912174605e-05, -1.6093124941107817e-05, -0.0007512131123803556, -8.344646857949556e-07, -3.3378546504536644e-06, -7.83174327807501e-05, -0.0015584002248942852, -0.014433620497584343], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -0.4201759099960327, -0.02241327054798603], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -1.3527753353118896, -0.0019468179671093822], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -0.3088756799697876], "finish_reason": "stop"}], "metrics": {"energy": 531.2907118167876, "energy_per_token": 5.592533808597764, "time": 15.989869, "time_per_token": 0.1683144105263158}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -1.678538203239441, -0.0016780118457973003, -0.004253388848155737, -0.012610340490937233, -0.00034397884155623615, -2.6225699912174605e-05, -1.6093124941107817e-05, -0.0007512131123803556, -8.344646857949556e-07, -3.3378546504536644e-06, -7.83174327807501e-05, -0.0015584002248942852, -0.014433620497584343], "finish_reason": "stop"}, {"text": " CountVectorizer(token_pattern=r\"\\b[a-zA-Z0-9]+\\b\", lowercase=True, max_df=0.9)", "tokens": [" Count", "Vector", "izer", "(", "token", "_", "pattern", "=", "r", "\"", "\\", "b", "[", "a", "-", "z", "A", "-", "Z", "0", "-", "9", "]", "+\\", "b", "\"", ",", " lower", "case", "=", "True", ",", " max", "_", "df", "=", "0", ".", "9", ")", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -1.0701202154159546, -0.48875391483306885, -0.14789830148220062, -0.0006962973857298493, -0.035741858184337616, -0.014566857367753983, -0.6532240509986877, -0.3557285666465759, -0.32869720458984375, -0.34901905059814453, -3.012833833694458, -3.4570634852570947e-06, -3.2782016205601394e-05, -0.16030767560005188, -5.960446742392378e-06, -0.005319962743669748, -0.4429970979690552, -0.00013481661153491586, -1.0490362910786644e-05, -0.4341663718223572, -0.001983581343665719, -1.311301275563892e-06, -0.002380991354584694, -2.240670919418335, -1.3695734739303589, -9.65590606938349e-06, -0.000668659748043865, -0.4836353361606598, -1.4747899770736694, -2.4763944149017334, -1.8000440832111053e-05, -0.22116214036941528, -0.0012697261990979314, -0.1405370980501175, -7.676783570786938e-05, -0.8933387398719788, -1.8388806581497192, -0.02936396934092045], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": "", "tokens": ["\n"], "logprobs": [-2.1053497791290283], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005762985907495022, -8.821448318485636e-06, -0.0024468740448355675, -0.00012134769349358976, -0.2891768515110016], "finish_reason": "stop"}], "metrics": {"energy": 637.0969250011444, "energy_per_token": 6.246048284324945, "time": 18.487942, "time_per_token": 0.18125433333333332}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [[token for token in text.split() if token not in STOPWORDS] for text in cleaned_texts]", "tokens": [" [[", "token", " for", " token", " in", " text", ".", "split", "()", " if", " token", " not", " in", " ST", "OP", "W", "OR", "DS", "]", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-2.1259605884552, -2.0513663291931152, -0.012216034345328808, -0.00032669928623363376, -9.238292841473594e-05, -0.2854316234588623, -0.006453388370573521, -0.009531821124255657, -0.2116815149784088, -0.01228268537670374, -0.0026666102930903435, -0.05578836426138878, -3.158996332786046e-05, -0.0013075858587399125, 0.0, -7.748573807475623e-06, 0.0, -1.1920928244535389e-07, -0.00539620453491807, -0.21591803431510925, -0.0007052318542264402, -0.00015507926582358778, -0.0013247294118627906, -4.768370445162873e-07, -2.145764938177308e-06, -2.658331868587993e-05, -0.00042274597217328846, -0.006120509933680296], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -0.4201759099960327, -0.02241327054798603], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -1.3527753353118896, -0.0019468179671093822], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -0.3088756799697876], "finish_reason": "stop"}], "metrics": {"energy": 529.6469045124054, "energy_per_token": 6.018714824004607, "time": 15.961952, "time_per_token": 0.18138581818181818}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [[word for word in doc.split() if word not in STOPWORDS] for doc in cleaned_texts]", "tokens": [" [[", "word", " for", " word", " in", " doc", ".", "split", "()", " if", " word", " not", " in", " ST", "OP", "W", "OR", "DS", "]", " for", " doc", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-2.1259605884552, -0.24680855870246887, -0.003709461074322462, -0.00014733182615600526, -9.798523387871683e-05, -2.275470495223999, -0.008981660939753056, -0.023565689101815224, -0.037340447306632996, -0.010371596552431583, -0.004410421010106802, -0.011559884995222092, -4.8636207793606445e-05, -0.002495510270819068, 0.0, -7.867782187531702e-06, 0.0, 0.0, -0.006294900085777044, -0.1701793223619461, -7.021180499577895e-05, -3.9219088648678735e-05, -0.0008734225411899388, -7.152555099310121e-07, -2.0265558760002023e-06, -4.184158387943171e-05, -0.0003181189822498709, -0.009420230984687805], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -0.4201759099960327, -0.02241327054798603], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform(tokenized_texts).todense(),", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", ".", "t", "od", "ense", "()", ",", "\n"], "logprobs": [-2.0311920642852783, -1.5497195136049413e-06, -2.610649426060263e-05, -0.002193665597587824, -0.037120964378118515, -1.3589766240329482e-05, -8.606540359323844e-05, -0.0001045410826918669, -1.4305104514278355e-06, -4.291525328881107e-06, -0.00014745102089364082, -0.0034481375478208065, -2.264974000354414e-06, -1.6689286894688848e-06, -3.576278118089249e-07, -3.969590397900902e-05, -0.0013256819220259786, -0.005512275733053684, -0.4627883732318878, -3.58813522325363e-05, -0.00021908267808612436, -0.1694987416267395, -0.006701020989567041, -2.0457305908203125], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.0002294515579706058, -1.8954096958623268e-05, -1.3112935448589269e-05, -0.00405347254127264, -0.016089249402284622, -1.1920922133867862e-06, -0.0012807984603568912, -0.09981514513492584, -2.7418097943154862e-06, -0.0054270317777991295, -0.005959480069577694, -0.005923929158598185, -0.002050560899078846, -0.0006625840906053782, -3.576278118089249e-07, -5.602820692729438e-06, -0.00018737945356406271, -3.576278118089249e-07, -7.033323527139146e-06, 0.0, -6.472854875028133e-05, -0.24142660200595856, -0.015009562484920025, -0.0045368121936917305, -0.0021224133670330048], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.145936518907547, -0.23963433504104614, -0.00022265815641731024, -0.010296912863850594, -0.005741651635617018, -0.00023803261865396053, -3.7788631743751466e-05, -1.3828182090946939e-05, -1.168244216387393e-05, -0.02126687578856945, -0.004852898418903351], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.004876031540334225, -1.0013530300057027e-05, -0.0024160738103091717, -0.0001431601122021675, -0.2821747958660126], "finish_reason": "stop"}], "metrics": {"energy": 603.2708066320414, "energy_per_token": 6.032708066320414, "time": 17.416916, "time_per_token": 0.17416916000000002}}
{"outputs": [{"text": " []", "tokens": [" []", "\n"], "logprobs": [-0.4457564949989319, -0.04423675686120987], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -1.678538203239441, -0.0016780118457973003, -0.004253388848155737, -0.012610340490937233, -0.00034397884155623615, -2.6225699912174605e-05, -1.6093124941107817e-05, -0.0007512131123803556, -8.344646857949556e-07, -3.3378546504536644e-06, -7.83174327807501e-05, -0.0015584002248942852, -0.014433620497584343], "finish_reason": "stop"}, {"text": " CountVectorizer(token_pattern=r'\\b[^\\d\\W]+\\b')", "tokens": [" Count", "Vector", "izer", "(", "token", "_", "pattern", "=", "r", "'\\", "b", "[", "^\\", "d", "\\", "W", "]", "+\\", "b", "')", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -1.0701202154159546, -0.48875391483306885, -0.14789830148220062, -0.0006962973857298493, -0.035741858184337616, -0.014566857367753983, -1.3510541915893555, -0.10290966928005219, -0.555173397064209, -0.04160865768790245, -0.9389618039131165, -0.0049335649237036705, -0.00022802136663813144, -0.7086465358734131, -0.00014661667228210717, -4.172316494077677e-06, -0.03708064556121826, -0.21651610732078552], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform(tokenized_texts).toarray())", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", ".", "to", "array", "())", "\n"], "logprobs": [-2.0311920642852783, -1.5497195136049413e-06, -2.610649426060263e-05, -0.002193665597587824, -0.037120964378118515, -1.3589766240329482e-05, -8.606540359323844e-05, -0.0001045410826918669, -1.4305104514278355e-06, -4.291525328881107e-06, -0.00014745102089364082, -0.0034481375478208065, -2.264974000354414e-06, -1.6689286894688848e-06, -3.576278118089249e-07, -3.969590397900902e-05, -0.0013256819220259786, -0.005512275733053684, -1.0068175792694092, -1.9907753085135482e-05, -0.36429864168167114, -0.008114229887723923], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.0002294515579706058, -1.8954096958623268e-05, -1.3112935448589269e-05, -0.00405347254127264, -0.016089249402284622, -1.1920922133867862e-06, -0.0012807984603568912, -0.09981514513492584, -2.7418097943154862e-06, -0.0054270317777991295, -0.005959480069577694, -0.005923929158598185, -0.002050560899078846, -0.0006625840906053782, -3.576278118089249e-07, -5.602820692729438e-06, -0.00018737945356406271, -3.576278118089249e-07, -7.033323527139146e-06, 0.0, -6.472854875028133e-05, -1.5658894777297974, -0.002230776706710458], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.145936518907547, -0.23963433504104614, -0.00022265815641731024, -0.010296912863850594, -0.005741651635617018, -0.00023803261865396053, -3.7788631743751466e-05, -1.3828182090946939e-05, -1.168244216387393e-05, -0.02126687578856945, -0.004852898418903351], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.004876031540334225, -1.0013530300057027e-05, -0.0024160738103091717, -0.0001431601122021675, -0.2821747958660126], "finish_reason": "stop"}], "metrics": {"energy": 615.8736480541227, "energy_per_token": 6.2844249801441086, "time": 17.854351, "time_per_token": 0.18218725510204084}}
{"outputs": [{"text": " [ALPHANUMERIC.sub('', text).lower() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", "'", ",", " text", ")", ".", "lower", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-1.0674796104431152, -0.6491523385047913, -7.867782187531702e-06, -1.8715683836489916e-05, -1.9073468138230965e-06, -7.152555099310121e-07, 0.0, -0.0005013877525925636, -3.099436753473128e-06, -0.017639191821217537, -1.1275209188461304, -6.925819616299123e-05, -0.25307905673980713, -2.143594264984131, -0.24201738834381104, -0.008296903222799301, -0.00025185750564560294, -0.10774873942136765, -0.00029297350556589663, -6.627816765103489e-05, -0.0015908931382000446, -0.006981028709560633, -0.14320620894432068], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -0.12287348508834839, -0.003407150972634554, -0.0001934579631779343, -1.311301275563892e-06, -0.00042763148667290807, -0.0264801774173975, -0.01235039159655571, -0.00126008247025311, -5.8053239627042785e-05, -1.2516897186287679e-05, -0.0016831292305141687, -3.576278118089249e-07, -4.768370445162873e-07, -3.3378546504536644e-06, -0.000668659748043865, -0.0129861356690526], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -0.4201759099960327, -0.02241327054798603], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": "", "tokens": ["\n"], "logprobs": [-2.1053497791290283], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005762985907495022, -8.821448318485636e-06, -0.0024468740448355675, -0.00012134769349358976, -0.2891768515110016], "finish_reason": "stop"}], "metrics": {"energy": 550.662014746666, "energy_per_token": 5.92109693275985, "time": 16.37625, "time_per_token": 0.17608870967741935}}
{"outputs": [{"text": " [preprocess(text) for text in texts]", "tokens": [" [", "pre", "process", "(", "text", ")", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-1.0674796104431152, -2.518319606781006, -0.02288222685456276, -1.0503963232040405, -0.11082097887992859, -0.026184093207120895, -0.003619193332269788, -0.00010287232726113871, -1.6689160474925302e-05, -0.0005158047424629331, -0.011368024162948132, -0.015884293243288994], "finish_reason": "stop"}, {"text": " [text.split() for text in cleaned_texts]", "tokens": [" [", "text", ".", "split", "()", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -1.678538203239441, -0.0016780118457973003, -0.004253388848155737, -0.012610340490937233, -0.00034397884155623615, -2.6225699912174605e-05, -1.6093124941107817e-05, -0.0007512131123803556, -8.344646857949556e-07, -3.3378546504536644e-06, -7.83174327807501e-05, -0.0015584002248942852, -0.014433620497584343], "finish_reason": "stop"}, {"text": " CountVectorizer(token_pattern=r'\\b[^\\d\\W]+\\b')", "tokens": [" Count", "Vector", "izer", "(", "token", "_", "pattern", "=", "r", "'\\", "b", "[", "^\\", "d", "\\", "W", "]", "+\\", "b", "')", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -1.0701202154159546, -0.48875391483306885, -0.14789830148220062, -0.0006962973857298493, -0.035741858184337616, -0.014566857367753983, -1.3510541915893555, -0.10290966928005219, -0.555173397064209, -0.04160865768790245, -0.9389618039131165, -0.0049335649237036705, -0.00022802136663813144, -0.7086465358734131, -0.00014661667228210717, -4.172316494077677e-06, -0.03708064556121826, -0.21651610732078552], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": "", "tokens": ["\n"], "logprobs": [-2.1053497791290283], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005762985907495022, -8.821448318485636e-06, -0.0024468740448355675, -0.00012134769349358976, -0.2891768515110016], "finish_reason": "stop"}], "metrics": {"energy": 570.2843485565188, "energy_per_token": 6.198742919092596, "time": 16.382813, "time_per_token": 0.17807405434782608}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', t.lower()).strip() for t in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " t", ".", "lower", "())", ".", "strip", "()", " for", " t", " in", " texts", "]", "\n"], "logprobs": [-1.0674796104431152, -0.6491523385047913, -7.867782187531702e-06, -1.8715683836489916e-05, -1.9073468138230965e-06, -7.152555099310121e-07, 0.0, -0.0005013877525925636, -3.099436753473128e-06, -0.017639191821217537, -0.3929665982723236, -0.0005068686441518366, -1.4121613502502441, -1.8498923778533936, -0.021271543577313423, -0.013453533872961998, -1.5335466861724854, -0.48444700241088867, -0.005161887500435114, -0.16901230812072754, -0.00025340684805996716, -7.724463648628443e-05, -0.0010882653295993805, -0.015210704877972603, -0.0773862823843956], "finish_reason": "stop"}, {"text": " [nltk.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -0.12287348508834839, -0.003407150972634554, -0.0001934579631779343, -1.311301275563892e-06, -0.00042763148667290807, -0.0264801774173975, -0.01235039159655571, -0.00126008247025311, -5.8053239627042785e-05, -1.2516897186287679e-05, -0.0016831292305141687, -3.576278118089249e-07, -4.768370445162873e-07, -3.3378546504536644e-06, -0.000668659748043865, -0.0129861356690526], "finish_reason": "stop"}, {"text": " CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")", "tokens": [" Count", "Vector", "izer", "(", "token", "_", "pattern", "=", "r", "\"", "(", "?", "u", ")\\", "b", "\\", "w", "+\\", "b", "\"", ")", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -1.0701202154159546, -0.48875391483306885, -0.14789830148220062, -0.0006962973857298493, -0.035741858184337616, -0.014566857367753983, -0.6532240509986877, -1.60374116897583, -0.0012290074955672026, -0.009722617454826832, -0.025805674493312836, -0.0009939497103914618, -0.019842110574245453, -0.00020883286197204143, -0.21375706791877747, -2.825220326485578e-05, -0.0030251238495111465, -0.17573589086532593, -0.426308274269104], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(tokenized_texts)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", "\n"], "logprobs": [-0.14188697934150696, -1.3351351299206726e-05, -2.2172682292875834e-05, -4.827859811484814e-05, -5.722029527532868e-06, -5.960446742392378e-06, -0.00037722624256275594, -0.002804277464747429, -1.6689286894688848e-06, -3.933898824470816e-06, -3.099436753473128e-06, -3.1709168979432434e-05, -0.0002015625941567123, -0.09779424965381622], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.00023827097902540118, -1.7404405298293568e-05, -1.2516897186287679e-05, -0.003769555827602744, -0.014943445101380348, -8.344646857949556e-07, -0.001301871263422072, -0.07673411816358566, -4.172316494077677e-06, -0.004849932622164488, -0.004078998696058989, -0.004898095969110727, -0.0023205752950161695, -0.0008288762182928622, -3.576278118089249e-07, -4.768360213347478e-06, -0.0001784403866622597, -2.3841855067985307e-07, -5.602820692729438e-06, 0.0, -5.221230458118953e-05, -0.30560654401779175, -0.0020251020323485136, -0.004259561188519001, -0.0021082572638988495], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.14558722078800201, -0.20209543406963348, -0.000219321038457565, -0.008857011795043945, -0.004889911040663719, -0.0002766464895103127, -3.683499380713329e-05, -1.3470558769768104e-05, -1.4305012882687151e-05, -0.022400330752134323, -0.0046623568050563335], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.005620509851723909, -1.0132738680113107e-05, -0.0020318832248449326, -9.536288416711614e-05, -0.3088756799697876], "finish_reason": "stop"}], "metrics": {"energy": 604.5975481147763, "energy_per_token": 4.955717607498166, "time": 18.074633, "time_per_token": 0.14815272950819672}}
{"outputs": [{"text": " [ALPHANUMERIC.sub(' ', text).lower() for text in texts]", "tokens": [" [", "AL", "PH", "AN", "UM", "ER", "IC", ".", "sub", "('", " '", ",", " text", ")", ".", "lower", "()", " for", " text", " in", " texts", "]", "\n"], "logprobs": [-1.0674796104431152, -0.6491523385047913, -7.867782187531702e-06, -1.8715683836489916e-05, -1.9073468138230965e-06, -7.152555099310121e-07, 0.0, -0.0005013877525925636, -3.099436753473128e-06, -0.017639191821217537, -0.3929665982723236, -0.0005068686441518366, -0.4038739800453186, -0.45941317081451416, -0.271437406539917, -0.018281299620866776, -0.0003507714136503637, -0.1953532099723816, -0.00028725311858579516, -8.308542601298541e-05, -0.0013675870141014457, -0.009983958676457405, -0.13813738524913788], "finish_reason": "stop"}, {"text": " [nltk.tokenize.word_tokenize(text) for text in cleaned_texts]", "tokens": [" [", "nl", "tk", ".", "token", "ize", ".", "word", "_", "token", "ize", "(", "text", ")", " for", " text", " in", " cleaned", "_", "text", "s", "]", "\n"], "logprobs": [-0.15359044075012207, -0.2876385748386383, -0.00011789103882620111, -0.00010871296399272978, -2.183624505996704, -7.152531907195225e-06, -0.00016950124700088054, -0.008658604696393013, -0.04936590418219566, -0.0001991788885788992, -5.960462772236497e-07, -0.0030448525212705135, -0.040741730481386185, -0.07512722164392471, -0.002049728063866496, -4.458328112377785e-05, -2.0146166207268834e-05, -0.0020320022013038397, -5.960462772236497e-07, -4.768370445162873e-07, -1.966933996300213e-05, -0.00028880240279249847, -0.011526417918503284], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00018892886873800308, -5.960446742392378e-06, -2.3841855067985307e-07, -0.4201759099960327, -0.02241327054798603], "finish_reason": "stop"}, {"text": " pd.DataFrame(vectorizer.fit_transform(tokenized_texts).toarray())", "tokens": [" pd", ".", "DataFrame", "(", "vector", "izer", ".", "fit", "_", "transform", "(", "token", "ized", "_", "text", "s", ")", ".", "to", "array", "())", "\n"], "logprobs": [-2.0311920642852783, -1.5497195136049413e-06, -2.610649426060263e-05, -0.002193665597587824, -0.037120964378118515, -1.3589766240329482e-05, -8.606540359323844e-05, -0.0001045410826918669, -1.4305104514278355e-06, -4.291525328881107e-06, -0.00014745102089364082, -0.0034481375478208065, -2.264974000354414e-06, -1.6689286894688848e-06, -3.576278118089249e-07, -3.969590397900902e-05, -0.0013256819220259786, -0.005512275733053684, -1.0068175792694092, -1.9907753085135482e-05, -0.36429864168167114, -0.008114229887723923], "finish_reason": "stop"}, {"text": " pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out())", "tokens": [" pd", ".", "DataFrame", "(", "dt", "m", ".", "to", "array", "()", ",", " columns", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "_", "out", "())", "\n"], "logprobs": [-0.0002294515579706058, -1.8954096958623268e-05, -1.3112935448589269e-05, -0.00405347254127264, -0.016089249402284622, -1.1920922133867862e-06, -0.0012807984603568912, -0.09981514513492584, -2.7418097943154862e-06, -0.0054270317777991295, -0.005959480069577694, -0.005923929158598185, -0.002050560899078846, -0.0006625840906053782, -3.576278118089249e-07, -5.602820692729438e-06, -0.00018737945356406271, -3.576278118089249e-07, -7.033323527139146e-06, 0.0, -6.472854875028133e-05, -0.24142660200595856, -0.015009562484920025, -0.0045368121936917305, -0.0021224133670330048], "finish_reason": "stop"}, {"text": " else vectorizer.get_feature_names())", "tokens": [" else", " vector", "izer", ".", "get", "_", "feature", "_", "names", "())", "\n"], "logprobs": [-0.145936518907547, -0.23963433504104614, -0.00022265815641731024, -0.010296912863850594, -0.005741651635617018, -0.00023803261865396053, -3.7788631743751466e-05, -1.3828182090946939e-05, -1.168244216387393e-05, -0.02126687578856945, -0.004852898418903351], "finish_reason": "stop"}, {"text": " dtm_df", "tokens": [" d", "tm", "_", "df", "\n"], "logprobs": [-0.004876031540334225, -1.0013530300057027e-05, -0.0024160738103091717, -0.0001431601122021675, -0.2821747958660126], "finish_reason": "stop"}], "metrics": {"energy": 613.8684809684755, "energy_per_token": 5.384811236565575, "time": 17.823212, "time_per_token": 0.15634396491228073}}
