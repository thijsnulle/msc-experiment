{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.023156575858592987, -0.0030651751440018415, -0.015534351579844952, -0.2573722302913666, -0.06962983310222626, -0.11354324221611023, -0.05926443263888359], "finish_reason": "stop"}, {"text": " fr\"^{letter.lower()}\\w+\"", "tokens": [" fr", "\"", "^{", "letter", ".", "lower", "()", "}\\", "w", "+", "\"", "\n"], "logprobs": [-1.5830717086791992, -0.7735363841056824, -0.8811259865760803, -0.018740732222795486, -2.1180331707000732, -0.6889632344245911, -0.23312196135520935, -2.848620653152466, -0.02561257779598236, -0.4323514997959137, -0.00641288049519062, -0.05601787939667702], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex, na=False)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ",", " na", "=", "False", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -0.6469361186027527, -0.00017653337272349745, -0.0006573423161171377, -2.9606077671051025, -0.8397893309593201, -0.004000756423920393, -0.00813303142786026, -0.08197624236345291, -0.023084355518221855], "finish_reason": "stop"}, {"text": " filtered_df['Word'].map(len)", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "map", "(", "len", ")", "\n"], "logprobs": [-0.20894022285938263, -5.602820692729438e-06, -6.556489552167477e-06, -0.031049977988004684, -0.0009684640099294484, -0.0004503904783632606, -0.0011272035771980882, -2.3419628143310547, -0.00014518637908622622, -0.1242976188659668, -0.0008990298374556005, -0.1181822270154953], "finish_reason": "stop"}, {"text": " word_lengths.describe().to_dict()", "tokens": [" word", "_", "length", "s", ".", "describe", "()", ".", "to", "_", "dict", "()", "\n"], "logprobs": [-1.890281319618225, -5.221230458118953e-05, -9.059495641849935e-05, -3.8742269680369645e-05, -0.009979474358260632, -0.1283474713563919, -0.03952702134847641, -2.186737060546875, -0.07876437157392502, -5.8412379075889476e-06, -0.0005876483046449721, -0.007516081444919109, -0.015065458603203297], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics"], "logprobs": [-0.0038814221043139696], "finish_reason": "stop"}], "metrics": {"energy": 109.82191081809997, "energy_per_token": 1.7432049336206343, "time": 4.808573, "time_per_token": 0.07632655555555555}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " '^' + letter", "tokens": [" '", "^", "'", " +", " letter", "\n"], "logprobs": [-1.6166315078735352, -0.0740356296300888, -0.17526669800281525, -0.0015501875896006823, -0.02851555496454239, -0.43649452924728394], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.001053374377079308, -0.20225447416305542, -0.004751225467771292, -0.1045674979686737, -0.002060316037386656, -0.0014296083245426416, -6.305972783593461e-05, -0.05578937754034996, -0.0008834273321554065, -0.5644080638885498, -0.0002004899288294837, -0.0008858094224706292, -0.06456461548805237, -0.019974395632743835], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.18388637900352478, -5.8412379075889476e-06, -6.9141146923357155e-06, -0.03650808334350586, -0.0007800396997481585, -0.000386640167562291, -0.0012311505852267146, -0.6664060354232788, -0.0003082277253270149, -0.01052271667867899, -0.0013100859941914678, -0.0998813807964325], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-1.2915430068969727, -0.019584618508815765], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.00394661258906126, -0.5826770663261414], "finish_reason": "stop"}], "metrics": {"energy": 56.06541513633727, "energy_per_token": 1.3038468636357505, "time": 2.9573092, "time_per_token": 0.06877463255813954}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " re.compile(rf\"{letter}[\\w]*\")", "tokens": [" re", ".", "compile", "(", "rf", "\"", "{", "letter", "}[", "\\", "w", "]*", "\"", ")", "\n"], "logprobs": [-2.16574764251709, -0.0005389191792346537, -0.00883515179157257, -0.2533490061759949, -1.6680209636688232, -0.40611499547958374, -2.1652047634124756, -0.04085148125886917, -1.9030516147613525, -2.379913330078125, -0.07570395618677139, -0.9541173577308655, -0.022822221741080284, -0.2056216597557068, -0.019930807873606682], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -1.0512425899505615, -0.00013553177996072918, -0.00037651124875992537, -0.05826626718044281, -0.01801193132996559], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.198097825050354, -6.079655122448457e-06, -6.437280717364047e-06, -0.032878387719392776, -0.0009758477681316435, -0.000459565402707085, -0.0012635351158678532, -0.814681351184845, -0.0002989322238136083, -0.009252645075321198, -0.0015206689713522792, -0.09549149125814438], "finish_reason": "stop"}, {"text": " {'mean': word_lengths.mean(),", "tokens": [" {'", "mean", "':", " word", "_", "length", "s", ".", "mean", "()", ",", "\n"], "logprobs": [-1.7151020765304565, -0.010197443887591362, -0.004220388829708099, -0.49152153730392456, -4.291525328881107e-06, -2.6225699912174605e-05, -6.079655122448457e-06, -0.00026556302327662706, -0.0011655449634417892, -0.00109576724935323, -0.0026983539573848248, -0.40882474184036255], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.003914314787834883, -0.6604083776473999], "finish_reason": "stop"}], "metrics": {"energy": 72.73695543098448, "energy_per_token": 1.1731767004997498, "time": 3.8007357, "time_per_token": 0.06130218870967742}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " fr'^{letter}.*'", "tokens": [" fr", "'^", "{", "letter", "}", ".", "*", "'", "\n"], "logprobs": [-1.5830717086791992, -1.205045461654663, -1.3925464153289795, -0.026469960808753967, -2.8219144344329834, -0.010738680139183998, -0.28063836693763733, -0.09564144164323807, -0.029873182997107506], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -1.0512425899505615, -0.00013553177996072918, -0.00037651124875992537, -0.05826626718044281, -0.01801193132996559], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(len)", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "len", ")", "\n"], "logprobs": [-0.198097825050354, -6.079655122448457e-06, -6.437280717364047e-06, -0.032878387719392776, -0.0009758477681316435, -0.000459565402707085, -0.0012635351158678532, -0.7728856205940247, -0.00011574551899684593, -0.24452707171440125, -0.0003673355677165091, -0.0822763592004776], "finish_reason": "stop"}, {"text": " word_lengths.describe()", "tokens": [" word", "_", "length", "s", ".", "describe", "()", "\n"], "logprobs": [-2.037017822265625, -5.376194530981593e-05, -0.00010883215873036534, -6.174850568640977e-05, -0.0073958649300038815, -0.11659033596515656, -0.03665473312139511, -0.08529792726039886], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics"], "logprobs": [-0.003890684340149164], "finish_reason": "stop"}], "metrics": {"energy": 65.15966870498657, "energy_per_token": 1.277640562842874, "time": 3.3706245, "time_per_token": 0.06609067647058824}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " f'^{letter}'", "tokens": [" f", "'^", "{", "letter", "}'", "\n"], "logprobs": [-1.836806297302246, -2.036292791366577, -0.28844794631004333, -0.008668768219649792, -0.20024056732654572, -0.02676677145063877], "finish_reason": "stop"}, {"text": " df.loc[df['Word'].str.match(regex)]", "tokens": [" df", ".", "loc", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -1.7547948360443115, -0.1119583323597908, -0.004274161532521248, -0.006696047727018595, -0.15212410688400269, -0.0011247029760852456, -0.0023063032422214746, -9.190614218823612e-05, -0.027374165132641792, -0.0006273209000937641, -0.584535539150238, -0.0005871717585250735, -0.0005159238935448229, -0.06522844731807709, -0.022235257551074028], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len().tolist()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", ".", "tol", "ist", "()", "\n"], "logprobs": [-0.17923925817012787, -7.986990567587782e-06, -7.152531907195225e-06, -0.033918797969818115, -0.0008304246584884822, -0.0004374024283606559, -0.0016166010173037648, -0.7365696430206299, -0.0003530356043484062, -0.008053804747760296, -0.0013304438907653093, -2.1263129711151123, -1.76414954662323, -1.5139465176616795e-05, -0.0003573255962692201, -0.013272741809487343], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-1.243082046508789, -0.02319268509745598], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.0037161121144890785, -0.6397988200187683], "finish_reason": "stop"}], "metrics": {"energy": 57.70609872627257, "energy_per_token": 1.1776754842096444, "time": 3.166361, "time_per_token": 0.06461961224489797}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " '^' + letter + '.*'", "tokens": [" '", "^", "'", " +", " letter", " +", " '", ".", "*", "'", "\n"], "logprobs": [-1.6166315078735352, -0.0740356296300888, -0.17526669800281525, -0.0015501875896006823, -0.02851555496454239, -1.2770802974700928, -0.1047840416431427, -0.23610620200634003, -0.33397218585014343, -0.0161848496645689, -0.046653423458337784], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.001053374377079308, -0.20225447416305542, -0.004751225467771292, -0.1045674979686737, -0.002060316037386656, -0.0014296083245426416, -6.305972783593461e-05, -0.05578937754034996, -0.0008834273321554065, -0.5644080638885498, -0.0002004899288294837, -0.0008858094224706292, -0.06456461548805237, -0.019974395632743835], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.18388637900352478, -5.8412379075889476e-06, -6.9141146923357155e-06, -0.03650808334350586, -0.0007800396997481585, -0.000386640167562291, -0.0012311505852267146, -0.6664060354232788, -0.0003082277253270149, -0.01052271667867899, -0.0013100859941914678, -0.0998813807964325], "finish_reason": "stop"}, {"text": " filtered_df[['Word']].describe()", "tokens": [" filtered", "_", "df", "[", "['", "Word", "']", "]", ".", "describe", "()", "\n"], "logprobs": [-3.0584325790405273, -0.00022015532886143774, -0.005167105700820684, -0.5022371411323547, -0.6680116653442383, -0.012762888334691525, -0.48159700632095337, -0.09156522899866104, -0.04688800126314163, -1.2295546531677246, -0.1955443024635315, -0.27222940325737], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.00394661258906126, -0.5826770663261414], "finish_reason": "stop"}], "metrics": {"energy": 85.89923728942874, "energy_per_token": 1.4810213325763575, "time": 3.3795063, "time_per_token": 0.05826735}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " letter + r'\\w+'", "tokens": [" letter", " +", " r", "'\\", "w", "+'", "\n"], "logprobs": [-3.296719551086426, -0.11187263578176498, -1.1903947591781616, -0.9560387134552002, -0.029889265075325966, -0.2540246844291687, -0.09069646894931793], "finish_reason": "stop"}, {"text": " df[df[\"Word\"].str.startswith(regex)]", "tokens": [" df", "[", "df", "[", "\"", "Word", "\"", "]", ".", "str", ".", "start", "sw", "ith", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -2.7707087993621826, -0.06303585320711136, -0.0032169281039386988, -0.00019488819816615433, -6.425174069590867e-05, -0.00010275312524754554, -0.048300787806510925, -0.0014399646315723658, -3.502166748046875, -0.00022587609419133514, -5.8412379075889476e-06, -0.00019059749320149422, -0.0018857807153835893, -0.05884021893143654, -0.02505526877939701], "finish_reason": "stop"}, {"text": " [len(word) for word in filtered_df['Word']]", "tokens": [" [", "len", "(", "word", ")", " for", " word", " in", " filtered", "_", "df", "['", "Word", "']", "]", "\n"], "logprobs": [-2.6911067962646484, -0.002454484812915325, -0.0013638966483995318, -0.13452333211898804, -0.03432456776499748, -0.00263569806702435, -0.0060325926169753075, -0.0005091324565000832, -0.007806980051100254, -1.2159273865108844e-05, -1.0132738680113107e-05, -0.01107061468064785, -0.00011562632425921038, -0.00037472377880476415, -0.5115838646888733, -0.003613848239183426], "finish_reason": "stop"}, {"text": " word_lengths.describe()", "tokens": [" word", "_", "length", "s", ".", "describe", "()", "\n"], "logprobs": [-1.8464086055755615, -4.2437604861333966e-05, -7.331102824537084e-05, -3.981510963058099e-05, -0.00780556071549654, -0.11286313086748123, -0.04621312767267227, -0.12230423837900162], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.003828459419310093, -0.634368360042572], "finish_reason": "stop"}], "metrics": {"energy": 83.40975692367553, "energy_per_token": 1.4380992573047506, "time": 3.7970452, "time_per_token": 0.06546629655172413}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " rf\"\\b{letter}\"", "tokens": [" r", "f", "\"", "\\", "b", "{", "letter", "}\"", "\n"], "logprobs": [-1.7171430587768555, -1.4639348983764648, -0.4218291938304901, -2.0741915702819824, -0.06480038911104202, -0.1458379179239273, -0.01350104995071888, -1.9470677375793457, -0.05317104235291481], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -0.6469361186027527, -0.00017653337272349745, -0.0006573423161171377, -0.0671197697520256, -0.0214015394449234], "finish_reason": "stop"}, {"text": " [len(word) for word in filtered_df['Word']]", "tokens": [" [", "len", "(", "word", ")", " for", " word", " in", " filtered", "_", "df", "['", "Word", "']", "]", "\n"], "logprobs": [-2.5662648677825928, -0.0025184601545333862, -0.0014881737297400832, -0.15335220098495483, -0.03467225655913353, -0.0025662605185061693, -0.005808379966765642, -0.0005589353386312723, -0.007856539450585842, -1.1086402082582936e-05, -9.894321920000948e-06, -0.013917305506765842, -0.00011836781777674332, -0.0004563482361845672, -0.5539207458496094, -0.00353925209492445], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-1.3653104305267334, -0.023714711889624596], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics"], "logprobs": [-0.003734877100214362], "finish_reason": "stop"}], "metrics": {"energy": 65.66383058166504, "energy_per_token": 1.3400781751360211, "time": 3.3808448, "time_per_token": 0.06899683265306122}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " f'^{letter}'", "tokens": [" f", "'^", "{", "letter", "}'", "\n"], "logprobs": [-1.836806297302246, -2.036292791366577, -0.28844794631004333, -0.008668768219649792, -0.20024056732654572, -0.02676677145063877], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -1.0512425899505615, -0.00013553177996072918, -0.00037651124875992537, -0.05826626718044281, -0.01801193132996559], "finish_reason": "stop"}, {"text": " [len(word) for word in filtered_df['Word']]", "tokens": [" [", "len", "(", "word", ")", " for", " word", " in", " filtered", "_", "df", "['", "Word", "']", "]", "\n"], "logprobs": [-2.623091220855713, -0.0027215369045734406, -0.0016872945707291365, -0.1728186160326004, -0.03492094203829765, -0.0028501623310148716, -0.004650491289794445, -0.0005860995152033865, -0.007830636575818062, -1.3470558769768104e-05, -8.4638240878121e-06, -0.012982252985239029, -0.00011431517486926168, -0.0004159538948442787, -0.45363402366638184, -0.0032881025690585375], "finish_reason": "stop"}, {"text": " word_lengths.describe()", "tokens": [" word", "_", "length", "s", ".", "describe", "()", "\n"], "logprobs": [-1.9990650415420532, -4.8993817472364753e-05, -8.83301836438477e-05, -4.577531944960356e-05, -0.006936161778867245, -0.1415787786245346, -0.03581765666604042, -0.08980124443769455], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.003827746957540512, -0.6208891868591309], "finish_reason": "stop"}], "metrics": {"energy": 67.45900676155092, "energy_per_token": 1.2728114483311495, "time": 3.3808722, "time_per_token": 0.06379004150943397}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " r\"^\" + letter", "tokens": [" r", "\"", "^", "\"", " +", " letter", "\n"], "logprobs": [-1.7171430587768555, -1.2045793533325195, -0.398112416267395, -0.22169052064418793, -0.05568080395460129, -0.07237327098846436, -0.4858540892601013], "finish_reason": "stop"}, {"text": " df.loc[df['Word'].str.match(regex)]", "tokens": [" df", ".", "loc", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -1.7547948360443115, -0.1119583323597908, -0.004274161532521248, -0.006696047727018595, -0.15212410688400269, -0.0011247029760852456, -0.0023063032422214746, -9.190614218823612e-05, -0.027374165132641792, -0.0006273209000937641, -0.584535539150238, -0.0005871717585250735, -0.0005159238935448229, -0.06522844731807709, -0.022235257551074028], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(len)", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "len", ")", "\n"], "logprobs": [-0.17923925817012787, -7.986990567587782e-06, -7.152531907195225e-06, -0.033918797969818115, -0.0008304246584884822, -0.0004374024283606559, -0.0016166010173037648, -0.8839313983917236, -0.00011443436960689723, -0.2987304627895355, -0.00035375059815123677, -0.08126892894506454], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-1.3235903978347778, -0.02563093602657318], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics"], "logprobs": [-0.003741527907550335], "finish_reason": "stop"}], "metrics": {"energy": 62.26639275455474, "energy_per_token": 1.383697616767883, "time": 3.1586373, "time_per_token": 0.07019194000000001}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " rf\"^[a-zA-Z]*?({letter})\"", "tokens": [" r", "f", "\"", "^", "[", "a", "-", "z", "A", "-", "Z", "]*", "?", "({", "letter", "})", "\"", "\n"], "logprobs": [-1.7171430587768555, -1.4639348983764648, -0.4218291938304901, -1.1498826742172241, -3.0879299640655518, -0.8480684757232666, -0.2128729373216629, -0.014373810961842537, -0.5768968462944031, -0.0008136299438774586, -0.009763936512172222, -2.002025604248047, -1.9481462240219116, -3.130239963531494, -0.018071172758936882, -0.738792359828949, -1.3242568969726562, -0.04662281647324562], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -0.6469361186027527, -0.00017653337272349745, -0.0006573423161171377, -0.0671197697520256, -0.0214015394449234], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(len)", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "len", ")", "\n"], "logprobs": [-0.20894022285938263, -5.602820692729438e-06, -6.556489552167477e-06, -0.031049977988004684, -0.0009684640099294484, -0.0004503904783632606, -0.0011272035771980882, -0.9183579683303833, -0.00012587709352374077, -0.21369776129722595, -0.0003692421887535602, -0.08216436207294464], "finish_reason": "stop"}, {"text": " {}", "tokens": [" {}", "\n"], "logprobs": [-1.7987819910049438, -0.0014484162675216794], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.0038814221043139696, -0.6533024311065674], "finish_reason": "stop"}], "metrics": {"energy": 71.76254868412018, "energy_per_token": 1.3047736124385487, "time": 3.5689352, "time_per_token": 0.0648897309090909}}
{"outputs": [{"text": " pd.DataFrame(df['Word'])", "tokens": [" pd", ".", "DataFrame", "(", "df", "['", "Word", "'])", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -2.9414451122283936, -0.002010706812143326, -0.16110759973526, -0.05755716934800148], "finish_reason": "stop"}, {"text": " '^' + letter + '.*'", "tokens": [" '", "^", "'", " +", " letter", " +", " '", ".", "*", "'", "\n"], "logprobs": [-1.6166315078735352, -0.0740356296300888, -0.17526669800281525, -0.0015501875896006823, -0.02851555496454239, -1.2770802974700928, -0.1047840416431427, -0.23610620200634003, -0.33397218585014343, -0.0161848496645689, -0.046653423458337784], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.001053374377079308, -0.20225447416305542, -0.004751225467771292, -0.1045674979686737, -0.002060316037386656, -0.0014296083245426416, -6.305972783593461e-05, -0.05578937754034996, -0.0008834273321554065, -0.5644080638885498, -0.0002004899288294837, -0.0008858094224706292, -0.06456461548805237, -0.019974395632743835], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(lambda x: len(x))", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "lambda", " x", ":", " len", "(", "x", "))", "\n"], "logprobs": [-0.18388637900352478, -5.8412379075889476e-06, -6.9141146923357155e-06, -0.03650808334350586, -0.0007800396997481585, -0.000386640167562291, -0.0012311505852267146, -1.0005277395248413, -0.00012730741582345217, -1.5694663524627686, -0.18988299369812012, -0.0008254220010712743, -0.0009616755996830761, -7.188061863416806e-05, -0.0016663487767800689, -0.0046737478114664555, -0.042344920337200165], "finish_reason": "stop"}, {"text": " word_lengths.describe()", "tokens": [" word", "_", "length", "s", ".", "describe", "()", "\n"], "logprobs": [-2.1317050457000732, -5.2927523938706145e-05, -9.989239333663136e-05, -4.708655978902243e-05, -0.007010860368609428, -0.10613241791725159, -0.03583605960011482, -0.12805835902690887], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics"], "logprobs": [-0.0038608787581324577], "finish_reason": "stop"}], "metrics": {"energy": 72.97001898193358, "energy_per_token": 1.2161669830322264, "time": 3.5911999, "time_per_token": 0.05985333166666666}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " r'%s.' % letter", "tokens": [" r", "'", "%", "s", ".", "'", " %", " letter", "\n"], "logprobs": [-1.7171430587768555, -1.545506477355957, -2.6345977783203125, -0.025158502161502838, -0.7656326293945312, -2.491063117980957, -0.018303539603948593, -0.08346351236104965, -0.09175470471382141], "finish_reason": "stop"}, {"text": " df.loc[df['Word'].str.match(regex)]", "tokens": [" df", ".", "loc", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -1.7547948360443115, -0.1119583323597908, -0.004274161532521248, -0.006696047727018595, -0.15212410688400269, -0.0011247029760852456, -0.0023063032422214746, -9.190614218823612e-05, -0.027374165132641792, -0.0006273209000937641, -0.584535539150238, -0.0005871717585250735, -0.0005159238935448229, -0.06522844731807709, -0.022235257551074028], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(len)", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "len", ")", "\n"], "logprobs": [-0.17923925817012787, -7.986990567587782e-06, -7.152531907195225e-06, -0.033918797969818115, -0.0008304246584884822, -0.0004374024283606559, -0.0016166010173037648, -0.8839313983917236, -0.00011443436960689723, -0.2987304627895355, -0.00035375059815123677, -0.08126892894506454], "finish_reason": "stop"}, {"text": " {'mean': word_lengths.mean(),", "tokens": [" {'", "mean", "':", " word", "_", "length", "s", ".", "mean", "()", ",", "\n"], "logprobs": [-1.7476893663406372, -0.009887173771858215, -0.003443147987127304, -0.3925834000110626, -2.9802276912960224e-06, -1.7881233361549675e-05, -7.152531907195225e-06, -0.00022635281493421644, -0.0012191252317279577, -0.0009436921682208776, -0.0027514954563230276, -0.5145531892776489], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.003772168420255184, -1.2525660991668701, -1.6689286894688848e-06, -9.536738616588991e-07, -2.47952248173533e-05, -0.0001714082609396428, -0.0590374581515789], "finish_reason": "stop"}], "metrics": {"energy": 76.56290550231934, "energy_per_token": 1.215284214322529, "time": 3.7883062, "time_per_token": 0.06013184444444444}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " '^' + letter", "tokens": [" '", "^", "'", " +", " letter", "\n"], "logprobs": [-1.6166315078735352, -0.0740356296300888, -0.17526669800281525, -0.0015501875896006823, -0.02851555496454239, -0.43649452924728394], "finish_reason": "stop"}, {"text": " df.loc[df['Word'].str.contains(regex)]", "tokens": [" df", ".", "loc", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.001053374377079308, -1.7774746417999268, -0.11941344290971756, -0.004771632142364979, -0.006558559834957123, -0.14128746092319489, -0.001263297046534717, -0.0018486568005755544, -9.321732068201527e-05, -0.026612283661961555, -0.00048792376765049994, -0.9170776605606079, -0.00017855956684798002, -0.0002644904307089746, -0.1457889825105667, -0.020406536757946014], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(len)", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "len", ")", "\n"], "logprobs": [-0.17886361479759216, -5.722029527532868e-06, -6.9141146923357155e-06, -0.03983980044722557, -0.000559292733669281, -0.000390215078368783, -0.0012882990995422006, -0.9023758172988892, -0.00011860620725201443, -0.23744593560695648, -0.00041059168870560825, -0.08504635095596313], "finish_reason": "stop"}, {"text": " {'mean': np.mean(word_lengths),", "tokens": [" {'", "mean", "':", " np", ".", "mean", "(", "word", "_", "length", "s", ")", ",", "\n"], "logprobs": [-1.811228632926941, -0.009995761327445507, -0.00427202507853508, -1.0286058187484741, -4.8040190449682996e-05, -0.03287908062338829, -0.0006361367995850742, -0.0030397421214729548, -1.3589766240329482e-05, -1.3351351299206726e-05, -2.2291887944447808e-05, -0.03905147686600685, -0.0005738280597142875, -0.4379245936870575], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.003894009394571185, -0.6482671499252319], "finish_reason": "stop"}], "metrics": {"energy": 74.57765603828429, "energy_per_token": 1.3083799304962156, "time": 3.5872002, "time_per_token": 0.06293333684210527}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " '^'+letter+''", "tokens": [" '", "^", "'+", "letter", "+", "''", "\n"], "logprobs": [-1.6166315078735352, -0.0740356296300888, -2.128530979156494, -0.055220212787389755, -1.5442644357681274, -1.908006191253662, -0.05135923996567726], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.0012050755321979523, -0.16424329578876495, -0.0043165371753275394, -0.12960174679756165, -0.002152270870283246, -0.0015394752845168114, -6.818538531661034e-05, -0.0665656104683876, -0.0006984416977502406, -1.0723786354064941, -0.00018106251081917435, -0.00036483307485468686, -0.06245668977499008, -0.021116670221090317], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len().tolist()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", ".", "tol", "ist", "()", "\n"], "logprobs": [-0.16940446197986603, -3.4570634852570947e-06, -7.986990567587782e-06, -0.03210556507110596, -0.000964533886872232, -0.0003746046277228743, -0.0009706076816655695, -0.8384286165237427, -0.00023850933939684182, -0.00873364694416523, -0.0011606630869209766, -2.167248249053955, -1.9754855632781982, -2.539125671319198e-05, -0.0003357561945449561, -0.011988727375864983], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-1.3176506757736206, -0.02409287355840206], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.003871447406709194, -0.6406136155128479], "finish_reason": "stop"}], "metrics": {"energy": 62.2956745147705, "energy_per_token": 1.2978265523910522, "time": 3.1805224, "time_per_token": 0.06626088333333334}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " r'^%s.*' % letter", "tokens": [" r", "'^", "%", "s", ".", "*", "'", " %", " letter", "\n"], "logprobs": [-1.7171430587768555, -1.8144598007202148, -2.1561007499694824, -0.012554189190268517, -1.1949560642242432, -0.1950598806142807, -0.08034442365169525, -0.021555202081799507, -0.1230194941163063, -0.1062774583697319], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -1.0512425899505615, -0.00013553177996072918, -0.00037651124875992537, -0.05826626718044281, -0.01801193132996559], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(len)", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "len", ")", "\n"], "logprobs": [-0.198097825050354, -6.079655122448457e-06, -6.437280717364047e-06, -0.032878387719392776, -0.0009758477681316435, -0.000459565402707085, -0.0012635351158678532, -0.7728856205940247, -0.00011574551899684593, -0.24452707171440125, -0.0003673355677165091, -0.0822763592004776], "finish_reason": "stop"}, {"text": " word_lengths.describe()", "tokens": [" word", "_", "length", "s", ".", "describe", "()", "\n"], "logprobs": [-2.037017822265625, -5.376194530981593e-05, -0.00010883215873036534, -6.174850568640977e-05, -0.0073958649300038815, -0.11659033596515656, -0.03665473312139511, -0.08529792726039886], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics"], "logprobs": [-0.003890684340149164], "finish_reason": "stop"}], "metrics": {"energy": 85.71426601982117, "energy_per_token": 1.6483512696119456, "time": 3.380752, "time_per_token": 0.06501446153846155}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " re.compile(letter+'[a-z]*')", "tokens": [" re", ".", "compile", "(", "letter", "+'", "[", "a", "-", "z", "]*", "')", "\n"], "logprobs": [-2.16574764251709, -0.0005389191792346537, -0.00883515179157257, -0.2533490061759949, -1.0271079540252686, -3.0491158962249756, -1.8885235786437988, -0.17673426866531372, -0.0033964586909860373, -0.0024335552006959915, -0.8855783343315125, -0.1966625601053238, -0.04513325169682503], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -1.0512425899505615, -0.00013553177996072918, -0.00037651124875992537, -0.05826626718044281, -0.01801193132996559], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.198097825050354, -6.079655122448457e-06, -6.437280717364047e-06, -0.032878387719392776, -0.0009758477681316435, -0.000459565402707085, -0.0012635351158678532, -0.814681351184845, -0.0002989322238136083, -0.009252645075321198, -0.0015206689713522792, -0.09549149125814438], "finish_reason": "stop"}, {"text": " {}", "tokens": [" {}", "\n"], "logprobs": [-1.774638056755066, -0.0015453074593096972], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics"], "logprobs": [-0.003892940701916814], "finish_reason": "stop"}], "metrics": {"energy": 80.5033970451355, "energy_per_token": 1.6429264703088877, "time": 2.9589174, "time_per_token": 0.0603860693877551}}
{"outputs": [{"text": " pd.DataFrame.from_dict(df)", "tokens": [" pd", ".", "DataFrame", ".", "from", "_", "dict", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -1.455574631690979, -0.0004505096294451505, -0.0005395148764364421, -0.003210273804143071, -0.0030670766718685627, -0.015230194665491581, -0.13401634991168976, -0.050955452024936676], "finish_reason": "stop"}, {"text": " \"^\" + letter", "tokens": [" \"", "^", "\"", " +", " letter", "\n"], "logprobs": [-2.862931251525879, -0.14158840477466583, -0.08186882734298706, -0.09142816066741943, -0.03922617807984352, -0.4448945224285126], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -0.6469361186027527, -0.00017653337272349745, -0.0006573423161171377, -0.0671197697520256, -0.0214015394449234], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(len)", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "len", ")", "\n"], "logprobs": [-0.20894022285938263, -5.602820692729438e-06, -6.556489552167477e-06, -0.031049977988004684, -0.0009684640099294484, -0.0004503904783632606, -0.0011272035771980882, -0.9183579683303833, -0.00012587709352374077, -0.21369776129722595, -0.0003692421887535602, -0.08216436207294464], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-1.2711464166641235, -0.02301550842821598], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.0038814221043139696, -0.6533024311065674], "finish_reason": "stop"}], "metrics": {"energy": 66.19270774078369, "energy_per_token": 1.4083554838464614, "time": 3.3842952, "time_per_token": 0.07200628085106382}}
{"outputs": [{"text": " pd.DataFrame.from_dict(df)", "tokens": [" pd", ".", "DataFrame", ".", "from", "_", "dict", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -1.455574631690979, -0.0004505096294451505, -0.0005395148764364421, -0.003210273804143071, -0.0030670766718685627, -0.015230194665491581, -0.13401634991168976, -0.050955452024936676], "finish_reason": "stop"}, {"text": " f\"^{letter}\"", "tokens": [" f", "\"", "^", "{", "letter", "}\"", "\n"], "logprobs": [-1.836806297302246, -0.4978998005390167, -1.018179178237915, -1.0819822549819946, -0.004977691452950239, -0.11767007410526276, -0.027025090530514717], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -0.6469361186027527, -0.00017653337272349745, -0.0006573423161171377, -0.0671197697520256, -0.0214015394449234], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.20894022285938263, -5.602820692729438e-06, -6.556489552167477e-06, -0.031049977988004684, -0.0009684640099294484, -0.0004503904783632606, -0.0011272035771980882, -0.7095528841018677, -0.0002162222663173452, -0.009750832803547382, -0.0012735360069200397, -0.10964003205299377], "finish_reason": "stop"}, {"text": " {'mean': np.mean(word_lengths),", "tokens": [" {'", "mean", "':", " np", ".", "mean", "(", "word", "_", "length", "s", ")", ",", "\n"], "logprobs": [-1.7437872886657715, -0.010291249491274357, -0.0036089783534407616, -0.9883490204811096, -4.2199197196168825e-05, -0.03618885576725006, -0.0005962263094261289, -0.003317806636914611, -1.3470558769768104e-05, -1.6212332411669195e-05, -2.610649426060263e-05, -0.05124157294631004, -0.0005887205479666591, -0.4142010509967804], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.003860997501760721, -1.2388463020324707, -1.0728830375228426e-06, -9.536738616588991e-07, -3.361645576660521e-05, -0.00014149141497910023, -0.06988020241260529], "finish_reason": "stop"}], "metrics": {"energy": 78.66978043079376, "energy_per_token": 1.2103043143199042, "time": 3.7997108, "time_per_token": 0.058457089230769234}}
{"outputs": [{"text": " pd.DataFrame.from_dict(df)", "tokens": [" pd", ".", "DataFrame", ".", "from", "_", "dict", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -1.455574631690979, -0.0004505096294451505, -0.0005395148764364421, -0.003210273804143071, -0.0030670766718685627, -0.015230194665491581, -0.13401634991168976, -0.050955452024936676], "finish_reason": "stop"}, {"text": " fr\"^({letter})\"", "tokens": [" fr", "\"", "^", "({", "letter", "})", "\"", "\n"], "logprobs": [-1.5830717086791992, -0.7735363841056824, -1.4188475608825684, -1.5694711208343506, -0.02682468481361866, -0.28410810232162476, -0.2620866298675537, -0.04597577452659607], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -0.6469361186027527, -0.00017653337272349745, -0.0006573423161171377, -0.0671197697520256, -0.0214015394449234], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(lambda x: len(x))", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "lambda", " x", ":", " len", "(", "x", "))", "\n"], "logprobs": [-0.20894022285938263, -5.602820692729438e-06, -6.556489552167477e-06, -0.031049977988004684, -0.0009684640099294484, -0.0004503904783632606, -0.0011272035771980882, -0.9183579683303833, -0.00012587709352374077, -1.6683696508407593, -0.17123258113861084, -0.0007312007946893573, -0.0008450751192867756, -7.939023635117337e-05, -0.001176380319520831, -0.004296951927244663, -0.04221133515238762], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-1.2711464166641235, -0.02301550842821598], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.0038814221043139696, -0.6533024311065674], "finish_reason": "stop"}], "metrics": {"energy": 90.0657636604309, "energy_per_token": 1.667884512230202, "time": 3.3745916, "time_per_token": 0.06249243703703704}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " '^' + letter + '.*'", "tokens": [" '", "^", "'", " +", " letter", " +", " '", ".", "*", "'", "\n"], "logprobs": [-1.6166315078735352, -0.0740356296300888, -0.17526669800281525, -0.0015501875896006823, -0.02851555496454239, -1.2770802974700928, -0.1047840416431427, -0.23610620200634003, -0.33397218585014343, -0.0161848496645689, -0.046653423458337784], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.001053374377079308, -0.20225447416305542, -0.004751225467771292, -0.1045674979686737, -0.002060316037386656, -0.0014296083245426416, -6.305972783593461e-05, -0.05578937754034996, -0.0008834273321554065, -0.5644080638885498, -0.0002004899288294837, -0.0008858094224706292, -0.06456461548805237, -0.019974395632743835], "finish_reason": "stop"}, {"text": " [len(word) for word in filtered_df['Word'].tolist()]", "tokens": [" [", "len", "(", "word", ")", " for", " word", " in", " filtered", "_", "df", "['", "Word", "']", ".", "tol", "ist", "()", "]", "\n"], "logprobs": [-2.6853187084198, -0.0023617250844836235, -0.0016990762669593096, -0.16130179166793823, -0.025451403111219406, -0.002687416272237897, -0.005337156355381012, -0.0006329201860353351, -0.0063646710477769375, -1.0371154530730564e-05, -9.298280929215252e-06, -0.014998523518443108, -0.00011777184408856556, -0.0004365683125797659, -0.8958173990249634, -0.8339419364929199, -1.6093124941107817e-05, -0.000105375460407231, -0.0022557545453310013, -0.005984483286738396], "finish_reason": "stop"}, {"text": " word_lengths.agg(['mean', 'median', 'mode'])", "tokens": [" word", "_", "length", "s", ".", "agg", "(['", "mean", "'", ",", " '", "med", "ian", "'", ",", " '", "mode", "'])", "\n"], "logprobs": [-2.10906982421875, -4.994744449504651e-05, -0.00013076403411105275, -4.410646579344757e-05, -0.010373719967901707, -2.8865787982940674, -0.5230647325515747, -0.06934670358896255, -0.0009371418273076415, -0.0001668790791882202, -0.021674660965800285, -0.0007366804056800902, -0.00012766500003635883, -0.011993910185992718, -2.7417760065873154e-05, -0.012695327401161194, -0.009700658731162548, -0.03080090507864952, -0.05050152167677879], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.0037915261927992105, -1.4045586585998535, -1.4305104514278355e-06, -9.536738616588991e-07, -2.1815061700181104e-05, -0.00019810620869975537, -0.06434018164873123], "finish_reason": "stop"}], "metrics": {"energy": 100.951946187973, "energy_per_token": 1.294255720358628, "time": 4.640177, "time_per_token": 0.05948944871794872}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " re.compile(letter.lower() + r'[\\w]+')", "tokens": [" re", ".", "compile", "(", "letter", ".", "lower", "()", " +", " r", "'", "[\\", "w", "]+", "')", "\n"], "logprobs": [-2.16574764251709, -0.0005389191792346537, -0.00883515179157257, -0.2533490061759949, -1.0271079540252686, -1.960031270980835, -0.35372889041900635, -0.4482157826423645, -0.1318795084953308, -0.9634518027305603, -0.8244720697402954, -1.4416866302490234, -0.15757586061954498, -1.2495468854904175, -0.08371756970882416, -0.03210221976041794], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -0.6469361186027527, -0.00017653337272349745, -0.0006573423161171377, -0.0671197697520256, -0.0214015394449234], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(lambda x: len(x))", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "lambda", " x", ":", " len", "(", "x", "))", "\n"], "logprobs": [-0.20894022285938263, -5.602820692729438e-06, -6.556489552167477e-06, -0.031049977988004684, -0.0009684640099294484, -0.0004503904783632606, -0.0011272035771980882, -0.9183579683303833, -0.00012587709352374077, -1.6683696508407593, -0.17123258113861084, -0.0007312007946893573, -0.0008450751192867756, -7.939023635117337e-05, -0.001176380319520831, -0.004296951927244663, -0.04221133515238762], "finish_reason": "stop"}, {"text": " word_lengths.describe()", "tokens": [" word", "_", "length", "s", ".", "describe", "()", "\n"], "logprobs": [-1.890281319618225, -5.221230458118953e-05, -9.059495641849935e-05, -3.8742269680369645e-05, -0.009979474358260632, -0.1283474713563919, -0.03952702134847641, -0.1253509819507599], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.0038814221043139696, -0.6533024311065674], "finish_reason": "stop"}], "metrics": {"energy": 77.96700166225432, "energy_per_token": 1.2182344009727237, "time": 3.8036664, "time_per_token": 0.0594322875}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " '^' + letter.lower()", "tokens": [" '", "^", "'", " +", " letter", ".", "lower", "()", "\n"], "logprobs": [-1.6166315078735352, -0.0740356296300888, -0.17526669800281525, -0.0015501875896006823, -0.02851555496454239, -2.800189733505249, -0.45635026693344116, -0.00033802041434682906, -0.18136100471019745], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.001053374377079308, -0.20225447416305542, -0.004751225467771292, -0.1045674979686737, -0.002060316037386656, -0.0014296083245426416, -6.305972783593461e-05, -0.05578937754034996, -0.0008834273321554065, -1.1606357097625732, -0.00015376816736534238, -0.00036042393185198307, -0.07840291410684586, -0.01824454590678215], "finish_reason": "stop"}, {"text": " [len(word) for word in filtered_df['Word']]", "tokens": [" [", "len", "(", "word", ")", " for", " word", " in", " filtered", "_", "df", "['", "Word", "']", "]", "\n"], "logprobs": [-2.6527514457702637, -0.002242314163595438, -0.001727756578475237, -0.17955251038074493, -0.029751690104603767, -0.002410484477877617, -0.008000470697879791, -0.0006335158832371235, -0.00807189755141735, -1.2993727978027891e-05, -8.34461570775602e-06, -0.014646509662270546, -0.00011991735664196312, -0.0004580163804348558, -0.4694748818874359, -0.003584034275263548], "finish_reason": "stop"}, {"text": " pd.Series(np.nan_to_num(np.sum(word_lengths, axis=0)),", "tokens": [" pd", ".", "Series", "(", "np", ".", "nan", "_", "to", "_", "num", "(", "np", ".", "sum", "(", "word", "_", "length", "s", ",", " axis", "=", "0", "))", ",", "\n"], "logprobs": [-2.4499340057373047, -0.0011366104008629918, -0.33222198486328125, -0.8192110061645508, -2.867166042327881, -0.00017248096992261708, -3.97745418548584, -0.8091461062431335, -0.0502021498978138, -3.576278118089249e-07, -0.03614827245473862, -0.13185745477676392, -1.8494391441345215, -0.0008825936238281429, -3.3306884765625, -0.07864382863044739, -0.14403560757637024, -5.185469490243122e-05, -5.4238757002167404e-05, -3.957670196541585e-05, -1.447059988975525, -0.08467916399240494, -0.01601850986480713, -0.011442039161920547, -2.3312082290649414, -0.49180901050567627, -1.4423935413360596], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.00383653468452394, -1.3763222694396973, -1.311301275563892e-06, -9.536738616588991e-07, -2.2053474822314456e-05, -0.00013791563105769455, -0.05946675315499306], "finish_reason": "stop"}], "metrics": {"energy": 96.25506735038756, "energy_per_token": 1.2031883418798446, "time": 4.6379848, "time_per_token": 0.05797481}}
{"outputs": [{"text": " pd.DataFrame(df['Word'], columns=['Word'])", "tokens": [" pd", ".", "DataFrame", "(", "df", "['", "Word", "']", ",", " columns", "=['", "Word", "'])", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -2.9414451122283936, -0.002010706812143326, -1.9104628562927246, -0.10501718521118164, -0.11766795068979263, -0.1670304387807846, -0.04678994417190552, -0.009470654651522636, -0.019104640930891037], "finish_reason": "stop"}, {"text": " fr\"^{letter}\"", "tokens": [" fr", "\"", "^{", "letter", "}\"", "\n"], "logprobs": [-1.5830717086791992, -0.7735363841056824, -0.8811259865760803, -0.018740732222795486, -0.3781116008758545, -0.02822725847363472], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -0.6469361186027527, -0.00017653337272349745, -0.0006573423161171377, -0.0671197697520256, -0.0214015394449234], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(lambda word: len(word))", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "lambda", " word", ":", " len", "(", "word", "))", "\n"], "logprobs": [-0.20894022285938263, -5.602820692729438e-06, -6.556489552167477e-06, -0.031049977988004684, -0.0009684640099294484, -0.0004503904783632606, -0.0011272035771980882, -0.9183579683303833, -0.00012587709352374077, -1.6683696508407593, -2.649937152862549, -0.0009784678695723414, -0.0007566926069557667, -5.543078441405669e-05, -0.0012181727215647697, -0.004255881533026695, -0.035892415791749954], "finish_reason": "stop"}, {"text": " {}", "tokens": [" {}", "\n"], "logprobs": [-1.7987819910049438, -0.0014484162675216794], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.0038814221043139696, -1.2195942401885986, -1.4305104514278355e-06, -9.536738616588991e-07, -2.6225699912174605e-05, -0.00015352977789007127, -0.056166987866163254], "finish_reason": "stop"}], "metrics": {"energy": 85.36988051795957, "energy_per_token": 1.4228313419659928, "time": 3.7954006, "time_per_token": 0.06325667666666666}}
{"outputs": [{"text": " pd.DataFrame(df, index=[0])", "tokens": [" pd", ".", "DataFrame", "(", "df", ",", " index", "=[", "0", "])", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -2.677414655685425, -0.7728450894355774, -1.4358923435211182, -0.10348071157932281, -0.044343046844005585, -0.04572504013776779], "finish_reason": "stop"}, {"text": " fr\"^{letter}\"", "tokens": [" fr", "\"", "^{", "letter", "}\"", "\n"], "logprobs": [-1.5830717086791992, -0.7735363841056824, -0.8811259865760803, -0.018740732222795486, -0.3781116008758545, -0.02822725847363472], "finish_reason": "stop"}, {"text": " df.loc[df['Word'].str.match(regex)]", "tokens": [" df", ".", "loc", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -1.7547948360443115, -0.1119583323597908, -0.004274161532521248, -0.006696047727018595, -0.15212410688400269, -0.0011247029760852456, -0.0023063032422214746, -9.190614218823612e-05, -0.027374165132641792, -0.0006273209000937641, -0.584535539150238, -0.0005871717585250735, -0.0005159238935448229, -0.06522844731807709, -0.022235257551074028], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(len)", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "len", ")", "\n"], "logprobs": [-0.17923925817012787, -7.986990567587782e-06, -7.152531907195225e-06, -0.033918797969818115, -0.0008304246584884822, -0.0004374024283606559, -0.0016166010173037648, -0.8839313983917236, -0.00011443436960689723, -0.2987304627895355, -0.00035375059815123677, -0.08126892894506454], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-1.3235903978347778, -0.02563093602657318], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.003741527907550335, -0.6273318529129028], "finish_reason": "stop"}], "metrics": {"energy": 85.78695573997496, "energy_per_token": 1.750754198774999, "time": 3.1657772, "time_per_token": 0.06460769795918367}}
{"outputs": [{"text": " pd.DataFrame.from_dict(df)", "tokens": [" pd", ".", "DataFrame", ".", "from", "_", "dict", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -1.455574631690979, -0.0004505096294451505, -0.0005395148764364421, -0.003210273804143071, -0.0030670766718685627, -0.015230194665491581, -0.13401634991168976, -0.050955452024936676], "finish_reason": "stop"}, {"text": " fr\"^\\{letter}\"", "tokens": [" fr", "\"", "^\\", "{", "letter", "}\"", "\n"], "logprobs": [-1.5830717086791992, -0.7735363841056824, -3.058774471282959, -0.559775173664093, -0.016864344477653503, -0.2521970868110657, -0.031192459166049957], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -0.6469361186027527, -0.00017653337272349745, -0.0006573423161171377, -0.0671197697520256, -0.0214015394449234], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(len)", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "len", ")", "\n"], "logprobs": [-0.20894022285938263, -5.602820692729438e-06, -6.556489552167477e-06, -0.031049977988004684, -0.0009684640099294484, -0.0004503904783632606, -0.0011272035771980882, -0.9183579683303833, -0.00012587709352374077, -0.21369776129722595, -0.0003692421887535602, -0.08216436207294464], "finish_reason": "stop"}, {"text": " {'mean': word_lengths.mean(), 'median': word_lengths.median(), 'mode': word_lengths.mode()[0]}", "tokens": [" {'", "mean", "':", " word", "_", "length", "s", ".", "mean", "()", ",", " '", "med", "ian", "':", " word", "_", "length", "s", ".", "med", "ian", "()", ",", " '", "mode", "':", " word", "_", "length", "s", ".", "mode", "()[", "0", "]}", "\n"], "logprobs": [-1.8295303583145142, -0.01046809833496809, -0.0042774854227900505, -0.3611404001712799, -4.6491513785440475e-06, -2.2411095415009186e-05, -7.510157047363464e-06, -0.0002343380037928, -0.0011934071080759168, -0.000985375139862299, -0.0027806211728602648, -0.8562254905700684, -0.0002775999018922448, -6.210611172718927e-05, -0.00014780859055463225, -0.0288307536393404, -1.311301275563892e-06, -2.861018856492592e-06, -7.152555099310121e-07, -0.00016223068814724684, -0.0019075546879321337, -2.4437606043647975e-05, -0.017054684460163116, -0.00036900385748595, -0.10572560131549835, -0.0029905380215495825, -0.00038532938924618065, -0.1238182857632637, -2.6225699912174605e-05, -1.5139465176616795e-05, -7.986990567587782e-06, -0.00027783826226368546, -0.018046937882900238, -0.28152891993522644, -0.0029678368009626865, -0.014078234322369099, -0.0033286185935139656], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.003935450688004494, -0.6479232907295227], "finish_reason": "stop"}], "metrics": {"energy": 124.94419787788387, "energy_per_token": 1.5053517816612514, "time": 4.6464424, "time_per_token": 0.05598123373493975}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " fr'^({letter}).+'", "tokens": [" fr", "'^", "({", "letter", "})", ".", "+'", "\n"], "logprobs": [-1.5830717086791992, -1.205045461654663, -2.8285739421844482, -0.038181982934474945, -0.3062877953052521, -1.2037818431854248, -2.3628509044647217, -0.04985448718070984], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -1.0512425899505615, -0.00013553177996072918, -0.00037651124875992537, -0.05826626718044281, -0.01801193132996559], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.198097825050354, -6.079655122448457e-06, -6.437280717364047e-06, -0.032878387719392776, -0.0009758477681316435, -0.000459565402707085, -0.0012635351158678532, -0.814681351184845, -0.0002989322238136083, -0.009252645075321198, -0.0015206689713522792, -0.09549149125814438], "finish_reason": "stop"}, {"text": " {'mean': np.mean(word_lengths),", "tokens": [" {'", "mean", "':", " np", ".", "mean", "(", "word", "_", "length", "s", ")", ",", "\n"], "logprobs": [-1.7151020765304565, -0.010197443887591362, -0.004220388829708099, -1.0067002773284912, -4.51792984677013e-05, -0.03553065285086632, -0.0005707303644157946, -0.003545785555616021, -1.9907753085135482e-05, -1.847726889536716e-05, -2.2291887944447808e-05, -0.035666171461343765, -0.0005218812730163336, -0.43210628628730774], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.00392072694376111, -0.6278749704360962], "finish_reason": "stop"}], "metrics": {"energy": 70.19608296012878, "energy_per_token": 1.2315102273706804, "time": 3.5905228, "time_per_token": 0.06299162807017544}}
{"outputs": [{"text": " pd.DataFrame.from_dict(df)", "tokens": [" pd", ".", "DataFrame", ".", "from", "_", "dict", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -1.455574631690979, -0.0004505096294451505, -0.0005395148764364421, -0.003210273804143071, -0.0030670766718685627, -0.015230194665491581, -0.13401634991168976, -0.050955452024936676], "finish_reason": "stop"}, {"text": " r'^{}'.format(letter)", "tokens": [" r", "'", "^{", "}'", ".", "format", "(", "letter", ")", "\n"], "logprobs": [-1.7171430587768555, -1.545506477355957, -0.9310588240623474, -1.0542209148406982, -0.007630605716258287, -0.0004564673872664571, -0.0004528927383944392, -0.004563275258988142, -0.10993611812591553, -0.017503786832094193], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -0.1338927000761032, -0.0020361661445349455, -0.0012196014868095517, -6.532455881824717e-05, -0.056759607046842575, -0.0010725465836003423, -0.6469361186027527, -0.00017653337272349745, -0.0006573423161171377, -0.0671197697520256, -0.0214015394449234], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(len)", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "len", ")", "\n"], "logprobs": [-0.20894022285938263, -5.602820692729438e-06, -6.556489552167477e-06, -0.031049977988004684, -0.0009684640099294484, -0.0004503904783632606, -0.0011272035771980882, -0.9183579683303833, -0.00012587709352374077, -0.21369776129722595, -0.0003692421887535602, -0.08216436207294464], "finish_reason": "stop"}, {"text": " {'mean': word_lengths.mean(), 'median': word_lengths.median(),", "tokens": [" {'", "mean", "':", " word", "_", "length", "s", ".", "mean", "()", ",", " '", "med", "ian", "':", " word", "_", "length", "s", ".", "med", "ian", "()", ",", "\n"], "logprobs": [-1.8295303583145142, -0.01046809833496809, -0.0042774854227900505, -0.3611404001712799, -4.6491513785440475e-06, -2.2411095415009186e-05, -7.510157047363464e-06, -0.0002343380037928, -0.0011934071080759168, -0.000985375139862299, -0.0027806211728602648, -0.8562254905700684, -0.0002775999018922448, -6.210611172718927e-05, -0.00014780859055463225, -0.0288307536393404, -1.311301275563892e-06, -2.861018856492592e-06, -7.152555099310121e-07, -0.00016223068814724684, -0.0019075546879321337, -2.4437606043647975e-05, -0.017054684460163116, -0.00036900385748595, -2.3348686695098877], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.003935450688004494, -1.1920020580291748, -1.1920922133867862e-06, -9.536738616588991e-07, -1.9788545614574105e-05, -9.297892393078655e-05, -0.06453712284564972], "finish_reason": "stop"}], "metrics": {"energy": 86.35687722110745, "energy_per_token": 1.0931250281152842, "time": 4.214711, "time_per_token": 0.05335077215189874}}
{"outputs": [{"text": " pd.DataFrame(df['Word'])", "tokens": [" pd", ".", "DataFrame", "(", "df", "['", "Word", "'])", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -2.9414451122283936, -0.002010706812143326, -0.16110759973526, -0.05755716934800148], "finish_reason": "stop"}, {"text": " fr\"^{letter.lower()}\"", "tokens": [" fr", "\"", "^{", "letter", ".", "lower", "()", "}\"", "\n"], "logprobs": [-1.5830717086791992, -0.7735363841056824, -0.8811259865760803, -0.018740732222795486, -2.1180331707000732, -0.6889632344245911, -0.23312196135520935, -0.22128988802433014, -0.044406451284885406], "finish_reason": "stop"}, {"text": " df[df.Word.str.match(regex)]", "tokens": [" df", "[", "df", ".", "Word", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -0.20483756065368652, -0.0039056462701410055, -2.771540403366089, -0.03154193237423897, -0.0008457897347398102, -0.0780869722366333, -0.0004732680681627244, -0.6623908281326294, -0.00015746307326480746, -0.0011263700434938073, -0.08273738622665405, -0.03033900074660778], "finish_reason": "stop"}, {"text": " filtered_df['Word'].map(len)", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "map", "(", "len", ")", "\n"], "logprobs": [-0.19391243159770966, -5.722029527532868e-06, -7.867782187531702e-06, -0.029428446665406227, -0.0008517451351508498, -0.0004226268210913986, -0.0011462554102763534, -2.3900747299194336, -0.00015793983766343445, -0.10479671508073807, -0.0008313775178976357, -0.11220674961805344], "finish_reason": "stop"}, {"text": " {}", "tokens": [" {}", "\n"], "logprobs": [-1.816077709197998, -0.0015345951542258263], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.003846034873276949, -0.5968858599662781], "finish_reason": "stop"}], "metrics": {"energy": 60.83372530937194, "energy_per_token": 1.294334581050467, "time": 3.1758265, "time_per_token": 0.06757077659574467}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.021817319095134735, -0.002952385460957885, -0.01901809126138687, -0.2920118272304535, -0.055171482264995575, -0.1395537555217743, -0.0670369416475296], "finish_reason": "stop"}, {"text": " re.compile('^' + letter)", "tokens": [" re", ".", "compile", "('", "^", "'", " +", " letter", ")", "\n"], "logprobs": [-2.16574764251709, -0.0005389191792346537, -0.00883515179157257, -1.5035169124603271, -0.1527077555656433, -0.2409614771604538, -0.0004334702098276466, -0.029966549947857857, -0.9922317862510681, -0.022269882261753082], "finish_reason": "stop"}, {"text": " df.loc[df['Word'].str.contains(regex)]", "tokens": [" df", ".", "loc", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.0010476582683622837, -1.7547948360443115, -0.1119583323597908, -0.004274161532521248, -0.006696047727018595, -0.15212410688400269, -0.0011247029760852456, -0.0023063032422214746, -9.190614218823612e-05, -0.027374165132641792, -0.0006273209000937641, -1.054443359375, -0.00016485285595990717, -0.00019762947340495884, -0.12346296012401581, -0.0164116732776165], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.17923925817012787, -7.986990567587782e-06, -7.152531907195225e-06, -0.033918797969818115, -0.0008304246584884822, -0.0004374024283606559, -0.0016166010173037648, -0.7365696430206299, -0.0003530356043484062, -0.008053804747760296, -0.0013304438907653093, -0.13532903790473938], "finish_reason": "stop"}, {"text": " {}", "tokens": [" {}", "\n"], "logprobs": [-1.8772296905517578, -0.0014105618465691805], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.0037161121144890785, -0.6397988200187683], "finish_reason": "stop"}], "metrics": {"energy": 66.6226891965866, "energy_per_token": 1.359646718297686, "time": 3.3803155, "time_per_token": 0.0689860306122449}}
