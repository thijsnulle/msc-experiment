{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " r'^' + letter", "tokens": [" r", "'^", "'", " +", " letter", "\n"], "logprobs": [-1.011061191558838, -0.5265149474143982, -0.3515666127204895, -0.0028010678943246603, -0.1649802327156067, -0.6227855086326599], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -0.3036694824695587, -0.0602850578725338], "finish_reason": "stop"}, {"text": " [len(word) for word in filtered_df['Word']]", "tokens": [" [", "len", "(", "word", ")", " for", " word", " in", " filtered", "_", "df", "['", "Word", "']", "]", "\n"], "logprobs": [-2.058218002319336, -0.008449755609035492, -0.0004881620698142797, -0.1976523995399475, -0.003200292121618986, -0.0012957995058968663, -0.001039560534991324, -0.00022492263815365732, -0.008039141073822975, -4.410734163684538e-06, -1.1920922133867862e-06, -0.01908920146524906, -1.3828182090946939e-05, -4.386805812828243e-05, -0.20648254454135895, -0.0024182144552469254], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.6403188109397888, -0.003099163994193077], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004381936509162188, -0.27156180143356323], "finish_reason": "stop"}], "metrics": {"energy": 280.31171139049536, "energy_per_token": 5.9640789657552205, "time": 8.007237, "time_per_token": 0.17036674468085106}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " re.compile(rf\"^{letter}.*\")", "tokens": [" re", ".", "compile", "(", "rf", "\"", "^{", "letter", "}", ".", "*", "\"", ")", "\n"], "logprobs": [-1.707918643951416, -4.2437604861333966e-05, -0.009344412945210934, -0.2553574740886688, -1.0971952676773071, -0.310580313205719, -0.0649668499827385, -0.018888486549258232, -1.8056223392486572, -0.028921207413077354, -0.18716850876808167, -0.12379332631826401, -0.5375996828079224, -0.03239389881491661], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -1.6185541152954102, -5.352353764465079e-05, -0.007279420271515846, -0.026977747678756714, -0.062476400285959244], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(len)", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "len", ")", "\n"], "logprobs": [-0.20517347753047943, -2.50339189733495e-06, -1.7881377516459906e-06, -0.0150444395840168, -0.0001408954558428377, -4.279521817807108e-05, -0.00018475732940714806, -2.1818227767944336, -6.937739817658439e-05, -0.2953266203403473, -0.0002321927313460037, -0.047247838228940964], "finish_reason": "stop"}, {"text": " {}", "tokens": [" {}", "\n"], "logprobs": [-2.1361641883850098, -0.0004801789182238281], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004383123014122248, -0.2588796317577362], "finish_reason": "stop"}], "metrics": {"energy": 321.48844871139534, "energy_per_token": 6.303695072772458, "time": 8.420113, "time_per_token": 0.16510025490196079}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " re.compile(rf\"^{letter}\", re.IGNORECASE)", "tokens": [" re", ".", "compile", "(", "rf", "\"", "^{", "letter", "}\"", ",", " re", ".", "IGN", "ORE", "C", "ASE", ")", "\n"], "logprobs": [-1.707918643951416, -4.2437604861333966e-05, -0.009344412945210934, -0.2553574740886688, -1.0971952676773071, -0.310580313205719, -0.0649668499827385, -0.018888486549258232, -0.6216051578521729, -0.6252854466438293, -0.1558396816253662, -6.174850568640977e-05, -0.16085387766361237, -2.3841855067985307e-07, -3.933898824470816e-06, -1.1920928244535389e-07, -0.0040543037466704845, -0.026088397949934006], "finish_reason": "stop"}, {"text": " df.loc[df['Word'].str.match(regex)]", "tokens": [" df", ".", "loc", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -1.9960311651229858, -0.04144192114472389, -0.0036452056374400854, -0.019171535968780518, -0.060247570276260376, -0.0005890780012123287, -0.00011240804451517761, -0.00020728347590193152, -0.024566976353526115, -0.0015206689713522792, -1.167739987373352, -7.021180499577895e-05, -0.015439392998814583, -0.11780889332294464, -0.06344374269247055], "finish_reason": "stop"}, {"text": " filtered_df['Word'].apply(len)", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "apply", "(", "len", ")", "\n"], "logprobs": [-0.18897345662117004, -2.0265558760002023e-06, -2.622600959512056e-06, -0.017348797991871834, -9.846202738117427e-05, -4.207999518257566e-05, -0.00020966715237591416, -2.031998634338379, -6.258291978156194e-05, -0.23170804977416992, -0.0002454218047205359, -0.04087013378739357], "finish_reason": "stop"}, {"text": " {}", "tokens": [" {}", "\n"], "logprobs": [-2.0983803272247314, -0.000448841426987201], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004393330309540033, -0.29514700174331665], "finish_reason": "stop"}], "metrics": {"energy": 319.80345730209353, "energy_per_token": 5.610586970212167, "time": 8.844635, "time_per_token": 0.15516903508771931}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " f\"^{letter}\"", "tokens": [" f", "\"", "^{", "letter", "}\"", "\n"], "logprobs": [-1.303652286529541, -0.32782211899757385, -0.12575924396514893, -0.0075958240777254105, -0.5715790390968323, -0.047201331704854965], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -0.3036694824695587, -0.0602850578725338], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.19437983632087708, -1.6689286894688848e-06, -1.7881377516459906e-06, -0.014201764017343521, -0.000129691296024248, -5.245071224635467e-05, -0.0001234931987710297, -0.14611710608005524, -6.603976362384856e-05, -0.0004557524516712874, -8.67805938469246e-05, -0.05894395709037781], "finish_reason": "stop"}, {"text": " {}", "tokens": [" {}", "\n"], "logprobs": [-2.081273078918457, -0.0005092516075819731], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.004539778921753168, -1.9046268463134766, -6.198863957251888e-06, -1.0728830375228426e-06, -5.125986263010418e-06, -4.2676016164477915e-05, -0.09542734175920486], "finish_reason": "stop"}], "metrics": {"energy": 278.7685652389526, "energy_per_token": 5.807678442478179, "time": 7.5811267, "time_per_token": 0.15794013958333333}}
{"outputs": [{"text": " pd.DataFrame.from_dict(df)  # Converts input dictionary into a DataFrame.", "tokens": [" pd", ".", "DataFrame", ".", "from", "_", "dict", "(", "df", ")", "  ", "#", " Con", "verts", " input", " dictionary", " into", " a", " Data", "Frame", ".", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -2.2493672370910645, -7.390703103737906e-05, -1.0013530300057027e-05, -0.05706050992012024, -0.0009273757459595799, -0.005441377870738506, -0.02833433635532856, -2.0810933113098145, -0.0004300146538298577, -2.6868863105773926, -0.5134968161582947, -1.722477912902832, -0.13616019487380981, -0.7017259001731873, -0.19812500476837158, -0.029940055683255196, -0.002152270870283246, -0.9965100288391113, -0.006476958282291889], "finish_reason": "stop"}, {"text": " f'^{letter}'", "tokens": [" f", "'", "^{", "letter", "}'", "\n"], "logprobs": [-1.303652286529541, -1.6536659002304077, -0.0042397379875183105, -0.007640661206096411, -0.2980191111564636, -0.05577100068330765], "finish_reason": "stop"}, {"text": " df[df['Word'].str.startswith(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "start", "sw", "ith", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -1.8056535720825195, -1.5616295058862306e-05, -1.1920928244535389e-07, -0.0006216024048626423, -0.0604122094810009, -0.13347604870796204, -0.0597420260310173], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.20517347753047943, -2.50339189733495e-06, -1.7881377516459906e-06, -0.0150444395840168, -0.0001408954558428377, -4.279521817807108e-05, -0.00018475732940714806, -0.12438488751649857, -5.769562994828448e-05, -0.0003219324571546167, -9.440929716220126e-05, -0.057024817913770676], "finish_reason": "stop"}, {"text": " {'mean': word_lengths.mean(), 'median': np.median(word_lengths), 'mode': word_lengths.mode()[0]}", "tokens": [" {'", "mean", "':", " word", "_", "length", "s", ".", "mean", "()", ",", " '", "med", "ian", "':", " np", ".", "med", "ian", "(", "word", "_", "length", "s", ")", ",", " '", "mode", "':", " word", "_", "length", "s", ".", "mode", "()[", "0", "]}", "\n"], "logprobs": [-1.2137413024902344, -0.003272061934694648, -0.003100233618170023, -0.3323141634464264, -2.7418097943154862e-06, -4.0531076592742465e-06, -8.106198947643861e-06, -0.00011753345461329445, -0.0003486264031380415, -0.003013238776475191, -0.003175813239067793, -0.30772319436073303, -0.0007979070069268346, -3.9934315282152966e-05, -0.00015639036428183317, -1.9079229831695557, -1.2993727978027891e-05, -0.010011340491473675, -3.8980677345534787e-05, -0.000494715350214392, -0.004739360883831978, -1.5497195136049413e-06, -7.986990567587782e-06, -2.098061486321967e-05, -0.02181055396795273, -0.0010954099707305431, -0.09046922624111176, -0.0026793316937983036, -0.00033885458833537996, -0.12359918653964996, -4.291525328881107e-06, -2.992108420585282e-05, -2.7656173188006505e-05, -0.00040665941196493804, -0.001416871091350913, -0.9725986123085022, -0.0008673481643199921, -0.007018199656158686, -0.002464830409735441], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.0045830924063920975, -0.24968263506889343], "finish_reason": "stop"}], "metrics": {"energy": 452.98948803710965, "energy_per_token": 4.669994722032058, "time": 11.983535, "time_per_token": 0.12354159793814433}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " f\"^{letter}\"", "tokens": [" f", "\"", "^{", "letter", "}\"", "\n"], "logprobs": [-1.303652286529541, -0.32782211899757385, -0.12575924396514893, -0.0075958240777254105, -0.5715790390968323, -0.047201331704854965], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex, case=False)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ",", " case", "=", "False", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -1.3555645942687988, -0.2676081359386444, -0.00914255902171135, -0.0722586065530777, -0.3357550799846649, -0.05193717032670975], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.22576995193958282, -1.7881377516459906e-06, -1.9073468138230965e-06, -0.01983381249010563, -0.0001232548092957586, -4.470248313737102e-05, -0.00019977481861133128, -0.14532387256622314, -5.209310256759636e-05, -0.00030286493711173534, -8.892617915989831e-05, -0.06495355814695358], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.6996928453445435, -0.003914314787834883], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004527081269770861, -0.29551345109939575], "finish_reason": "stop"}], "metrics": {"energy": 269.9106649093628, "energy_per_token": 5.742780104454528, "time": 7.791748, "time_per_token": 0.16578187234042555}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " r'^' + letter + r'.*'", "tokens": [" r", "'^", "'", " +", " letter", " +", " r", "'", ".", "*", "'", "\n"], "logprobs": [-1.011061191558838, -0.5265149474143982, -0.3515666127204895, -0.0028010678943246603, -0.1649802327156067, -0.988038957118988, -0.05054549500346184, -0.343648761510849, -1.0600879192352295, -0.085356704890728, -0.1499568074941635, -0.058558739721775055], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex, case=False, regex=True)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ",", " case", "=", "False", ",", " regex", "=", "True", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -1.3555645942687988, -0.2676081359386444, -0.00914255902171135, -0.0722586065530777, -1.2738349437713623, -0.5611267685890198, -0.0012465096078813076, -0.003150858450680971, -0.030478693544864655, -0.05930240452289581], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.22576995193958282, -1.7881377516459906e-06, -1.9073468138230965e-06, -0.01983381249010563, -0.0001232548092957586, -4.470248313737102e-05, -0.00019977481861133128, -0.14532387256622314, -5.209310256759636e-05, -0.00030286493711173534, -8.892617915989831e-05, -0.06495355814695358], "finish_reason": "stop"}, {"text": " {}", "tokens": [" {}", "\n"], "logprobs": [-2.1252355575561523, -0.0004690977220889181], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004527081269770861, -0.29551345109939575], "finish_reason": "stop"}], "metrics": {"energy": 310.4484847793578, "energy_per_token": 5.446464645251891, "time": 8.419979, "time_per_token": 0.1477189298245614}}
{"outputs": [{"text": " pd.DataFrame.from_dict(df)  # Convert dictionary to a DataFrame", "tokens": [" pd", ".", "DataFrame", ".", "from", "_", "dict", "(", "df", ")", "  ", "#", " Convert", " dictionary", " to", " a", " Data", "Frame", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -2.2493672370910645, -7.390703103737906e-05, -1.0013530300057027e-05, -0.05706050992012024, -0.0009273757459595799, -0.005441377870738506, -0.02833433635532856, -2.0810933113098145, -0.0004300146538298577, -0.41608670353889465, -1.4594290256500244, -0.19592244923114777, -1.7013397216796875, -0.07163182646036148, -0.0031726048327982426, -0.28655484318733215], "finish_reason": "stop"}, {"text": " f\"^{letter}.*\"", "tokens": [" f", "\"", "^{", "letter", "}", ".", "*", "\"", "\n"], "logprobs": [-1.303652286529541, -0.32782211899757385, -0.12575924396514893, -0.0075958240777254105, -1.9379158020019531, -0.03484012559056282, -0.1728348731994629, -0.07232403010129929, -0.05618513375520706], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -0.3036694824695587, -0.0602850578725338], "finish_reason": "stop"}, {"text": " [len(word) for word in filtered_df['Word']]", "tokens": [" [", "len", "(", "word", ")", " for", " word", " in", " filtered", "_", "df", "['", "Word", "']", "]", "\n"], "logprobs": [-2.058218002319336, -0.008449755609035492, -0.0004881620698142797, -0.1976523995399475, -0.003200292121618986, -0.0012957995058968663, -0.001039560534991324, -0.00022492263815365732, -0.008039141073822975, -4.410734163684538e-06, -1.1920922133867862e-06, -0.01908920146524906, -1.3828182090946939e-05, -4.386805812828243e-05, -0.20648254454135895, -0.0024182144552469254], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.6403188109397888, -0.003099163994193077], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004381936509162188, -0.27156180143356323], "finish_reason": "stop"}], "metrics": {"energy": 351.6609523200988, "energy_per_token": 5.671950843872561, "time": 9.461078, "time_per_token": 0.15259803225806454}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " '^' + letter  # Compile the letter prefix", "tokens": [" '", "^", "'", " +", " letter", "  ", "#", " Com", "pile", " the", " letter", " prefix", "\n"], "logprobs": [-2.265615940093994, -0.10030730068683624, -0.11396295577287674, -0.0019821536261588335, -0.06102093681693077, -2.805406093597412, -0.00645113829523325, -4.412342548370361, -0.0028671605978161097, -1.5677353143692017, -1.9080588817596436, -4.0505523681640625, -2.0598692893981934], "finish_reason": "stop"}, {"text": " df[df['Word'].str.startswith(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "start", "sw", "ith", "(", "regex", ")]", "\n"], "logprobs": [-0.0038653912488371134, -0.1809624880552292, -0.03135143965482712, -0.10288085043430328, -0.0009191579301841557, -0.0001062098381225951, -0.00029047083808109164, -0.04669734090566635, -0.0012732979375869036, -1.70499587059021, -1.4305012882687151e-05, -1.1920928244535389e-07, -0.0007563352701254189, -0.07716791331768036, -0.14123240113258362, -0.06859488785266876], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.1806112676858902, -1.6689286894688848e-06, -1.7881377516459906e-06, -0.017256824299693108, -0.0001113352773245424, -4.792098479811102e-05, -0.00015293381875380874, -0.10304560512304306, -5.566918844124302e-05, -0.00030727434204891324, -0.00010477947944309562, -0.0550188347697258], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.7407781481742859, -0.003097024979069829], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004541914910078049, -0.24162828922271729], "finish_reason": "stop"}], "metrics": {"energy": 279.2819346504211, "energy_per_token": 5.3708064355850205, "time": 8.002604, "time_per_token": 0.15389623076923076}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " '^' + letter + '.*'", "tokens": [" '", "^", "'", " +", " letter", " +", " '", ".", "*", "'", "\n"], "logprobs": [-2.265615940093994, -0.10030730068683624, -0.11396295577287674, -0.0019821536261588335, -0.06102093681693077, -0.7098708748817444, -0.2769974172115326, -0.47977200150489807, -0.07913009822368622, -0.06792593747377396, -0.06309214979410172], "finish_reason": "stop"}, {"text": " df.loc[df['Word'].str.match(regex)]", "tokens": [" df", ".", "loc", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.0038653912488371134, -2.045315742492676, -0.03945081681013107, -0.003721100278198719, -0.014314232394099236, -0.06479055434465408, -0.0006935574929229915, -0.00011801023356383666, -0.00023457636416424066, -0.025753512978553772, -0.0010637345258146524, -1.0503132343292236, -9.989239333663136e-05, -0.017821189016103745, -0.11667510122060776, -0.06867502629756927], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.2855178117752075, -1.7881377516459906e-06, -2.0265558760002023e-06, -0.016619568690657616, -0.00013326710904948413, -5.3165931603871286e-05, -0.00019905969384126365, -0.12235908955335617, -6.115249561844394e-05, -0.00041869457345455885, -0.00010406429646536708, -0.05683157593011856], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.6728259921073914, -0.0031890033278614283], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.0044580125249922276, -1.848968744277954, -6.6756979322235566e-06, -1.4305104514278355e-06, -3.576272320060525e-06, -4.95898348162882e-05, -0.09815417230129242], "finish_reason": "stop"}], "metrics": {"energy": 290.0457149639129, "energy_per_token": 5.273558453889326, "time": 8.415055, "time_per_token": 0.153001}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " re.compile(rf\"^{letter}\\w*\", re.IGNORECASE)", "tokens": [" re", ".", "compile", "(", "rf", "\"", "^{", "letter", "}\\", "w", "*", "\"", ",", " re", ".", "IGN", "ORE", "C", "ASE", ")", "\n"], "logprobs": [-1.707918643951416, -4.2437604861333966e-05, -0.009344412945210934, -0.2553574740886688, -1.0971952676773071, -0.310580313205719, -0.0649668499827385, -0.018888486549258232, -2.202373743057251, -0.10892102122306824, -1.9334574937820435, -0.24899747967720032, -1.1082837581634521, -0.2106221318244934, -4.207999518257566e-05, -0.33944419026374817, -3.576278118089249e-07, -3.576272320060525e-06, -1.1920928244535389e-07, -0.005804350133985281, -0.03634072467684746], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -1.6185541152954102, -5.352353764465079e-05, -0.007279420271515846, -0.026977747678756714, -0.062476400285959244], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.20517347753047943, -2.50339189733495e-06, -1.7881377516459906e-06, -0.0150444395840168, -0.0001408954558428377, -4.279521817807108e-05, -0.00018475732940714806, -0.12438488751649857, -5.769562994828448e-05, -0.0003219324571546167, -9.440929716220126e-05, -0.057024817913770676], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.7681045532226562, -0.003453364595770836], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004609554074704647, -0.2510150671005249], "finish_reason": "stop"}], "metrics": {"energy": 302.7148594112397, "energy_per_token": 5.219221713986891, "time": 8.626816, "time_per_token": 0.14873820689655173}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " f'^{letter}'", "tokens": [" f", "'", "^{", "letter", "}'", "\n"], "logprobs": [-1.303652286529541, -1.6536659002304077, -0.0042397379875183105, -0.007640661206096411, -0.2980191111564636, -0.05577100068330765], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -0.3036694824695587, -0.0602850578725338], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.19437983632087708, -1.6689286894688848e-06, -1.7881377516459906e-06, -0.014201764017343521, -0.000129691296024248, -5.245071224635467e-05, -0.0001234931987710297, -0.14611710608005524, -6.603976362384856e-05, -0.0004557524516712874, -8.67805938469246e-05, -0.05894395709037781], "finish_reason": "stop"}, {"text": " {}", "tokens": [" {}", "\n"], "logprobs": [-2.081273078918457, -0.0005092516075819731], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.004539778921753168, -1.9046268463134766, -6.198863957251888e-06, -1.0728830375228426e-06, -5.125986263010418e-06, -4.2676016164477915e-05, -0.09542734175920486], "finish_reason": "stop"}], "metrics": {"energy": 279.4723490562439, "energy_per_token": 5.822340605338415, "time": 7.580703, "time_per_token": 0.1579313125}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " re.compile('^{}'.format(letter))", "tokens": [" re", ".", "compile", "('", "^{", "}'", ".", "format", "(", "letter", "))", "\n"], "logprobs": [-1.707918643951416, -4.2437604861333966e-05, -0.009344412945210934, -1.4925248622894287, -0.9990345239639282, -0.1280101090669632, -0.0007165487040765584, -0.00022206225548870862, -0.0011262509506195784, -0.011227995157241821, -0.0953003391623497, -0.0332280769944191], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -0.3036694824695587, -0.0602850578725338], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.19437983632087708, -1.6689286894688848e-06, -1.7881377516459906e-06, -0.014201764017343521, -0.000129691296024248, -5.245071224635467e-05, -0.0001234931987710297, -0.14611710608005524, -6.603976362384856e-05, -0.0004557524516712874, -8.67805938469246e-05, -0.05894395709037781], "finish_reason": "stop"}, {"text": " {}", "tokens": [" {}", "\n"], "logprobs": [-2.081273078918457, -0.0005092516075819731], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004539778921753168, -0.2586039900779724], "finish_reason": "stop"}], "metrics": {"energy": 264.3159185657502, "energy_per_token": 5.394202419709188, "time": 7.5845914, "time_per_token": 0.15478757959183673}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " f\"^{letter}.*$\"", "tokens": [" f", "\"", "^{", "letter", "}", ".", "*", "$", "\"", "\n"], "logprobs": [-1.303652286529541, -0.32782211899757385, -0.12575924396514893, -0.0075958240777254105, -1.9379158020019531, -0.03484012559056282, -0.1728348731994629, -2.741215944290161, -9.321732068201527e-05, -0.036614738404750824], "finish_reason": "stop"}, {"text": " df[df['Word'].str.startswith(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "start", "sw", "ith", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -1.8056535720825195, -1.5616295058862306e-05, -1.1920928244535389e-07, -0.0006216024048626423, -0.0604122094810009, -0.13347604870796204, -0.0597420260310173], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.20517347753047943, -2.50339189733495e-06, -1.7881377516459906e-06, -0.0150444395840168, -0.0001408954558428377, -4.279521817807108e-05, -0.00018475732940714806, -0.12438488751649857, -5.769562994828448e-05, -0.0003219324571546167, -9.440929716220126e-05, -0.057024817913770676], "finish_reason": "stop"}, {"text": " {'mean': word_lengths.mean(), 'median': word_lengths.median(), 'mode': np.sum(word_lengths.mode())}", "tokens": [" {'", "mean", "':", " word", "_", "length", "s", ".", "mean", "()", ",", " '", "med", "ian", "':", " word", "_", "length", "s", ".", "med", "ian", "()", ",", " '", "mode", "':", " np", ".", "sum", "(", "word", "_", "length", "s", ".", "mode", "()", ")}", "\n"], "logprobs": [-1.2137413024902344, -0.003272061934694648, -0.003100233618170023, -0.3323141634464264, -2.7418097943154862e-06, -4.0531076592742465e-06, -8.106198947643861e-06, -0.00011753345461329445, -0.0003486264031380415, -0.003013238776475191, -0.003175813239067793, -0.30772319436073303, -0.0007979070069268346, -3.9934315282152966e-05, -0.00015639036428183317, -0.16776874661445618, -2.264974000354414e-06, -2.3841830625315197e-06, -9.059865078597795e-06, -1.8596476365928538e-05, -0.003864441066980362, -6.9141146923357155e-06, -0.07966997474431992, -0.0005455912905745208, -0.05076783150434494, -0.0014791273279115558, -0.00035565727739594877, -2.8246257305145264, -3.361645576660521e-05, -4.413886070251465, -0.03994002938270569, -0.3081205189228058, -1.1444026313256472e-05, -4.0649541915627196e-05, -4.684815212385729e-05, -0.10695381462574005, -0.04686582088470459, -0.01869674026966095, -0.053625911474227905, -0.003518464043736458], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics"], "logprobs": [-0.0045830924063920975], "finish_reason": "stop"}], "metrics": {"energy": 421.0967679576875, "energy_per_token": 4.896474046019622, "time": 10.938654, "time_per_token": 0.1271936511627907}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " r'^' + letter", "tokens": [" r", "'^", "'", " +", " letter", "\n"], "logprobs": [-1.011061191558838, -0.5265149474143982, -0.3515666127204895, -0.0028010678943246603, -0.1649802327156067, -0.6227855086326599], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -0.3036694824695587, -0.0602850578725338], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.19437983632087708, -1.6689286894688848e-06, -1.7881377516459906e-06, -0.014201764017343521, -0.000129691296024248, -5.245071224635467e-05, -0.0001234931987710297, -0.14611710608005524, -6.603976362384856e-05, -0.0004557524516712874, -8.67805938469246e-05, -0.05894395709037781], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.6811531782150269, -0.003061728784814477], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004539778921753168, -0.2586039900779724], "finish_reason": "stop"}], "metrics": {"energy": 270.66021172142024, "energy_per_token": 6.2944235284051215, "time": 7.571325, "time_per_token": 0.17607732558139536}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " f\"^[{letter}]\"", "tokens": [" f", "\"", "^", "[{", "letter", "}]", "\"", "\n"], "logprobs": [-1.303652286529541, -0.32782211899757385, -2.9173545837402344, -0.9527336359024048, -0.005698625463992357, -0.8307545781135559, -0.16780845820903778, -0.07574351876974106], "finish_reason": "stop"}, {"text": " df[df['Word'].str.startswith(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "start", "sw", "ith", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -1.8056535720825195, -1.5616295058862306e-05, -1.1920928244535389e-07, -0.0006216024048626423, -0.0604122094810009, -0.13347604870796204, -0.0597420260310173], "finish_reason": "stop"}, {"text": " [len(word) for word in filtered_df['Word']]", "tokens": [" [", "len", "(", "word", ")", " for", " word", " in", " filtered", "_", "df", "['", "Word", "']", "]", "\n"], "logprobs": [-2.042980194091797, -0.005761563777923584, -0.0005138983833603561, -0.17263507843017578, -0.004276654217392206, -0.0016975292237475514, -0.0012507957872003317, -0.00016807096835691482, -0.008937591686844826, -4.768360213347478e-06, -1.9073468138230965e-06, -0.02777390368282795, -1.3708974620385561e-05, -5.3881147323409095e-05, -0.22848528623580933, -0.002249807585030794], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.6485856771469116, -0.0032871519215404987], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004423120059072971, -0.26137539744377136], "finish_reason": "stop"}], "metrics": {"energy": 327.6584658660889, "energy_per_token": 6.4246758012958605, "time": 8.621338, "time_per_token": 0.1690458431372549}}
{"outputs": [{"text": " pd.DataFrame(df)  # Convert input dictionary to a DataFrame", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "  ", "#", " Convert", " input", " dictionary", " to", " a", " Data", "Frame", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -2.2967395782470703, -0.0004297763225622475, -0.40973028540611267, -1.2567609548568726, -0.123763307929039, -0.42562106251716614, -0.8050306439399719, -0.04477459192276001, -0.0008579387213103473, -0.25058844685554504], "finish_reason": "stop"}, {"text": " f\"^{letter}.*\"", "tokens": [" f", "\"", "^{", "letter", "}", ".", "*", "\"", "\n"], "logprobs": [-1.303652286529541, -0.32782211899757385, -0.12575924396514893, -0.0075958240777254105, -1.9379158020019531, -0.03484012559056282, -0.1728348731994629, -0.07232403010129929, -0.05618513375520706], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex, regex=True)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ",", " regex", "=", "True", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -1.3555645942687988, -2.1875147819519043, -0.008625039830803871, -0.000900101731531322, -0.32108986377716064, -0.044111866503953934], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.2372397482395172, -2.0265558760002023e-06, -2.3841830625315197e-06, -0.019359683617949486, -7.879423355916515e-05, -4.005352093372494e-05, -0.0001938155182870105, -0.12971608340740204, -4.51792984677013e-05, -0.0003923600015696138, -9.512448741588742e-05, -0.05847834795713425], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.7782615423202515, -0.0032124125864356756], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.0044486369006335735, -0.2891300618648529], "finish_reason": "stop"}], "metrics": {"energy": 290.025245344162, "energy_per_token": 4.915682124477322, "time": 8.410518, "time_per_token": 0.14255115254237288}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " re.compile(f\"^{letter}\")", "tokens": [" re", ".", "compile", "(", "f", "\"", "^{", "letter", "}\"", ")", "\n"], "logprobs": [-1.707918643951416, -4.2437604861333966e-05, -0.009344412945210934, -0.2553574740886688, -0.9759145975112915, -0.41170576214790344, -0.05053450167179108, -0.014351719059050083, -0.34678733348846436, -0.438077837228775, -0.03522319719195366], "finish_reason": "stop"}, {"text": " df.loc[df['Word'].str.contains(regex)]", "tokens": [" df", ".", "loc", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -1.9960311651229858, -0.04144192114472389, -0.0036452056374400854, -0.019171535968780518, -0.060247570276260376, -0.0005890780012123287, -0.00011240804451517761, -0.00020728347590193152, -0.024566976353526115, -0.0015206689713522792, -0.611007809638977, -0.00010406429646536708, -0.009191815741360188, -0.325573593378067, -0.058504097163677216], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.18897345662117004, -2.0265558760002023e-06, -2.622600959512056e-06, -0.017348797991871834, -9.846202738117427e-05, -4.207999518257566e-05, -0.00020966715237591416, -0.1454896181821823, -4.9828242481453344e-05, -0.0004215544031467289, -8.332382276421413e-05, -0.05135323852300644], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.5926482677459717, -0.004135390743613243], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004513077903538942, -0.23372144997119904], "finish_reason": "stop"}], "metrics": {"energy": 313.64708143424986, "energy_per_token": 6.272941628684997, "time": 8.424413, "time_per_token": 0.16848826}}
{"outputs": [{"text": " pd.DataFrame(df)  # Convert input dictionary to a DataFrame.", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "  ", "#", " Convert", " input", " dictionary", " to", " a", " Data", "Frame", ".", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -2.2967395782470703, -0.0004297763225622475, -0.40973028540611267, -1.2567609548568726, -0.123763307929039, -0.42562106251716614, -0.8050306439399719, -0.04477459192276001, -0.0008579387213103473, -1.7164239883422852, -0.0034935176372528076], "finish_reason": "stop"}, {"text": " r'^%s' % letter", "tokens": [" r", "'^", "%", "s", "'", " %", " letter", "\n"], "logprobs": [-1.011061191558838, -0.5265149474143982, -2.732403039932251, -0.0035902110394090414, -0.3145187795162201, -0.035848021507263184, -0.04193233326077461, -0.09710215032100677], "finish_reason": "stop"}, {"text": " df.loc[df['Word'].str.contains(regex)]", "tokens": [" df", ".", "loc", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -1.9960311651229858, -0.04144192114472389, -0.0036452056374400854, -0.019171535968780518, -0.060247570276260376, -0.0005890780012123287, -0.00011240804451517761, -0.00020728347590193152, -0.024566976353526115, -0.0015206689713522792, -0.611007809638977, -0.00010406429646536708, -0.009191815741360188, -0.325573593378067, -0.058504097163677216], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.18897345662117004, -2.0265558760002023e-06, -2.622600959512056e-06, -0.017348797991871834, -9.846202738117427e-05, -4.207999518257566e-05, -0.00020966715237591416, -0.1454896181821823, -4.9828242481453344e-05, -0.0004215544031467289, -8.332382276421413e-05, -0.05135323852300644], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.5926482677459717, -0.004135390743613243], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004513077903538942, -0.23372144997119904], "finish_reason": "stop"}], "metrics": {"energy": 313.00204864120485, "energy_per_token": 5.491264011249208, "time": 8.845471, "time_per_token": 0.15518370175438595}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " f\"^{letter}\"", "tokens": [" f", "\"", "^{", "letter", "}\"", "\n"], "logprobs": [-1.303652286529541, -0.32782211899757385, -0.12575924396514893, -0.0075958240777254105, -0.5715790390968323, -0.047201331704854965], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -1.6185541152954102, -5.352353764465079e-05, -0.007279420271515846, -0.026977747678756714, -0.062476400285959244], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.20517347753047943, -2.50339189733495e-06, -1.7881377516459906e-06, -0.0150444395840168, -0.0001408954558428377, -4.279521817807108e-05, -0.00018475732940714806, -0.12438488751649857, -5.769562994828448e-05, -0.0003219324571546167, -9.440929716220126e-05, -0.057024817913770676], "finish_reason": "stop"}, {"text": " {'mean': word_lengths.mean(), 'median': word_lengths.median(), 'mode': word_lengths.mode().get(0)}", "tokens": [" {'", "mean", "':", " word", "_", "length", "s", ".", "mean", "()", ",", " '", "med", "ian", "':", " word", "_", "length", "s", ".", "med", "ian", "()", ",", " '", "mode", "':", " word", "_", "length", "s", ".", "mode", "()", ".", "get", "(", "0", ")}", "\n"], "logprobs": [-1.2137413024902344, -0.003272061934694648, -0.003100233618170023, -0.3323141634464264, -2.7418097943154862e-06, -4.0531076592742465e-06, -8.106198947643861e-06, -0.00011753345461329445, -0.0003486264031380415, -0.003013238776475191, -0.003175813239067793, -0.30772319436073303, -0.0007979070069268346, -3.9934315282152966e-05, -0.00015639036428183317, -0.16776874661445618, -2.264974000354414e-06, -2.3841830625315197e-06, -9.059865078597795e-06, -1.8596476365928538e-05, -0.003864441066980362, -6.9141146923357155e-06, -0.07966997474431992, -0.0005455912905745208, -0.05076783150434494, -0.0014791273279115558, -0.00035565727739594877, -0.08907010406255722, -5.125986263010418e-06, -1.3589766240329482e-05, -0.00011550712952157483, -0.0005721600609831512, -0.0010177677031606436, -0.618051290512085, -0.004737699870020151, -2.653127431869507, -0.41864970326423645, -0.0010896942112594843, -0.3002021014690399, -0.00748141435906291], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.0045830924063920975, -0.24968263506889343], "finish_reason": "stop"}], "metrics": {"energy": 390.6182071857452, "energy_per_token": 4.82244700229315, "time": 10.512157, "time_per_token": 0.1297797160493827}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " r\"^\" + letter", "tokens": [" r", "\"", "^", "\"", " +", " letter", "\n"], "logprobs": [-1.011061191558838, -1.432662010192871, -0.8297566771507263, -0.29308873414993286, -0.0877269059419632, -0.0982380285859108, -0.7806922793388367], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex, regex=True)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ",", " regex", "=", "True", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -1.3555645942687988, -2.1875147819519043, -0.008625039830803871, -0.000900101731531322, -0.32108986377716064, -0.044111866503953934], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.2372397482395172, -2.0265558760002023e-06, -2.3841830625315197e-06, -0.019359683617949486, -7.879423355916515e-05, -4.005352093372494e-05, -0.0001938155182870105, -0.12971608340740204, -4.51792984677013e-05, -0.0003923600015696138, -9.512448741588742e-05, -0.05847834795713425], "finish_reason": "stop"}, {"text": " {'mean': word_lengths.mean(),", "tokens": [" {'", "mean", "':", " word", "_", "length", "s", ".", "mean", "()", ",", "\n"], "logprobs": [-1.2022002935409546, -0.0027315232437103987, -0.002800592454150319, -0.3496311902999878, -2.50339189733495e-06, -5.602820692729438e-06, -9.298280929215252e-06, -0.00010394509445177391, -0.0002613918040879071, -0.002566736191511154, -0.0032696856651455164, -1.4452145099639893], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004474864806979895, -0.2502038776874542], "finish_reason": "stop"}], "metrics": {"energy": 293.50721376991254, "energy_per_token": 5.060469202929527, "time": 8.417727, "time_per_token": 0.14513322413793103}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " f'^[{letter.lower()}, {letter.upper()}]'", "tokens": [" f", "'^", "[{", "letter", ".", "lower", "()}", ",", " {", "letter", ".", "upper", "()", "}]", "'", "\n"], "logprobs": [-1.303652286529541, -2.5704941749572754, -0.4989028871059418, -0.005018376279622316, -2.1863441467285156, -0.7638224959373474, -1.6725122928619385, -1.9427239894866943, -0.8786613345146179, -9.059495641849935e-05, -0.00023767507809679955, -0.013322618789970875, -0.2741933763027191, -0.0037125491071492434, -0.053012214601039886, -0.07448188215494156], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -0.3036694824695587, -0.0602850578725338], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.19437983632087708, -1.6689286894688848e-06, -1.7881377516459906e-06, -0.014201764017343521, -0.000129691296024248, -5.245071224635467e-05, -0.0001234931987710297, -0.14611710608005524, -6.603976362384856e-05, -0.0004557524516712874, -8.67805938469246e-05, -0.05894395709037781], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.6811531782150269, -0.003061728784814477], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004539778921753168, -0.2586039900779724], "finish_reason": "stop"}], "metrics": {"energy": 280.5145480880738, "energy_per_token": 5.292727322416487, "time": 7.9957566, "time_per_token": 0.1508633320754717}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " re.compile(f'^[{letter}][A-Za-z]+')", "tokens": [" re", ".", "compile", "(", "f", "'^", "[{", "letter", "}", "][", "A", "-", "Z", "a", "-", "z", "]+", "')", "\n"], "logprobs": [-1.707918643951416, -4.2437604861333966e-05, -0.009344412945210934, -0.2553574740886688, -0.9759145975112915, -2.840111494064331, -0.458662748336792, -0.029456572607159615, -2.3167223930358887, -0.19714170694351196, -2.115912914276123, -0.0008045773720368743, -0.10840356349945068, -0.009098615497350693, -6.9141146923357155e-06, -0.0001734344696160406, -0.9808480739593506, -0.43839672207832336, -0.05879750847816467], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -0.3036694824695587, -0.0602850578725338], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.19437983632087708, -1.6689286894688848e-06, -1.7881377516459906e-06, -0.014201764017343521, -0.000129691296024248, -5.245071224635467e-05, -0.0001234931987710297, -0.14611710608005524, -6.603976362384856e-05, -0.0004557524516712874, -8.67805938469246e-05, -0.05894395709037781], "finish_reason": "stop"}, {"text": " {'mean': word_lengths.mean(), 'median': word_lengths.median(), 'mode': word_lengths.mode().iloc[0]}", "tokens": [" {'", "mean", "':", " word", "_", "length", "s", ".", "mean", "()", ",", " '", "med", "ian", "':", " word", "_", "length", "s", ".", "med", "ian", "()", ",", " '", "mode", "':", " word", "_", "length", "s", ".", "mode", "()", ".", "il", "oc", "[", "0", "]}", "\n"], "logprobs": [-1.3184174299240112, -0.0029762755148112774, -0.0024442579597234726, -0.2856396734714508, -2.50339189733495e-06, -4.172316494077677e-06, -9.298280929215252e-06, -9.238292841473594e-05, -0.0002828436263371259, -0.0025584129616618156, -0.004911619704216719, -0.34064486622810364, -0.0008061258122324944, -4.446407547220588e-05, -0.0001731960946926847, -0.18806575238704681, -1.9073468138230965e-06, -2.264974000354414e-06, -1.0490362910786644e-05, -1.645074735279195e-05, -0.0041066608391702175, -4.291525328881107e-06, -0.07595789432525635, -0.0005236684810370207, -0.056193359196186066, -0.0015310243470594287, -0.00036566724884323776, -0.08755774050951004, -5.006777428206988e-06, -1.3589766240329482e-05, -0.00011062010162277147, -0.0005355831235647202, -0.0010318199638277292, -0.583330512046814, -0.004742208402603865, -0.8432880640029907, -1.1920928244535389e-07, -8.320462075062096e-05, -0.0008088654140010476, -0.006632812786847353, -0.003540796460583806], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004507381934672594, -0.2872064411640167], "finish_reason": "stop"}], "metrics": {"energy": 429.1662691717148, "energy_per_token": 4.517539675491735, "time": 11.772943, "time_per_token": 0.12392571578947369}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " f\"^{letter}(.*)\"", "tokens": [" f", "\"", "^{", "letter", "}(", ".", "*", ")\"", "\n"], "logprobs": [-1.303652286529541, -0.32782211899757385, -0.12575924396514893, -0.0075958240777254105, -3.5648727416992188, -0.9739449620246887, -0.8366878628730774, -0.12101035565137863, -0.05014296621084213], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex, case=True, na=False)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ",", " case", "=", "True", ",", " na", "=", "False", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -1.3555645942687988, -0.2676081359386444, -0.00914255902171135, -2.66804575920105, -0.43390733003616333, -0.29003146290779114, -0.00031716562807559967, -0.002830310957506299, -0.047563325613737106, -0.031063267961144447], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.22576995193958282, -1.7881377516459906e-06, -1.9073468138230965e-06, -0.01983381249010563, -0.0001232548092957586, -4.470248313737102e-05, -0.00019977481861133128, -0.14532387256622314, -5.209310256759636e-05, -0.00030286493711173534, -8.892617915989831e-05, -0.06495355814695358], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.6996928453445435, -0.003914314787834883], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004527081269770861, -0.29551345109939575], "finish_reason": "stop"}], "metrics": {"energy": 287.60999394130704, "energy_per_token": 5.3261109989130935, "time": 8.224031, "time_per_token": 0.15229687037037037}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " '^' + letter + '.*'", "tokens": [" '", "^", "'", " +", " letter", " +", " '", ".", "*", "'", "\n"], "logprobs": [-2.265615940093994, -0.10030730068683624, -0.11396295577287674, -0.0019821536261588335, -0.06102093681693077, -0.7098708748817444, -0.2769974172115326, -0.47977200150489807, -0.07913009822368622, -0.06792593747377396, -0.06309214979410172], "finish_reason": "stop"}, {"text": " df[df['Word'].str.startswith(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "start", "sw", "ith", "(", "regex", ")]", "\n"], "logprobs": [-0.0038653912488371134, -0.1809624880552292, -0.03135143965482712, -0.10288085043430328, -0.0009191579301841557, -0.0001062098381225951, -0.00029047083808109164, -0.04669734090566635, -0.0012732979375869036, -1.70499587059021, -1.4305012882687151e-05, -1.1920928244535389e-07, -0.0007563352701254189, -0.07716791331768036, -0.14123240113258362, -0.06859488785266876], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.1806112676858902, -1.6689286894688848e-06, -1.7881377516459906e-06, -0.017256824299693108, -0.0001113352773245424, -4.792098479811102e-05, -0.00015293381875380874, -0.10304560512304306, -5.566918844124302e-05, -0.00030727434204891324, -0.00010477947944309562, -0.0550188347697258], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.7407781481742859, -0.003097024979069829], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.004541914910078049, -1.9648834466934204, -4.887569048150908e-06, -9.536738616588991e-07, -4.6491513785440475e-06, -5.531158240046352e-05, -0.10083737224340439], "finish_reason": "stop"}], "metrics": {"energy": 293.1000297470093, "energy_per_token": 5.329091449945623, "time": 8.209915, "time_per_token": 0.14927118181818183}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " r'^' + letter", "tokens": [" r", "'^", "'", " +", " letter", "\n"], "logprobs": [-1.011061191558838, -0.5265149474143982, -0.3515666127204895, -0.0028010678943246603, -0.1649802327156067, -0.6227855086326599], "finish_reason": "stop"}, {"text": " df[df['Word'].str.match(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "match", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -1.6185541152954102, -5.352353764465079e-05, -0.007279420271515846, -0.026977747678756714, -0.062476400285959244], "finish_reason": "stop"}, {"text": " [len(word) for word in filtered_df['Word']]", "tokens": [" [", "len", "(", "word", ")", " for", " word", " in", " filtered", "_", "df", "['", "Word", "']", "]", "\n"], "logprobs": [-2.042980194091797, -0.005761563777923584, -0.0005138983833603561, -0.17263507843017578, -0.004276654217392206, -0.0016975292237475514, -0.0012507957872003317, -0.00016807096835691482, -0.008937591686844826, -4.768360213347478e-06, -1.9073468138230965e-06, -0.02777390368282795, -1.3708974620385561e-05, -5.3881147323409095e-05, -0.22848528623580933, -0.002249807585030794], "finish_reason": "stop"}, {"text": " {'mean': word_lengths.mean(),", "tokens": [" {'", "mean", "':", " word", "_", "length", "s", ".", "mean", "()", ",", "\n"], "logprobs": [-1.3327134847640991, -0.0031112858559936285, -0.0025718489196151495, -0.32173019647598267, -2.7418097943154862e-06, -4.529942543740617e-06, -1.2516897186287679e-05, -0.00012039413559250534, -0.000359351426595822, -0.002798809204250574, -0.003993513528257608, -1.2989554405212402], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.00444104103371501, -0.2762509882450104], "finish_reason": "stop"}], "metrics": {"energy": 313.2883182373047, "energy_per_token": 5.496286284864994, "time": 8.810305, "time_per_token": 0.1545667543859649}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " r'^' + re.escape(letter)", "tokens": [" r", "'^", "'", " +", " re", ".", "escape", "(", "letter", ")", "\n"], "logprobs": [-1.011061191558838, -0.5265149474143982, -0.3515666127204895, -0.0028010678943246603, -2.032392740249634, -0.0003195490571670234, -0.0012256737099960446, -0.0008708022069185972, -0.004863930866122246, -0.016824256628751755, -0.35751983523368835], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -0.3036694824695587, -0.0602850578725338], "finish_reason": "stop"}, {"text": " [len(word) for word in filtered_df['Word']]", "tokens": [" [", "len", "(", "word", ")", " for", " word", " in", " filtered", "_", "df", "['", "Word", "']", "]", "\n"], "logprobs": [-2.058218002319336, -0.008449755609035492, -0.0004881620698142797, -0.1976523995399475, -0.003200292121618986, -0.0012957995058968663, -0.001039560534991324, -0.00022492263815365732, -0.008039141073822975, -4.410734163684538e-06, -1.1920922133867862e-06, -0.01908920146524906, -1.3828182090946939e-05, -4.386805812828243e-05, -0.20648254454135895, -0.0024182144552469254], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.6403188109397888, -0.003099163994193077], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004381936509162188, -0.27156180143356323], "finish_reason": "stop"}], "metrics": {"energy": 316.43530805206314, "energy_per_token": 6.085294385616598, "time": 8.603558, "time_per_token": 0.16545303846153844}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " f\"^{letter}\"", "tokens": [" f", "\"", "^{", "letter", "}\"", "\n"], "logprobs": [-1.303652286529541, -0.32782211899757385, -0.12575924396514893, -0.0075958240777254105, -0.5715790390968323, -0.047201331704854965], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -0.3036694824695587, -0.0602850578725338], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.19437983632087708, -1.6689286894688848e-06, -1.7881377516459906e-06, -0.014201764017343521, -0.000129691296024248, -5.245071224635467e-05, -0.0001234931987710297, -0.14611710608005524, -6.603976362384856e-05, -0.0004557524516712874, -8.67805938469246e-05, -0.05894395709037781], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.6811531782150269, -0.003061728784814477], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004539778921753168, -0.2586039900779724], "finish_reason": "stop"}], "metrics": {"energy": 259.18839961051947, "energy_per_token": 6.027637200244639, "time": 7.151344, "time_per_token": 0.16631032558139536}}
{"outputs": [{"text": " pd.DataFrame.from_dict(df)", "tokens": [" pd", ".", "DataFrame", ".", "from", "_", "dict", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -2.2493672370910645, -7.390703103737906e-05, -1.0013530300057027e-05, -0.05706050992012024, -0.0009273757459595799, -0.005441377870738506, -0.02833433635532856, -0.15995848178863525], "finish_reason": "stop"}, {"text": " '^' + letter + '.*'", "tokens": [" '", "^", "'", " +", " letter", " +", " '", ".", "*", "'", "\n"], "logprobs": [-2.265615940093994, -0.10030730068683624, -0.11396295577287674, -0.0019821536261588335, -0.06102093681693077, -0.7098708748817444, -0.2769974172115326, -0.47977200150489807, -0.07913009822368622, -0.06792593747377396, -0.06309214979410172], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.0038653912488371134, -0.1809624880552292, -0.03135143965482712, -0.10288085043430328, -0.0009191579301841557, -0.0001062098381225951, -0.00029047083808109164, -0.04669734090566635, -0.0012732979375869036, -0.4420373737812042, -0.00014435203047469258, -0.0066412207670509815, -0.33773428201675415, -0.05546654760837555], "finish_reason": "stop"}, {"text": " filtered_df['Word'].str.len()", "tokens": [" filtered", "_", "df", "['", "Word", "']", ".", "str", ".", "len", "()", "\n"], "logprobs": [-0.17004618048667908, -1.7881377516459906e-06, -1.6689286894688848e-06, -0.0160163976252079, -9.285972191719338e-05, -4.95898348162882e-05, -0.00015376816736534238, -0.09326844662427902, -4.7205765440594405e-05, -0.0003899767471011728, -0.00012730741582345217, -0.058250635862350464], "finish_reason": "stop"}, {"text": " {", "tokens": [" {", "\n"], "logprobs": [-0.8617573380470276, -0.0040345946326851845], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.00443273363634944, -2.034403085708618, -4.768360213347478e-06, -1.4305104514278355e-06, -4.6491513785440475e-06, -4.172238186583854e-05, -0.10124155133962631], "finish_reason": "stop"}], "metrics": {"energy": 280.60293549442287, "energy_per_token": 4.9228585174460155, "time": 8.207343, "time_per_token": 0.14398847368421053}}
{"outputs": [{"text": " pd.DataFrame(df)", "tokens": [" pd", ".", "DataFrame", "(", "df", ")", "\n"], "logprobs": [-0.01335226185619831, -7.510157047363464e-06, -0.000964414793998003, -0.12044955044984818, -0.017259635031223297, -0.05538365617394447, -0.12946507334709167], "finish_reason": "stop"}, {"text": " re.compile(r\"^\\w\", re.IGNORECASE)", "tokens": [" re", ".", "compile", "(", "r", "\"", "^\\", "w", "\"", ",", " re", ".", "IGN", "ORE", "C", "ASE", ")", "\n"], "logprobs": [-1.707918643951416, -4.2437604861333966e-05, -0.009344412945210934, -0.2553574740886688, -1.8232275247573853, -1.0061883926391602, -2.918454885482788, -1.5479459762573242, -1.4698468446731567, -0.9545010924339294, -0.08221069723367691, -0.0001357701694360003, -0.37224656343460083, -3.2186455882765586e-06, -4.327203714638017e-05, 0.0, -0.006108069326728582, -0.06606224924325943], "finish_reason": "stop"}, {"text": " df[df['Word'].str.contains(regex)]", "tokens": [" df", "[", "df", "['", "Word", "']", ".", "str", ".", "contains", "(", "regex", ")]", "\n"], "logprobs": [-0.004644202534109354, -0.18457260727882385, -0.03299004212021828, -0.08508707582950592, -0.0008351890719495714, -0.00010609064338495955, -0.00025567124248482287, -0.041438374668359756, -0.0015489972429350019, -0.4713105857372284, -0.00014232576359063387, -0.008623739704489708, -0.3036694824695587, -0.0602850578725338], "finish_reason": "stop"}, {"text": " [len(word) for word in filtered_df['Word']]", "tokens": [" [", "len", "(", "word", ")", " for", " word", " in", " filtered", "_", "df", "['", "Word", "']", "]", "\n"], "logprobs": [-2.058218002319336, -0.008449755609035492, -0.0004881620698142797, -0.1976523995399475, -0.003200292121618986, -0.0012957995058968663, -0.001039560534991324, -0.00022492263815365732, -0.008039141073822975, -4.410734163684538e-06, -1.1920922133867862e-06, -0.01908920146524906, -1.3828182090946939e-05, -4.386805812828243e-05, -0.20648254454135895, -0.0024182144552469254], "finish_reason": "stop"}, {"text": " {'mean': word_lengths.mean(),", "tokens": [" {'", "mean", "':", " word", "_", "length", "s", ".", "mean", "()", ",", "\n"], "logprobs": [-1.3365049362182617, -0.0031519278418272734, -0.002435457892715931, -0.29465293884277344, -2.50339189733495e-06, -3.2186455882765586e-06, -9.775113539944869e-06, -0.00010024998482549563, -0.0002759314374998212, -0.0027272433508187532, -0.0031533539295196533, -1.34941828250885], "finish_reason": "stop"}, {"text": " statistics", "tokens": [" statistics", "\n"], "logprobs": [-0.004376832861453295, -0.288358598947525], "finish_reason": "stop"}], "metrics": {"energy": 400.4325990028383, "energy_per_token": 5.8033710000411345, "time": 10.731128, "time_per_token": 0.15552359420289855}}
