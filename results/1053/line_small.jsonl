{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.005173983983695507, -0.00017379203927703202, -0.0023097521625459194, -1.5139465176616795e-05, -0.0009378563845530152, -0.0005874100024811924, -0.007867065258324146, -0.0002094287920044735, -2.5033637939486653e-05, -0.6469104886054993, -0.029181979596614838], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ")", "\n"], "logprobs": [-0.00025781645672395825, -7.271740287251305e-06, -1.8000440832111053e-05, -0.07604783028364182, -0.2979539632797241, -0.0003000047872774303, -7.617183291586116e-05, -0.1092836856842041, -0.0344008170068264, -3.576278118089249e-07, -0.014434677548706532, -6.079655122448457e-06, -4.529942543740617e-06, -1.7046782886609435e-05, -0.32258516550064087, -0.028298065066337585], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"]).toarray()", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", ".", "to", "array", "()", "\n"], "logprobs": [-0.00984928384423256, -1.2993727978027891e-05, -6.770858453819528e-05, -0.008332251571118832, -0.0007544293766841292, -0.0001134808044298552, -0.005398457404226065, -0.02183224819600582, -0.5150436162948608, -0.003564434824511409, -0.0005304598016664386, -9.095255518332124e-05, -0.07122193276882172, -1.7981398105621338, -0.12487267702817917, -0.0019507441902533174, -0.06882326304912567, -0.07900243997573853], "finish_reason": "stop"}, {"text": " sum(word_count.toarray())", "tokens": [" sum", "(", "word", "_", "count", ".", "to", "array", "())", "\n"], "logprobs": [-0.8599192500114441, -0.48794442415237427, -0.10821861028671265, -0.01172590721398592, -0.0015901790466159582, -0.010838684625923634, -0.2559657394886017, -0.0014747231034561992, -0.22538883984088898, -0.012592330574989319], "finish_reason": "stop"}, {"text": " (word_count.T / sum_words).T", "tokens": [" (", "word", "_", "count", ".", "T", " /", " sum", "_", "words", ")", ".", "T", "\n"], "logprobs": [-0.9663421511650085, -0.1986439973115921, -0.0009544108179397881, -4.2914423829643056e-05, -0.11986570060253143, -0.2590146064758301, -0.01908990368247032, -0.009995879605412483, -0.0001823735801735893, -4.1126360883936286e-05, -0.03903542459011078, -0.10872001200914383, -1.4356831312179565, -0.10345438122749329], "finish_reason": "stop"}, {"text": "word, sum_words[i]) for word, i in vectorizer.vocabulary_.items()", "tokens": ["word", ",", " sum", "_", "words", "[", "i", "])", " for", " word", ",", " i", " in", " vector", "izer", ".", "voc", "abulary", "_", ".", "items", "()", "\n"], "logprobs": [-0.0690324455499649, -0.09284625202417374, -1.218300223350525, -0.018209194764494896, -0.01652412675321102, -0.05751597881317139, -1.1175178289413452, -0.19256171584129333, -0.5725239515304565, -0.03402446210384369, -0.002999570919200778, -0.003968222998082638, -0.0029407371766865253, -0.09438882768154144, -8.821448318485636e-06, -9.524368942948058e-05, -0.04253195598721504, -0.007344507612287998, -9.798523387871683e-05, -0.00016497205069754273, -0.0009684640099294484, -9.679325739853084e-05, -0.022983821108937263], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.08250953257083893, -0.00030071981018409133, -0.1488153487443924, -0.0009756095823831856, -6.007967749610543e-05, -0.002518816851079464, -0.019914332777261734, -0.0028627626597881317, -0.0015676839975640178, -0.02268553525209427, -0.0003554189461283386, -0.26011183857917786, -0.0058275796473026276, -0.0022879871539771557, -0.02342805452644825, -0.0001486429391661659, -0.005796409212052822, -0.0004391897819004953, -0.0005155664402991533, -0.01713847555220127, -0.18215657770633698], "finish_reason": "stop"}, {"text": " words_freq[0:10]", "tokens": [" words", "_", "freq", "[", "0", ":", "1", "0", "]", "\n"], "logprobs": [-0.3154958188533783, -8.177422569133341e-05, -3.4927710657939315e-05, -1.6727137565612793, -0.03807113692164421, -0.02615041472017765, -0.018585583195090294, -0.0045376429334282875, -0.0018991068936884403, -0.005611381959170103], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Frequency\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "F", "requency", "\"", "])", "\n"], "logprobs": [-0.01768510416150093, -0.0044648959301412106, -0.0023321115877479315, -0.0793665423989296, -0.15420643985271454, -7.068861305015162e-05, -8.583032467868179e-06, -0.06033814325928688, -0.022706860676407814, -0.04433745890855789, -0.0073359874077141285, -0.24426117539405823, -0.005907338112592697, -0.0002181292074965313, -0.0022851326502859592, -0.6359559297561646, -0.08300205320119858, -0.0038538724184036255, -0.0051009273156523705, -0.036858003586530685], "finish_reason": "stop"}, {"text": " df_top.plot(kind='barh', figsize=(14, 3), rot=90)", "tokens": [" df", "_", "top", ".", "plot", "(", "kind", "='", "bar", "h", "'", ",", " fig", "size", "=(", "1", "4", ",", " ", "3", ")", ",", " rot", "=", "9", "0", ")", "\n"], "logprobs": [-0.19081731140613556, -0.0011276798322796822, -2.4199192921514623e-05, -0.01543575432151556, -0.11343671381473541, -0.8088793158531189, -0.6439679861068726, -1.9299061298370361, -0.0066784038208425045, -0.3201071619987488, -0.04554964601993561, -8.642300235806033e-05, -1.0266988277435303, -0.0001734344696160406, -0.021670229732990265, -0.3939276933670044, -2.7793684005737305, -0.0025234543718397617, -0.1405801922082901, -3.244309902191162, -0.42198851704597473, -0.00035577642847783864, -1.6391780376434326, -0.013099564239382744, -0.46160632371902466, -0.0006603206275030971, -0.504652738571167, -0.02109437622129917], "finish_reason": "stop"}, {"text": " save_path is not None:", "tokens": [" save", "_", "path", " is", " not", " None", ":", "\n"], "logprobs": [-0.021582501009106636, -3.433168603805825e-05, -1.311301275563892e-06, -0.893371045589447, -0.2040269821882248, -2.47952248173533e-05, -0.0011232740944251418, -0.0021564343478530645], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.009099560789763927, -0.0003023882454726845, -0.0002244459028588608, -0.009342523291707039, -8.4638240878121e-06, -6.556489552167477e-06, -0.18800847232341766, -0.006408852990716696], "finish_reason": "stop"}, {"text": "show()", "tokens": ["show", "()", "\n"], "logprobs": [-2.659780740737915, -0.05902835726737976, -0.01733122393488884], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.031794168055057526, -0.05420840531587601], "finish_reason": "stop"}, {"text": " Exception as e:", "tokens": [" Exception", " as", " e", ":", "\n"], "logprobs": [-0.9274697303771973, -0.16191568970680237, -0.23742902278900146, -0.000341476290486753, -0.0070311021991074085], "finish_reason": "stop"}, {"text": " FileNotFoundError(", "tokens": [" File", "NotFound", "Error", "(", "\n"], "logprobs": [-0.24988041818141937, -0.0001662831346038729, -0.0002451834443490952, -0.02339475043118, -1.1562913656234741], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.016820153221488, -0.0745224878191948, -0.014732616022229195, -0.0007503792876377702, -0.00687649380415678], "finish_reason": "stop"}, {"text": "f\"An error occurred: {type(e).__name__}\")", "tokens": ["f", "\"", "An", " error", " occurred", ":", " {", "type", "(", "e", ")", ".", "__", "name", "__", "}\"", ")", "\n"], "logprobs": [-0.45295095443725586, -0.0056373425759375095, -1.010070562362671, -0.11082460731267929, -0.021667080000042915, -0.135516956448555, -0.0065753767266869545, -1.973181962966919, -0.0002643712505232543, -0.008043516427278519, -0.39549440145492554, -0.0018507986096665263, -0.0003800861886702478, -0.001004906021989882, -0.0001433984871255234, -0.46021905541419983, -0.13237451016902924, -0.009795691817998886], "finish_reason": "stop"}, {"text": " None", "tokens": [" None"], "logprobs": [-0.01887175813317299], "finish_reason": "stop"}], "metrics": {"energy": 402.4585774974821, "energy_per_token": 1.7807901659180625, "time": 16.7914, "time_per_token": 0.07429823008849558}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.00498623214662075, -0.00015448330668732524, -0.0029444219544529915, -1.8954096958623268e-05, -0.001007764250971377, -0.0005876483046449721, -0.0081194331869483, -0.00022420754248742014, -2.8490614567999728e-05, -0.553931713104248, -0.030561480671167374], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS, tokenizer=str.split)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ",", " token", "izer", "=", "str", ".", "split", ")", "\n"], "logprobs": [-0.0002379134384682402, -6.6756979322235566e-06, -2.13382354559144e-05, -0.10027042031288147, -0.2961236834526062, -0.0002366024418734014, -7.283422019099817e-05, -0.11842232197523117, -0.029111698269844055, -3.576278118089249e-07, -0.010065983049571514, -7.390948667307384e-06, -5.483612312673358e-06, -1.645074735279195e-05, -1.5136433839797974, -1.4267548322677612, -1.0706723928451538, -0.0059555694460868835, -0.9420206546783447, -0.008509093895554543, -0.033929284662008286, -0.2069540023803711, -0.018702708184719086], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.006787103600800037, -1.2159273865108844e-05, -5.721882189391181e-05, -0.006773842498660088, -0.0004994813934899867, -0.00011050090688513592, -0.005885058548301458, -0.01904475875198841, -0.5851930975914001, -0.002874292666092515, -0.0006057572900317609, -8.165503095369786e-05, -0.07653459906578064, -0.1903267651796341], "finish_reason": "stop"}, {"text": " sum(word_count.sum(axis=0))", "tokens": [" sum", "(", "word", "_", "count", ".", "sum", "(", "axis", "=", "0", "))", "\n"], "logprobs": [-0.9072086811065674, -0.41431841254234314, -0.12164272367954254, -0.014297427609562874, -0.0016423083143308759, -0.011860329657793045, -1.9840790033340454, -0.00032634177478030324, -0.00871213898062706, -0.001281036646105349, -0.15050438046455383, -0.3689052164554596, -0.019714249297976494], "finish_reason": "stop"}, {"text": " pd.DataFrame(word_count.toarray() / sum_words.values(), index=vectorizer.get_feature_names(), columns=[\"Word Count\"])", "tokens": [" pd", ".", "DataFrame", "(", "word", "_", "count", ".", "to", "array", "()", " /", " sum", "_", "words", ".", "values", "()", ",", " index", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " columns", "=[", "\"", "Word", " Count", "\"", "])", "\n"], "logprobs": [-2.9290645122528076, -0.0035628906916826963, -0.40220338106155396, -0.06620685756206512, -0.21938100457191467, -9.643566590966657e-05, -1.4662635294371285e-05, -0.03949332982301712, -0.6881932020187378, -0.0026211924850940704, -0.012230400927364826, -1.760355830192566, -0.02769865281879902, -0.001755721983499825, -4.172238186583854e-05, -1.7517999410629272, -2.0078253746032715, -0.8674557209014893, -0.0084703229367733, -1.070227861404419, -0.03168492019176483, -0.07616415619850159, -3.45700973412022e-05, -0.00011467275908216834, -0.053110115230083466, -9.536738616588991e-07, -0.00021360022947192192, -1.1920928244535389e-07, -0.0010177677031606436, -0.5473857522010803, -0.0032124125864356756, -0.4939427375793457, -0.05327491834759712, -0.007762741297483444, -1.9434337615966797, -1.1822624206542969, -0.03471382334828377, -0.003196846228092909, -0.033708129078149796], "finish_reason": "stop"}, {"text": "word, word_count[0, idx] / sum_words[1])", "tokens": ["word", ",", " word", "_", "count", "[", "0", ",", " idx", "]", " /", " sum", "_", "words", "[", "1", "])", "\n"], "logprobs": [-0.08792780339717865, -0.08964420109987259, -1.544729232788086, -0.0029432333540171385, -0.0015501875896006823, -0.29829373955726624, -0.5029107332229614, -0.07471975684165955, -1.4382413625717163, -0.9483055472373962, -0.06626085191965103, -0.03652267903089523, -0.0018443731823936105, -0.00014232576359063387, -0.5455731153488159, -2.032339572906494, -0.008742627687752247, -0.33046573400497437], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.07787062972784042, -0.00025829317746683955, -0.19082529842853546, -0.0016264794394373894, -5.519237674889155e-05, -0.002419760450720787, -0.019232813268899918, -0.0030906074680387974, -0.0017314456636086106, -0.025241615250706673, -0.0003691230376716703, -0.18912915885448456, -0.004991688299924135, -0.0026315366849303246, -0.024302087724208832, -0.0001532914029667154, -0.005788587033748627, -0.00045408427831716835, -0.0005694198189303279, -0.01601850986480713, -0.18351367115974426], "finish_reason": "stop"}, {"text": " [words_freq[i] for i in range(10)]", "tokens": [" [", "words", "_", "freq", "[", "i", "]", " for", " i", " in", " range", "(", "1", "0", ")]", "\n"], "logprobs": [-1.9824731349945068, -2.9130821228027344, -0.3377048373222351, -0.004484239965677261, -0.009480101056396961, -0.3121319115161896, -0.17269054055213928, -0.0223239753395319, -0.0001532914029667154, -0.0007808735244907439, -0.0019621660467237234, -0.0003962923656217754, -0.2734763026237488, -0.04055206850171089, -0.02274787798523903, -0.004263241309672594], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Count\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "Count", "\"", "])", "\n"], "logprobs": [-0.017498280853033066, -0.004328643903136253, -0.0020864878315478563, -0.09542485326528549, -0.13958661258220673, -6.627816765103489e-05, -1.0013530300057027e-05, -0.06087052822113037, -0.02357942797243595, -0.04727012291550636, -0.006983278319239616, -0.24823178350925446, -0.005702892318367958, -0.0002803409588523209, -0.0022286358289420605, -0.9532126188278198, -0.01063854806125164, -0.0034583541564643383, -0.033920757472515106], "finish_reason": "stop"}, {"text": " df_top.plot(x=\"Word\", y=\"Count\")", "tokens": [" df", "_", "top", ".", "plot", "(", "x", "=", "\"", "Word", "\"", ",", " y", "=", "\"", "Count", "\"", ")", "\n"], "logprobs": [-0.18407858908176422, -0.0012293646577745676, -2.5629668016335927e-05, -0.01149189006537199, -0.11426223814487457, -0.7371842861175537, -1.358757734298706, -0.10237478464841843, -0.0011653067776933312, -0.0026003853417932987, -8.642300235806033e-05, -0.0006718761869706213, -0.03846203535795212, -0.0022038952447474003, -0.0002115741081070155, -5.125868119648658e-05, -4.088794958079234e-05, -2.3757054805755615, -0.05451888591051102], "finish_reason": "stop"}, {"text": " save_path:", "tokens": [" save", "_", "path", ":", "\n"], "logprobs": [-0.02155531756579876, -3.325883881188929e-05, -1.311301275563892e-06, -0.47120967507362366, -0.0024567442014813423], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.008422095328569412, -0.000289159914245829, -0.0002456601650919765, -0.0093602379783988, -5.960446742392378e-06, -5.483612312673358e-06, -0.15858864784240723, -0.006676509045064449], "finish_reason": "stop"}, {"text": "close()  # Avoid memory leakage when saving plots", "tokens": ["close", "()", "  ", "#", " Avoid", " memory", " leakage", " when", " saving", " plots", "\n"], "logprobs": [-0.17403268814086914, -0.07598518580198288, -2.4856183528900146, -0.0008586533949710429, -4.080918788909912, -0.8835567235946655, -1.6954538822174072, -2.4482574462890625, -1.3369706869125366, -3.56825590133667, -0.216743603348732], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.027844974771142006, -0.050035249441862106], "finish_reason": "stop"}, {"text": " FileNotFoundError as e:", "tokens": [" File", "NotFound", "Error", " as", " e", ":", "\n"], "logprobs": [-0.544350266456604, -2.5987286790041253e-05, -5.8412379075889476e-06, -0.2957569360733032, -0.43043628334999084, -0.0022703842259943485, -0.003735114587470889], "finish_reason": "stop"}, {"text": " FileNotFoundError(", "tokens": [" File", "NotFound", "Error", "(", "\n"], "logprobs": [-0.28743746876716614, -0.00011491115583339706, -0.00021717573690693825, -0.021740568801760674, -1.3040111064910889], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.01422432903200388, -0.06129230931401253, -0.013994540087878704, -0.0008864049450494349, -0.0059786769561469555], "finish_reason": "stop"}, {"text": "\"Unexpected error:\", type(e), e)", "tokens": ["\"", "U", "nexpected", " error", ":\"", ",", " type", "(", "e", ")", ",", " e", ")", "\n"], "logprobs": [-1.2316136360168457, -3.4268746376037598, -0.07215413451194763, -0.029827596619725227, -0.07476909458637238, -0.007883151061832905, -1.1133325099945068, -0.00011622230522334576, -0.0070548951625823975, -0.0614183247089386, -0.11777795106172562, -0.2226223349571228, -0.19783592224121094, -0.02120070345699787], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "\n"], "logprobs": [-0.018349185585975647, -0.9130445122718811], "finish_reason": "stop"}], "metrics": {"energy": 459.4058226127624, "energy_per_token": 1.823038978622073, "time": 17.856827, "time_per_token": 0.0708604246031746}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.0051756445318460464, -0.00015817821258679032, -0.0030563806649297476, -1.7404405298293568e-05, -0.0009894242975860834, -0.0005026984144933522, -0.007219536229968071, -0.00020549570035655051, -3.075552376685664e-05, -0.5617414712905884, -0.028226330876350403], "finish_reason": "stop"}, {"text": " CountVectorizer(", "tokens": [" Count", "Vector", "izer", "(", "\n"], "logprobs": [-0.0002455409849062562, -8.4638240878121e-06, -2.074220174108632e-05, -0.0847858414053917, -2.564764976501465], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df.Text)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", ".", "Text", ")", "\n"], "logprobs": [-0.008196289651095867, -1.1205610462639015e-05, -4.9828242481453344e-05, -0.006556428037583828, -0.0007550249574705958, -0.0001072826053132303, -0.005117887631058693, -0.017478249967098236, -1.5609924793243408, -0.4074462354183197, -0.20316632091999054, -0.12580759823322296], "finish_reason": "stop"}, {"text": " word_count.sum(axis=1)", "tokens": [" word", "_", "count", ".", "sum", "(", "axis", "=", "1", ")", "\n"], "logprobs": [-0.7721602916717529, -0.00015364897262770683, -0.0003196682082489133, -0.00048792376765049994, -0.033053942024707794, -1.2153594493865967, -0.0018695986364036798, -0.002774677239358425, -1.7901594638824463, -0.012584090232849121, -0.18266238272190094], "finish_reason": "stop"}, {"text": " (word_count.T / sum_words).round(2)", "tokens": [" (", "word", "_", "count", ".", "T", " /", " sum", "_", "words", ")", ".", "round", "(", "2", ")", "\n"], "logprobs": [-0.9653369784355164, -0.18753986060619354, -0.0010306290350854397, -5.006664650863968e-05, -0.12407904118299484, -0.30241504311561584, -0.016679830849170685, -0.00986616313457489, -0.000179036331246607, -4.9232225137529895e-05, -0.036221276968717575, -0.09405402839183807, -0.3707710802555084, -0.030956711620092392, -0.35950878262519836, -0.0025766051840037107, -0.1442585289478302], "finish_reason": "stop"}, {"text": "word, word_count.get_count(word), word_count.get_weight(word) / sum_words)", "tokens": ["word", ",", " word", "_", "count", ".", "get", "_", "count", "(", "word", ")", ",", " word", "_", "count", ".", "get", "_", "weight", "(", "word", ")", " /", " sum", "_", "words", ")", "\n"], "logprobs": [-0.08713739365339279, -0.11406443268060684, -1.7283744812011719, -0.003374479478225112, -0.0012729407753795385, -1.4184995889663696, -0.2634752690792084, -0.33018070459365845, -0.3037605583667755, -0.0451689176261425, -0.23796118795871735, -0.19332189857959747, -2.5248069763183594, -0.3861028552055359, -0.00837977509945631, -0.0008256602450273931, -0.005545233376324177, -0.015577074140310287, -0.005186791997402906, -1.0994964838027954, -0.008710484951734543, -0.006585088092833757, -1.3492252826690674, -0.3475722074508667, -0.10192874819040298, -0.001637547742575407, -0.0003326578007545322, -0.5202810168266296, -0.04881986230611801], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.07866895198822021, -0.00025042734341695905, -0.14547878503799438, -0.001039560534991324, -6.580135959666222e-05, -0.0018605556106194854, -0.01466013677418232, -0.0024661386851221323, -0.001572444918565452, -0.02225414291024208, -0.0004190520558040589, -0.2211763858795166, -0.005734539590775967, -0.002605617046356201, -0.01981639862060547, -0.0001512651506345719, -0.004348940681666136, -0.0005086558521725237, -0.0005296258023008704, -0.011230706237256527, -0.14727820456027985], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.3772231340408325, -0.00010287232726113871, -2.8729025871143676e-05, -0.21286898851394653, -0.017242763191461563, -0.002997193718329072, -0.0013330630026757717, -0.004982673563063145], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Frequency\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "F", "requency", "\"", "])", "\n"], "logprobs": [-0.020574131980538368, -0.004559003282338381, -0.002291436307132244, -0.08510952442884445, -0.17015056312084198, -7.70062324590981e-05, -1.0013530300057027e-05, -0.05027073621749878, -0.02859896793961525, -0.04411551356315613, -0.0049634575843811035, -0.248749777674675, -0.005769623443484306, -0.00023719835735391825, -0.0018760239472612739, -0.5710007548332214, -0.08013109862804413, -0.004256000276654959, -0.004758344031870365, -0.03166666999459267], "finish_reason": "stop"}, {"text": " df_top.plot(", "tokens": [" df", "_", "top", ".", "plot", "(", "\n"], "logprobs": [-0.18808215856552124, -0.0011403016978874803, -2.753696753643453e-05, -0.012660015374422073, -0.12286684662103653, -0.7387653589248657, -1.8285328149795532], "finish_reason": "stop"}, {"text": " save_path is not None:", "tokens": [" save", "_", "path", " is", " not", " None", ":", "\n"], "logprobs": [-0.02157386764883995, -2.9682672902708873e-05, -1.311301275563892e-06, -1.036900281906128, -0.20380230247974396, -1.9907753085135482e-05, -0.001019553979858756, -0.002386818639934063], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.007804496213793755, -0.00033539868309162557, -0.00022897482267580926, -0.009357640519738197, -6.556489552167477e-06, -5.364403477869928e-06, -0.15965043008327484, -0.006680416874587536], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.22144456207752228, -0.07760780304670334, -0.07583171129226685], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.027421023696660995, -0.05471065640449524], "finish_reason": "stop"}, {"text": " (FileNotFoundError, Exception) as e:", "tokens": [" (", "File", "NotFound", "Error", ",", " Exception", ")", " as", " e", ":", "\n"], "logprobs": [-2.667706251144409, -0.07693083584308624, -4.2676016164477915e-05, -4.768360213347478e-06, -0.21189314126968384, -0.15255333483219147, -0.190232053399086, -0.00017820201173890382, -0.4435531795024872, -0.0002181292074965313, -0.003112711710855365], "finish_reason": "stop"}, {"text": " FileNotFoundError(str(exc)) from exc", "tokens": [" File", "NotFound", "Error", "(", "str", "(", "exc", "))", " from", " exc", "\n"], "logprobs": [-0.26359280943870544, -0.0001419681793777272, -0.00021264675888232887, -0.02734934352338314, -2.290785789489746, -0.0006343498243950307, -0.017606163397431374, -0.13732220232486725, -1.0976231098175049, -0.11845165491104126, -0.01332473661750555], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.016019096598029137, -0.05831361189484596, -0.013419189490377903, -0.0006161222117953002, -0.0057900091633200645], "finish_reason": "stop"}, {"text": "f\"Error: {e}\")", "tokens": ["f", "\"", "Error", ":", " {", "e", "}\"", ")", "\n"], "logprobs": [-0.47155892848968506, -0.006577982101589441, -0.9615113735198975, -0.9973865151405334, -0.009625335223972797, -0.2948242127895355, -0.09465748071670532, -0.03493072837591171, -0.012404552660882473], "finish_reason": "stop"}, {"text": " None", "tokens": [" None"], "logprobs": [-0.01799355074763298], "finish_reason": "stop"}], "metrics": {"energy": 319.41470652008064, "energy_per_token": 1.6050990277390986, "time": 14.319416, "time_per_token": 0.07195686432160804}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.005211459007114172, -0.00015066919149830937, -0.002838750835508108, -1.9430925021879375e-05, -0.0008761619683355093, -0.0005546461907215416, -0.0068722316063940525, -0.00018618757894728333, -2.8729025871143676e-05, -0.5224968194961548, -0.025802770629525185], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00025817399728111923, -6.794906312279636e-06, -1.8358061424805783e-05, -2.4533541202545166, -0.024687355384230614], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.007134082727134228, -9.894321920000948e-06, -5.2689116273541003e-05, -0.009904760867357254, -0.000518664310220629, -9.202533692587167e-05, -0.004485070705413818, -0.02060379460453987, -0.5130606293678284, -0.0032794286962598562, -0.0005639393348246813, -7.652943895664066e-05, -0.07613831013441086, -0.16487470269203186], "finish_reason": "stop"}, {"text": " sum(word_count.toarray())", "tokens": [" sum", "(", "word", "_", "count", ".", "to", "array", "())", "\n"], "logprobs": [-0.9494540691375732, -0.37736955285072327, -0.1197400689125061, -0.014926767908036709, -0.001842707279138267, -0.010665557347238064, -0.24992136657238007, -0.0014919828390702605, -0.21244919300079346, -0.013792329467833042], "finish_reason": "stop"}, {"text": " (word_count.transpose() * sum_words).A[0].tolist()", "tokens": [" (", "word", "_", "count", ".", "trans", "pose", "()", " *", " sum", "_", "words", ")", ".", "A", "[", "0", "]", ".", "tol", "ist", "()", "\n"], "logprobs": [-1.0123094320297241, -0.16528575122356415, -0.000726197671610862, -4.970903682988137e-05, -0.16117699444293976, -2.4250075817108154, -0.0007447806419804692, -0.0014381790533661842, -0.5612082481384277, -2.185096263885498, -0.0007060657371766865, -5.340433563105762e-05, -0.03553767129778862, -0.9650862216949463, -1.096795678138733, -0.5604043006896973, -0.0013448490062728524, -0.010408877395093441, -2.2773754596710205, -0.4949515461921692, -1.585470999998506e-05, -0.06898505240678787, -0.010988673195242882], "finish_reason": "stop"}, {"text": "word, sum_words[0, word])", "tokens": ["word", ",", " sum", "_", "words", "[", "0", ",", " word", "])", "\n"], "logprobs": [-0.08267153799533844, -0.09946553409099579, -0.8848133087158203, -0.015519562177360058, -0.01192217506468296, -0.05832463502883911, -1.4003067016601562, -0.8403888940811157, -1.3605880737304688, -0.5511690974235535, -0.7426829934120178], "finish_reason": "stop"}, {"text": " sorted(", "tokens": [" sorted", "(", "\n"], "logprobs": [-0.08011943846940994, -0.00020728347590193152, -1.8055390119552612], "finish_reason": "stop"}, {"text": " words_freq[0:10]", "tokens": [" words", "_", "freq", "[", "0", ":", "1", "0", "]", "\n"], "logprobs": [-0.40261179208755493, -9.655486064730212e-05, -3.325883881188929e-05, -1.4862399101257324, -0.03999409079551697, -0.030820207670331, -0.020258305594325066, -0.005146114155650139, -0.002070903778076172, -0.004795834422111511], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Frequency\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "F", "requency", "\"", "])", "\n"], "logprobs": [-0.016966668888926506, -0.002985308412462473, -0.0024296308401972055, -0.07451418787240982, -0.14035934209823608, -5.3881147323409095e-05, -8.583032467868179e-06, -0.05633725970983505, -0.02121412567794323, -0.04281410202383995, -0.007586359512060881, -0.2403627634048462, -0.006525635719299316, -0.00028975578607060015, -0.0018999397289007902, -0.6446892023086548, -0.09054479748010635, -0.004643134772777557, -0.004281165078282356, -0.032374974340200424], "finish_reason": "stop"}, {"text": " plt.barh(df_top[\"Word\"], df_top[\"Count\"], alpha=0.7)", "tokens": [" plt", ".", "bar", "h", "(", "df", "_", "top", "[", "\"", "Word", "\"", "]", ",", " df", "_", "top", "[", "\"", "Count", "\"", "]", ",", " alpha", "=", "0", ".", "7", ")", "\n"], "logprobs": [-1.8435173034667969, -0.00022635281493421644, -0.9838570356369019, -1.0163986682891846, -0.019249066710472107, -1.1245259046554565, -0.0010674261720851064, -1.4305012882687151e-05, -0.12529303133487701, -0.0004940004437230527, -0.0005000770906917751, -3.909988299710676e-05, -0.0018111744429916143, -0.01813778653740883, -0.011751708574593067, -2.9801878554280847e-05, -2.3841855067985307e-07, -0.0020553194917738438, -1.680836794548668e-05, -3.6000557884108275e-05, -2.8490614567999728e-05, -1.1767549514770508, -0.010891159996390343, -2.951951265335083, -0.00369473360478878, -0.04653463512659073, -0.0005052005290053785, -1.1512280702590942, -1.2283689975738525, -0.004861083813011646], "finish_reason": "stop"}, {"text": " save_path:", "tokens": [" save", "_", "path", ":", "\n"], "logprobs": [-0.021861523389816284, -4.100715523236431e-05, -1.6689286894688848e-06, -0.43594303727149963, -0.002415122464299202], "finish_reason": "stop"}, {"text": "savefig(save_path, bbox_inches=\"tight\", transparent=True)", "tokens": ["save", "fig", "(", "save", "_", "path", ",", " b", "box", "_", "in", "ches", "=", "\"", "tight", "\"", ",", " transparent", "=", "True", ")", "\n"], "logprobs": [-0.007641962729394436, -0.0003216941258870065, -0.0002213471452705562, -0.008749245665967464, -6.6756979322235566e-06, -6.198863957251888e-06, -1.8454314470291138, -0.3585972189903259, -0.00047791501856409013, -0.0002847504511009902, -0.00027223696815781295, -0.0018980359891429543, -0.16687700152397156, -0.001627550576813519, -0.0047034104354679585, -5.2689116273541003e-05, -1.4315159320831299, -1.75071120262146, -0.0010056205792352557, -0.02784682996571064, -0.13397027552127838, -0.010574618354439735], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.1798550933599472, -0.09561359882354736, -0.09331992268562317], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.028095712885260582, -0.06075577065348625], "finish_reason": "stop"}, {"text": " FileNotFoundError as err:", "tokens": [" File", "NotFound", "Error", " as", " err", ":", "\n"], "logprobs": [-0.6109086871147156, -2.5033637939486653e-05, -5.8412379075889476e-06, -0.20828785002231598, -2.210084915161133, -0.004665679298341274, -0.004528624005615711], "finish_reason": "stop"}, {"text": " FileNotFoundError(", "tokens": [" File", "NotFound", "Error", "(", "\n"], "logprobs": [-0.2409537136554718, -0.00015758226800244302, -0.00019774865359067917, -0.029857216402888298, -1.2119921445846558], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.014822238124907017, -0.05714968591928482, -0.012384654954075813, -0.0007401349139399827, -0.005503977183252573], "finish_reason": "stop"}, {"text": "f\"Unexpected error: {e}\")", "tokens": ["f", "\"", "U", "nexpected", " error", ":", " {", "e", "}\"", ")", "\n"], "logprobs": [-0.4119381606578827, -0.006016714498400688, -2.8269412517547607, -0.06092683598399162, -0.051092520356178284, -0.12639419734477997, -0.004132541362196207, -0.3552953004837036, -0.09243366867303848, -0.07917746156454086, -0.02055474743247032], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.014116199687123299, -1.25632905960083, -3.576278118089249e-07, -1.9073468138230965e-06, -0.00010466027742950246, -0.00029583368450403214, -0.134088397026062], "finish_reason": "stop"}], "metrics": {"energy": 320.0309228115081, "energy_per_token": 1.5687790333897456, "time": 14.491356, "time_per_token": 0.07103605882352941}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.005211459007114172, -0.00015066919149830937, -0.002838750835508108, -1.9430925021879375e-05, -0.0008761619683355093, -0.0005546461907215416, -0.0068722316063940525, -0.00018618757894728333, -2.8729025871143676e-05, -0.5224968194961548, -0.025802770629525185], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ")", "\n"], "logprobs": [-0.00025817399728111923, -6.794906312279636e-06, -1.8358061424805783e-05, -0.0906127467751503, -0.2650561034679413, -0.000248401309363544, -7.343022298300639e-05, -0.11092213541269302, -0.037477556616067886, -4.768370445162873e-07, -0.015035162679851055, -8.22540732769994e-06, -5.602820692729438e-06, -1.7523612768854946e-05, -0.2928990423679352, -0.026718953624367714], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.007707854732871056, -1.3112935448589269e-05, -5.328513361746445e-05, -0.010148354806005955, -0.0003936707798857242, -9.7508447652217e-05, -0.0057126120664179325, -0.021334325894713402, -0.4810216724872589, -0.004112122114747763, -0.0005335576133802533, -7.438383181579411e-05, -0.06843281537294388, -0.17909148335456848], "finish_reason": "stop"}, {"text": " word_count.sum(axis=0)", "tokens": [" word", "_", "count", ".", "sum", "(", "axis", "=", "0", ")", "\n"], "logprobs": [-0.8224682211875916, -0.00013505500101018697, -0.0003499372396618128, -0.0004558716027531773, -0.0403115339577198, -1.2364673614501953, -0.0018358058296144009, -0.0027526842895895243, -0.14450864493846893, -0.006579640321433544, -0.17778006196022034], "finish_reason": "stop"}, {"text": " word_count.toarray().T / sum_words", "tokens": [" word", "_", "count", ".", "to", "array", "()", ".", "T", " /", " sum", "_", "words", "\n"], "logprobs": [-1.7367104291915894, -0.00013839241000823677, -2.777537883957848e-05, -0.1345377117395401, -0.955309271812439, -0.008651867508888245, -0.023960551247000694, -1.0141947269439697, -1.314963936805725, -0.12382271140813828, -0.019459180533885956, -0.0013275867095217109, -3.111314072157256e-05, -0.21151307225227356], "finish_reason": "stop"}, {"text": "word, sum_words[word])", "tokens": ["word", ",", " sum", "_", "words", "[", "word", "])", "\n"], "logprobs": [-0.07576518505811691, -0.06839306652545929, -0.8715373873710632, -0.017096523195505142, -0.010960965417325497, -0.07930047065019608, -1.86641263961792, -0.8766341209411621, -1.0198626518249512], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.09257092326879501, -0.0002598424907773733, -0.1716979593038559, -0.001081834896467626, -6.794698856538162e-05, -0.002263010013848543, -0.016704097390174866, -0.002542122732847929, -0.0019101722864434123, -0.018442580476403236, -0.00035553809721022844, -0.23427633941173553, -0.006746964529156685, -0.0023352038115262985, -0.020667903125286102, -0.00014435203047469258, -0.004830001853406429, -0.0004925706889480352, -0.0004928089329041541, -0.013045793399214745, -0.1348041296005249], "finish_reason": "stop"}, {"text": " words_freq[0:10]", "tokens": [" words", "_", "freq", "[", "0", ":", "1", "0", "]", "\n"], "logprobs": [-0.33510079979896545, -0.00011777184408856556, -2.825220326485578e-05, -1.7676301002502441, -0.04127652570605278, -0.027326028794050217, -0.019085809588432312, -0.004769140388816595, -0.002084703417494893, -0.0055476040579378605], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Frequency\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "F", "requency", "\"", "])", "\n"], "logprobs": [-0.019216910004615784, -0.004035544581711292, -0.00220104050822556, -0.0744084045290947, -0.1758567839860916, -7.056941103655845e-05, -7.033323527139146e-06, -0.05185443535447121, -0.026373712345957756, -0.045477885752916336, -0.007419293746352196, -0.2390104979276657, -0.005671007093042135, -0.00029225845355540514, -0.0021438251715153456, -0.5917457938194275, -0.07332079112529755, -0.004458487033843994, -0.004473677836358547, -0.03645394742488861], "finish_reason": "stop"}, {"text": " df_top.plot.barh(x=\"Word\", y=\"Count\", color=\"green\", title=\"Top 10 words\")", "tokens": [" df", "_", "top", ".", "plot", ".", "bar", "h", "(", "x", "=", "\"", "Word", "\"", ",", " y", "=", "\"", "Count", "\"", ",", " color", "=", "\"", "green", "\"", ",", " title", "=", "\"", "Top", " ", "1", "0", " words", "\"", ")", "\n"], "logprobs": [-0.167045459151268, -0.0012287693098187447, -2.3364747903542593e-05, -0.015493622981011868, -0.11711269617080688, -0.568409264087677, -0.0049562216736376286, -1.0023187398910522, -0.014544300734996796, -0.3381923735141754, -0.060469891875982285, -0.0015766106080263853, -0.012686853297054768, -6.639736966462806e-05, -0.0021305023692548275, -0.05789045989513397, -0.00255651050247252, -0.00016497205069754273, -4.708655978902243e-05, -3.111314072157256e-05, -0.22870580852031708, -2.1555941104888916, -0.1207839772105217, -0.005091794766485691, -2.5730934143066406, -0.0032772899139672518, -0.5727351307868958, -1.3607667684555054, -0.022923937067389488, -0.02375953085720539, -0.8493002653121948, -0.09129117429256439, -0.00163433444686234, -0.00033802041434682906, -1.8245426416397095, -1.0199847221374512, -0.37785133719444275, -0.012453296221792698], "finish_reason": "stop"}, {"text": " save_path:", "tokens": [" save", "_", "path", ":", "\n"], "logprobs": [-0.02145194634795189, -3.075552376685664e-05, -1.1920922133867862e-06, -0.4763408899307251, -0.002926830668002367], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.007492299657315016, -0.0003461238811723888, -0.00025006983196362853, -0.006631746888160706, -8.702239938429557e-06, -5.8412379075889476e-06, -0.2058064341545105, -0.005170782096683979], "finish_reason": "stop"}, {"text": "clf()", "tokens": ["cl", "f", "()", "\n"], "logprobs": [-2.262652635574341, -0.022989295423030853, -0.00226205843500793, -0.06786500662565231], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.02940020151436329, -0.051818326115608215], "finish_reason": "stop"}, {"text": " FileNotFoundError as err:", "tokens": [" File", "NotFound", "Error", " as", " err", ":", "\n"], "logprobs": [-0.6533181667327881, -3.0397906812140718e-05, -5.602820692729438e-06, -0.2171693742275238, -2.1706762313842773, -0.0050504012033343315, -0.004479374270886183], "finish_reason": "stop"}, {"text": " FileNotFoundError(f\"The file path: {file_path}, was not found\") from exc", "tokens": [" File", "NotFound", "Error", "(", "f", "\"", "The", " file", " path", ":", " {", "file", "_", "path", "}", ",", " was", " not", " found", "\"", ")", " from", " exc", "\n"], "logprobs": [-0.2816736400127411, -0.00017820201173890382, -0.00021109737281221896, -0.02268192172050476, -1.0207468271255493, -0.019727574661374092, -2.1465706825256348, -0.5694148540496826, -1.2967393398284912, -2.5237464904785156, -0.22724869847297668, -0.27303028106689453, -0.0002797450579237193, -7.009260298218578e-05, -0.017474500462412834, -2.4969260692596436, -0.8152797818183899, -0.007985570468008518, -0.004640643019229174, -1.731824517250061, -0.027579795569181442, -0.1779405027627945, -0.0017847575945779681, -0.01700546219944954], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.015104209072887897, -0.07340719550848007, -0.012385360896587372, -0.0008080316474661231, -0.006159134209156036], "finish_reason": "stop"}, {"text": "f\"Error occurred: {type(e)}\")", "tokens": ["f", "\"", "Error", " occurred", ":", " {", "type", "(", "e", ")}", "\"", ")", "\n"], "logprobs": [-0.5244382619857788, -0.005142674781382084, -0.990766704082489, -1.0725884437561035, -0.22407656908035278, -0.005403200164437294, -1.9369601011276245, -0.00021431533969007432, -0.006252964027225971, -1.1913303136825562, -0.7022271156311035, -0.10034924745559692, -0.008345255628228188], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.020985586568713188, -1.1957592964172363, -3.576278118089249e-07, -1.6689286894688848e-06, -0.00011538793478393927, -0.00029702542815357447, -0.13602577149868011], "finish_reason": "stop"}], "metrics": {"energy": 386.42285267257677, "energy_per_token": 1.6168320195505304, "time": 16.590757, "time_per_token": 0.06941739330543933}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.004559715278446674, -0.00019071667338721454, -0.0024027545005083084, -1.597391747054644e-05, -0.000821014866232872, -0.0005164004978723824, -0.007414560765028, -0.00024279984063468874, -3.182837463100441e-05, -0.5615230798721313, -0.024881096556782722], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ")", "\n"], "logprobs": [-0.0002681849291548133, -7.390948667307384e-06, -2.276871418871451e-05, -0.07359903305768967, -0.30806225538253784, -0.00025555206229910254, -6.4490144723095e-05, -0.10011275857686996, -0.03194531798362732, -4.768370445162873e-07, -0.010094896890223026, -6.794906312279636e-06, -4.291525328881107e-06, -1.8596476365928538e-05, -0.3261796832084656, -0.031053675338625908], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.007143906317651272, -1.1205610462639015e-05, -5.9960475482512265e-05, -0.008236134424805641, -0.00048315772437490523, -9.500529267825186e-05, -0.005159159656614065, -0.015544679947197437, -0.5016923546791077, -0.0027050115168094635, -0.0005471401382237673, -7.176141662057489e-05, -0.08899856358766556, -0.19954605400562286], "finish_reason": "stop"}, {"text": " word_count.sum()", "tokens": [" word", "_", "count", ".", "sum", "()", "\n"], "logprobs": [-0.9245784282684326, -0.0001426833332516253, -0.00023874769976828247, -0.0004681444843299687, -0.036170922219753265, -0.4441624879837036, -0.011744404211640358], "finish_reason": "stop"}, {"text": " (word_count.transpose() * sum_words) / sum_words.sum()", "tokens": [" (", "word", "_", "count", ".", "trans", "pose", "()", " *", " sum", "_", "words", ")", " /", " sum", "_", "words", ".", "sum", "()", "\n"], "logprobs": [-0.9924603700637817, -0.16387887299060822, -0.0008100565755739808, -6.317892984952778e-05, -0.1567382514476776, -2.7226953506469727, -0.0006940339808352292, -0.0016387379728257656, -0.5693815350532532, -2.231607437133789, -0.0006204110686667264, -5.876845170860179e-05, -0.041864313185214996, -0.6842998266220093, -0.23186859488487244, -0.0013456823071464896, -5.245195097813848e-06, -0.10677994787693024, -0.5348445773124695, -0.016679948195815086, -0.013444830663502216], "finish_reason": "stop"}, {"text": "word_count[i].toarray().flatten(), sum_words[i])", "tokens": ["word", "_", "count", "[", "i", "]", ".", "to", "array", "()", ".", "fl", "atten", "()", ",", " sum", "_", "words", "[", "i", "])", "\n"], "logprobs": [-0.07577788829803467, -2.7323269844055176, -0.12975336611270905, -0.47605499625205994, -1.2871450185775757, -0.19637902081012726, -0.2668396830558777, -0.9496940970420837, -0.02402491122484207, -0.5278685092926025, -0.21392205357551575, -1.0837563276290894, -8.34430247778073e-05, -0.380928099155426, -1.7579485177993774, -0.8111987113952637, -0.002932892646640539, -0.0007726544863544405, -0.07374576479196548, -0.03301114961504936, -0.12171556055545807, -0.27715110778808594], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: -x[1])", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " -", "x", "[", "1", "])", "\n"], "logprobs": [-0.09178841859102249, -0.000259723310591653, -0.14716677367687225, -0.0014993627555668354, -5.8410845667822286e-05, -0.002089223824441433, -0.016290761530399323, -0.0027651668060570955, -0.0016160060185939074, -0.01856171153485775, -0.0003212174342479557, -1.3838839530944824, -0.00612892210483551, -0.00603887252509594, -0.000482442817883566, -0.002298929262906313, -0.18744023144245148], "finish_reason": "stop"}, {"text": " [w[0] for w in words_freq[:10]]", "tokens": [" [", "w", "[", "0", "]", " for", " w", " in", " words", "_", "freq", "[:", "1", "0", "]]", "\n"], "logprobs": [-1.9896326065063477, -3.039536952972412, -0.29945915937423706, -0.003375786356627941, -0.0025563915260136127, -0.023697948083281517, -0.002492894185706973, -9.285972191719338e-05, -0.003230711678043008, -9.298280929215252e-06, -1.2516897186287679e-05, -0.7005577087402344, -0.013975026085972786, -0.006452914793044329, -0.008446327410638332, -0.0034329311456531286], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"word\", \"count\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "word", "\"", ",", " \"", "count", "\"", "])", "\n"], "logprobs": [-0.022974150255322456, -0.004466676153242588, -0.0026159610133618116, -0.07709717005491257, -0.14977209270000458, -5.495397272170521e-05, -9.894321920000948e-06, -0.05648542195558548, -0.025483593344688416, -0.042096588760614395, -0.007454909849911928, -2.4390811920166016, -0.008736482821404934, -0.00036554806865751743, -0.002483856864273548, -0.8146635293960571, -0.0065691000781953335, -0.004029489122331142, -0.0492066964507103], "finish_reason": "stop"}, {"text": " df_top.plot.bar(x=\"Word\", y=\"Count\", rot=0, figsize=(15, 8))", "tokens": [" df", "_", "top", ".", "plot", ".", "bar", "(", "x", "=", "\"", "Word", "\"", ",", " y", "=", "\"", "Count", "\"", ",", " rot", "=", "0", ",", " fig", "size", "=(", "1", "5", ",", " ", "8", "))", "\n"], "logprobs": [-0.18126991391181946, -0.001278060139156878, -2.4199192921514623e-05, -0.018650639802217484, -0.13279996812343597, -0.5974592566490173, -0.005044589750468731, -0.5113285183906555, -0.39776432514190674, -0.15171602368354797, -0.0010425376240164042, -0.0007788485381752253, -9.715084888739511e-05, -0.0034950620029121637, -0.03948003798723221, -0.0028880813624709845, -0.00012575789878610522, -4.649054244509898e-05, -3.4450891689630225e-05, -0.21541628241539001, -0.642163872718811, -0.003301885211840272, -0.4357982575893402, -0.5318760275840759, -0.8839967250823975, -0.0011461363174021244, -0.05244293808937073, -0.4013272225856781, -1.6119203567504883, -0.002601098734885454, -0.03859325498342514, -2.3223681449890137, -0.39872923493385315, -0.013430128805339336], "finish_reason": "stop"}, {"text": " save_path is None:", "tokens": [" save", "_", "path", " is", " None", ":", "\n"], "logprobs": [-0.02022874914109707, -3.45700973412022e-05, -1.311301275563892e-06, -1.029064655303955, -1.903327226638794, -0.0003122795606032014, -0.005861593410372734], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.008404363878071308, -0.0003911683743353933, -0.0002454218047205359, -0.009225242771208286, -7.390948667307384e-06, -5.722029527532868e-06, -0.16695235669612885, -0.006277012173086405], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.19308370351791382, -0.1056007519364357, -0.07425712049007416], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.030115893110632896, -0.055757924914360046], "finish_reason": "stop"}, {"text": " FileNotFoundError as err:", "tokens": [" File", "NotFound", "Error", " as", " err", ":", "\n"], "logprobs": [-0.5818544030189514, -3.0874729418428615e-05, -6.079655122448457e-06, -0.20859019458293915, -1.9264981746673584, -0.005649196449667215, -0.005251897498965263], "finish_reason": "stop"}, {"text": " FileNotFoundError(", "tokens": [" File", "NotFound", "Error", "(", "\n"], "logprobs": [-0.23527224361896515, -0.00014423283573705703, -0.0002212279650848359, -0.02486470155417919, -1.1350481510162354], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.013555855490267277, -0.05719989910721779, -0.015163857489824295, -0.00070296844933182, -0.00690739369019866], "finish_reason": "stop"}, {"text": "f\"Error occurred: {e}\")", "tokens": ["f", "\"", "Error", " occurred", ":", " {", "e", "}\"", ")", "\n"], "logprobs": [-0.4740583002567291, -0.005691513419151306, -0.9455742239952087, -0.9855181574821472, -0.26338815689086914, -0.0065246885642409325, -0.4439503252506256, -0.09196371585130692, -0.05417972430586815, -0.01426452212035656], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.01653726026415825, -1.1555047035217285, -3.576278118089249e-07, -1.5497195136049413e-06, -8.701899787411094e-05, -0.0002512616047170013, -0.14099213480949402], "finish_reason": "stop"}], "metrics": {"energy": 434.64917756080644, "energy_per_token": 1.8815981712589023, "time": 18.035639, "time_per_token": 0.0780763593073593}}
{"outputs": [{"text": " pd.read_csv(file_path, header=None)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ",", " header", "=", "None", ")", "\n"], "logprobs": [-0.00498623214662075, -0.00015448330668732524, -0.0029444219544529915, -1.8954096958623268e-05, -0.001007764250971377, -0.0005876483046449721, -0.0081194331869483, -0.00022420754248742014, -2.8490614567999728e-05, -0.8573088645935059, -0.28095075488090515, -0.03210221976041794, -0.6569797396659851, -0.8538299202919006, -0.04558882862329483], "finish_reason": "stop"}, {"text": " CountVectorizer(", "tokens": [" Count", "Vector", "izer", "(", "\n"], "logprobs": [-0.0002668739762157202, -7.629365427419543e-06, -1.823885577323381e-05, -0.08144047856330872, -2.573206901550293], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df['Text'].values)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "['", "Text", "']", ".", "values", ")", "\n"], "logprobs": [-0.00863177701830864, -1.1801649634435307e-05, -6.12716976320371e-05, -0.009697471745312214, -0.0006061147432774305, -0.00010227633902104571, -0.006132239475846291, -0.014637229032814503, -1.652585506439209, -0.0005958688561804593, -2.5670218467712402, -0.01699667237699032, -0.70086270570755, -0.24491822719573975, -0.1317232847213745], "finish_reason": "stop"}, {"text": " np.array(word_count.sum(axis=0))[0]", "tokens": [" np", ".", "array", "(", "word", "_", "count", ".", "sum", "(", "axis", "=", "0", "))", "[", "0", "]", "\n"], "logprobs": [-2.5011000633239746, -0.000226472009671852, -1.4450626373291016, -0.043497778475284576, -0.01411478966474533, -3.58813522325363e-05, -0.0002401778765488416, -0.003545785555616021, -0.007835367694497108, -0.00035565727739594877, -0.009187091141939163, -0.0021607165690511465, -0.18702425062656403, -0.10577632486820221, -1.039839267730713, -0.004225374665111303, -0.09919698536396027, -0.06261805444955826], "finish_reason": "stop"}, {"text": " word_count.toarray().T / sum_words", "tokens": [" word", "_", "count", ".", "to", "array", "()", ".", "T", " /", " sum", "_", "words", "\n"], "logprobs": [-1.463035225868225, -0.00015484087634831667, -2.3603161025675945e-05, -0.1373310387134552, -1.2777221202850342, -0.008967955596745014, -0.02952069602906704, -1.001774787902832, -1.2711669206619263, -0.10394474864006042, -0.017003588378429413, -0.00144091690890491, -2.90866428258596e-05, -0.2171916365623474], "finish_reason": "stop"}, {"text": "word, sum_words[i]) for word, i in vectorizer.vocabulary_.items()", "tokens": ["word", ",", " sum", "_", "words", "[", "i", "])", " for", " word", ",", " i", " in", " vector", "izer", ".", "voc", "abulary", "_", ".", "items", "()", "\n"], "logprobs": [-0.06564794480800629, -0.08463282883167267, -0.9555498361587524, -0.0248419102281332, -0.01252405159175396, -0.07249556481838226, -0.9579814076423645, -0.16653937101364136, -0.6235891580581665, -0.02801874838769436, -0.004078998696058989, -0.004249471705406904, -0.0036139669828116894, -0.08937180042266846, -9.894321920000948e-06, -8.797258487902582e-05, -0.0468398854136467, -0.008205866441130638, -0.00011574551899684593, -0.0001932195882545784, -0.0008961713756434619, -8.880697714630514e-05, -0.024922259151935577], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.0703655406832695, -0.00023827097902540118, -0.17837095260620117, -0.0010715939570218325, -5.304672595229931e-05, -0.0021642851643264294, -0.019975680857896805, -0.002858958672732115, -0.0017970141489058733, -0.025108397006988525, -0.0003831844369415194, -0.2609977126121521, -0.006009130738675594, -0.00235565984621644, -0.026791144162416458, -0.00014554394874721766, -0.004504889715462923, -0.00043299360550008714, -0.0004574206250254065, -0.017140116542577744, -0.17869095504283905], "finish_reason": "stop"}, {"text": " words_freq[0:10]", "tokens": [" words", "_", "freq", "[", "0", ":", "1", "0", "]", "\n"], "logprobs": [-0.33751723170280457, -9.035655966727063e-05, -3.397406908334233e-05, -1.6383705139160156, -0.03939695283770561, -0.036907751113176346, -0.018293356522917747, -0.004840323235839605, -0.002147988649085164, -0.004671849310398102], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Count\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "Count", "\"", "])", "\n"], "logprobs": [-0.020389599725604057, -0.004610147327184677, -0.002283110748976469, -0.07798024266958237, -0.1546229124069214, -7.199982064776123e-05, -9.179073458653875e-06, -0.05491266027092934, -0.022280026227235794, -0.04170287773013115, -0.006945514120161533, -0.24072302877902985, -0.0046560680493712425, -0.0002108589978888631, -0.0019250449258834124, -0.9779893159866333, -0.012074002996087074, -0.003275864291936159, -0.03469862416386604], "finish_reason": "stop"}, {"text": " df_top.plot(kind=\"bar\", rot=0, title=\"Top 10 most common words in the file\")", "tokens": [" df", "_", "top", ".", "plot", "(", "kind", "=", "\"", "bar", "\"", ",", " rot", "=", "0", ",", " title", "=", "\"", "Top", " ", "1", "0", " most", " common", " words", " in", " the", " file", "\"", ")", "\n"], "logprobs": [-0.15665192902088165, -0.0010630200849846005, -2.276871418871451e-05, -0.013207921758294106, -0.11846213787794113, -0.7869523763656616, -0.6687607765197754, -0.19375570118427277, -0.00025614796322770417, -0.00820113718509674, -1.6161715984344482, -0.0793849304318428, -2.117898464202881, -0.0009173714206553996, -0.941410481929779, -0.5470687747001648, -2.129087448120117, -0.027503950521349907, -0.048969823867082596, -0.6756883859634399, -0.08010007441043854, -0.0014763895887881517, -0.0003759154351428151, -2.104159355163574, -0.1907426416873932, -0.024127434939146042, -1.3703020811080933, -0.5798574090003967, -2.0251426696777344, -0.2044478952884674, -0.48408737778663635, -0.011001761071383953], "finish_reason": "stop"}, {"text": " save_path is not None:", "tokens": [" save", "_", "path", " is", " not", " None", ":", "\n"], "logprobs": [-0.021719688549637794, -3.0517112463712692e-05, -1.311301275563892e-06, -1.148917317390442, -0.19297824800014496, -2.2053474822314456e-05, -0.0008741371566429734, -0.0019249258330091834], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.008788831532001495, -0.00032062159152701497, -0.00023457636416424066, -0.007471120450645685, -6.794906312279636e-06, -6.437280717364047e-06, -0.15139147639274597, -0.006818835157901049], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.1874314397573471, -0.11134582757949829, -0.08139684796333313], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.02825959213078022, -0.06264448165893555], "finish_reason": "stop"}, {"text": " FileNotFoundError as e:", "tokens": [" File", "NotFound", "Error", " as", " e", ":", "\n"], "logprobs": [-0.5387307405471802, -2.706014311115723e-05, -6.198863957251888e-06, -0.24467754364013672, -0.419384241104126, -0.0022908414248377085, -0.0036083844024688005], "finish_reason": "stop"}, {"text": " exc", "tokens": [" exc", "\n"], "logprobs": [-1.58366060256958, -0.10201077908277512], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.014333386905491352, -0.05520430952310562, -0.015001693740487099, -0.0007214327342808247, -0.006909525021910667], "finish_reason": "stop"}, {"text": "\"An error occurred:\", e)", "tokens": ["\"", "An", " error", " occurred", ":\"", ",", " e", ")<", "|", "end", "of", "text", "|>"], "logprobs": [-1.1691217422485352, -0.6824266314506531, -0.14904502034187317, -0.028731027618050575, -0.26174211502075195, -0.14124026894569397, -0.6337081789970398, -3.0313189029693604, -1.1920928244535389e-07, -2.3841830625315197e-06, -5.972207145532593e-05, -0.00022027450904715806, -0.11292202025651932], "finish_reason": "stop"}, {"text": " None", "tokens": [" None"], "logprobs": [-0.017391208559274673], "finish_reason": "stop"}], "metrics": {"energy": 394.0309523754121, "energy_per_token": 1.7829454858615932, "time": 16.395187, "time_per_token": 0.0741863665158371}}
{"outputs": [{"text": " pd.read_csv(file_path, header=0, keep_default_na=False, na_values=[' '])", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ",", " header", "=", "0", ",", " keep", "_", "default", "_", "na", "=", "False", ",", " na", "_", "values", "=['", " '", "])", "\n"], "logprobs": [-0.005211459007114172, -0.00015066919149830937, -0.002838750835508108, -1.9430925021879375e-05, -0.0008761619683355093, -0.0005546461907215416, -0.0068722316063940525, -0.00018618757894728333, -2.8729025871143676e-05, -0.9013782739639282, -0.2783486843109131, -0.035412032157182693, -0.6836928129196167, -0.7140761017799377, -3.9048550128936768, -3.528532761265524e-05, -0.02830096147954464, -1.9550132492440753e-05, -0.2175140231847763, -0.0007448997348546982, -0.046463970094919205, -1.057996392250061, -0.11005935817956924, -1.5497195136049413e-06, -0.12021998316049576, -1.5766892433166504, -2.6216769218444824, -0.2503034472465515, -0.03808146342635155], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ")", "\n"], "logprobs": [-0.00025733973598107696, -7.390948667307384e-06, -1.8715683836489916e-05, -0.08696091920137405, -0.3014380633831024, -0.00029023250681348145, -6.818538531661034e-05, -0.11813434958457947, -0.0442926399409771, -3.576278118089249e-07, -0.011576265096664429, -8.106198947643861e-06, -6.318072337307967e-06, -1.9788545614574105e-05, -0.26670336723327637, -0.03259088471531868], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"]).toarray()", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", ".", "to", "array", "()", "\n"], "logprobs": [-0.007937082089483738, -1.2874520507466514e-05, -7.080780778778717e-05, -0.00997652392834425, -0.0005166388000361621, -9.798523387871683e-05, -0.006202259100973606, -0.014834336005151272, -0.5505146384239197, -0.00348912226036191, -0.0005469018360599875, -7.199982064776123e-05, -0.08183620870113373, -1.750485897064209, -0.1319696605205536, -0.0014644861221313477, -0.05905431509017944, -0.07322174310684204], "finish_reason": "stop"}, {"text": " sum(word_count.toarray())", "tokens": [" sum", "(", "word", "_", "count", ".", "to", "array", "())", "\n"], "logprobs": [-0.8473010063171387, -0.4640234708786011, -0.10303227603435516, -0.012029128149151802, -0.0018468719208613038, -0.009128974750638008, -0.2425059676170349, -0.0015769677702337503, -0.2784675061702728, -0.014598812907934189], "finish_reason": "stop"}, {"text": " sum_words[1] / sum_words[0]", "tokens": [" sum", "_", "words", "[", "1", "]", " /", " sum", "_", "words", "[", "0", "]", "\n"], "logprobs": [-3.4293160438537598, -0.0017456068890169263, -9.238292841473594e-05, -1.2177870273590088, -2.1653008460998535, -1.0033533573150635, -0.32654181122779846, -0.1433694213628769, -0.04425443708896637, -4.2437604861333966e-05, -0.010721225291490555, -0.014878145419061184, -0.0015491163358092308, -0.09193598479032516], "finish_reason": "stop"}, {"text": "word, sum_words[i])", "tokens": ["word", ",", " sum", "_", "words", "[", "i", "])", "\n"], "logprobs": [-0.08383563905954361, -0.09161341935396194, -0.9097616672515869, -0.012196484953165054, -0.011026520282030106, -0.0628061518073082, -0.9580925107002258, -0.15691424906253815, -0.8315643668174744], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.07973689585924149, -0.00023767507809679955, -0.16440372169017792, -0.001353539526462555, -6.997340824455023e-05, -0.001790826441720128, -0.01590130478143692, -0.0028161650989204645, -0.001508289948105812, -0.01699257083237171, -0.0003660247311927378, -0.20852777361869812, -0.004204719327390194, -0.002273952355608344, -0.01694943942129612, -0.0001728385395836085, -0.0043586730025708675, -0.0005061537376604974, -0.000510204816237092, -0.014375103637576103, -0.1353517323732376], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.31206604838371277, -9.786603914108127e-05, -2.90866428258596e-05, -0.2556424140930176, -0.01627058908343315, -0.0030567371286451817, -0.001476746634580195, -0.005420273635536432], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Count\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "Count", "\"", "])", "\n"], "logprobs": [-0.01709195226430893, -0.004270600620657206, -0.0022689569741487503, -0.07344075292348862, -0.15694940090179443, -6.05564855504781e-05, -8.34461570775602e-06, -0.05512455105781555, -0.01685836724936962, -0.04361772909760475, -0.006480037700384855, -0.25992122292518616, -0.005138523876667023, -0.00027533553657121956, -0.0024177387822419405, -0.8446739315986633, -0.00930024217814207, -0.0028754814993590117, -0.03256388381123543], "finish_reason": "stop"}, {"text": " df_top.plot(kind=\"bar\", figsize=(10, 6))", "tokens": [" df", "_", "top", ".", "plot", "(", "kind", "=", "\"", "bar", "\"", ",", " fig", "size", "=(", "1", "0", ",", " ", "6", "))", "\n"], "logprobs": [-0.17228183150291443, -0.0011982887517660856, -2.4914430468925275e-05, -0.013727894984185696, -0.11624845862388611, -0.8179343938827515, -0.811933696269989, -0.16044679284095764, -0.0002890407631639391, -0.009544809348881245, -1.6576883792877197, -0.06932634860277176, -1.1718525886535645, -0.00025328766787424684, -0.026203369721770287, -0.35353806614875793, -0.7503587007522583, -0.0031070075929164886, -0.03655095398426056, -2.1885757446289062, -0.7632645964622498, -0.017604991793632507], "finish_reason": "stop"}, {"text": " save_path:", "tokens": [" save", "_", "path", ":", "\n"], "logprobs": [-0.021578067913651466, -3.480850500636734e-05, -1.311301275563892e-06, -0.44372981786727905, -0.0021856960374861956], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.007805797271430492, -0.00034707720624282956, -0.00028081765049137175, -0.007667870260775089, -8.34461570775602e-06, -5.722029527532868e-06, -0.1485464721918106, -0.007123666815459728], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.18015260994434357, -0.11193317919969559, -0.07192640751600266], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.030571425333619118, -0.04691928252577782], "finish_reason": "stop"}, {"text": " (FileNotFoundError) as e:", "tokens": [" (", "File", "NotFound", "Error", ")", " as", " e", ":", "\n"], "logprobs": [-2.6411590576171875, -0.07686968147754669, -3.218599158572033e-05, -4.0531076592742465e-06, -1.841245174407959, -0.0007900454220362008, -0.4356631636619568, -0.002595034893602133, -0.005134728737175465], "finish_reason": "stop"}, {"text": " exc", "tokens": [" exc", "\n"], "logprobs": [-1.7110294103622437, -0.09488128125667572], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.012950598262250423, -0.0518370047211647, -0.01178151648491621, -0.0007929041748866439, -0.005119547713547945], "finish_reason": "stop"}, {"text": "f\"Error occurred: {type(e)}\")", "tokens": ["f", "\"", "Error", " occurred", ":", " {", "type", "(", "e", ")}", "\"", ")", "\n"], "logprobs": [-0.4702397882938385, -0.005849030800163746, -0.9857752323150635, -1.0647094249725342, -0.25212982296943665, -0.005644454620778561, -1.9522796869277954, -0.0002351722796447575, -0.009176341816782951, -1.0575165748596191, -0.7903883457183838, -0.11778473109006882, -0.007769365329295397], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.022203544154763222, -1.3673715591430664, -3.576278118089249e-07, -1.5497195136049413e-06, -8.761498611420393e-05, -0.0003303935518488288, -0.14645139873027802], "finish_reason": "stop"}], "metrics": {"energy": 423.7506080932615, "energy_per_token": 1.9261391276966433, "time": 16.369228, "time_per_token": 0.07440558181818181}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.00498623214662075, -0.00015448330668732524, -0.0029444219544529915, -1.8954096958623268e-05, -0.001007764250971377, -0.0005876483046449721, -0.0081194331869483, -0.00022420754248742014, -2.8490614567999728e-05, -0.553931713104248, -0.030561480671167374], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ")", "\n"], "logprobs": [-0.0002379134384682402, -6.6756979322235566e-06, -2.13382354559144e-05, -0.10027042031288147, -0.2961236834526062, -0.0002366024418734014, -7.283422019099817e-05, -0.11842232197523117, -0.029111698269844055, -3.576278118089249e-07, -0.010065983049571514, -7.390948667307384e-06, -5.483612312673358e-06, -1.645074735279195e-05, -0.2510663568973541, -0.028602328151464462], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df.Text)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", ".", "Text", ")", "\n"], "logprobs": [-0.006787103600800037, -1.2159273865108844e-05, -5.721882189391181e-05, -0.006773842498660088, -0.0004994813934899867, -0.00011050090688513592, -0.005885058548301458, -0.01904475875198841, -1.5586657524108887, -0.42979559302330017, -0.2022721916437149, -0.14023326337337494], "finish_reason": "stop"}, {"text": " word_count.sum()", "tokens": [" word", "_", "count", ".", "sum", "()", "\n"], "logprobs": [-0.858882486820221, -8.761498611420393e-05, -0.00029988560709170997, -0.0005267662927508354, -0.03450953960418701, -0.4709506034851074, -0.009769248776137829], "finish_reason": "stop"}, {"text": " (word_count / sum_words).T.sort_values(ascending=False)", "tokens": [" (", "word", "_", "count", " /", " sum", "_", "words", ")", ".", "T", ".", "sort", "_", "values", "(", "asc", "ending", "=", "False", ")", "\n"], "logprobs": [-0.9213349223136902, -0.20255659520626068, -0.000880449719261378, -6.258291978156194e-05, -2.035623550415039, -0.01750870607793331, -0.000791236583609134, -3.93382906622719e-05, -0.06548907607793808, -0.11792565137147903, -2.1034255027770996, -1.1871213912963867, -3.137711524963379, -0.006822387222200632, -0.0031411137897521257, -0.07328610867261887, -0.9077898263931274, -1.0251946150674485e-05, -0.0030141896568238735, -0.008878870867192745, -0.06914959847927094, -0.011483286507427692], "finish_reason": "stop"}, {"text": "word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()", "tokens": ["word", ",", " sum", "_", "words", "[", "0", ",", " idx", "])", " for", " word", ",", " idx", " in", " vector", "izer", ".", "voc", "abulary", "_", ".", "items", "()", "\n"], "logprobs": [-0.07223320752382278, -0.09211353957653046, -0.8444532155990601, -0.013974555768072605, -0.013386255130171776, -0.054267458617687225, -1.3147435188293457, -0.9100687503814697, -1.1245625019073486, -0.05666780844330788, -0.9568617939949036, -0.3703997731208801, -0.0008206575294025242, -0.00047386385267600417, -0.0025592453312128782, -0.12069649994373322, -1.2397689715726301e-05, -0.00011848701251437888, -0.017080584540963173, -0.006739978212863207, -0.00010835537250386551, -0.0002449450839776546, -0.0007350126979872584, -8.987976616481319e-05, -0.020570045337080956], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.09991633892059326, -0.00021205084340181202, -0.16410744190216064, -0.001110890181735158, -6.317892984952778e-05, -0.0019096963806077838, -0.01728810742497444, -0.003061728784814477, -0.0015182883944362402, -0.01568962261080742, -0.0003292018664069474, -0.26825395226478577, -0.004716106224805117, -0.0025654281489551067, -0.021116552874445915, -0.00018606838420964777, -0.00440602982416749, -0.0005278385942801833, -0.0004997196956537664, -0.013170979917049408, -0.11690760403871536], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.31241604685783386, -9.119095193454996e-05, -3.0636318115284666e-05, -0.23075070977210999, -0.017388630658388138, -0.0031829429790377617, -0.0014828173443675041, -0.00500841299071908], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Count\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "Count", "\"", "])", "\n"], "logprobs": [-0.018868716433644295, -0.004466201178729534, -0.002214124659076333, -0.07679826021194458, -0.14261968433856964, -6.115249561844394e-05, -9.894321920000948e-06, -0.052830860018730164, -0.022899238392710686, -0.044122129678726196, -0.0061385189183056355, -0.24397821724414825, -0.005711308214813471, -0.0002656822034623474, -0.001929566147737205, -0.9451972246170044, -0.009564882144331932, -0.0034898349549621344, -0.04389933869242668], "finish_reason": "stop"}, {"text": " df_top.plot(kind=\"bar\", figsize=(12, 6), rot=0)", "tokens": [" df", "_", "top", ".", "plot", "(", "kind", "=", "\"", "bar", "\"", ",", " fig", "size", "=(", "1", "2", ",", " ", "6", ")", ",", " rot", "=", "0", ")", "\n"], "logprobs": [-0.17740465700626373, -0.0011132716899737716, -2.396077979938127e-05, -0.01351328194141388, -0.12044543027877808, -0.7613345980644226, -0.6151854395866394, -0.15983149409294128, -0.00028534632292576134, -0.00961943157017231, -1.5118155479431152, -0.08179336786270142, -1.0151697397232056, -0.00021109737281221896, -0.023334309458732605, -0.3387545049190521, -1.6251227855682373, -0.002176061272621155, -0.026990048587322235, -1.2034598588943481, -0.4473224878311157, -0.00023052419419400394, -0.8885672688484192, -0.0019135037437081337, -1.006455659866333, -0.5052182674407959, -0.022515494376420975], "finish_reason": "stop"}, {"text": " save_path is not None:", "tokens": [" save", "_", "path", " is", " not", " None", ":", "\n"], "logprobs": [-0.021618200466036797, -3.731181277544238e-05, -1.311301275563892e-06, -0.9838974475860596, -0.1712304800748825, -2.062299427052494e-05, -0.0010568277211859822, -0.0021678535267710686], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.0077355350367724895, -0.0003104920033365488, -0.00023552982020191848, -0.008452828973531723, -5.960446742392378e-06, -5.483612312673358e-06, -0.1641891747713089, -0.006553940940648317], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.18218261003494263, -0.13521209359169006, -0.06901286542415619], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.02601034939289093, -0.04928840324282646], "finish_reason": "stop"}, {"text": " Exception:", "tokens": [" Exception", ":", "\n"], "logprobs": [-1.0551823377609253, -2.1278576850891113, -0.015814010053873062], "finish_reason": "stop"}, {"text": " FileNotFoundError(f\"File not found: {exc.filename}\")", "tokens": [" File", "NotFound", "Error", "(", "f", "\"", "File", " not", " found", ":", " {", "exc", ".", "filename", "}\"", ")", "\n"], "logprobs": [-0.27627241611480713, -0.000161038784426637, -0.00022218143567442894, -0.02093702368438244, -1.0517802238464355, -0.020782332867383957, -0.5861416459083557, -0.46044015884399414, -0.0035101487301290035, -0.16393807530403137, -0.01697944477200508, -0.3127254545688629, -0.40430158376693726, -0.3760141432285309, -0.09908363223075867, -0.005614464171230793, -0.02386091835796833], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.01327380072325468, -0.058899566531181335, -0.012678142637014389, -0.0007510940195061266, -0.007468043826520443], "finish_reason": "stop"}, {"text": "f\"Exception occurred: {e}\")", "tokens": ["f", "\"", "Exception", " occurred", ":", " {", "e", "}\"", ")", "\n"], "logprobs": [-0.48138415813446045, -0.006377227138727903, -2.430068016052246, -0.6377432942390442, -0.13738569617271423, -0.004964524880051613, -0.3847801983356476, -0.07743240147829056, -0.049298275262117386, -0.013611127622425556], "finish_reason": "stop"}, {"text": " None", "tokens": [" None"], "logprobs": [-0.018467742949724197], "finish_reason": "stop"}], "metrics": {"energy": 368.22883496570597, "energy_per_token": 1.6365725998475822, "time": 15.925221, "time_per_token": 0.07077876}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.0051756445318460464, -0.00015817821258679032, -0.0030563806649297476, -1.7404405298293568e-05, -0.0009894242975860834, -0.0005026984144933522, -0.007219536229968071, -0.00020549570035655051, -3.075552376685664e-05, -0.5617414712905884, -0.028226330876350403], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ")", "\n"], "logprobs": [-0.0002455409849062562, -8.4638240878121e-06, -2.074220174108632e-05, -0.0847858414053917, -0.28072643280029297, -0.00033146608620882034, -7.760223525110632e-05, -0.11030589789152145, -0.03700379282236099, -3.576278118089249e-07, -0.013025437481701374, -6.9141146923357155e-06, -4.768360213347478e-06, -1.6569954823353328e-05, -0.30473288893699646, -0.027390984818339348], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.006867851130664349, -1.0847986231965479e-05, -5.328513361746445e-05, -0.007971142418682575, -0.00041059168870560825, -0.0001045410826918669, -0.005309409461915493, -0.019272103905677795, -0.5632238388061523, -0.0028594343457370996, -0.0006070678355172276, -6.12716976320371e-05, -0.07140597701072693, -0.18828915059566498], "finish_reason": "stop"}, {"text": " word_count.sum(axis=0)", "tokens": [" word", "_", "count", ".", "sum", "(", "axis", "=", "0", ")", "\n"], "logprobs": [-0.7786545753479004, -0.00012063252506777644, -0.00026663561584427953, -0.0005869334563612938, -0.0395544059574604, -1.2145190238952637, -0.0016281455755233765, -0.0028225842397660017, -0.13119231164455414, -0.00714473519474268, -0.18171215057373047], "finish_reason": "stop"}, {"text": " np.asarray(word_count.toarray()) / sum_words", "tokens": [" np", ".", "as", "array", "(", "word", "_", "count", ".", "to", "array", "())", " /", " sum", "_", "words", "\n"], "logprobs": [-3.8179569244384766, -7.116541382856667e-05, -2.6271464824676514, -0.0306929349899292, -0.4032217860221863, -0.16108781099319458, -7.593343616463244e-05, -2.658331868587993e-05, -0.03863225132226944, -1.8926057815551758, -0.0034033493138849735, -0.2760258615016937, -0.11702107638120651, -0.15830570459365845, -0.004166494123637676, -4.625213477993384e-05, -0.182305708527565], "finish_reason": "stop"}, {"text": "word, sum_words[0][i]) for word, i in vectorizer.vocabulary_.items()", "tokens": ["word", ",", " sum", "_", "words", "[", "0", "][", "i", "])", " for", " word", ",", " i", " in", " vector", "izer", ".", "voc", "abulary", "_", ".", "items", "()", "\n"], "logprobs": [-0.06549644470214844, -0.11040443181991577, -0.9704859256744385, -0.015517919324338436, -0.012717456556856632, -0.06194397434592247, -1.5033971071243286, -0.5920319557189941, -1.0498486757278442, -0.1020607277750969, -0.7617906332015991, -0.04134321212768555, -0.00303082843311131, -0.005367155186831951, -0.003819552715867758, -0.07563963532447815, -1.0490362910786644e-05, -0.00011514954530866817, -0.03102489933371544, -0.0071441433392465115, -0.00012087091454304755, -0.00011955977242905647, -0.0006202919175848365, -0.00010609064338495955, -0.02448461949825287], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.07207515835762024, -0.00024768622824922204, -0.16205722093582153, -0.0011757849715650082, -6.794698856538162e-05, -0.002226851647719741, -0.018093768507242203, -0.0029951734468340874, -0.0018205749802291393, -0.020107246935367584, -0.0003375437227077782, -0.23335327208042145, -0.00582366855815053, -0.0027215369045734406, -0.02268436923623085, -0.0001627074379939586, -0.00539620453491807, -0.0005085367010906339, -0.0004580163804348558, -0.014085168950259686, -0.20123475790023804], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.2969532310962677, -8.570780482841656e-05, -2.658331868587993e-05, -0.21697518229484558, -0.015271521173417568, -0.0031969649717211723, -0.0014424644177779555, -0.004898214712738991], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Freq\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "F", "req", "\"", "])", "\n"], "logprobs": [-0.01966761238873005, -0.004313095007091761, -0.0024612629786133766, -0.0701482966542244, -0.14417298138141632, -6.4490144723095e-05, -7.986990567587782e-06, -0.05195821821689606, -0.024079374969005585, -0.042988378554582596, -0.007635692600160837, -0.2517469525337219, -0.006092903204262257, -0.00023922442051116377, -0.0019506252137944102, -0.6171188354492188, -2.479182004928589, -0.043768469244241714, -0.00569056486710906, -0.050798311829566956], "finish_reason": "stop"}, {"text": " plt.plot(", "tokens": [" plt", ".", "plot", "(", "\n"], "logprobs": [-2.041381359100342, -0.0002671123365871608, -3.090052366256714, -0.09968513250350952, -1.206498384475708], "finish_reason": "stop"}, {"text": " save_path is not None:", "tokens": [" save", "_", "path", " is", " not", " None", ":", "\n"], "logprobs": [-0.021516816690564156, -3.242440288886428e-05, -1.5497195136049413e-06, -1.0530424118041992, -0.18992863595485687, -1.9430925021879375e-05, -0.0009105826611630619, -0.001833782996982336], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.009425780735909939, -0.0003116837178822607, -0.00023040501400828362, -0.007076083682477474, -6.079655122448457e-06, -5.960446742392378e-06, -0.15762168169021606, -0.006500408984720707], "finish_reason": "stop"}, {"text": "close()  # Ensure closing the plot", "tokens": ["close", "()", "  ", "#", " Ensure", " closing", " the", " plot", "\n"], "logprobs": [-0.17483040690422058, -0.11217606067657471, -2.464399814605713, -0.0012017417466267943, -2.8689804077148438, -3.217604160308838, -0.283189594745636, -0.19333182275295258, -1.2706186771392822], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.029953591525554657, -0.04624602571129799], "finish_reason": "stop"}, {"text": " (FileNotFoundError, Exception) as e:", "tokens": [" (", "File", "NotFound", "Error", ",", " Exception", ")", " as", " e", ":", "\n"], "logprobs": [-2.7861080169677734, -0.0751204714179039, -4.815939246327616e-05, -3.6954811548639555e-06, -0.17738649249076843, -0.1529647707939148, -0.23882612586021423, -0.00021920185827184469, -0.516207754611969, -0.00019298121333122253, -0.0035217900294810534], "finish_reason": "stop"}, {"text": " exc", "tokens": [" exc", "\n"], "logprobs": [-1.5486066341400146, -0.08143267780542374], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.01579030603170395, -0.061671432107686996, -0.011887306347489357, -0.000760385300964117, -0.006061148829758167], "finish_reason": "stop"}, {"text": "\"An error occurred:\", str(e))", "tokens": ["\"", "An", " error", " occurred", ":\"", ",", " str", "(", "e", "))", "\n"], "logprobs": [-1.271714448928833, -0.666797399520874, -0.19480924308300018, -0.026957904919981956, -0.30257686972618103, -0.1436719000339508, -1.7280592918395996, -8.856858039507642e-05, -0.018043074756860733, -0.03871666267514229, -0.01867474429309368], "finish_reason": "stop"}, {"text": " None", "tokens": [" None"], "logprobs": [-0.017869433388113976], "finish_reason": "stop"}], "metrics": {"energy": 360.12958874702474, "energy_per_token": 1.7567297012049987, "time": 15.34914, "time_per_token": 0.07487385365853659}}
{"outputs": [{"text": " pd.read_csv(file_path, header=None)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ",", " header", "=", "None", ")", "\n"], "logprobs": [-0.004767479375004768, -0.00014995403762441128, -0.0032484165858477354, -1.7046782886609435e-05, -0.0010191967012360692, -0.0005153281381353736, -0.007697681430727243, -0.00025388356880284846, -3.099393507000059e-05, -0.7640590071678162, -0.28430548310279846, -0.0362929031252861, -0.6712893843650818, -0.8495736122131348, -0.04020286723971367], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ")", "\n"], "logprobs": [-0.00029404606902971864, -7.152531907195225e-06, -2.2053474822314456e-05, -0.09170728176832199, -0.275307297706604, -0.0002640137099660933, -7.712543447269127e-05, -0.10849971324205399, -0.033961087465286255, -3.576278118089249e-07, -0.00932268239557743, -5.125986263010418e-06, -4.768360213347478e-06, -1.764281842042692e-05, -0.28360292315483093, -0.02692471817135811], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df['Text'])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "['", "Text", "'])", "\n"], "logprobs": [-0.00794890895485878, -1.3470558769768104e-05, -5.018585216021165e-05, -0.010039901360869408, -0.0006083783227950335, -9.226373367710039e-05, -0.007302142214030027, -0.01746489480137825, -1.5068655014038086, -0.0006927236099727452, -0.09780030697584152, -0.1558350771665573], "finish_reason": "stop"}, {"text": " sum([sum(x) for x in word_count.toarray()])", "tokens": [" sum", "([", "sum", "(", "x", ")", " for", " x", " in", " word", "_", "count", ".", "to", "array", "()", "])", "\n"], "logprobs": [-0.8234146237373352, -1.0005676746368408, -1.6712892055511475, -0.003940319176763296, -1.1892205476760864, -0.05490374565124512, -0.0024905160535126925, -0.00034767304896377027, -0.0003641180810518563, -0.018916912376880646, -1.966933996300213e-05, -3.111314072157256e-05, -0.03534863144159317, -0.09279139339923859, -0.0008385241380892694, -0.0005086558521725237, -0.0035245222970843315, -0.01257337722927332], "finish_reason": "stop"}, {"text": " (word_count.T / sum_words).T", "tokens": [" (", "word", "_", "count", ".", "T", " /", " sum", "_", "words", ")", ".", "T", "\n"], "logprobs": [-1.0261749029159546, -0.17780570685863495, -0.0007321537705138326, -5.1973900554003194e-05, -0.15678921341896057, -0.2630884051322937, -0.01717679388821125, -0.00867396779358387, -0.00024077377747744322, -3.909988299710676e-05, -0.0379939042031765, -0.106392040848732, -1.0712018013000488, -0.11282884329557419], "finish_reason": "stop"}, {"text": "word, count / (sum_words + 0.0001) * 100)", "tokens": ["word", ",", " count", " /", " (", "sum", "_", "words", " +", " ", "0", ".", "0", "0", "0", "1", ")", " *", " ", "1", "0", "0", ")", "\n"], "logprobs": [-0.08322540670633316, -0.11661293357610703, -0.9743735790252686, -0.9623144865036011, -2.6631603240966797, -0.033823609352111816, -0.004509280435740948, -0.0018572239205241203, -1.8232684135437012, -0.051421746611595154, -1.3667936325073242, -0.0002980979916173965, -0.46402138471603394, -0.11233875900506973, -0.6684565544128418, -0.6291340589523315, -2.5821642875671387, -0.13621284067630768, -0.007678753696382046, -0.0014037764631211758, -0.0010558750946074724, -0.0028601475059986115, -0.0751219093799591, -0.3874666690826416], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)[:10]", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "[:", "1", "0", "]", "\n"], "logprobs": [-0.08330657333135605, -0.00020644917094614357, -0.12866197526454926, -0.0012507957872003317, -3.85038583772257e-05, -0.001879355520941317, -0.016436299309134483, -0.0028778587002307177, -0.0015285247936844826, -0.02151530049741268, -0.00034707720624282956, -0.25778234004974365, -0.005544047802686691, -0.002534988336265087, -0.020421020686626434, -0.00014876213390380144, -0.004316655918955803, -0.0005018643569201231, -0.00047791501856409013, -0.015234304592013359, -1.8830208778381348, -0.014396372251212597, -0.00651450315490365, -0.0017752378480508924, -0.009388817474246025], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.3360927104949951, -0.00011276562872808427, -3.790783375734463e-05, -0.2321767508983612, -0.016106609255075455, -0.0034815194085240364, -0.0013572300085797906, -0.004967016167938709], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Frequency\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "F", "requency", "\"", "])", "\n"], "logprobs": [-0.018322501331567764, -0.004195697605609894, -0.0024607873056083918, -0.07995559275150299, -0.17225633561611176, -7.343022298300639e-05, -8.702239938429557e-06, -0.053077105432748795, -0.023157041519880295, -0.04526371508836746, -0.006842988543212414, -0.2394719421863556, -0.005456909537315369, -0.00023409964342135936, -0.0020561523269861937, -0.6725788116455078, -0.09215572476387024, -0.004062020685523748, -0.004653101786971092, -0.044737428426742554], "finish_reason": "stop"}, {"text": " plt.subplot(111)", "tokens": [" plt", ".", "sub", "plot", "(", "1", "1", "1", ")", "\n"], "logprobs": [-1.816066861152649, -0.0002810560108628124, -1.1876308917999268, -0.37777072191238403, -0.9512977004051208, -0.12054793536663055, -0.3366590142250061, -0.00028010259848088026, -0.0201050266623497, -0.015342430211603642], "finish_reason": "stop"}, {"text": " save_path:", "tokens": [" save", "_", "path", ":", "\n"], "logprobs": [-0.021798772737383842, -3.516612196108326e-05, -1.311301275563892e-06, -0.41697242856025696, -0.0024446146562695503], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.00964717660099268, -0.00031251792097464204, -0.00021669900161214173, -0.007535722106695175, -7.271740287251305e-06, -5.125986263010418e-06, -0.1501075178384781, -0.006105936598032713], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.20535540580749512, -0.09608790278434753, -0.07578717172145844], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.025977015495300293, -0.049306560307741165], "finish_reason": "stop"}, {"text": " FileNotFoundError as fnf:", "tokens": [" File", "NotFound", "Error", " as", " f", "nf", ":", "\n"], "logprobs": [-0.602020800113678, -3.349725011503324e-05, -5.8412379075889476e-06, -0.19423486292362213, -2.4139506816864014, -0.5513690114021301, -1.7569438219070435, -0.005187503527849913], "finish_reason": "stop"}, {"text": " FileNotFoundError(\"File path not found! {}\".format(exc.filename))", "tokens": [" File", "NotFound", "Error", "(", "\"", "File", " path", " not", " found", "!", " {", "}\"", ".", "format", "(", "exc", ".", "filename", "))", "\n"], "logprobs": [-0.2504063844680786, -0.0001357701694360003, -0.0002796259068418294, -0.024750739336013794, -1.8085545301437378, -0.5958490371704102, -2.094292163848877, -0.6169942617416382, -0.012020530179142952, -2.747379779815674, -2.7256758213043213, -0.256396621465683, -0.007069217972457409, -0.0026497275102883577, -0.00033182359766215086, -0.24298253655433655, -1.4390463829040527, -1.2908728122711182, -0.010975467972457409, -0.5051547884941101], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.012462714686989784, -0.06917840987443924, -0.013679332099854946, -0.0007513322634622455, -0.00571450823917985], "finish_reason": "stop"}, {"text": "\"An error occurred:\", str(e))", "tokens": ["\"", "An", " error", " occurred", ":\"", ",", " str", "(", "e", "))", "\n"], "logprobs": [-1.2550517320632935, -0.6851990222930908, -0.17902898788452148, -0.02720724232494831, -0.25964054465293884, -0.1696445345878601, -1.4637467861175537, -0.00011073929636040702, -0.022414669394493103, -0.02738669142127037, -0.018802620470523834], "finish_reason": "stop"}, {"text": " None", "tokens": [" None"], "logprobs": [-0.01743467152118683], "finish_reason": "stop"}], "metrics": {"energy": 393.54189271450076, "energy_per_token": 1.7490750787311145, "time": 16.56872, "time_per_token": 0.07363875555555555}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.005211459007114172, -0.00015066919149830937, -0.002838750835508108, -1.9430925021879375e-05, -0.0008761619683355093, -0.0005546461907215416, -0.0068722316063940525, -0.00018618757894728333, -2.8729025871143676e-05, -0.5224968194961548, -0.025802770629525185], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS, analyzer=\"char\", n_jobs=-1)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ",", " analy", "zer", "=", "\"", "char", "\"", ",", " n", "_", "jobs", "=-", "1", ")", "\n"], "logprobs": [-0.00025817399728111923, -6.794906312279636e-06, -1.8358061424805783e-05, -0.0906127467751503, -0.2650561034679413, -0.000248401309363544, -7.343022298300639e-05, -0.11092213541269302, -0.037477556616067886, -4.768370445162873e-07, -0.015035162679851055, -8.22540732769994e-06, -5.602820692729438e-06, -1.7523612768854946e-05, -1.376414179801941, -3.909633159637451, -0.0002431573811918497, -0.2028777003288269, -0.12803664803504944, -1.6129385232925415, -0.6967877745628357, -0.7479945421218872, -0.4794159233570099, -1.082966923713684, -1.1045066118240356, -0.4963458478450775, -0.020950449630618095, -0.22562745213508606, -0.040796663612127304], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"]).toarray()", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", ".", "to", "array", "()", "\n"], "logprobs": [-0.007707854732871056, -1.3112935448589269e-05, -5.328513361746445e-05, -0.010148354806005955, -0.0003936707798857242, -9.7508447652217e-05, -0.0057126120664179325, -0.021334325894713402, -0.4810216724872589, -0.004112122114747763, -0.0005335576133802533, -7.438383181579411e-05, -0.06843281537294388, -1.9071874618530273, -0.12893372774124146, -0.0016548046842217445, -0.05026144161820412, -0.07319094240665436], "finish_reason": "stop"}, {"text": " word_count.sum(axis=0)", "tokens": [" word", "_", "count", ".", "sum", "(", "axis", "=", "0", ")", "\n"], "logprobs": [-0.8224682211875916, -0.00013505500101018697, -0.0003499372396618128, -0.0004558716027531773, -0.0403115339577198, -1.2364673614501953, -0.0018358058296144009, -0.0027526842895895243, -0.14450864493846893, -0.006579640321433544, -0.17778006196022034], "finish_reason": "stop"}, {"text": " [float(x) / sum_words for x in word_count.sum(axis=1)]", "tokens": [" [", "float", "(", "x", ")", " /", " sum", "_", "words", " for", " x", " in", " word", "_", "count", ".", "sum", "(", "axis", "=", "1", ")]", "\n"], "logprobs": [-3.6032190322875977, -3.1859776973724365, -0.009934505447745323, -0.9134082198143005, -0.01737152598798275, -0.40143248438835144, -0.0453747920691967, -0.005513698328286409, -0.00010251473577227443, -0.4788699746131897, -0.0002584123576525599, -0.000777776469476521, -0.10742255300283432, -0.00015364897262770683, -5.8412379075889476e-06, -0.0551837757229805, -0.9842759966850281, -0.00019786784832831472, -0.002479932736605406, -0.0004633783537428826, -0.17199690639972687, -0.04918774589896202, -0.007015003357082605], "finish_reason": "stop"}, {"text": "word, word_count.get_count(word) / sum_words.get(\"count\"))", "tokens": ["word", ",", " word", "_", "count", ".", "get", "_", "count", "(", "word", ")", " /", " sum", "_", "words", ".", "get", "(", "\"", "count", "\"", "))", "\n"], "logprobs": [-0.07576518505811691, -0.06839306652545929, -1.8892300128936768, -0.0031898352317512035, -0.0014384171226993203, -1.4054447412490845, -0.2736292779445648, -0.4109845757484436, -0.4359421133995056, -0.06972489506006241, -0.27746784687042236, -0.20786088705062866, -0.13288462162017822, -0.11691439151763916, -0.006153684109449387, -0.00018273114983458072, -0.7855352163314819, -0.041679780930280685, -0.05659143254160881, -0.5655654072761536, -0.30299967527389526, -0.1609697788953781, -0.1476336121559143, -0.1801418662071228], "finish_reason": "stop"}, {"text": " sorted(", "tokens": [" sorted", "(", "\n"], "logprobs": [-0.08227339386940002, -0.0002426806604489684, -1.9667799472808838], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.4015122652053833, -9.953480184776708e-05, -3.0636318115284666e-05, -0.20274125039577484, -0.017134491354227066, -0.0033496483229100704, -0.0015049570938572288, -0.004618216305971146], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Count\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "Count", "\"", "])", "\n"], "logprobs": [-0.020256903022527695, -0.004369830247014761, -0.002228992525488138, -0.07859798520803452, -0.1559908390045166, -6.341733387671411e-05, -7.033323527139146e-06, -0.05483897402882576, -0.025324605405330658, -0.04242821782827377, -0.007616882212460041, -0.23950767517089844, -0.006179630756378174, -0.0002755738969426602, -0.0021082572638988495, -0.8546990156173706, -0.012050447054207325, -0.00296522188000381, -0.03576371446251869], "finish_reason": "stop"}, {"text": " df_top.plot.bar(rot=90, legend=False)", "tokens": [" df", "_", "top", ".", "plot", ".", "bar", "(", "rot", "=", "9", "0", ",", " legend", "=", "False", ")", "\n"], "logprobs": [-0.19242414832115173, -0.001354134758003056, -2.002696055569686e-05, -0.0129444794729352, -0.11579933762550354, -0.642509937286377, -0.004895486403256655, -0.5521571636199951, -2.8823351860046387, -0.011130268685519695, -0.9762048125267029, -0.00020454221521504223, -0.18394728004932404, -2.3813536167144775, -0.033647384494543076, -0.10358132421970367, -0.8639295101165771, -0.06384655088186264], "finish_reason": "stop"}, {"text": " save_path is not None:", "tokens": [" save", "_", "path", " is", " not", " None", ":", "\n"], "logprobs": [-0.021525917574763298, -3.325883881188929e-05, -1.4305104514278355e-06, -0.8912481665611267, -0.17841394245624542, -2.109982233378105e-05, -0.0009517907164990902, -0.00199333718046546], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.008605184964835644, -0.0003762729174923152, -0.0002307625545654446, -0.008691339753568172, -8.106198947643861e-06, -5.483612312673358e-06, -0.1806844025850296, -0.005671362392604351], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.19025668501853943, -0.10136306285858154, -0.07379227131605148], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.03509003669023514, -0.05589963123202324], "finish_reason": "stop"}, {"text": " FileNotFoundError as e:", "tokens": [" File", "NotFound", "Error", " as", " e", ":", "\n"], "logprobs": [-0.5442646741867065, -3.302042750874534e-05, -4.6491513785440475e-06, -0.21950343251228333, -0.4372229278087616, -0.0021029042545706034, -0.0036688416730612516], "finish_reason": "stop"}, {"text": " FileNotFoundError(", "tokens": [" File", "NotFound", "Error", "(", "\n"], "logprobs": [-0.30216559767723083, -0.00013624693383462727, -0.000205018965061754, -0.027039825916290283, -1.1036955118179321], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.013487289659678936, -0.05496625602245331, -0.014438790269196033, -0.0007335832342505455, -0.006270851939916611], "finish_reason": "stop"}, {"text": "f\"An error occurred: {str(e)}\")", "tokens": ["f", "\"", "An", " error", " occurred", ":", " {", "str", "(", "e", ")}", "\"", ")", "\n"], "logprobs": [-0.5260226130485535, -0.006155342794954777, -1.0959692001342773, -0.10833585262298584, -0.023753127083182335, -0.13223916292190552, -0.007745826151221991, -1.7120475769042969, -7.819823804311454e-05, -0.03408529609441757, -0.02310613915324211, -0.01766730286180973, -0.05592894181609154, -0.016618162393569946], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "\n"], "logprobs": [-0.015980146825313568, -0.9882820248603821], "finish_reason": "stop"}], "metrics": {"energy": 366.6333771076204, "energy_per_token": 1.6818044821450477, "time": 15.747942, "time_per_token": 0.07223826605504587}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.004559715278446674, -0.00019071667338721454, -0.0024027545005083084, -1.597391747054644e-05, -0.000821014866232872, -0.0005164004978723824, -0.007414560765028, -0.00024279984063468874, -3.182837463100441e-05, -0.5615230798721313, -0.024881096556782722], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS, max_features=10000)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ",", " max", "_", "features", "=", "1", "0", "0", "0", "0", ")", "\n"], "logprobs": [-0.0002681849291548133, -7.390948667307384e-06, -2.276871418871451e-05, -0.07359903305768967, -0.30806225538253784, -0.00025555206229910254, -6.4490144723095e-05, -0.10011275857686996, -0.03194531798362732, -4.768370445162873e-07, -0.010094896890223026, -6.794906312279636e-06, -4.291525328881107e-06, -1.8596476365928538e-05, -1.2845308780670166, -1.339149832725525, -0.0008918836829252541, -0.07849141955375671, -0.006121576298028231, -0.24279767274856567, -0.02142954245209694, -1.1642816066741943, -0.7402895092964172, -0.8191984295845032, -0.7478616833686829, -0.03684283420443535], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df['Text'])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "['", "Text", "'])", "\n"], "logprobs": [-0.007143906317651272, -1.1205610462639015e-05, -5.9960475482512265e-05, -0.008236134424805641, -0.00048315772437490523, -9.500529267825186e-05, -0.005159159656614065, -0.015544679947197437, -1.6485886573791504, -0.0005932478234171867, -0.0910833328962326, -0.14880229532718658], "finish_reason": "stop"}, {"text": " sum(word_count.toarray())", "tokens": [" sum", "(", "word", "_", "count", ".", "to", "array", "())", "\n"], "logprobs": [-0.876081109046936, -0.43639272451400757, -0.11297674477100372, -0.016024257987737656, -0.001821288955397904, -0.007646103389561176, -0.2262014001607895, -0.001838304684497416, -0.1998385637998581, -0.012956011109054089], "finish_reason": "stop"}, {"text": " sum_words[1:].toarray().flatten()", "tokens": [" sum", "_", "words", "[", "1", ":]", ".", "to", "array", "()", ".", "fl", "atten", "()", "\n"], "logprobs": [-3.18200421333313, -0.0014106809394434094, -0.00010716341057559475, -1.1412856578826904, -2.3292343616485596, -0.5994759202003479, -1.927390694618225, -1.944078803062439, -0.5263581871986389, -0.014954601414501667, -0.46135738492012024, -1.167177438735962, -8.260862523457035e-05, -0.006690719164907932, -0.37774136662483215], "finish_reason": "stop"}, {"text": "word, count)", "tokens": ["word", ",", " count", ")", "\n"], "logprobs": [-0.0892668142914772, -0.09973185509443283, -1.3880360126495361, -0.8156373500823975, -0.8959527015686035], "finish_reason": "stop"}, {"text": " sorted(", "tokens": [" sorted", "(", "\n"], "logprobs": [-0.08244388550519943, -0.00019298121333122253, -1.9861781597137451], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.4016391932964325, -7.855583680793643e-05, -2.5033637939486653e-05, -0.265485018491745, -0.018269594758749008, -0.003632971551269293, -0.0014699617167934775, -0.004908298142254353], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"word\", \"frequency\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "word", "\"", ",", " \"", "frequency", "\"", "])", "\n"], "logprobs": [-0.016589554026722908, -0.005054434295743704, -0.0024639980401843786, -0.0672469511628151, -0.16353274881839752, -6.139089964563027e-05, -7.748573807475623e-06, -0.05895688384771347, -0.020909123122692108, -0.04416695609688759, -0.007567074615508318, -2.562344551086426, -0.010034944862127304, -0.0004198861715849489, -0.002488494385033846, -1.2128217220306396, -0.004320335108786821, -0.004141564015299082, -0.02761191688477993], "finish_reason": "stop"}, {"text": " plt.barh(", "tokens": [" plt", ".", "bar", "h", "(", "\n"], "logprobs": [-2.0620245933532715, -0.00026472879108041525, -1.1858989000320435, -0.8220739960670471, -0.02392551861703396, -1.3955812454223633], "finish_reason": "stop"}, {"text": " save_path is not None:", "tokens": [" save", "_", "path", " is", " not", " None", ":", "\n"], "logprobs": [-0.021640131250023842, -3.290122185717337e-05, -1.5497195136049413e-06, -1.0437184572219849, -0.20712602138519287, -2.0861407392658293e-05, -0.0010526598198339343, -0.0021503677126020193], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.0071495878510177135, -0.000316212244797498, -0.0002195594133809209, -0.010519767180085182, -7.748573807475623e-06, -4.6491513785440475e-06, -0.1935669183731079, -0.006702560465782881], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.19715237617492676, -0.1103823333978653, -0.07182611525058746], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.029697533696889877, -0.05657239630818367], "finish_reason": "stop"}, {"text": " Exception as e:", "tokens": [" Exception", " as", " e", ":", "\n"], "logprobs": [-1.0293066501617432, -0.14583957195281982, -0.19304488599300385, -0.00038521020906046033, -0.006778697017580271], "finish_reason": "stop"}, {"text": " FileNotFoundError(\"The specified file path does not exist.\") from exc", "tokens": [" File", "NotFound", "Error", "(", "\"", "The", " specified", " file", " path", " does", " not", " exist", ".", "\"", ")", " from", " exc", "\n"], "logprobs": [-0.24653469026088715, -0.00013064485392533243, -0.00018034738604910672, -0.019713081419467926, -1.7687851190567017, -1.4596340656280518, -0.7704882025718689, -0.07750024646520615, -0.9097933769226074, -0.4940890967845917, -0.0005538121913559735, -0.003826678032055497, -0.34089961647987366, -0.2060646116733551, -0.05489979684352875, -0.24973101913928986, -0.001433893688954413, -0.014202586375176907], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.014331623911857605, -0.06644068658351898, -0.014878850430250168, -0.0008332832949236035, -0.007197167258709669], "finish_reason": "stop"}, {"text": "f\"An error occurred: {e}\")", "tokens": ["f", "\"", "An", " error", " occurred", ":", " {", "e", "}\"", ")", "\n"], "logprobs": [-0.49100127816200256, -0.005966708529740572, -0.9471994042396545, -0.11119277775287628, -0.022331319749355316, -0.11516941338777542, -0.006537715904414654, -0.4286138415336609, -0.11541862785816193, -0.04936034604907036, -0.01817571558058262], "finish_reason": "stop"}, {"text": " None", "tokens": [" None"], "logprobs": [-0.02192321978509426], "finish_reason": "stop"}], "metrics": {"energy": 357.87717864036534, "energy_per_token": 2.0333930604566213, "time": 14.918724, "time_per_token": 0.08476547727272726}}
{"outputs": [{"text": " pd.read_csv(file_path, header=0, dtype={'Text': object})", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ",", " header", "=", "0", ",", " dtype", "={", "'", "Text", "':", " object", "})", "\n"], "logprobs": [-0.005211459007114172, -0.00015066919149830937, -0.002838750835508108, -1.9430925021879375e-05, -0.0008761619683355093, -0.0005546461907215416, -0.0068722316063940525, -0.00018618757894728333, -2.8729025871143676e-05, -0.9013782739639282, -0.2783486843109131, -0.035412032157182693, -0.6836928129196167, -0.7140761017799377, -1.908179521560669, -2.987976551055908, -0.10536249727010727, -0.06465982645750046, -0.006785091012716293, -2.661396026611328, -0.040372446179389954, -0.043761853128671646], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ")", "\n"], "logprobs": [-0.00025733973598107696, -7.390948667307384e-06, -1.8715683836489916e-05, -0.08696091920137405, -0.3014380633831024, -0.00029023250681348145, -6.818538531661034e-05, -0.11813434958457947, -0.0442926399409771, -3.576278118089249e-07, -0.011576265096664429, -8.106198947643861e-06, -6.318072337307967e-06, -1.9788545614574105e-05, -0.26670336723327637, -0.03259088471531868], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df.Text)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", ".", "Text", ")", "\n"], "logprobs": [-0.007937082089483738, -1.2874520507466514e-05, -7.080780778778717e-05, -0.00997652392834425, -0.0005166388000361621, -9.798523387871683e-05, -0.006202259100973606, -0.014834336005151272, -1.9025464057922363, -0.3779345154762268, -0.20185726881027222, -0.13866500556468964], "finish_reason": "stop"}, {"text": " word_count.sum()", "tokens": [" word", "_", "count", ".", "sum", "()", "\n"], "logprobs": [-0.9166467189788818, -0.00011383838864276186, -0.00033206192892976105, -0.0005112771177664399, -0.04093009606003761, -0.41776663064956665, -0.009938518516719341], "finish_reason": "stop"}, {"text": " word_count.toarray() / sum_words", "tokens": [" word", "_", "count", ".", "to", "array", "()", " /", " sum", "_", "words", "\n"], "logprobs": [-1.6666758060455322, -0.00012981049076188356, -2.8371408916427754e-05, -0.12443004548549652, -1.1826952695846558, -0.006969782989472151, -0.02578720450401306, -0.5137788653373718, -0.03612550348043442, -0.0019286142196506262, -3.635817120084539e-05, -0.40992090106010437], "finish_reason": "stop"}, {"text": "word, sum_words[0][word_count[0][word]])", "tokens": ["word", ",", " sum", "_", "words", "[", "0", "][", "word", "_", "count", "[", "0", "][", "word", "]]", ")", "\n"], "logprobs": [-0.06745925545692444, -0.10008557885885239, -0.9979369640350342, -0.012923179194331169, -0.010294906795024872, -0.054139070212841034, -1.258801817893982, -0.5107349157333374, -1.015554428100586, -2.0727739334106445, -0.0883161723613739, -1.7880730628967285, -0.22637300193309784, -0.6493381857872009, -0.0560498870909214, -0.0642520934343338, -0.0303733479231596, -0.4695647060871124], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: -x[1])", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " -", "x", "[", "1", "])", "\n"], "logprobs": [-0.08197811245918274, -0.00018594920402392745, -0.17390766739845276, -0.0010919567430391908, -5.686121585313231e-05, -0.0018779276870191097, -0.015166793018579483, -0.002855036174878478, -0.0012373419012874365, -0.018730904906988144, -0.0003967689990531653, -1.5647027492523193, -0.008046945556998253, -0.008277987129986286, -0.0004318020073696971, -0.0025056179147213697, -0.19418753683567047], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.3254663348197937, -7.30726242181845e-05, -3.40932747349143e-05, -0.23861590027809143, -0.016962919384241104, -0.002983050188049674, -0.0014873405452817678, -0.005022290628403425], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Words\", \"Frequency\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Words", "\"", ",", " \"", "F", "requency", "\"", "])", "\n"], "logprobs": [-0.018062274903059006, -0.0047732931561768055, -0.0023738557938486338, -0.07850607484579086, -0.12803789973258972, -6.353653589030728e-05, -8.583032467868179e-06, -0.05591011792421341, -0.02169659174978733, -0.04894871264696121, -0.006872350350022316, -2.815213441848755, -0.011536435224115849, -0.0010674261720851064, -0.0023491187021136284, -0.3735080063343048, -0.10682976245880127, -0.00843119714409113, -0.005802453961223364, -0.031867608428001404], "finish_reason": "stop"}, {"text": " df_top.plot(kind=\"barh\", figsize=(10, 6), grid=True)", "tokens": [" df", "_", "top", ".", "plot", "(", "kind", "=", "\"", "bar", "h", "\"", ",", " fig", "size", "=(", "1", "0", ",", " ", "6", ")", ",", " grid", "=", "True", ")", "\n"], "logprobs": [-0.18672619760036469, -0.0012460333527997136, -2.6464111215318553e-05, -0.016089601442217827, -0.12825991213321686, -0.7156038880348206, -0.6469177007675171, -0.18010543286800385, -0.00026425207033753395, -0.008878988213837147, -0.23266014456748962, -0.0001113352773245424, -0.04990563541650772, -0.9770544767379761, -0.00015793983766343445, -0.031469736248254776, -0.4002058506011963, -0.7563806772232056, -0.0030314228497445583, -0.051109395921230316, -2.181565046310425, -0.49020951986312866, -0.00035613393993116915, -2.310256004333496, -0.035303063690662384, -0.05441107600927353, -0.9194698333740234, -0.018419994041323662], "finish_reason": "stop"}, {"text": " save_path is not None:", "tokens": [" save", "_", "path", " is", " not", " None", ":", "\n"], "logprobs": [-0.02155916765332222, -3.5523738915799186e-05, -1.4305104514278355e-06, -0.9968172907829285, -0.1946524679660797, -1.9311717551317997e-05, -0.0010665925219655037, -0.0019847711082547903], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.007008847780525684, -0.00036090059438720345, -0.00026603974401950836, -0.009001863189041615, -7.748573807475623e-06, -6.6756979322235566e-06, -0.1650116741657257, -0.007014293223619461], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.19096505641937256, -0.10385417193174362, -0.08661946654319763], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.03179936483502388, -0.047738026827573776], "finish_reason": "stop"}, {"text": " FileNotFoundError as e:", "tokens": [" File", "NotFound", "Error", " as", " e", ":", "\n"], "logprobs": [-0.5944133996963501, -2.5629668016335927e-05, -6.318072337307967e-06, -0.25405576825141907, -0.4418985843658447, -0.0020896997302770615, -0.004538829438388348], "finish_reason": "stop"}, {"text": " exc", "tokens": [" exc", "\n"], "logprobs": [-1.4377503395080566, -0.0979216992855072], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.0140602495521307, -0.05409886687994003, -0.014358299784362316, -0.0006803343421779573, -0.0055004204623401165], "finish_reason": "stop"}, {"text": "f\"Error: {e}\")", "tokens": ["f", "\"", "Error", ":", " {", "e", "}\"", ")", "\n"], "logprobs": [-0.4875411093235016, -0.005975477397441864, -0.9093698859214783, -1.011371374130249, -0.009549296461045742, -0.31327229738235474, -0.08023397624492645, -0.036645423620939255, -0.013575024902820587], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.0179172083735466, -1.109633445739746, -4.768370445162873e-07, -1.6689286894688848e-06, -7.86750388215296e-05, -0.00035529976594261825, -0.13284015655517578], "finish_reason": "stop"}], "metrics": {"energy": 385.5851569995881, "energy_per_token": 1.8274178056852517, "time": 16.152195, "time_per_token": 0.07655068720379146}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.004559715278446674, -0.00019071667338721454, -0.0024027545005083084, -1.597391747054644e-05, -0.000821014866232872, -0.0005164004978723824, -0.007414560765028, -0.00024279984063468874, -3.182837463100441e-05, -0.5615230798721313, -0.024881096556782722], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words='english', tokenizer=lambda s: s.split())", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "='", "eng", "lish", "'", ",", " token", "izer", "=", "lambda", " s", ":", " s", ".", "split", "())", "\n"], "logprobs": [-0.0002681849291548133, -7.390948667307384e-06, -2.276871418871451e-05, -0.07359903305768967, -0.30806225538253784, -0.00025555206229910254, -6.4490144723095e-05, -2.472625494003296, -0.09972764551639557, -7.629365427419543e-06, -1.0279953479766846, -0.0011984078446403146, -1.8273146152496338, -1.5799524784088135, -0.004959305748343468, -0.34371715784072876, -2.058863401412964, -0.005805653985589743, -0.05924656614661217, -0.006576087325811386, -0.021300600841641426, -0.21822002530097961, -0.014418932609260082], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.007064010016620159, -1.3351351299206726e-05, -5.4596363042946905e-05, -0.007201546337455511, -0.0005723983631469309, -9.345571743324399e-05, -0.00540047325193882, -0.02250710316002369, -0.43761682510375977, -0.003456809790804982, -0.0004920940846204758, -7.10462118149735e-05, -0.07988845556974411, -0.2329372614622116], "finish_reason": "stop"}, {"text": " sum(word_count.toarray())", "tokens": [" sum", "(", "word", "_", "count", ".", "to", "array", "())", "\n"], "logprobs": [-0.8195419907569885, -0.403138130903244, -0.09750373661518097, -0.011419057846069336, -0.0017138330731540918, -0.012536648660898209, -0.23282666504383087, -0.0013916341122239828, -0.20650416612625122, -0.015502308495342731], "finish_reason": "stop"}, {"text": " [(word, count) for word, count in sum_words.to_dict().items()]", "tokens": [" [(", "word", ",", " count", ")", " for", " word", ",", " count", " in", " sum", "_", "words", ".", "to", "_", "dict", "()", ".", "items", "()", "]", "\n"], "logprobs": [-3.4662022590637207, -0.13386912643909454, -0.13178828358650208, -0.8643692135810852, -0.5059993863105774, -0.058970142155885696, -0.0031481252517551184, -0.0006323245470412076, -0.0018772137118503451, -0.004605994094163179, -2.596693277359009, -6.770858453819528e-05, -6.556489552167477e-06, -0.013017200864851475, -0.29070189595222473, -0.02143735997378826, -0.2124037891626358, -0.012293989770114422, -0.0009220162755809724, -0.0004967409186065197, -0.00024732868769206107, -0.015886053442955017, -0.00361634255386889], "finish_reason": "stop"}, {"text": "word, sum_words.get(word, 0)) for word in vectorizer.vocabulary_", "tokens": ["word", ",", " sum", "_", "words", ".", "get", "(", "word", ",", " ", "0", "))", " for", " word", " in", " vector", "izer", ".", "voc", "abulary", "_", "\n"], "logprobs": [-0.0756850615143776, -0.10092002898454666, -1.011169672012329, -0.01919819787144661, -0.011608198285102844, -2.848560333251953, -0.043105531483888626, -0.001553639187477529, -0.018357614055275917, -0.08165297657251358, -0.021488115191459656, -0.00339443888515234, -0.35747724771499634, -0.3857470154762268, -0.0007799206068739295, -0.0034563345834612846, -0.5711178779602051, -2.1576648578047752e-05, -0.00014256415306590497, -2.303908348083496, -0.006045152433216572, -0.00018952481332235038, -0.42056840658187866], "finish_reason": "stop"}, {"text": " sorted(", "tokens": [" sorted", "(", "\n"], "logprobs": [-0.06310916692018509, -0.00023493390472140163, -1.692347764968872], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.39028099179267883, -8.570780482841656e-05, -3.099393507000059e-05, -0.25226590037345886, -0.018926620483398438, -0.0032087289728224277, -0.0015572099946439266, -0.00500900624319911], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Frequency\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "F", "requency", "\"", "])", "\n"], "logprobs": [-0.018988030031323433, -0.003668128978461027, -0.002218763343989849, -0.07474840432405472, -0.15281365811824799, -6.675497570540756e-05, -9.775113539944869e-06, -0.058563798666000366, -0.024213775992393494, -0.04874288663268089, -0.00676081795245409, -0.2309785932302475, -0.00538090942427516, -0.000254241080256179, -0.002325689420104027, -0.5824393630027771, -0.08136091381311417, -0.004030320327728987, -0.004842340014874935, -0.031143926084041595], "finish_reason": "stop"}, {"text": " df_top.plot.bar(y=\"Count\", x=\"Word\", rot=0)", "tokens": [" df", "_", "top", ".", "plot", ".", "bar", "(", "y", "=", "\"", "Count", "\"", ",", " x", "=", "\"", "Word", "\"", ",", " rot", "=", "0", ")", "\n"], "logprobs": [-0.20588979125022888, -0.001211862312629819, -2.3841574147809297e-05, -0.01641835644841194, -0.11537794768810272, -0.6403927206993103, -0.005624066106975079, -0.4875018000602722, -3.177987813949585, -0.08288048207759857, -0.004634947050362825, -0.04058034345507622, -8.272782724816352e-05, -0.04460404813289642, -0.3023863136768341, -0.010103747248649597, -0.0006273209000937641, -0.00021073981770314276, -5.447716102935374e-05, -0.20262600481510162, -0.5539469718933105, -0.004612520802766085, -0.44716647267341614, -0.8245317935943604, -0.019608933478593826], "finish_reason": "stop"}, {"text": " save_path:", "tokens": [" save", "_", "path", ":", "\n"], "logprobs": [-0.021432459354400635, -3.1709168979432434e-05, -1.4305104514278355e-06, -0.4173518121242523, -0.0024029924534261227], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.008665459230542183, -0.0003271759778726846, -0.0002451834443490952, -0.009086920879781246, -9.059865078597795e-06, -6.079655122448457e-06, -0.16898997128009796, -0.0067300316877663136], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.15973852574825287, -0.10346738249063492, -0.06649734824895859], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.030806567519903183, -0.05521897226572037], "finish_reason": "stop"}, {"text": " FileNotFoundError as err:", "tokens": [" File", "NotFound", "Error", " as", " err", ":", "\n"], "logprobs": [-0.6184811592102051, -2.7656173188006505e-05, -5.483612312673358e-06, -0.2249087691307068, -2.033210277557373, -0.006187213119119406, -0.0059562805108726025], "finish_reason": "stop"}, {"text": " FileNotFoundError(f\"File not found: {exc}\")", "tokens": [" File", "NotFound", "Error", "(", "f", "\"", "File", " not", " found", ":", " {", "exc", "}\"", ")", "\n"], "logprobs": [-0.203203484416008, -0.0001656871900195256, -0.0001998939987970516, -0.02488098107278347, -1.0769861936569214, -0.01914580725133419, -0.6434163451194763, -0.4362049400806427, -0.003448018804192543, -0.15546391904354095, -0.018574584275484085, -0.40457478165626526, -0.9645063281059265, -0.0024931321386247873, -0.021028660237789154], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.014634409919381142, -0.0637136772274971, -0.01360289566218853, -0.0008273277780972421, -0.006817650981247425], "finish_reason": "stop"}, {"text": "\"An error occurred: \", e)", "tokens": ["\"", "An", " error", " occurred", ":", " \"", ",", " e", ")", "\n"], "logprobs": [-1.2714738845825195, -0.6548295021057129, -0.1548471599817276, -0.026533231139183044, -2.462045431137085, -0.13138027489185333, -0.043157827109098434, -0.43717634677886963, -0.10247001051902771, -0.007965702563524246], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.02051784284412861, -1.2117950916290283, -5.960462772236497e-07, -1.6689286894688848e-06, -0.00010418349120300263, -0.0003270567976869643, -0.14004166424274445], "finish_reason": "stop"}], "metrics": {"energy": 421.587506616592, "energy_per_token": 1.8990428225972613, "time": 16.585793, "time_per_token": 0.07471077927927927}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.0051756445318460464, -0.00015817821258679032, -0.0030563806649297476, -1.7404405298293568e-05, -0.0009894242975860834, -0.0005026984144933522, -0.007219536229968071, -0.00020549570035655051, -3.075552376685664e-05, -0.5617414712905884, -0.028226330876350403], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS, max_features=1000)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ",", " max", "_", "features", "=", "1", "0", "0", "0", ")", "\n"], "logprobs": [-0.0002455409849062562, -8.4638240878121e-06, -2.074220174108632e-05, -0.0847858414053917, -0.28072643280029297, -0.00033146608620882034, -7.760223525110632e-05, -0.11030589789152145, -0.03700379282236099, -3.576278118089249e-07, -0.013025437481701374, -6.9141146923357155e-06, -4.768360213347478e-06, -1.6569954823353328e-05, -1.3418880701065063, -1.406885027885437, -0.0006597249885089695, -0.05873489752411842, -0.005259960889816284, -0.2362031638622284, -0.02444332279264927, -0.9614006876945496, -0.8004229664802551, -0.8499735593795776, -0.033466633409261703], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df['Text'])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "['", "Text", "'])", "\n"], "logprobs": [-0.006867851130664349, -1.0847986231965479e-05, -5.328513361746445e-05, -0.007971142418682575, -0.00041059168870560825, -0.0001045410826918669, -0.005309409461915493, -0.019272103905677795, -1.633143424987793, -0.000679500459227711, -0.08179358392953873, -0.12964048981666565], "finish_reason": "stop"}, {"text": " word_count.sum(axis=0).toarray().flatten()", "tokens": [" word", "_", "count", ".", "sum", "(", "axis", "=", "0", ")", ".", "to", "array", "()", ".", "fl", "atten", "()", "\n"], "logprobs": [-0.8482826352119446, -0.00013171759201213717, -0.0002627027570270002, -0.0005372511222958565, -0.03244733437895775, -0.9467579126358032, -0.0020663831382989883, -0.0026811149436980486, -0.1431192308664322, -0.00740710599347949, -1.9616296291351318, -0.5123093724250793, -0.2769894599914551, -0.12373349815607071, -1.1753915548324585, -0.7299145460128784, -0.0001308832288486883, -0.05187356099486351, -0.05918420851230621], "finish_reason": "stop"}, {"text": " (word_count.T / sum_words).round(2)", "tokens": [" (", "word", "_", "count", ".", "T", " /", " sum", "_", "words", ")", ".", "round", "(", "2", ")", "\n"], "logprobs": [-1.1466960906982422, -0.2284395545721054, -0.0009160612826235592, -5.519237674889155e-05, -0.13273055851459503, -0.2782600522041321, -0.018728798255324364, -0.01027366891503334, -0.00021944021864328533, -3.45700973412022e-05, -0.02967323176562786, -0.10056369751691818, -0.39403557777404785, -0.030827721580863, -0.4020470976829529, -0.001980725908651948, -0.1506209671497345], "finish_reason": "stop"}, {"text": "word, sum_words[index] / (sum_words.sum() + 1)) for word, index in vectorizer.vocabulary_.items()", "tokens": ["word", ",", " sum", "_", "words", "[", "index", "]", " /", " (", "sum", "_", "words", ".", "sum", "()", " +", " ", "1", "))", " for", " word", ",", " index", " in", " vector", "izer", ".", "voc", "abulary", "_", ".", "items", "()", "\n"], "logprobs": [-0.07365396618843079, -0.1199711263179779, -0.9599443078041077, -0.015927821397781372, -0.014517865143716335, -0.06696213781833649, -2.669571876525879, -2.518700122833252, -0.5690816640853882, -2.4252021312713623, -1.334944486618042, -0.32149574160575867, -0.006006879266351461, -1.9164108037948608, -0.08274451643228531, -0.12080828100442886, -0.4374350905418396, -0.11882390826940536, -0.3861614465713501, -0.547490119934082, -1.4591718912124634, -0.03172961249947548, -0.020274192094802856, -0.006302244495600462, -0.009257841855287552, -0.33613505959510803, -5.352353764465079e-05, -0.00031799983116798103, -0.013992189429700375, -0.006887504365295172, -0.00011395759065635502, -0.0005423743859864771, -0.0005714452126994729, -0.00011896379146492109, -0.014573084190487862], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)[:10]", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "[:", "1", "0", "]", "\n"], "logprobs": [-0.07754305005073547, -0.0002451834443490952, -0.15543565154075623, -0.0014368696138262749, -5.507317473529838e-05, -0.002291793003678322, -0.019475314766168594, -0.0031939942855387926, -0.0016301688738167286, -0.01850331947207451, -0.00037531962152570486, -0.2611043155193329, -0.005320555530488491, -0.002412268426269293, -0.023807955905795097, -0.00015221867943182588, -0.004944003652781248, -0.0004637358069885522, -0.000493762141559273, -0.015258019790053368, -2.100658416748047, -0.014264756813645363, -0.00691082701086998, -0.002070070942863822, -0.009906059131026268], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.30448007583618164, -8.654219709569588e-05, -2.8013790142722428e-05, -0.2052592933177948, -0.01899540051817894, -0.0030830015894025564, -0.0013616346986964345, -0.005231144838035107], "finish_reason": "stop"}, {"text": " pd.DataFrame(", "tokens": [" pd", ".", "DataFrame", "(", "\n"], "logprobs": [-0.017983831465244293, -0.003957061562687159, -0.002524167764931917, -0.08067318052053452, -2.991708755493164], "finish_reason": "stop"}, {"text": " df_top.plot(", "tokens": [" df", "_", "top", ".", "plot", "(", "\n"], "logprobs": [-0.18960709869861603, -0.0012867513578385115, -2.5152843591058627e-05, -0.014057193882763386, -0.12119549512863159, -0.72597736120224, -1.5162088871002197], "finish_reason": "stop"}, {"text": " save_path is not None:", "tokens": [" save", "_", "path", " is", " not", " None", ":", "\n"], "logprobs": [-0.021573401987552643, -3.683499380713329e-05, -1.311301275563892e-06, -1.0607967376708984, -0.20082195103168488, -2.1576648578047752e-05, -0.001023007556796074, -0.0019096963806077838], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.009301659651100636, -0.0003962923656217754, -0.0002321927313460037, -0.009523909538984299, -7.986990567587782e-06, -5.602820692729438e-06, -0.19965903460979462, -0.006588522344827652], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.1732582002878189, -0.1061568632721901, -0.06120103597640991], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.0271680299192667, -0.051101695746183395], "finish_reason": "stop"}, {"text": " FileNotFoundError as e:", "tokens": [" File", "NotFound", "Error", " as", " e", ":", "\n"], "logprobs": [-0.5516005158424377, -2.3483953555114567e-05, -5.960446742392378e-06, -0.2903311252593994, -0.43297672271728516, -0.002444376703351736, -0.003756254445761442], "finish_reason": "stop"}, {"text": " FileNotFoundError(str(exc))", "tokens": [" File", "NotFound", "Error", "(", "str", "(", "exc", "))", "\n"], "logprobs": [-0.31890618801116943, -0.00015138434537220746, -0.00022206225548870862, -0.025340761989355087, -2.3872971534729004, -0.0005091324565000832, -0.020244520157575607, -0.12768176198005676, -0.4065946638584137], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.01543575432151556, -0.06131047010421753, -0.015807438641786575, -0.0006860524881631136, -0.005597393959760666], "finish_reason": "stop"}, {"text": "\"Exception occurred: \", e)", "tokens": ["\"", "Exception", " occurred", ":", " \"", ",", " e", ")", "\n"], "logprobs": [-1.317192554473877, -2.7249321937561035, -0.6578974723815918, -2.3107316493988037, -0.22609947621822357, -0.028993932530283928, -0.42780381441116333, -0.07827714830636978, -0.007572872098535299], "finish_reason": "stop"}, {"text": " None", "tokens": [" None"], "logprobs": [-0.01752018742263317], "finish_reason": "stop"}], "metrics": {"energy": 395.0349759712218, "energy_per_token": 1.8288656294963972, "time": 16.365767, "time_per_token": 0.07576743981481482}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.004767479375004768, -0.00014995403762441128, -0.0032484165858477354, -1.7046782886609435e-05, -0.0010191967012360692, -0.0005153281381353736, -0.007697681430727243, -0.00025388356880284846, -3.099393507000059e-05, -0.6285304427146912, -0.03330879285931587], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words='english')", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "='", "eng", "lish", "')", "\n"], "logprobs": [-0.00026306029758416116, -7.390948667307384e-06, -1.9192511899746023e-05, -0.10336698591709137, -0.2994992733001709, -0.0002076410164590925, -6.270212179515511e-05, -2.248875379562378, -0.10956855863332748, -9.298280929215252e-06, -0.4392271041870117, -0.03283282369375229], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"].values)", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "]", ".", "values", ")", "\n"], "logprobs": [-0.008532378822565079, -1.4424220353248529e-05, -5.519237674889155e-05, -0.009660517796874046, -0.00047434045700356364, -9.417090768693015e-05, -0.005654648877680302, -0.02104838751256466, -0.44952312111854553, -0.004041124600917101, -0.0005927712772972882, -7.807903602952138e-05, -2.6617562770843506, -0.006675088312476873, -0.7115827202796936, -0.20203125476837158, -0.14576414227485657], "finish_reason": "stop"}, {"text": " word_count.sum()", "tokens": [" word", "_", "count", ".", "sum", "()", "\n"], "logprobs": [-0.9091275334358215, -0.00011729506513802335, -0.0002356490003876388, -0.0005006728461012244, -0.039870958775281906, -0.4286057651042938, -0.010420320555567741], "finish_reason": "stop"}, {"text": " (word_count.T / sum_words).toarray()", "tokens": [" (", "word", "_", "count", ".", "T", " /", " sum", "_", "words", ")", ".", "to", "array", "()", "\n"], "logprobs": [-0.9936211705207825, -0.17280538380146027, -0.0008418591460213065, -4.4225667807040736e-05, -0.2204049527645111, -0.22161000967025757, -0.02003445476293564, -0.012259134091436863, -0.00019643761334009469, -3.0517112463712692e-05, -0.03052401915192604, -0.11009406298398972, -3.094022750854492, -0.02353040874004364, -0.017287053167819977, -0.1582198292016983], "finish_reason": "stop"}, {"text": "word, int(sum_words[word]))", "tokens": ["word", ",", " int", "(", "sum", "_", "words", "[", "word", "]))", "\n"], "logprobs": [-0.08069440722465515, -0.10998300462961197, -3.255523443222046, -0.08446884155273438, -1.8554432392120361, -0.013611833564937115, -0.03458451107144356, -0.042802341282367706, -1.378465175628662, -0.43177247047424316, -0.9442840218544006], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.07505876570940018, -0.0002083561266772449, -0.1346295177936554, -0.0009329734020866454, -5.411955135059543e-05, -0.0019973821472376585, -0.018148791044950485, -0.0027585094794631004, -0.001734539750032127, -0.019721612334251404, -0.00038938093348406255, -0.273324579000473, -0.005986734759062529, -0.002354946220293641, -0.022857408970594406, -0.00016342257731594145, -0.004470829851925373, -0.0005486889858730137, -0.0004967409186065197, -0.01438908651471138, -0.16303884983062744], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.3120465874671936, -9.405170567333698e-05, -3.0040289857424796e-05, -0.24438881874084473, -0.015186987817287445, -0.0034905478823930025, -0.0014918637461960316, -0.004804139491170645], "finish_reason": "stop"}, {"text": " pd.DataFrame(", "tokens": [" pd", ".", "DataFrame", "(", "\n"], "logprobs": [-0.023487791419029236, -0.0036765618715435266, -0.002221618080511689, -0.0810454711318016, -2.7592594623565674], "finish_reason": "stop"}, {"text": " df_top.plot.barh(x=\"Word\", y=\"Count\", title=\"Most common words in text\", figsize=(15, 7), rot=90, figs=\"all\")", "tokens": [" df", "_", "top", ".", "plot", ".", "bar", "h", "(", "x", "=", "\"", "Word", "\"", ",", " y", "=", "\"", "Count", "\"", ",", " title", "=", "\"", "Most", " common", " words", " in", " text", "\"", ",", " fig", "size", "=(", "1", "5", ",", " ", "7", ")", ",", " rot", "=", "9", "0", ",", " fig", "s", "=", "\"", "all", "\"", ")", "\n"], "logprobs": [-0.18269316852092743, -0.001212100381962955, -1.9550132492440753e-05, -0.013050146400928497, -0.10661644488573074, -0.7586534023284912, -0.004871642217040062, -1.0393469333648682, -0.013948693871498108, -0.3517540693283081, -0.06990888714790344, -0.001907792640849948, -0.012624584138393402, -6.3774932641536e-05, -0.002299523912370205, -0.05892721191048622, -0.0024217821191996336, -0.00018368464952800423, -3.981510963058099e-05, -3.4450891689630225e-05, -0.23600396513938904, -1.9238252639770508, -0.020107481628656387, -0.029560858383774757, -3.1134414672851562, -0.7117583751678467, -0.09532222896814346, -0.8052062392234802, -1.4671392440795898, -0.9204370379447937, -0.7153786420822144, -0.5682717561721802, -0.00045622908510267735, -0.037535082548856735, -0.3581753671169281, -1.868434190750122, -0.0016141016967594624, -0.039649851620197296, -2.113234043121338, -1.4602594375610352, -0.0012656782055273652, -2.3503048419952393, -0.0040525225922465324, -0.37706536054611206, -0.00023862851958256215, -2.2165887355804443, -3.4179296493530273, -1.8646721839904785, -0.6318536400794983, -2.7207894325256348, -2.589385986328125, -0.01794484257698059, -0.15452629327774048, -0.015237121842801571], "finish_reason": "stop"}, {"text": " save_path:", "tokens": [" save", "_", "path", ":", "\n"], "logprobs": [-0.021413324400782585, -3.397406908334233e-05, -1.311301275563892e-06, -0.44085198640823364, -0.0023758774623274803], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.007737545762211084, -0.0002461368858348578, -0.00026901919045485556, -0.008488881401717663, -7.033323527139146e-06, -5.960446742392378e-06, -0.1823538839817047, -0.005790601950138807], "finish_reason": "stop"}, {"text": "close()  # Closing the plot window to free resources", "tokens": ["close", "()", "  ", "#", " Cl", "osing", " the", " plot", " window", " to", " free", " resources", "\n"], "logprobs": [-0.16566996276378632, -0.11927590519189835, -2.6798672676086426, -0.001177928177639842, -1.7116113901138306, -0.24385744333267212, -0.06362777203321457, -0.3054567873477936, -2.599759340286255, -2.5350799560546875, -0.48339229822158813, -2.13891339302063, -0.13516783714294434], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.026130208745598793, -0.05527887120842934], "finish_reason": "stop"}, {"text": " Exception:", "tokens": [" Exception", ":", "\n"], "logprobs": [-1.0843709707260132, -2.0210306644439697, -0.012308591045439243], "finish_reason": "stop"}, {"text": " exc", "tokens": [" exc", "\n"], "logprobs": [-1.7766239643096924, -0.09854453057050705], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.015818819403648376, -0.050043076276779175, -0.014795340597629547, -0.0007351318490691483, -0.005333005916327238], "finish_reason": "stop"}, {"text": "\"An error occurred:\", type(e).__name__)", "tokens": ["\"", "An", " error", " occurred", ":\"", ",", " type", "(", "e", ")", ".", "__", "name", "__", ")", "\n"], "logprobs": [-1.0732307434082031, -0.6689733862876892, -0.14439690113067627, -0.029230257496237755, -0.29320141673088074, -0.12715493142604828, -1.8621922731399536, -8.427741704508662e-05, -0.006700902711600065, -0.04271770268678665, -1.1038793325424194, -0.00030214988510124385, -0.0003343261778354645, -0.00017927470616996288, -1.0611013174057007, -0.009805725887417793], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.016666581854224205, -1.3488261699676514, -4.768370445162873e-07, -1.9073468138230965e-06, -8.95221673999913e-05, -0.00026425207033753395, -0.1407316029071808], "finish_reason": "stop"}], "metrics": {"energy": 384.61869441795335, "energy_per_token": 1.7247475086006876, "time": 15.774193, "time_per_token": 0.07073629147982063}}
{"outputs": [{"text": " pd.read_csv(file_path, header=None)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ",", " header", "=", "None", ")", "\n"], "logprobs": [-0.005211459007114172, -0.00015066919149830937, -0.002838750835508108, -1.9430925021879375e-05, -0.0008761619683355093, -0.0005546461907215416, -0.0068722316063940525, -0.00018618757894728333, -2.8729025871143676e-05, -0.9013782739639282, -0.2783486843109131, -0.035412032157182693, -0.7336157560348511, -0.8750434517860413, -0.04929044470191002], "finish_reason": "stop"}, {"text": " CountVectorizer()", "tokens": [" Count", "Vector", "izer", "()", "\n"], "logprobs": [-0.00025733973598107696, -7.390948667307384e-06, -1.8715683836489916e-05, -2.4919846057891846, -0.021432459354400635], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.007516200188547373, -1.2040065485052764e-05, -5.769562994828448e-05, -0.0073884096927940845, -0.0005802616360597312, -9.285972191719338e-05, -0.00557309202849865, -0.01597416400909424, -0.46417200565338135, -0.0036741863004863262, -0.000556314189452678, -7.712543447269127e-05, -0.08612927794456482, -0.1846410036087036], "finish_reason": "stop"}, {"text": " sum(word_count.toarray())", "tokens": [" sum", "(", "word", "_", "count", ".", "to", "array", "())", "\n"], "logprobs": [-0.8483366370201111, -0.416681706905365, -0.12411947548389435, -0.012723341584205627, -0.001739775761961937, -0.00829323846846819, -0.2572093904018402, -0.0014672239776700735, -0.21113835275173187, -0.01477490272372961], "finish_reason": "stop"}, {"text": " {word: count/sum_words for word, count in word_count.toarray().flatten().tolist()}", "tokens": [" {", "word", ":", " count", "/", "sum", "_", "words", " for", " word", ",", " count", " in", " word", "_", "count", ".", "to", "array", "()", ".", "fl", "atten", "()", ".", "tol", "ist", "()}", "\n"], "logprobs": [-2.6436336040496826, -0.06897781789302826, -0.062484126538038254, -0.3354954123497009, -1.6468505859375, -0.01233343593776226, -0.004709936212748289, -0.00015698630886618048, -0.4180857539176941, -0.02118074707686901, -0.001206861576065421, -0.01559432689100504, -0.0022975020110607147, -0.6417039036750793, -4.625213477993384e-05, -6.353653589030728e-05, -0.02660346031188965, -0.045783232897520065, -0.03522699698805809, -0.20633135735988617, -0.0005258131423033774, -0.5770878195762634, -0.0013100859941914678, -0.35846295952796936, -0.0008032671175897121, -0.1376674473285675, -2.5152843591058627e-05, -0.0456010140478611, -0.006401272490620613], "finish_reason": "stop"}, {"text": "word, sum_words[word])", "tokens": ["word", ",", " sum", "_", "words", "[", "word", "])", "\n"], "logprobs": [-0.08009225875139236, -0.08765155076980591, -1.0357327461242676, -0.01883888617157936, -0.013143920339643955, -0.05358501151204109, -1.9520350694656372, -0.8531314730644226, -0.9863613843917847], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.07939847558736801, -0.0002366024418734014, -0.15147025883197784, -0.0011725700460374355, -6.842378934379667e-05, -0.002004520269110799, -0.015603246167302132, -0.0026610223576426506, -0.001786899520084262, -0.02384229563176632, -0.000388665939681232, -0.2362729012966156, -0.0061867390759289265, -0.002706676023080945, -0.020834404975175858, -0.00015364897262770683, -0.004692138638347387, -0.0004798214649781585, -0.0005397531786002219, -0.019588125869631767, -0.15992526710033417], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.35315343737602234, -8.511180931236595e-05, -3.325883881188929e-05, -0.2121513932943344, -0.016479920595884323, -0.003426634706556797, -0.0016739654820412397, -0.005132356658577919], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Frequency\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "F", "requency", "\"", "])", "\n"], "logprobs": [-0.017636850476264954, -0.00482169771566987, -0.002226256998255849, -0.07260310649871826, -0.14090795814990997, -6.735097849741578e-05, -9.059865078597795e-06, -0.05030281841754913, -0.024577094241976738, -0.045251864939928055, -0.005771401338279247, -0.22619208693504333, -0.005874985363334417, -0.000316212244797498, -0.0021645228844136, -0.5544859170913696, -0.07982143014669418, -0.004069500602781773, -0.004927159287035465, -0.03802293911576271], "finish_reason": "stop"}, {"text": " df_top.plot(x=\"Word\", y=\"Count\", kind=\"bar\", rot=0, legend=False)", "tokens": [" df", "_", "top", ".", "plot", "(", "x", "=", "\"", "Word", "\"", ",", " y", "=", "\"", "Count", "\"", ",", " kind", "=", "\"", "bar", "\"", ",", " rot", "=", "0", ",", " legend", "=", "False", ")", "\n"], "logprobs": [-0.20492011308670044, -0.0013066334649920464, -2.682172998902388e-05, -0.014016170054674149, -0.12100760638713837, -0.821442723274231, -1.2511012554168701, -0.0813392698764801, -0.0013469918631017208, -0.002915657591074705, -9.035655966727063e-05, -0.0008172033121809363, -0.04341959208250046, -0.002438668627291918, -0.00021002470748499036, -5.769562994828448e-05, -4.482168878894299e-05, -0.09025456756353378, -0.26622274518013, -0.031647615134716034, -0.00048780461656861007, -0.007634746376425028, -0.590004026889801, -0.46302926540374756, -0.9155515432357788, -0.0018867325270548463, -0.4953145384788513, -0.8880041837692261, -2.9152326583862305, -0.018193859606981277, -0.1602185219526291, -0.3125361204147339, -0.02987757883965969], "finish_reason": "stop"}, {"text": " save_path is not None:", "tokens": [" save", "_", "path", " is", " not", " None", ":", "\n"], "logprobs": [-0.021438410505652428, -4.0649541915627196e-05, -1.4305104514278355e-06, -0.9973032474517822, -0.17105799913406372, -1.9907753085135482e-05, -0.001259606215171516, -0.002375164069235325], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.008176307193934917, -0.00035065223346464336, -0.00027616979787126184, -0.007973271422088146, -9.894321920000948e-06, -5.722029527532868e-06, -0.1612055003643036, -0.007265100721269846], "finish_reason": "stop"}, {"text": "close(\"all\")", "tokens": ["close", "(", "\"", "all", "\"", ")", "\n"], "logprobs": [-0.19318875670433044, -2.558248281478882, -0.8514137268066406, -0.01353292167186737, -1.8000440832111053e-05, -4.017272294731811e-05, -0.07698723673820496], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.03159356117248535, -0.05345393344759941], "finish_reason": "stop"}, {"text": " FileNotFoundError as e:", "tokens": [" File", "NotFound", "Error", " as", " e", ":", "\n"], "logprobs": [-0.542400598526001, -2.729855441430118e-05, -5.245195097813848e-06, -0.28107452392578125, -0.47410985827445984, -0.0019902437925338745, -0.003965729381889105], "finish_reason": "stop"}, {"text": " exc", "tokens": [" exc", "\n"], "logprobs": [-1.836639642715454, -0.10523910820484161], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.014795223250985146, -0.04505428299307823, -0.014315642416477203, -0.0007936188485473394, -0.005371423903852701], "finish_reason": "stop"}, {"text": "\"An error occurred:\")", "tokens": ["\"", "An", " error", " occurred", ":\"", ")", "\n"], "logprobs": [-1.2434524297714233, -0.6486548781394958, -0.1860240250825882, -0.03011300228536129, -0.25086575746536255, -2.050772190093994, -0.0012548437807708979], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "\n"], "logprobs": [-0.01681370660662651, -1.036540150642395], "finish_reason": "stop"}], "metrics": {"energy": 415.6612680778506, "energy_per_token": 1.9606663588577857, "time": 17.02264, "time_per_token": 0.0802954716981132}}
{"outputs": [{"text": " pd.read_csv(file_path, header=None, index_col=0)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ",", " header", "=", "None", ",", " index", "_", "col", "=", "0", ")", "\n"], "logprobs": [-0.0051756445318460464, -0.00015817821258679032, -0.0030563806649297476, -1.7404405298293568e-05, -0.0009894242975860834, -0.0005026984144933522, -0.007219536229968071, -0.00020549570035655051, -3.075552376685664e-05, -0.8464361429214478, -0.2741415202617645, -0.045571401715278625, -0.6463140845298767, -0.5486842393875122, -2.73726224899292, -1.9073468138230965e-06, -0.00041500062798149884, -0.011323235929012299, -0.642920732498169, -0.2222936600446701, -0.03628290072083473], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ")", "\n"], "logprobs": [-0.00024101213784888387, -7.510157047363464e-06, -2.038458114839159e-05, -0.10417303442955017, -0.31459859013557434, -0.00022659118985757232, -7.986703712958843e-05, -0.09840549528598785, -0.029273556545376778, -3.576278118089249e-07, -0.014281092211604118, -6.556489552167477e-06, -5.364403477869928e-06, -1.8358061424805783e-05, -0.30865567922592163, -0.028454262763261795], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.007412667386233807, -1.3470558769768104e-05, -5.1020273531321436e-05, -0.007809937000274658, -0.0004557524516712874, -9.536288416711614e-05, -0.004932615906000137, -0.015450544655323029, -0.4377317726612091, -0.0031395689584314823, -0.0005110388156026602, -7.10462118149735e-05, -0.0849517434835434, -0.16938936710357666], "finish_reason": "stop"}, {"text": " np.sum(word_count.toarray(), axis=0)", "tokens": [" np", ".", "sum", "(", "word", "_", "count", ".", "to", "array", "()", ",", " axis", "=", "0", ")", "\n"], "logprobs": [-2.6744210720062256, -0.0003332536434754729, -0.6006401181221008, -0.00452518230304122, -0.013883211649954319, -6.794698856538162e-05, -0.0001284993631998077, -0.03661037236452103, -0.05047454684972763, -0.0004419303731992841, -1.3689887523651123, -0.00926575530320406, -0.048079151660203934, -0.004484714940190315, -0.02340989001095295, -0.0034732038620859385, -0.040638260543346405], "finish_reason": "stop"}, {"text": " (word_count.T / sum_words).round(2)", "tokens": [" (", "word", "_", "count", ".", "T", " /", " sum", "_", "words", ")", ".", "round", "(", "2", ")", "\n"], "logprobs": [-0.9528786540031433, -0.18393319845199585, -0.0006960591417737305, -6.41325386823155e-05, -0.1535467803478241, -0.19261087477207184, -0.016015460714697838, -0.008490418083965778, -0.00021753329201601446, -3.0874729418428615e-05, -0.033553555607795715, -0.1007503941655159, -0.5111918449401855, -0.032010551542043686, -0.37222084403038025, -0.002092316746711731, -0.14538437128067017], "finish_reason": "stop"}, {"text": "word, sum_words[i])", "tokens": ["word", ",", " sum", "_", "words", "[", "i", "])", "\n"], "logprobs": [-0.08325063437223434, -0.0983492061495781, -1.0093005895614624, -0.017093006521463394, -0.012399137020111084, -0.07635248452425003, -1.0163929462432861, -0.18110999464988708, -0.8229341506958008], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.07316900789737701, -0.0002493547508493066, -0.15899313986301422, -0.0012242449447512627, -5.829164365422912e-05, -0.0021357364021241665, -0.016978155821561813, -0.0029916076455265284, -0.001387705677188933, -0.0179170910269022, -0.0003916450368706137, -0.25626665353775024, -0.005838009063154459, -0.002643188228830695, -0.027486901730298996, -0.00017093151109293103, -0.005321385804563761, -0.0005411829333752394, -0.0004960260121151805, -0.01294742152094841, -0.14312046766281128], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.36949223279953003, -0.00010954733443213627, -2.932505594799295e-05, -0.20482367277145386, -0.01536262221634388, -0.0032277412246912718, -0.0013952055014669895, -0.0050082942470908165], "finish_reason": "stop"}, {"text": " pd.DataFrame(", "tokens": [" pd", ".", "DataFrame", "(", "\n"], "logprobs": [-0.018772203475236893, -0.003983065020292997, -0.002462571021169424, -0.07757525891065598, -2.573563814163208], "finish_reason": "stop"}, {"text": " df_top.plot.barh(x=\"Word\", y=\"Count\", title=\"Histogram of top 10 words\", legend=False, figsize=(8, 5), fontsize=8)", "tokens": [" df", "_", "top", ".", "plot", ".", "bar", "h", "(", "x", "=", "\"", "Word", "\"", ",", " y", "=", "\"", "Count", "\"", ",", " title", "=", "\"", "H", "ist", "ogram", " of", " top", " ", "1", "0", " words", "\"", ",", " legend", "=", "False", ",", " fig", "size", "=(", "8", ",", " ", "5", ")", ",", " fonts", "ize", "=", "8", ")", "\n"], "logprobs": [-0.1796094924211502, -0.0014416311169043183, -2.3245540432981215e-05, -0.014783477410674095, -0.12025687843561172, -0.6114706993103027, -0.0053063263185322285, -0.9483553171157837, -0.014435970224440098, -0.3551749885082245, -0.05873231217265129, -0.0014762704959139228, -0.01430906169116497, -6.854299135738984e-05, -0.002410603454336524, -0.06491591036319733, -0.0023048759903758764, -0.0001770101225702092, -5.304672595229931e-05, -3.0517112463712692e-05, -0.25914379954338074, -1.8779813051223755, -0.023215629160404205, -0.029845530167222023, -1.5741429328918457, -0.004900350235402584, -0.005233398173004389, -0.28811517357826233, -1.4986610412597656, -0.1987994909286499, -0.001611959422007203, -0.00039283663500100374, -0.1427241861820221, -0.23742403090000153, -0.7053772807121277, -1.8169200420379639, -0.00317308004014194, -0.04031840339303017, -1.059339165687561, -0.4495977461338043, -0.00040344204171560705, -0.0397285632789135, -1.5023574829101562, -0.009083022363483906, -0.056509532034397125, -1.9527602195739746, -1.6838678121566772, -0.002338652964681387, -1.83017897605896, -0.0003800861886702478, -0.022110266610980034, -1.3800030946731567, -0.18371984362602234, -0.009241778403520584], "finish_reason": "stop"}, {"text": " save_path is None:", "tokens": [" save", "_", "path", " is", " None", ":", "\n"], "logprobs": [-0.02149231545627117, -2.7894584491150454e-05, -1.1920922133867862e-06, -1.0439708232879639, -1.7755974531173706, -0.0003636414185166359, -0.005611856002360582], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.007109581492841244, -0.000278195773717016, -0.000276765669696033, -0.009617660194635391, -7.510157047363464e-06, -7.271740287251305e-06, -0.18593654036521912, -0.007440829649567604], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.21368379890918732, -0.10681669414043427, -0.07959236204624176], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.02761133760213852, -0.05207047984004021], "finish_reason": "stop"}, {"text": " FileNotFoundError as e:", "tokens": [" File", "NotFound", "Error", " as", " e", ":", "\n"], "logprobs": [-0.5554105639457703, -2.038458114839159e-05, -5.245195097813848e-06, -0.22073549032211304, -0.3835171163082123, -0.0020864878315478563, -0.003990901168435812], "finish_reason": "stop"}, {"text": " exc", "tokens": [" exc", "\n"], "logprobs": [-1.6135003566741943, -0.09328082948923111], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.016238098964095116, -0.07342834770679474, -0.013563617132604122, -0.0007693191873840988, -0.006335768382996321], "finish_reason": "stop"}, {"text": "f\"Error in function: {e}\")", "tokens": ["f", "\"", "Error", " in", " function", ":", " {", "e", "}\"", ")", "\n"], "logprobs": [-0.5560269355773926, -0.006321671884506941, -0.9990323185920715, -2.8344881534576416, -2.1627533435821533, -0.3225003778934479, -0.023083772510290146, -0.5562834143638611, -0.11146803945302963, -0.055680353194475174, -0.016503607854247093], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.01686704158782959, -1.1553564071655273, -3.576278118089249e-07, -1.4305104514278355e-06, -7.438383181579411e-05, -0.00025733973598107696, -0.13545668125152588], "finish_reason": "stop"}], "metrics": {"energy": 487.62163028812375, "energy_per_token": 2.0838531208894175, "time": 19.537663, "time_per_token": 0.08349428632478632}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.005211459007114172, -0.00015066919149830937, -0.002838750835508108, -1.9430925021879375e-05, -0.0008761619683355093, -0.0005546461907215416, -0.0068722316063940525, -0.00018618757894728333, -2.8729025871143676e-05, -0.5224968194961548, -0.025802770629525185], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS,", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ",", "\n"], "logprobs": [-0.00025817399728111923, -6.794906312279636e-06, -1.8358061424805783e-05, -0.0906127467751503, -0.2650561034679413, -0.000248401309363544, -7.343022298300639e-05, -0.11092213541269302, -0.037477556616067886, -4.768370445162873e-07, -0.015035162679851055, -8.22540732769994e-06, -5.602820692729438e-06, -1.7523612768854946e-05, -1.376414179801941, -2.5988879203796387], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.007707854732871056, -1.3112935448589269e-05, -5.328513361746445e-05, -0.010148354806005955, -0.0003936707798857242, -9.7508447652217e-05, -0.0057126120664179325, -0.021334325894713402, -0.4810216724872589, -0.004112122114747763, -0.0005335576133802533, -7.438383181579411e-05, -0.06843281537294388, -0.17909148335456848], "finish_reason": "stop"}, {"text": " word_count.sum()", "tokens": [" word", "_", "count", ".", "sum", "()", "\n"], "logprobs": [-0.8224682211875916, -0.00013505500101018697, -0.0003499372396618128, -0.0004558716027531773, -0.0403115339577198, -0.34441179037094116, -0.010761677287518978], "finish_reason": "stop"}, {"text": " (word_count / sum_words).round(2).astype(int)", "tokens": [" (", "word", "_", "count", " /", " sum", "_", "words", ")", ".", "round", "(", "2", ")", ".", "ast", "ype", "(", "int", ")", "\n"], "logprobs": [-0.884898841381073, -0.14328637719154358, -0.0008052920456975698, -5.0424259825376794e-05, -1.7829164266586304, -0.015915971249341965, -0.0006350646144710481, -3.313963316031732e-05, -0.055997252464294434, -0.10175971686840057, -0.7946507930755615, -0.060571104288101196, -0.4383451044559479, -0.002776222536340356, -1.0905725955963135, -1.3660131692886353, -2.4199192921514623e-05, -0.01121986098587513, -0.8712522387504578, -0.001081953989341855, -0.08101215958595276], "finish_reason": "stop"}, {"text": "word, sum_words[i]) for word, i in vectorizer.vocabulary_.items()", "tokens": ["word", ",", " sum", "_", "words", "[", "i", "])", " for", " word", ",", " i", " in", " vector", "izer", ".", "voc", "abulary", "_", ".", "items", "()", "\n"], "logprobs": [-0.07121250033378601, -0.08663717657327652, -1.0539638996124268, -0.017581213265657425, -0.011142411269247532, -0.06702267378568649, -1.0515186786651611, -0.17191238701343536, -0.5866175889968872, -0.016020270064473152, -0.004293628502637148, -0.0036206187214702368, -0.0023965705186128616, -0.06971011310815811, -8.702239938429557e-06, -7.64102369430475e-05, -0.05430596321821213, -0.007903139106929302, -0.00010013079008786008, -0.00017975145601667464, -0.0008351890719495714, -9.023735765367746e-05, -0.019841760396957397], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: -x[1])", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " -", "x", "[", "1", "])", "\n"], "logprobs": [-0.09132806211709976, -0.0002079985715681687, -0.14054755866527557, -0.0009017692063935101, -6.770858453819528e-05, -0.001895775320008397, -0.015208357013761997, -0.0030409307219088078, -0.001629097736440599, -0.016300730407238007, -0.0003736513026524335, -1.5770150423049927, -0.00544884754344821, -0.006131291389465332, -0.0004751745145767927, -0.002522384049370885, -0.14387322962284088], "finish_reason": "stop"}, {"text": " [word for word, _ in words_freq][:10]", "tokens": [" [", "word", " for", " word", ",", " _", " in", " words", "_", "freq", "][", ":", "1", "0", "]", "\n"], "logprobs": [-1.8810169696807861, -1.0351364612579346, -0.21737313270568848, -0.19593362510204315, -0.010009097866714, -0.5503402352333069, -0.0027545862831175327, -0.004523877054452896, -3.814624506048858e-05, -9.775113539944869e-06, -1.5353507995605469, -0.11761315912008286, -0.027418704703450203, -0.0027186835650354624, -0.0012401993153616786, -0.0048196809366345406], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Count\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "Count", "\"", "])", "\n"], "logprobs": [-0.017904797568917274, -0.003853278700262308, -0.0024182144552469254, -0.07455556839704514, -0.1530800461769104, -6.19869097135961e-05, -9.536697689327411e-06, -0.05693146586418152, -0.0253501757979393, -0.045893456786870956, -0.006981975864619017, -0.22539463639259338, -0.0055651492439210415, -0.0002516191452741623, -0.002079231198877096, -0.8854778409004211, -0.010048634372651577, -0.002913993550464511, -0.03285243362188339], "finish_reason": "stop"}, {"text": " plt.subplot()", "tokens": [" plt", ".", "sub", "plot", "()", "\n"], "logprobs": [-1.947965145111084, -0.0002618685248307884, -1.262026309967041, -0.39664632081985474, -0.4720876216888428, -0.01061000395566225], "finish_reason": "stop"}, {"text": " save_path is not None:", "tokens": [" save", "_", "path", " is", " not", " None", ":", "\n"], "logprobs": [-0.021561618894338608, -3.504691630951129e-05, -1.311301275563892e-06, -0.9974797964096069, -0.18489597737789154, -1.7165990357170813e-05, -0.0012055517872795463, -0.002111945068463683], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.010019956156611443, -0.0003741279651876539, -0.00022742546570952982, -0.008296784944832325, -8.4638240878121e-06, -6.198863957251888e-06, -0.18074381351470947, -0.005994911305606365], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.17736852169036865, -0.12264078110456467, -0.08782321214675903], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.025341110303997993, -0.05506137013435364], "finish_reason": "stop"}, {"text": " FileNotFoundError as e:", "tokens": [" File", "NotFound", "Error", " as", " e", ":", "\n"], "logprobs": [-0.587127149105072, -2.074220174108632e-05, -5.483612312673358e-06, -0.2416783720254898, -0.46160879731178284, -0.0021324055269360542, -0.004105829633772373], "finish_reason": "stop"}, {"text": " FileNotFoundError(", "tokens": [" File", "NotFound", "Error", "(", "\n"], "logprobs": [-0.20668596029281616, -0.0001255195093108341, -0.00017498392844572663, -0.025287993252277374, -1.0894588232040405], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.014707125723361969, -0.062195491045713425, -0.013997596688568592, -0.000734178873244673, -0.006199534051120281], "finish_reason": "stop"}, {"text": "\"Error occurred while processing the data:\", e)", "tokens": ["\"", "Error", " occurred", " while", " processing", " the", " data", ":\"", ",", " e", ")", "\n"], "logprobs": [-1.2124500274658203, -1.0851880311965942, -0.7972593903541565, -2.9937198162078857, -0.16856372356414795, -0.30651408433914185, -0.9596431851387024, -0.20863179862499237, -0.3351338803768158, -0.546124279499054, -0.09398013353347778, -0.009249219670891762], "finish_reason": "stop"}, {"text": " None", "tokens": [" None"], "logprobs": [-0.018351644277572632], "finish_reason": "stop"}], "metrics": {"energy": 359.45912975883476, "energy_per_token": 1.7883538793971878, "time": 15.13757, "time_per_token": 0.07531129353233831}}
{"outputs": [{"text": " pd.read_csv(file_path, header=0, dtype=str)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ",", " header", "=", "0", ",", " dtype", "=", "str", ")", "\n"], "logprobs": [-0.004559715278446674, -0.00019071667338721454, -0.0024027545005083084, -1.597391747054644e-05, -0.000821014866232872, -0.0005164004978723824, -0.007414560765028, -0.00024279984063468874, -3.182837463100441e-05, -0.8470054864883423, -0.26998797059059143, -0.0336461178958416, -0.6332752704620361, -0.7126103043556213, -1.8685325384140015, -0.27378377318382263, -0.10890477150678635, -0.23482348024845123, -0.04692690074443817], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words='english', token_pattern=r\"\\S+\")", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "='", "eng", "lish", "'", ",", " token", "_", "pattern", "=", "r", "\"", "\\", "S", "+", "\"", ")", "\n"], "logprobs": [-0.0002834395272657275, -6.318072337307967e-06, -2.002696055569686e-05, -0.0756838396191597, -0.2562394142150879, -0.00023588736075907946, -7.116541382856667e-05, -2.3640408515930176, -0.057373031973838806, -1.0967194612021558e-05, -1.0019464492797852, -0.0012406755704432726, -1.7155463695526123, -0.192240908741951, -0.03404716029763222, -0.2685208320617676, -0.30955252051353455, -0.7755330204963684, -0.3522926867008209, -2.656238317489624, -0.025689728558063507, -0.05446029454469681, -0.2265123575925827, -0.023629840463399887], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"].values.flatten()).toarray()", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "]", ".", "values", ".", "fl", "atten", "())", ".", "to", "array", "()", "\n"], "logprobs": [-0.006129751447588205, -1.0490362910786644e-05, -5.2569914259947836e-05, -0.01095047127455473, -0.0005297449533827603, -0.00011300401820335537, -0.00688703078776598, -0.01568528078496456, -0.4947921633720398, -0.0033527372870594263, -0.0005610798834823072, -6.925819616299123e-05, -2.5662739276885986, -0.007263206876814365, -0.6959534883499146, -1.8347618579864502, -1.4650731086730957, -7.033100700937212e-05, -0.0780920460820198, -1.350016474723816, -0.20392392575740814, -0.006522556766867638, -0.02002849616110325, -0.15059728920459747], "finish_reason": "stop"}, {"text": " sum([x.count(1) for x in word_count])", "tokens": [" sum", "([", "x", ".", "count", "(", "1", ")", " for", " x", " in", " word", "_", "count", "])", "\n"], "logprobs": [-0.7507991194725037, -1.0641800165176392, -2.1364736557006836, -0.8418453335762024, -1.2247657775878906, -0.19925299286842346, -0.5093422532081604, -0.002437717281281948, -0.004140614531934261, -0.0026223815511912107, -0.001404847833327949, -0.007890483364462852, -5.8530047681415454e-05, -2.7656173188006505e-05, -0.7043817043304443, -0.0235219094902277], "finish_reason": "stop"}, {"text": " word_count.toarray()", "tokens": [" word", "_", "count", ".", "to", "array", "()", "\n"], "logprobs": [-1.7447203397750854, -0.00015269544383045286, -2.9801878554280847e-05, -0.13555067777633667, -1.187188744544983, -0.006605338770896196, -0.01995476335287094, -2.789313793182373], "finish_reason": "stop"}, {"text": "word, sum_words[i]) for word, i in vectorizer.vocabulary_.items()", "tokens": ["word", ",", " sum", "_", "words", "[", "i", "])", " for", " word", ",", " i", " in", " vector", "izer", ".", "voc", "abulary", "_", ".", "items", "()", "\n"], "logprobs": [-0.0753774344921112, -0.11200107634067535, -0.9078878164291382, -0.01412713062018156, -0.012645772658288479, -0.061786867678165436, -1.0602428913116455, -0.19355277717113495, -0.673412561416626, -0.02955622784793377, -0.004850525874644518, -0.003771574702113867, -0.002608946058899164, -0.07070014625787735, -8.34461570775602e-06, -8.391981828026474e-05, -0.04336400330066681, -0.011883066035807133, -9.178694017464295e-05, -0.00019071667338721454, -0.0007474012672901154, -9.250213042832911e-05, -0.019014231860637665], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: -x[1])", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " -", "x", "[", "1", "])", "\n"], "logprobs": [-0.0767451599240303, -0.000228140561375767, -0.13340209424495697, -0.001206861576065421, -6.401333666872233e-05, -0.0019990478176623583, -0.018782615661621094, -0.0029569019097834826, -0.001632549217902124, -0.018841927871108055, -0.00036173476837575436, -1.2101755142211914, -0.006285422947257757, -0.007590381894260645, -0.0004451475979294628, -0.0019340872531756759, -0.16718041896820068], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.3329620659351349, -8.856858039507642e-05, -2.90866428258596e-05, -0.19081436097621918, -0.014794048853218555, -0.003367469646036625, -0.0015391181223094463, -0.004881369415670633], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Frequency\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "F", "requency", "\"", "])", "\n"], "logprobs": [-0.018607933074235916, -0.005692698527127504, -0.0022963127121329308, -0.06856182962656021, -0.1419370472431183, -7.331102824537084e-05, -7.152531907195225e-06, -0.054136134684085846, -0.022196199744939804, -0.04183230176568031, -0.00673760985955596, -0.2757030725479126, -0.006018610205501318, -0.00023338454775512218, -0.002034857403486967, -0.5665997862815857, -0.09080152958631516, -0.004023315384984016, -0.00456624198704958, -0.04020389914512634], "finish_reason": "stop"}, {"text": " df_top.plot(kind=\"barh\", figsize=(15, 10), rot=90, x=\"Word\", y=\"Count\")", "tokens": [" df", "_", "top", ".", "plot", "(", "kind", "=", "\"", "bar", "h", "\"", ",", " fig", "size", "=(", "1", "5", ",", " ", "1", "0", ")", ",", " rot", "=", "9", "0", ",", " x", "=", "\"", "Word", "\"", ",", " y", "=", "\"", "Count", "\"", ")", "\n"], "logprobs": [-0.18365228176116943, -0.0010162194957956672, -1.883488948806189e-05, -0.01286998763680458, -0.1234564259648323, -0.6849244236946106, -0.6181642413139343, -0.18739517033100128, -0.00025054652360267937, -0.010264582931995392, -0.1949731707572937, -0.00010382589971413836, -0.05442507192492485, -1.098747730255127, -0.00017033556650858372, -0.033386968076229095, -0.3862507939338684, -1.945164442062378, -0.0019219514215365052, -0.046502772718667984, -1.5729598999023438, -0.33230099081993103, -0.5157476663589478, -0.00012838016846217215, -1.865213394165039, -0.0028335205279290676, -0.37822970747947693, -0.00044204952428117394, -1.0622141361236572, -2.6905417442321777, -0.2050839364528656, -0.0026135831139981747, -0.04871745407581329, -0.00019667598826345056, -0.028591901063919067, -0.05149749666452408, -0.0024367659352719784, -0.0003923600015696138, -8.570780482841656e-05, -6.365573790390044e-05, -0.42060551047325134, -0.013299562968313694], "finish_reason": "stop"}, {"text": " save_path is not None:", "tokens": [" save", "_", "path", " is", " not", " None", ":", "\n"], "logprobs": [-0.0216151662170887, -3.218599158572033e-05, -1.4305104514278355e-06, -1.041862964630127, -0.19683557748794556, -2.13382354559144e-05, -0.0011582816950976849, -0.002005472080782056], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.00838462170213461, -0.0002648479712661356, -0.0002503081923350692, -0.009108302183449268, -5.602820692729438e-06, -6.556489552167477e-06, -0.1848379224538803, -0.007154085673391819], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.1947929710149765, -0.09633032977581024, -0.08333903551101685], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.03338996693491936, -0.053784530609846115], "finish_reason": "stop"}, {"text": " FileNotFoundError:", "tokens": [" File", "NotFound", "Error", ":", "\n"], "logprobs": [-0.6063179969787598, -2.8013790142722428e-05, -6.556489552167477e-06, -1.5771384239196777, -0.008696657605469227], "finish_reason": "stop"}, {"text": " FileNotFoundError(", "tokens": [" File", "NotFound", "Error", "(", "\n"], "logprobs": [-0.25000911951065063, -0.00015710550360381603, -0.0002650863316375762, -0.02279483899474144, -1.2625937461853027], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.01616467349231243, -0.04975093901157379, -0.012365697883069515, -0.0006450717919506133, -0.0051985327154397964], "finish_reason": "stop"}, {"text": "f\"Error occurred: {str(e)}\")", "tokens": ["f", "\"", "Error", " occurred", ":", " {", "str", "(", "e", ")}", "\"", ")", "\n"], "logprobs": [-0.4469797611236572, -0.006509765516966581, -0.8539493083953857, -1.0438462495803833, -0.24855828285217285, -0.006166953593492508, -1.656787633895874, -8.380061626667157e-05, -0.04009075462818146, -0.02819921262562275, -0.01701940968632698, -0.051721204072237015, -0.0139521025121212], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "<", "|", "end", "of", "text", "|>"], "logprobs": [-0.01700042374432087, -1.1834584474563599, -4.768370445162873e-07, -1.7881377516459906e-06, -0.00011038171214750037, -0.0003051292151212692, -0.12857916951179504], "finish_reason": "stop"}], "metrics": {"energy": 444.74604922580716, "energy_per_token": 1.7305293744194832, "time": 17.595566, "time_per_token": 0.0684652373540856}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.0051756445318460464, -0.00015817821258679032, -0.0030563806649297476, -1.7404405298293568e-05, -0.0009894242975860834, -0.0005026984144933522, -0.007219536229968071, -0.00020549570035655051, -3.075552376685664e-05, -0.5617414712905884, -0.028226330876350403], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ")", "\n"], "logprobs": [-0.0002455409849062562, -8.4638240878121e-06, -2.074220174108632e-05, -0.0847858414053917, -0.28072643280029297, -0.00033146608620882034, -7.760223525110632e-05, -0.11030589789152145, -0.03700379282236099, -3.576278118089249e-07, -0.013025437481701374, -6.9141146923357155e-06, -4.768360213347478e-06, -1.6569954823353328e-05, -0.30473288893699646, -0.027390984818339348], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.006867851130664349, -1.0847986231965479e-05, -5.328513361746445e-05, -0.007971142418682575, -0.00041059168870560825, -0.0001045410826918669, -0.005309409461915493, -0.019272103905677795, -0.5632238388061523, -0.0028594343457370996, -0.0006070678355172276, -6.12716976320371e-05, -0.07140597701072693, -0.18828915059566498], "finish_reason": "stop"}, {"text": " word_count.sum(axis=0).toarray()", "tokens": [" word", "_", "count", ".", "sum", "(", "axis", "=", "0", ")", ".", "to", "array", "()", "\n"], "logprobs": [-0.7786545753479004, -0.00012063252506777644, -0.00026663561584427953, -0.0005869334563612938, -0.0395544059574604, -1.2145190238952637, -0.0016281455755233765, -0.0028225842397660017, -0.13119231164455414, -0.00714473519474268, -1.9685869216918945, -0.35084301233291626, -0.22176530957221985, -0.1251121163368225, -0.3189348876476288], "finish_reason": "stop"}, {"text": " 100 / sum_words[0] * word_count.T", "tokens": [" ", "1", "0", "0", " /", " sum", "_", "words", "[", "0", "]", " *", " word", "_", "count", ".", "T", "\n"], "logprobs": [-2.9827651977539062, -0.05104970186948776, -0.04856507107615471, -0.07680488377809525, -1.647655725479126, -0.28471699357032776, -0.002054605633020401, -2.169585604860913e-05, -2.3038723468780518, -0.1309831738471985, -0.003810527501627803, -2.0750958919525146, -0.09469413012266159, -8.666139910928905e-05, -3.516612196108326e-05, -0.31838080286979675, -1.594273328781128, -0.4529188871383667], "finish_reason": "stop"}, {"text": "word, count / sum_words)", "tokens": ["word", ",", " count", " /", " sum", "_", "words", ")", "\n"], "logprobs": [-0.06549644470214844, -0.11040443181991577, -1.137340784072876, -0.9159810543060303, -0.09049786627292633, -0.003791407449170947, -0.000302030734019354, -1.6275309324264526, -0.7926334738731384], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.07977993786334991, -0.0002051381452474743, -0.1251952201128006, -0.001167331007309258, -5.185469490243122e-05, -0.0018816161900758743, -0.019435914233326912, -0.0024645926896482706, -0.0013948483392596245, -0.021907124668359756, -0.0003303935518488288, -0.26532110571861267, -0.004238788038492203, -0.002925998531281948, -0.025348084047436714, -0.0001472126314183697, -0.005079934373497963, -0.0004766043566633016, -0.0004731489170808345, -0.017294200137257576, -0.18700547516345978], "finish_reason": "stop"}, {"text": " [", "tokens": [" [", "\n"], "logprobs": [-2.002209424972534, -1.2042230367660522], "finish_reason": "stop"}, {"text": " pd.DataFrame(", "tokens": [" pd", ".", "DataFrame", "(", "\n"], "logprobs": [-0.019018908962607384, -0.005001296289265156, -0.002387532265856862, -0.07941268384456635, -3.0082805156707764], "finish_reason": "stop"}, {"text": " df_top.plot(", "tokens": [" df", "_", "top", ".", "plot", "(", "\n"], "logprobs": [-0.20740672945976257, -0.0013633014168590307, -2.312633478140924e-05, -0.014658374711871147, -0.10454634577035904, -0.7677015662193298, -1.723451852798462], "finish_reason": "stop"}, {"text": " save_path:", "tokens": [" save", "_", "path", ":", "\n"], "logprobs": [-0.02170475758612156, -3.504691630951129e-05, -1.0728830375228426e-06, -0.5336366295814514, -0.0027367540169507265], "finish_reason": "stop"}, {"text": "savefig(save_path, dpi=300, bbox_inches=\"tight\", transparent=False)", "tokens": ["save", "fig", "(", "save", "_", "path", ",", " d", "pi", "=", "3", "0", "0", ",", " b", "box", "_", "in", "ches", "=", "\"", "tight", "\"", ",", " transparent", "=", "False", ")", "\n"], "logprobs": [-0.008862210437655449, -0.00031895318534225225, -0.0002814135223161429, -0.009458019398152828, -6.6756979322235566e-06, -6.437280717364047e-06, -1.9508644342422485, -1.5851919651031494, -0.00012146688823122531, -0.0012724645202979445, -0.5160109400749207, -0.006022402085363865, -0.0009738231892697513, -1.1333777904510498, -0.13687288761138916, -0.0004905451205559075, -0.00047743841423653066, -0.00016616393986623734, -0.002157623879611492, -0.09541574865579605, -0.005330279003828764, -0.003007058519870043, -3.40932747349143e-05, -1.5190268754959106, -0.5306731462478638, -0.0005471401382237673, -2.821817636489868, -0.16116127371788025, -0.008129602298140526], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.20785634219646454, -0.10194382071495056, -0.08525019884109497], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.02558213472366333, -0.05830371752381325], "finish_reason": "stop"}, {"text": " FileNotFoundError:", "tokens": [" File", "NotFound", "Error", ":", "\n"], "logprobs": [-0.5994403958320618, -2.5152843591058627e-05, -6.079655122448457e-06, -1.5990307331085205, -0.009763581678271294], "finish_reason": "stop"}, {"text": " FileNotFoundError(str(exc)) from exc", "tokens": [" File", "NotFound", "Error", "(", "str", "(", "exc", "))", " from", " exc", "\n"], "logprobs": [-0.28444212675094604, -0.00014304091746453196, -0.00021765247220173478, -0.02384764887392521, -2.1356658935546875, -0.0005791893927380443, -0.019025225192308426, -0.11710420995950699, -0.9650256633758545, -0.15122997760772705, -0.01580626517534256], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.013440478593111038, -0.058991946280002594, -0.01285245269536972, -0.0007220283732749522, -0.004939970560371876], "finish_reason": "stop"}, {"text": "\"An unexpected error occurred: \", e)", "tokens": ["\"", "An", " unexpected", " error", " occurred", ":", " \"", ",", " e", ")", "\n"], "logprobs": [-1.2968666553497314, -0.7739092111587524, -2.0274674892425537, -0.007021395489573479, -0.08968158066272736, -2.4791605472564697, -0.11548766493797302, -0.046275388449430466, -0.4412515461444855, -0.11781015992164612, -0.010574618354439735], "finish_reason": "stop"}, {"text": " None", "tokens": [" None"], "logprobs": [-0.020444029942154884], "finish_reason": "stop"}], "metrics": {"energy": 397.51427618217446, "energy_per_token": 2.0921804009588127, "time": 15.333812, "time_per_token": 0.08070427368421053}}
{"outputs": [{"text": " pd.read_csv(file_path, header=0, dtype=str)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ",", " header", "=", "0", ",", " dtype", "=", "str", ")", "\n"], "logprobs": [-0.005211459007114172, -0.00015066919149830937, -0.002838750835508108, -1.9430925021879375e-05, -0.0008761619683355093, -0.0005546461907215416, -0.0068722316063940525, -0.00018618757894728333, -2.8729025871143676e-05, -0.9013782739639282, -0.2783486843109131, -0.035412032157182693, -0.6836928129196167, -0.7140761017799377, -1.908179521560669, -0.27699896693229675, -0.10050202906131744, -0.2570546865463257, -0.04218139126896858], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ")", "\n"], "logprobs": [-0.00025733973598107696, -7.390948667307384e-06, -1.8715683836489916e-05, -0.08696091920137405, -0.3014380633831024, -0.00029023250681348145, -6.818538531661034e-05, -0.11813434958457947, -0.0442926399409771, -3.576278118089249e-07, -0.011576265096664429, -8.106198947643861e-06, -6.318072337307967e-06, -1.9788545614574105e-05, -0.26670336723327637, -0.03259088471531868], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"].tolist()).toarray()", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "]", ".", "tol", "ist", "())", ".", "to", "array", "()", "\n"], "logprobs": [-0.007937082089483738, -1.2874520507466514e-05, -7.080780778778717e-05, -0.00997652392834425, -0.0005166388000361621, -9.798523387871683e-05, -0.006202259100973606, -0.014834336005151272, -0.5505146384239197, -0.00348912226036191, -0.0005469018360599875, -7.199982064776123e-05, -2.573197841644287, -0.007242022547870874, -1.3072266578674316, -6.556489552167477e-06, -0.003089775564149022, -2.2380123138427734, -0.17413605749607086, -0.0038934156764298677, -0.02505584992468357, -0.062305379658937454], "finish_reason": "stop"}, {"text": " word_count.sum()", "tokens": [" word", "_", "count", ".", "sum", "()", "\n"], "logprobs": [-0.7861963510513306, -0.00012790338951162994, -0.00026782741770148277, -0.00045217780279926956, -0.036573365330696106, -0.40970614552497864, -0.010213255882263184], "finish_reason": "stop"}, {"text": " word_count.transpose().T / sum_words", "tokens": [" word", "_", "count", ".", "trans", "pose", "()", ".", "T", " /", " sum", "_", "words", "\n"], "logprobs": [-1.5909650325775146, -0.00012170527770649642, -2.706014311115723e-05, -0.09965276718139648, -3.5355570316314697, -0.0006772369961254299, -0.0015826807357370853, -0.19957897067070007, -1.886916160583496, -0.6452381610870361, -0.03571586310863495, -0.001446868758648634, -6.4490144723095e-05, -0.1816081702709198], "finish_reason": "stop"}, {"text": "word, sum_words[word])", "tokens": ["word", ",", " sum", "_", "words", "[", "word", "])", "\n"], "logprobs": [-0.07486798614263535, -0.08037874847650528, -0.9008099436759949, -0.012030188925564289, -0.010757314041256905, -0.05277477204799652, -1.9323376417160034, -0.7265101671218872, -0.9641832113265991], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.07673268020153046, -0.00024029705673456192, -0.19099509716033936, -0.0011264891363680363, -4.649054244509898e-05, -0.0022467151284217834, -0.01679178513586521, -0.0029900625813752413, -0.001517931348644197, -0.01795339025557041, -0.00031990656862035394, -0.2981882691383362, -0.005734302569180727, -0.002556153805926442, -0.02059725485742092, -0.00016616393986623734, -0.005092269275337458, -0.00043072958942502737, -0.0005472592893056571, -0.01520553883165121, -0.1788020133972168], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.2734663188457489, -0.00011634149996098131, -3.4689302992774174e-05, -0.23384854197502136, -0.014214927330613136, -0.0036042272113263607, -0.0015073377871885896, -0.004862507339566946], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"word\", \"frequency\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "word", "\"", ",", " \"", "frequency", "\"", "])", "\n"], "logprobs": [-0.018115894868969917, -0.004024384077638388, -0.0022128161508589983, -0.07620271295309067, -0.13358139991760254, -7.331102824537084e-05, -6.794906312279636e-06, -0.05723952502012253, -0.030109301209449768, -0.040798380970954895, -0.006746490485966206, -2.5939760208129883, -0.008835860528051853, -0.000442407006630674, -0.0023474537301808596, -1.0824344158172607, -0.0041801463812589645, -0.0049128057435154915, -0.035339079797267914], "finish_reason": "stop"}, {"text": " df_top.plot.bar(x=\"Word\", y=\"Count\")", "tokens": [" df", "_", "top", ".", "plot", ".", "bar", "(", "x", "=", "\"", "Word", "\"", ",", " y", "=", "\"", "Count", "\"", ")", "\n"], "logprobs": [-0.17336444556713104, -0.001259010867215693, -2.7417760065873154e-05, -0.011462898924946785, -0.11326748877763748, -0.6075191497802734, -0.004069856833666563, -0.5174161791801453, -0.42076706886291504, -0.15108823776245117, -0.0011707840021699667, -0.0007713441736996174, -9.667406266089529e-05, -0.0037781065329909325, -0.03544332832098007, -0.0024619766045361757, -0.0001461399078834802, -5.030505417380482e-05, -4.2437604861333966e-05, -1.527301549911499, -0.015573552809655666], "finish_reason": "stop"}, {"text": " save_path:", "tokens": [" save", "_", "path", ":", "\n"], "logprobs": [-0.025223249569535255, -3.158996332786046e-05, -1.311301275563892e-06, -0.3937705159187317, -0.002614177530631423], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.007641607895493507, -0.0002936885575763881, -0.00023910524032544345, -0.008741091936826706, -7.390948667307384e-06, -5.722029527532868e-06, -0.14143432676792145, -0.006426264997571707], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.20081248879432678, -0.0998954102396965, -0.07469940185546875], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.031233707442879677, -0.04804438352584839], "finish_reason": "stop"}, {"text": " FileNotFoundError as e:", "tokens": [" File", "NotFound", "Error", " as", " e", ":", "\n"], "logprobs": [-0.6309665441513062, -2.932505594799295e-05, -6.079655122448457e-06, -0.2345159649848938, -0.4460035562515259, -0.0023057085927575827, -0.003207778325304389], "finish_reason": "stop"}, {"text": " FileNotFoundError(", "tokens": [" File", "NotFound", "Error", "(", "\n"], "logprobs": [-0.3025788962841034, -0.0001429217227268964, -0.00017617580306250602, -0.026752959936857224, -1.265272617340088], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.014469457790255547, -0.06998580694198608, -0.01374365109950304, -0.0006967739318497479, -0.00679823337122798], "finish_reason": "stop"}, {"text": "f\"Exception: {e}\")", "tokens": ["f", "\"", "Exception", ":", " {", "e", "}\"", ")", "\n"], "logprobs": [-0.4776667058467865, -0.005958531983196735, -2.328701972961426, -1.513670802116394, -0.007767236325889826, -0.37458792328834534, -0.08194351941347122, -0.03371066227555275, -0.009771727956831455], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "\n"], "logprobs": [-0.017550993710756302, -0.8561758995056152], "finish_reason": "stop"}], "metrics": {"energy": 394.8708759403231, "energy_per_token": 1.954806316536253, "time": 15.32219, "time_per_token": 0.07585242574257427}}
{"outputs": [{"text": " pd.read_csv(file_path, header=0)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ",", " header", "=", "0", ")", "\n"], "logprobs": [-0.004559715278446674, -0.00019071667338721454, -0.0024027545005083084, -1.597391747054644e-05, -0.000821014866232872, -0.0005164004978723824, -0.007414560765028, -0.00024279984063468874, -3.182837463100441e-05, -0.8470054864883423, -0.26998797059059143, -0.0336461178958416, -0.6332752704620361, -0.6914120316505432, -0.06989932805299759], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words='english')", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "='", "eng", "lish", "')", "\n"], "logprobs": [-0.0002834395272657275, -6.318072337307967e-06, -2.002696055569686e-05, -0.0756838396191597, -0.2562394142150879, -0.00023588736075907946, -7.116541382856667e-05, -2.3640408515930176, -0.057373031973838806, -1.0967194612021558e-05, -0.4578542411327362, -0.037490300834178925], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.006129751447588205, -1.0490362910786644e-05, -5.2569914259947836e-05, -0.01095047127455473, -0.0005297449533827603, -0.00011300401820335537, -0.00688703078776598, -0.01568528078496456, -0.4947921633720398, -0.0033527372870594263, -0.0005610798834823072, -6.925819616299123e-05, -0.08246727287769318, -0.20191991329193115], "finish_reason": "stop"}, {"text": " sum([i.count(1) for i in word_count.toarray()])", "tokens": [" sum", "([", "i", ".", "count", "(", "1", ")", " for", " i", " in", " word", "_", "count", ".", "to", "array", "()", "])", "\n"], "logprobs": [-0.8294459581375122, -1.0115940570831299, -2.5131516456604004, -0.4376319646835327, -0.7876916527748108, -0.3353978991508484, -0.37266963720321655, -0.002310941694304347, -0.006059608422219753, -0.0032599421683698893, -0.0015328098088502884, -0.012014876119792461, -3.731181277544238e-05, -2.8967437174287625e-05, -0.5291537642478943, -0.2428910881280899, -0.002946917898952961, -0.0026605469174683094, -0.021817201748490334, -0.025611532852053642], "finish_reason": "stop"}, {"text": " word_count.multiply(1.0 / sum_words, axis=0)", "tokens": [" word", "_", "count", ".", "multip", "ly", "(", "1", ".", "0", " /", " sum", "_", "words", ",", " axis", "=", "0", ")", "\n"], "logprobs": [-1.721975564956665, -0.00010585224663373083, -3.4450891689630225e-05, -0.15907062590122223, -2.252120018005371, -0.011639541015028954, -0.007683722302317619, -0.038560450077056885, -2.339245557785034, -0.22974394261837006, -0.04224230349063873, -0.01724616065621376, -0.0003971264814026654, -1.0251946150674485e-05, -0.6532328128814697, -0.008379420265555382, -0.006105699576437473, -0.0373627245426178, -0.006546124815940857, -0.13596709072589874], "finish_reason": "stop"}, {"text": "word, count)", "tokens": ["word", ",", " count", ")", "\n"], "logprobs": [-0.07622579485177994, -0.08666089922189713, -1.2347187995910645, -0.7482860684394836, -0.8222681283950806], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.0694119855761528, -0.0002325502864550799, -0.1883930265903473, -0.0009575072908774018, -4.8993817472364753e-05, -0.002020343439653516, -0.015558529645204544, -0.0030074152164161205, -0.0016914597945287824, -0.01889375038444996, -0.0003051292151212692, -0.251558780670166, -0.004227986093610525, -0.0024176198057830334, -0.021141648292541504, -0.00013886917440686375, -0.004367456305772066, -0.0005770448478870094, -0.0005569098866544664, -0.01469855010509491, -0.16231396794319153], "finish_reason": "stop"}, {"text": " words_freq[0:10]", "tokens": [" words", "_", "freq", "[", "0", ":", "1", "0", "]", "\n"], "logprobs": [-0.30769890546798706, -0.0001267114421352744, -3.671578815556131e-05, -1.535880208015442, -0.0429103821516037, -0.026453126221895218, -0.01971541903913021, -0.00529031828045845, -0.0020722122862935066, -0.004902959801256657], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Frequency\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "F", "requency", "\"", "])", "\n"], "logprobs": [-0.018217623233795166, -0.00459578912705183, -0.0021188445389270782, -0.0849713459610939, -0.1676090657711029, -6.139089964563027e-05, -8.34461570775602e-06, -0.05025849491357803, -0.024638159200549126, -0.042697370052337646, -0.007837969809770584, -0.2438891977071762, -0.005634734407067299, -0.0002526917669456452, -0.0019512200960889459, -0.6088225245475769, -0.07933956384658813, -0.003744734451174736, -0.004624505061656237, -0.036190927028656006], "finish_reason": "stop"}, {"text": " df_top.plot.barh(", "tokens": [" df", "_", "top", ".", "plot", ".", "bar", "h", "(", "\n"], "logprobs": [-0.15823203325271606, -0.0010587330907583237, -2.2411095415009186e-05, -0.015961259603500366, -0.1295647770166397, -0.6277674436569214, -0.00456897122785449, -1.0609681606292725, -0.013639233075082302, -2.3113882541656494], "finish_reason": "stop"}, {"text": " save_path is not None:", "tokens": [" save", "_", "path", " is", " not", " None", ":", "\n"], "logprobs": [-0.021631382405757904, -3.5523738915799186e-05, -1.1920922133867862e-06, -0.9767798185348511, -0.2053963840007782, -2.3603161025675945e-05, -0.0010968389688059688, -0.0018635302549228072], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.007345454301685095, -0.0003240775258745998, -0.0002553137019276619, -0.009093417786061764, -8.106198947643861e-06, -7.390948667307384e-06, -0.1826569139957428, -0.006070627830922604], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.1676536351442337, -0.09181658178567886, -0.07247117906808853], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.034102924168109894, -0.05698484182357788], "finish_reason": "stop"}, {"text": " Exception as e:", "tokens": [" Exception", " as", " e", ":", "\n"], "logprobs": [-1.0931951999664307, -0.1893855631351471, -0.22490011155605316, -0.00038044367101974785, -0.006519713904708624], "finish_reason": "stop"}, {"text": " FileNotFoundError(", "tokens": [" File", "NotFound", "Error", "(", "\n"], "logprobs": [-0.24012154340744019, -0.00013386306818574667, -0.00018475732940714806, -0.023780250921845436, -1.2485246658325195], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.015436106361448765, -0.05378611013293266, -0.010458661243319511, -0.0007588367443531752, -0.006872350350022316], "finish_reason": "stop"}, {"text": "f\"Unexpected error: {str(e)}\")", "tokens": ["f", "\"", "U", "nexpected", " error", ":", " {", "str", "(", "e", ")}", "\"", ")", "\n"], "logprobs": [-0.5263735055923462, -0.0053785378113389015, -2.6768598556518555, -0.0634351298213005, -0.053591903299093246, -0.13095222413539886, -0.004145837854593992, -1.979758620262146, -0.00010013079008786008, -0.020434102043509483, -0.025179194286465645, -0.014904570765793324, -0.0653407871723175, -0.018337832763791084], "finish_reason": "stop"}, {"text": " None", "tokens": [" None"], "logprobs": [-0.018690772354602814], "finish_reason": "stop"}], "metrics": {"energy": 386.1845996894836, "energy_per_token": 1.950427271159008, "time": 15.324851, "time_per_token": 0.07739823737373738}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.0051756445318460464, -0.00015817821258679032, -0.0030563806649297476, -1.7404405298293568e-05, -0.0009894242975860834, -0.0005026984144933522, -0.007219536229968071, -0.00020549570035655051, -3.075552376685664e-05, -0.5617414712905884, -0.028226330876350403], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ")", "\n"], "logprobs": [-0.0002455409849062562, -8.4638240878121e-06, -2.074220174108632e-05, -0.0847858414053917, -0.28072643280029297, -0.00033146608620882034, -7.760223525110632e-05, -0.11030589789152145, -0.03700379282236099, -3.576278118089249e-07, -0.013025437481701374, -6.9141146923357155e-06, -4.768360213347478e-06, -1.6569954823353328e-05, -0.30473288893699646, -0.027390984818339348], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.006867851130664349, -1.0847986231965479e-05, -5.328513361746445e-05, -0.007971142418682575, -0.00041059168870560825, -0.0001045410826918669, -0.005309409461915493, -0.019272103905677795, -0.5632238388061523, -0.0028594343457370996, -0.0006070678355172276, -6.12716976320371e-05, -0.07140597701072693, -0.18828915059566498], "finish_reason": "stop"}, {"text": " word_count.sum()", "tokens": [" word", "_", "count", ".", "sum", "()", "\n"], "logprobs": [-0.7786545753479004, -0.00012063252506777644, -0.00026663561584427953, -0.0005869334563612938, -0.0395544059574604, -0.35370972752571106, -0.010386107489466667], "finish_reason": "stop"}, {"text": " word_count.toarray() / sum_words.astype(float)", "tokens": [" word", "_", "count", ".", "to", "array", "()", " /", " sum", "_", "words", ".", "ast", "ype", "(", "float", ")", "\n"], "logprobs": [-1.6756479740142822, -9.321732068201527e-05, -3.349725011503324e-05, -0.13533632457256317, -1.1830099821090698, -0.007727018091827631, -0.02409392222762108, -0.5597215890884399, -0.03941609337925911, -0.002190335188060999, -3.099393507000059e-05, -1.4351719617843628, -0.8777446746826172, -7.676783570786938e-05, -0.0688227042555809, -0.859696090221405, -0.0045617325231432915, -0.03085372969508171], "finish_reason": "stop"}, {"text": "word, sum_words[i]) for word, i in vectorizer.vocabulary_.items()", "tokens": ["word", ",", " sum", "_", "words", "[", "i", "])", " for", " word", ",", " i", " in", " vector", "izer", ".", "voc", "abulary", "_", ".", "items", "()", "\n"], "logprobs": [-0.06571336090564728, -0.0990523248910904, -1.0405861139297485, -0.02077089063823223, -0.014679402112960815, -0.05219155550003052, -0.9328175187110901, -0.21487706899642944, -0.6380236744880676, -0.024192018434405327, -0.00356704811565578, -0.0036336842458695173, -0.002664113650098443, -0.08630862832069397, -8.940656698541716e-06, -8.21318244561553e-05, -0.04183138906955719, -0.009946898557245731, -8.11782301752828e-05, -0.00017307691450696439, -0.0010481346398591995, -9.047575440490618e-05, -0.018495243042707443], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.07642725855112076, -0.00021526881027966738, -0.19263969361782074, -0.0010846928926184773, -5.2569914259947836e-05, -0.002003211760893464, -0.01574113965034485, -0.0028292411006987095, -0.0015194787411019206, -0.017095936462283134, -0.00037353215157054365, -0.29643478989601135, -0.005501724313944578, -0.0022448119707405567, -0.02505050227046013, -0.0001463782973587513, -0.00438134279102087, -0.0004303721070755273, -0.0005133026279509068, -0.01485453825443983, -0.16889391839504242], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.3052539825439453, -0.00011812942830147222, -3.635817120084539e-05, -0.17862744629383087, -0.016753101721405983, -0.0032765772193670273, -0.001358896610327065, -0.003986745607107878], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Count\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "Count", "\"", "])", "\n"], "logprobs": [-0.01768428459763527, -0.004958712495863438, -0.0025952726136893034, -0.07558227330446243, -0.1167067140340805, -8.034383063204587e-05, -8.583032467868179e-06, -0.06348782777786255, -0.02038527838885784, -0.04506533592939377, -0.0058125280775129795, -0.22568586468696594, -0.006138992961496115, -0.0002029928145930171, -0.0019334923708811402, -0.9725450277328491, -0.012155503034591675, -0.003336816793307662, -0.04420767351984978], "finish_reason": "stop"}, {"text": " df_top.plot.bar(x=\"Word\", y=\"Count\", rot=90)", "tokens": [" df", "_", "top", ".", "plot", ".", "bar", "(", "x", "=", "\"", "Word", "\"", ",", " y", "=", "\"", "Count", "\"", ",", " rot", "=", "9", "0", ")", "\n"], "logprobs": [-0.18736492097377777, -0.0011849532602354884, -2.4318398573086597e-05, -0.016927873715758324, -0.11750219017267227, -0.6665576100349426, -0.0062760645523667336, -0.5025431513786316, -0.4645461440086365, -0.13843606412410736, -0.001057184999808669, -0.0007825411157682538, -8.809178689261898e-05, -0.0037763251457363367, -0.02962207980453968, -0.002668155822902918, -0.000125281119835563, -5.4238757002167404e-05, -4.160317621426657e-05, -0.19716519117355347, -0.5909973978996277, -0.003337767207995057, -1.819692611694336, -0.0007333449902944267, -0.7595776915550232, -0.01966363750398159], "finish_reason": "stop"}, {"text": " save_path:", "tokens": [" save", "_", "path", ":", "\n"], "logprobs": [-0.02326955646276474, -3.158996332786046e-05, -1.1920922133867862e-06, -0.5265460014343262, -0.002713571535423398], "finish_reason": "stop"}, {"text": "savefig(save_path, bbox_inches=\"tight\")", "tokens": ["save", "fig", "(", "save", "_", "path", ",", " b", "box", "_", "in", "ches", "=", "\"", "tight", "\"", ")", "\n"], "logprobs": [-0.00776285957545042, -0.00026603974401950836, -0.00023910524032544345, -0.01113121211528778, -7.271740287251305e-06, -5.722029527532868e-06, -1.8762279748916626, -0.3849630653858185, -0.00048720886115916073, -0.0002796259068418294, -0.00018857131362892687, -0.002549376105889678, -0.18157128989696503, -0.0017567930044606328, -0.0038015018217265606, -6.067568756407127e-05, -0.24927930533885956, -0.01845814660191536], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.1973920464515686, -0.09402147680521011, -0.07241351902484894], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.029567686840891838, -0.0561375729739666], "finish_reason": "stop"}, {"text": " FileNotFoundError as e:", "tokens": [" File", "NotFound", "Error", " as", " e", ":", "\n"], "logprobs": [-0.512761652469635, -2.6225699912174605e-05, -5.245195097813848e-06, -0.2687920033931732, -0.4444756805896759, -0.002092316746711731, -0.0037319078110158443], "finish_reason": "stop"}, {"text": " FileNotFoundError(f\"File not found: {exc.filename}\")", "tokens": [" File", "NotFound", "Error", "(", "f", "\"", "File", " not", " found", ":", " {", "exc", ".", "filename", "}\"", ")", "\n"], "logprobs": [-0.28818854689598083, -0.00011955977242905647, -0.0002119316632160917, -0.02356359176337719, -0.9910153746604919, -0.02072196826338768, -0.622508704662323, -0.45987042784690857, -0.0032174033112823963, -0.18987904489040375, -0.02027185633778572, -0.34672781825065613, -0.49595868587493896, -0.3811127245426178, -0.07809954136610031, -0.004820036701858044, -0.01737011969089508], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.014060838147997856, -0.06111031770706177, -0.015703469514846802, -0.0006812873762100935, -0.005861356388777494], "finish_reason": "stop"}, {"text": "f\"Error occurred during data processing: {e}\")", "tokens": ["f", "\"", "Error", " occurred", " during", " data", " processing", ":", " {", "e", "}\"", ")", "\n"], "logprobs": [-0.4564480781555176, -0.006173706613481045, -0.9291824102401733, -1.0948781967163086, -2.58303165435791, -3.2224581241607666, -0.1789998859167099, -0.06220255047082901, -0.009496986865997314, -0.37771376967430115, -0.06632734835147858, -0.04630475491285324, -0.01999659650027752], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "\n"], "logprobs": [-0.017553336918354034, -0.8977891802787781], "finish_reason": "stop"}], "metrics": {"energy": 421.2013119544985, "energy_per_token": 1.792346008317015, "time": 16.189384, "time_per_token": 0.06889099574468086}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.00498623214662075, -0.00015448330668732524, -0.0029444219544529915, -1.8954096958623268e-05, -0.001007764250971377, -0.0005876483046449721, -0.0081194331869483, -0.00022420754248742014, -2.8490614567999728e-05, -0.553931713104248, -0.030561480671167374], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ")", "\n"], "logprobs": [-0.0002379134384682402, -6.6756979322235566e-06, -2.13382354559144e-05, -0.10027042031288147, -0.2961236834526062, -0.0002366024418734014, -7.283422019099817e-05, -0.11842232197523117, -0.029111698269844055, -3.576278118089249e-07, -0.010065983049571514, -7.390948667307384e-06, -5.483612312673358e-06, -1.645074735279195e-05, -0.2510663568973541, -0.028602328151464462], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.006787103600800037, -1.2159273865108844e-05, -5.721882189391181e-05, -0.006773842498660088, -0.0004994813934899867, -0.00011050090688513592, -0.005885058548301458, -0.01904475875198841, -0.5851930975914001, -0.002874292666092515, -0.0006057572900317609, -8.165503095369786e-05, -0.07653459906578064, -0.1903267651796341], "finish_reason": "stop"}, {"text": " sum(word_count.toarray())", "tokens": [" sum", "(", "word", "_", "count", ".", "to", "array", "())", "\n"], "logprobs": [-0.9072086811065674, -0.41431841254234314, -0.12164272367954254, -0.014297427609562874, -0.0016423083143308759, -0.011860329657793045, -0.2208743840456009, -0.001620528637431562, -0.25060170888900757, -0.01386992633342743], "finish_reason": "stop"}, {"text": " 10 * np.log10(sum_words)", "tokens": [" ", "1", "0", " *", " np", ".", "log", "1", "0", "(", "sum", "_", "words", ")", "\n"], "logprobs": [-3.0953738689422607, -0.050214506685733795, -0.05745958909392357, -2.7430191040039062, -1.1683053970336914, -2.098061486321967e-05, -0.19772382080554962, -0.20477354526519775, -0.0032725371420383453, -0.08976037800312042, -0.49510473012924194, -0.00017820201173890382, -6.782778655178845e-05, -0.4106917083263397, -0.3458236753940582], "finish_reason": "stop"}, {"text": "word, count)", "tokens": ["word", ",", " count", ")", "\n"], "logprobs": [-0.08792780339717865, -0.08964420109987259, -0.9690399765968323, -0.9333169460296631, -0.7330801486968994], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: -x[1])", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " -", "x", "[", "1", "])", "\n"], "logprobs": [-0.07787062972784042, -0.00025829317746683955, -0.19082529842853546, -0.0016264794394373894, -5.519237674889155e-05, -0.002419760450720787, -0.019232813268899918, -0.0030906074680387974, -0.0017314456636086106, -0.025241615250706673, -0.0003691230376716703, -1.785310983657837, -0.007419767323881388, -0.007872032932937145, -0.0005229535745456815, -0.0024743436370044947, -0.15912796556949615], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.3597811162471771, -8.427741704508662e-05, -3.45700973412022e-05, -0.24640266597270966, -0.01593380607664585, -0.003001829143613577, -0.001426870352588594, -0.004625454545021057], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Frequency\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "F", "requency", "\"", "])", "\n"], "logprobs": [-0.018476169556379318, -0.005248576868325472, -0.0024984830524772406, -0.081239253282547, -0.13473932445049286, -7.676783570786938e-05, -1.0132738680113107e-05, -0.05100269243121147, -0.026154248043894768, -0.04694896936416626, -0.005649907514452934, -0.22552956640720367, -0.005240631755441427, -0.00022671037004329264, -0.002298334613442421, -0.5999603271484375, -0.08368774503469467, -0.004542033653706312, -0.004365201108157635, -0.042279213666915894], "finish_reason": "stop"}, {"text": " df_top.plot(kind=\"barh\", figsize=(10, 10), fontsize=8, title=\"Top 10 Words\")", "tokens": [" df", "_", "top", ".", "plot", "(", "kind", "=", "\"", "bar", "h", "\"", ",", " fig", "size", "=(", "1", "0", ",", " ", "1", "0", ")", ",", " fonts", "ize", "=", "8", ",", " title", "=", "\"", "Top", " ", "1", "0", " Words", "\"", ")", "\n"], "logprobs": [-0.180743008852005, -0.0012879418209195137, -2.396077979938127e-05, -0.013659929856657982, -0.12688016891479492, -0.711349606513977, -0.6360639929771423, -0.16674180328845978, -0.0003014348621945828, -0.009637495502829552, -0.22205805778503418, -9.83428253675811e-05, -0.04282483831048012, -1.0390293598175049, -0.00016044282529037446, -0.031322211027145386, -0.3543754518032074, -0.7453643083572388, -0.00317450612783432, -0.06266586482524872, -1.7809357643127441, -0.05941901355981827, -0.5098471641540527, -0.00022456508304458112, -2.544841766357422, -0.0001174142598756589, -0.007817388512194157, -1.4080201387405396, -0.7869011759757996, -1.848757028579712, -0.050329457968473434, -0.06602095812559128, -0.6955618262290955, -0.07483281195163727, -0.0016563518438488245, -0.0003578022588044405, -0.9958392381668091, -0.6575170159339905, -0.4385794699192047, -0.015576370060443878], "finish_reason": "stop"}, {"text": " save_path is not None:", "tokens": [" save", "_", "path", " is", " not", " None", ":", "\n"], "logprobs": [-0.021472714841365814, -3.194758028257638e-05, -1.311301275563892e-06, -1.0963168144226074, -0.20405088365077972, -2.074220174108632e-05, -0.0009442876325920224, -0.0022408869117498398], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.0083366259932518, -0.00028618055512197316, -0.00023421882360707968, -0.00722095649689436, -7.748573807475623e-06, -6.437280717364047e-06, -0.17372563481330872, -0.00537213496863842], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.18375256657600403, -0.11298824846744537, -0.07953610271215439], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.029461434110999107, -0.05228320136666298], "finish_reason": "stop"}, {"text": " FileNotFoundError as err:", "tokens": [" File", "NotFound", "Error", " as", " err", ":", "\n"], "logprobs": [-0.5762081742286682, -2.6702524337451905e-05, -6.318072337307967e-06, -0.25483864545822144, -2.032397747039795, -0.0055610002018511295, -0.004612639080733061], "finish_reason": "stop"}, {"text": " FileNotFoundError(", "tokens": [" File", "NotFound", "Error", "(", "\n"], "logprobs": [-0.23117130994796753, -0.00014995403762441128, -0.00018869050836656243, -0.02287360467016697, -1.1515746116638184], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.013604189269244671, -0.058036256581544876, -0.01543375849723816, -0.0007120219524949789, -0.007299656979739666], "finish_reason": "stop"}, {"text": "\"Error in task_func\", e)", "tokens": ["\"", "Error", " in", " task", "_", "func", "\"", ",", " e", ")", "\n"], "logprobs": [-1.1718578338623047, -1.2163844108581543, -2.8748555183410645, -0.8710111379623413, -0.48553216457366943, -0.023760229349136353, -2.7001614570617676, -0.46170729398727417, -0.5883030295372009, -0.13416823744773865, -0.01640487089753151], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "\n"], "logprobs": [-0.01737304963171482, -0.9366636276245117], "finish_reason": "stop"}], "metrics": {"energy": 423.1365353298186, "energy_per_token": 2.0441378518348725, "time": 17.19047, "time_per_token": 0.08304574879227054}}
{"outputs": [{"text": " pd.read_csv(file_path, header=None, names=[\"Text\"])", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ",", " header", "=", "None", ",", " names", "=[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.004657966550439596, -0.00013958434283267707, -0.002737467410042882, -1.5616295058862306e-05, -0.0010170531459152699, -0.0006011109799146652, -0.006524569820612669, -0.00022516099852509797, -3.6000557884108275e-05, -0.9574381113052368, -0.26484063267707825, -0.03776170685887337, -0.7174824476242065, -0.6254891157150269, -0.8474476933479309, -0.6597700119018555, -0.008989812806248665, -0.12352491170167923, -0.01089894212782383, -0.06248423829674721, -0.035401444882154465], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS, lowercase=True)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ",", " lower", "case", "=", "True", ")", "\n"], "logprobs": [-0.00030071981018409133, -7.033323527139146e-06, -1.764281842042692e-05, -0.08342535048723221, -0.25999897718429565, -0.0002671123365871608, -7.164221460698172e-05, -0.12533530592918396, -0.03725718334317207, -3.576278118089249e-07, -0.013476586900651455, -5.960446742392378e-06, -5.722029527532868e-06, -2.038458114839159e-05, -1.2848957777023315, -2.652754306793213, -0.0005259322933852673, -0.0037180122453719378, -0.16594982147216797, -0.5023775100708008, -0.01926017552614212], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.007504013366997242, -1.5020257706055418e-05, -5.400034933700226e-05, -0.006829609628766775, -0.0004897110629826784, -9.83428253675811e-05, -0.005454538390040398, -0.02027243934571743, -0.46571648120880127, -0.0035539816599339247, -0.00044764988706447184, -6.663577369181439e-05, -0.08190002292394638, -0.16290627419948578], "finish_reason": "stop"}, {"text": " word_count.sum(axis=0)", "tokens": [" word", "_", "count", ".", "sum", "(", "axis", "=", "0", ")", "\n"], "logprobs": [-0.9267576336860657, -0.00016532962035853416, -0.0002843929105438292, -0.0005749003030359745, -0.03485279157757759, -1.0415422916412354, -0.0016429034294560552, -0.0029393110889941454, -0.148658886551857, -0.006623338907957077, -0.16937939822673798], "finish_reason": "stop"}, {"text": " pd.DataFrame(word_count.toarray(), index=vectorizer.get_feature_names(), columns=[\"Word Count\"]) / sum_words", "tokens": [" pd", ".", "DataFrame", "(", "word", "_", "count", ".", "to", "array", "()", ",", " index", "=", "vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " columns", "=[", "\"", "Word", " Count", "\"", "])", " /", " sum", "_", "words", "\n"], "logprobs": [-2.3657732009887695, -0.0040374440141022205, -0.589134693145752, -0.08032649755477905, -0.18217743933200836, -8.511180931236595e-05, -1.2993727978027891e-05, -0.038675375282764435, -0.6784272193908691, -0.002849211450666189, -0.012060576118528843, -0.3225500285625458, -1.2668756246566772, -0.029863927513360977, -0.0412009134888649, -3.4450891689630225e-05, -0.0001479277852922678, -0.03333577513694763, -1.4305104514278355e-06, -0.00022539935889653862, -1.1920928244535389e-07, -0.0010238410905003548, -0.2112170159816742, -0.0011797142215073109, -0.30453336238861084, -0.02579858899116516, -0.004458724521100521, -2.774383783340454, -0.9424564242362976, -0.029965275898575783, -0.0032943999394774437, -2.0264172554016113, -0.1848142296075821, -0.0017313265707343817, -0.00017832119192462415, -0.5822021961212158], "finish_reason": "stop"}, {"text": "word, count)", "tokens": ["word", ",", " count", ")", "\n"], "logprobs": [-0.08283878117799759, -0.10028864443302155, -1.0489176511764526, -0.798427402973175, -0.7296478152275085], "finish_reason": "stop"}, {"text": " sorted(", "tokens": [" sorted", "(", "\n"], "logprobs": [-0.08511313796043396, -0.00022635281493421644, -1.9291892051696777], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.37596896290779114, -7.962863310240209e-05, -3.2782016205601394e-05, -0.18126444518566132, -0.016253933310508728, -0.003030947409570217, -0.0014319891342893243, -0.004720970522612333], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Count\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "Count", "\"", "])", "\n"], "logprobs": [-0.020963873714208603, -0.005428810138255358, -0.0022971450816839933, -0.06960837543010712, -0.15066978335380554, -6.0794889577664435e-05, -8.106198947643861e-06, -0.05660145729780197, -0.02605471760034561, -0.04384560137987137, -0.006368106231093407, -0.2334158569574356, -0.005373439285904169, -0.00024399164249189198, -0.0022716925013810396, -0.832825243473053, -0.014783242717385292, -0.0032563775312155485, -0.04060804471373558], "finish_reason": "stop"}, {"text": " df_top.plot.barh(x=\"Word\", y=\"Count\", color=\"blue\")", "tokens": [" df", "_", "top", ".", "plot", ".", "bar", "h", "(", "x", "=", "\"", "Word", "\"", ",", " y", "=", "\"", "Count", "\"", ",", " color", "=", "\"", "blue", "\"", ")", "\n"], "logprobs": [-0.16422852873802185, -0.0013812773395329714, -2.7179348762729205e-05, -0.01750730164349079, -0.11432656645774841, -0.6130884289741516, -0.004025689791887999, -1.0677684545516968, -0.016479451209306717, -0.3763779103755951, -0.061325833201408386, -0.0014890070306137204, -0.014277096837759018, -6.48477507638745e-05, -0.0023535192012786865, -0.06094320863485336, -0.0030954801477491856, -0.00019202772818971425, -4.160317621426657e-05, -2.9801878554280847e-05, -0.2601741552352905, -2.2016994953155518, -0.14636170864105225, -0.0038727535866200924, -2.1254982948303223, -0.00335119292140007, -0.8067318201065063, -0.013744710013270378], "finish_reason": "stop"}, {"text": " save_path is None:", "tokens": [" save", "_", "path", " is", " None", ":", "\n"], "logprobs": [-0.021630914881825447, -4.005352093372494e-05, -1.1920922133867862e-06, -0.9531875848770142, -1.7954819202423096, -0.00037222131504677236, -0.006792668718844652], "finish_reason": "stop"}, {"text": "savefig(save_path, dpi=300)", "tokens": ["save", "fig", "(", "save", "_", "path", ",", " d", "pi", "=", "3", "0", "0", ")", "\n"], "logprobs": [-0.0074785747565329075, -0.0003045333724003285, -0.0002138386043952778, -0.007630487438291311, -1.0251946150674485e-05, -6.198863957251888e-06, -1.8919875621795654, -1.5045244693756104, -0.00011431517486926168, -0.001178285456262529, -0.46291664242744446, -0.005565030965954065, -0.0008326877141371369, -0.40173572301864624, -0.011655566282570362], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.1705869883298874, -0.08782419562339783, -0.08660034090280533], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.0263676755130291, -0.04830782860517502], "finish_reason": "stop"}, {"text": " FileNotFoundError as e:", "tokens": [" File", "NotFound", "Error", " as", " e", ":", "\n"], "logprobs": [-0.5367321372032166, -3.325883881188929e-05, -4.529942543740617e-06, -0.24561409652233124, -0.4503609836101532, -0.001758220954798162, -0.004354044329375029], "finish_reason": "stop"}, {"text": " exc", "tokens": [" exc", "\n"], "logprobs": [-1.8363933563232422, -0.08105437457561493], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.016362419351935387, -0.061465296894311905, -0.013329794630408287, -0.0007197650265879929, -0.004475814290344715], "finish_reason": "stop"}, {"text": "f\"Error: {e}\")", "tokens": ["f", "\"", "Error", ":", " {", "e", "}\"", ")", "\n"], "logprobs": [-0.47106537222862244, -0.006285659968852997, -0.8351991176605225, -0.9316856265068054, -0.009716833010315895, -0.2789272367954254, -0.09562323987483978, -0.035001639276742935, -0.013674040324985981], "finish_reason": "stop"}, {"text": " None", "tokens": [" None"], "logprobs": [-0.0183633491396904], "finish_reason": "stop"}], "metrics": {"energy": 384.5743575134277, "energy_per_token": 1.7722320622738603, "time": 16.355156, "time_per_token": 0.07536938248847927}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.005211459007114172, -0.00015066919149830937, -0.002838750835508108, -1.9430925021879375e-05, -0.0008761619683355093, -0.0005546461907215416, -0.0068722316063940525, -0.00018618757894728333, -2.8729025871143676e-05, -0.5224968194961548, -0.025802770629525185], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words='english', max_features=20)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "='", "eng", "lish", "'", ",", " max", "_", "features", "=", "2", "0", ")", "\n"], "logprobs": [-0.00025817399728111923, -6.794906312279636e-06, -1.8358061424805783e-05, -0.0906127467751503, -0.2650561034679413, -0.000248401309363544, -7.343022298300639e-05, -2.3600637912750244, -0.05996928736567497, -8.106198947643861e-06, -0.9421061277389526, -0.0010186012368649244, -1.240010142326355, -0.0004489606071729213, -0.08204499632120132, -0.006658746860921383, -2.618089437484741, -0.15418784320354462, -0.6737297177314758, -0.037382591515779495], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df['Text']).toarray()", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "['", "Text", "'])", ".", "to", "array", "()", "\n"], "logprobs": [-0.0055564953945577145, -1.0490362910786644e-05, -4.792098479811102e-05, -0.008658604696393013, -0.0004557524516712874, -9.858122211880982e-05, -0.005680015776306391, -0.015140608884394169, -1.6036193370819092, -0.0006216024048626423, -0.09723357856273651, -2.02154803276062, -0.10155855864286423, -0.0015031717484816909, -0.033099379390478134, -0.06550080329179764], "finish_reason": "stop"}, {"text": " np.asarray(word_count.sum(axis=0))[0]", "tokens": [" np", ".", "as", "array", "(", "word", "_", "count", ".", "sum", "(", "axis", "=", "0", "))", "[", "0", "]", "\n"], "logprobs": [-2.814019203186035, -0.00035494225448928773, -2.7000057697296143, -0.013206391595304012, -0.022241203114390373, -0.04084404185414314, -5.5549986427649856e-05, -0.00032109825406223536, -0.013061678037047386, -0.03936154022812843, -0.00044383687782101333, -0.002600504318252206, -0.0036640907637774944, -0.19702012836933136, -0.11161252111196518, -0.5584517121315002, -0.003714567981660366, -0.2565692067146301, -0.054113321006298065], "finish_reason": "stop"}, {"text": " {word: count for word, count in zip(vectorizer.get_feature_names(), sum_words)}", "tokens": [" {", "word", ":", " count", " for", " word", ",", " count", " in", " zip", "(", "vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " sum", "_", "words", ")}", "\n"], "logprobs": [-2.951011896133423, -0.09344261884689331, -0.06679634004831314, -0.3291322886943817, -1.372189998626709, -0.0076345098204910755, -0.0001793938863556832, -0.005693291313946247, -0.0015282867243513465, -0.3038333058357239, -0.003072781255468726, -0.0999605655670166, -1.2755313036905136e-05, -7.939023635117337e-05, -0.025715753436088562, -3.099436753473128e-06, -0.00025519452174194157, -1.1920928244535389e-07, -0.0012038849527016282, -0.23699410259723663, -0.0014450832968577743, -0.2793900966644287, -0.0001839230244513601, -1.5258672647178173e-05, -0.1782875806093216, -0.004568852484226227], "finish_reason": "stop"}, {"text": "word_count[i, :].A1.index[0], word_count[i, :].A1.sum())", "tokens": ["word", "_", "count", "[", "i", ",", " :", "]", ".", "A", "1", ".", "index", "[", "0", "]", ",", " word", "_", "count", "[", "i", ",", " :", "]", ".", "A", "1", ".", "sum", "())", "\n"], "logprobs": [-0.07266385853290558, -2.8592498302459717, -0.11787278205156326, -0.5698506832122803, -1.1680362224578857, -2.2120590209960938, -1.3225300312042236, -0.06218182295560837, -0.06777266412973404, -3.481498956680298, -0.07240641862154007, -1.8695415258407593, -2.2636289596557617, -0.19479119777679443, -0.016224611550569534, -0.08907512575387955, -0.020638711750507355, -0.3640446960926056, -0.0011506610317155719, -0.0002699726028367877, -0.003268616273999214, -0.0014362744987010956, -0.003886172082275152, -0.011248505674302578, -0.0008507922757416964, -0.001053255284205079, -0.008507557213306427, -0.0007496645557694137, -0.14879408478736877, -0.27527379989624023, -0.28950631618499756, -0.1936948001384735], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: x[1], reverse=True)", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-0.09112468361854553, -0.00023529145983047783, -0.18436166644096375, -0.0012815127847716212, -5.721882189391181e-05, -0.00246649538166821, -0.018407823517918587, -0.0030232220888137817, -0.0014650813536718488, -0.024889817461371422, -0.000316212244797498, -0.29023775458335876, -0.007184503600001335, -0.002089223824441433, -0.020273491740226746, -0.00015698630886618048, -0.005282373167574406, -0.0004881620698142797, -0.000491855782456696, -0.017340127378702164, -0.13062526285648346], "finish_reason": "stop"}, {"text": " [words for words, _ in words_freq]", "tokens": [" [", "words", " for", " words", ",", " _", " in", " words", "_", "freq", "]", "\n"], "logprobs": [-2.000675916671753, -2.8534421920776367, -1.775066614151001, -0.6624749302864075, -0.05017346516251564, -0.5178439617156982, -0.002624878427013755, -0.005781001411378384, -2.312633478140924e-05, -1.2040065485052764e-05, -2.289090394973755, -0.032717686146497726], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Count\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "Count", "\"", "])", "\n"], "logprobs": [-0.018256952986121178, -0.005427861586213112, -0.0021192014683037996, -0.07085663080215454, -0.17408688366413116, -5.781483559985645e-05, -8.702239938429557e-06, -0.05336465686559677, -0.025903254747390747, -0.04198114201426506, -0.006348679773509502, -0.23710085451602936, -0.005602254066616297, -0.00021550717065110803, -0.0021347845904529095, -0.9455050826072693, -0.011842305772006512, -0.0031112858559936285, -0.035116393119096756], "finish_reason": "stop"}, {"text": " df_top.plot.barh(figsize=(8, 5), y=\"Word\", x=\"Count\")", "tokens": [" df", "_", "top", ".", "plot", ".", "bar", "h", "(", "fig", "size", "=(", "8", ",", " ", "5", ")", ",", " y", "=", "\"", "Word", "\"", ",", " x", "=", "\"", "Count", "\"", ")", "\n"], "logprobs": [-0.1934279203414917, -0.0010669498005881906, -1.9907753085135482e-05, -0.014755991287529469, -0.11762333661317825, -0.6385931968688965, -0.005011615343391895, -0.9514686465263367, -0.017573248594999313, -3.1114275455474854, -7.950943836476654e-05, -0.027726365253329277, -1.6350109577178955, -0.009720847010612488, -0.09292860329151154, -1.8970698118209839, -0.2189883589744568, -0.00017045476124621928, -2.5813915729522705, -0.1276140809059143, -0.001755721983499825, -0.019736573100090027, -0.00014482879487331957, -0.002261701738461852, -0.04116155952215195, -0.008640285581350327, -0.0003510097449179739, -0.0001497156627010554, -3.981510963058099e-05, -1.3458936214447021, -0.01175324060022831], "finish_reason": "stop"}, {"text": " save_path:", "tokens": [" save", "_", "path", ":", "\n"], "logprobs": [-0.021715722978115082, -2.8371408916427754e-05, -1.1920922133867862e-06, -0.4530470371246338, -0.0024397389497607946], "finish_reason": "stop"}, {"text": "savefig(save_path, bbox_inches='tight')", "tokens": ["save", "fig", "(", "save", "_", "path", ",", " b", "box", "_", "in", "ches", "='", "tight", "')", "\n"], "logprobs": [-0.010008743964135647, -0.00038413776201196015, -0.0002498314715921879, -0.009161222726106644, -7.629365427419543e-06, -5.602820692729438e-06, -2.0091302394866943, -0.3440015912055969, -0.0004919749335385859, -0.00029488030122593045, -0.0002181292074965313, -0.0018924438627436757, -1.8941104412078857, -0.001143040368333459, -0.21573646366596222, -0.017239950597286224], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.18406996130943298, -0.12934304773807526, -0.07584662735462189], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.03087557479739189, -0.05741377919912338], "finish_reason": "stop"}, {"text": " Exception as e:", "tokens": [" Exception", " as", " e", ":", "\n"], "logprobs": [-1.1075537204742432, -0.12879550457000732, -0.2001107782125473, -0.00037520044133998454, -0.007771849632263184], "finish_reason": "stop"}, {"text": " FileNotFoundError(", "tokens": [" File", "NotFound", "Error", "(", "\n"], "logprobs": [-0.2725599408149719, -0.00013791563105769455, -0.00016664070426486433, -0.027789555490016937, -1.194148063659668], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.015568975359201431, -0.0639314278960228, -0.012203315272927284, -0.0005875291535630822, -0.006484420038759708], "finish_reason": "stop"}, {"text": "e)", "tokens": ["e", ")", "\n"], "logprobs": [-2.895500898361206, -0.08698146790266037, -0.016006896272301674], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "\n"], "logprobs": [-0.020743802189826965, -1.010475993156433], "finish_reason": "stop"}], "metrics": {"energy": 427.3665932989121, "energy_per_token": 1.6891960209443166, "time": 18.084753, "time_per_token": 0.0714812371541502}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.004559715278446674, -0.00019071667338721454, -0.0024027545005083084, -1.597391747054644e-05, -0.000821014866232872, -0.0005164004978723824, -0.007414560765028, -0.00024279984063468874, -3.182837463100441e-05, -0.5615230798721313, -0.024881096556782722], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS, max_features=10, max_df=0.7, min_df=0.05,", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ",", " max", "_", "features", "=", "1", "0", ",", " max", "_", "df", "=", "0", ".", "7", ",", " min", "_", "df", "=", "0", ".", "0", "5", ",", "\n"], "logprobs": [-0.0002681849291548133, -7.390948667307384e-06, -2.276871418871451e-05, -0.07359903305768967, -0.30806225538253784, -0.00025555206229910254, -6.4490144723095e-05, -0.10011275857686996, -0.03194531798362732, -4.768370445162873e-07, -0.010094896890223026, -6.794906312279636e-06, -4.291525328881107e-06, -1.8596476365928538e-05, -1.2845308780670166, -1.339149832725525, -0.0008918836829252541, -0.07849141955375671, -0.006121576298028231, -0.24279767274856567, -0.02142954245209694, -1.9382741451263428, -3.2115607261657715, -0.03256803750991821, -0.15525469183921814, -0.002474581589922309, -0.11845313757658005, -0.0033803009428083897, -1.9776337146759033, -1.568626880645752, -0.7963683605194092, -2.3364747903542593e-05, -0.0031522843055427074, -0.0010187203297391534, -0.08680004626512527, -0.03521180525422096, -0.6810059547424316, -1.602447748184204, -1.2747883796691895, -1.92143976688385], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df[\"Text\"])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "[", "\"", "Text", "\"", "])", "\n"], "logprobs": [-0.007143906317651272, -1.1205610462639015e-05, -5.9960475482512265e-05, -0.008236134424805641, -0.00048315772437490523, -9.500529267825186e-05, -0.005159159656614065, -0.015544679947197437, -0.5016923546791077, -0.0027050115168094635, -0.0005471401382237673, -7.176141662057489e-05, -0.08899856358766556, -0.19954605400562286], "finish_reason": "stop"}, {"text": " word_count.sum(axis=0)", "tokens": [" word", "_", "count", ".", "sum", "(", "axis", "=", "0", ")", "\n"], "logprobs": [-0.9245784282684326, -0.0001426833332516253, -0.00023874769976828247, -0.0004681444843299687, -0.036170922219753265, -1.0283833742141724, -0.0017482249531894922, -0.0028373245149850845, -0.1266101598739624, -0.004945071414113045, -0.16644400358200073], "finish_reason": "stop"}, {"text": " (word_count.T / sum_words).round(3)", "tokens": [" (", "word", "_", "count", ".", "T", " /", " sum", "_", "words", ")", ".", "round", "(", "3", ")", "\n"], "logprobs": [-0.9859219789505005, -0.15992587804794312, -0.0007446615491062403, -5.125868119648658e-05, -0.17483460903167725, -0.2397180050611496, -0.01852286048233509, -0.008907699957489967, -0.00023862851958256215, -4.184158387943171e-05, -0.031032757833600044, -0.07697001844644547, -0.4810633063316345, -0.035269804298877716, -1.3564345836639404, -0.0012694880133494735, -0.1357230544090271], "finish_reason": "stop"}, {"text": "word, count) for word, count in zip(vectorizer.get_feature_names(), sum_words)", "tokens": ["word", ",", " count", ")", " for", " word", ",", " count", " in", " zip", "(", "vector", "izer", ".", "get", "_", "feature", "_", "names", "()", ",", " sum", "_", "words", ")", "\n"], "logprobs": [-0.0825299471616745, -0.11313889175653458, -1.2475566864013672, -0.7383992671966553, -0.5842341780662537, -0.011362838558852673, -0.0009908534120768309, -0.0018760239472612739, -0.0027403205167502165, -0.20561186969280243, -0.0016742035513743758, -0.10305001586675644, -2.3364747903542593e-05, -5.686121585313231e-05, -0.020591065287590027, -3.099436753473128e-06, -0.00022027450904715806, -1.1920928244535389e-07, -0.0008578196284361184, -0.4010365605354309, -0.0014293702552095056, -0.196391761302948, -0.0002714027068577707, -2.6940935640595853e-05, -0.19191843271255493, -0.0183283518999815], "finish_reason": "stop"}, {"text": " sorted(", "tokens": [" sorted", "(", "\n"], "logprobs": [-0.08485231548547745, -0.00022682955022901297, -1.9236059188842773], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.40871551632881165, -9.023735765367746e-05, -2.9205850296420977e-05, -0.24886709451675415, -0.015611931681632996, -0.003389449091628194, -0.0015645894454792142, -0.004228816833347082], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Frequency\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "F", "requency", "\"", "])", "\n"], "logprobs": [-0.021640364080667496, -0.003755066776648164, -0.0023178397677838802, -0.06651720404624939, -0.19132494926452637, -6.651657167822123e-05, -7.748573807475623e-06, -0.046971604228019714, -0.021788274869322777, -0.04384971037507057, -0.0072325547225773335, -0.22467826306819916, -0.006253556348383427, -0.0002944036095868796, -0.0021802245173603296, -0.6108986735343933, -0.09293273091316223, -0.004971879534423351, -0.00488303042948246, -0.032202765345573425], "finish_reason": "stop"}, {"text": " plt.bar(df_top[\"Word\"], df_top[\"Count\"])", "tokens": [" plt", ".", "bar", "(", "df", "_", "top", "[", "\"", "Word", "\"", "]", ",", " df", "_", "top", "[", "\"", "Count", "\"", "])", "\n"], "logprobs": [-1.9204415082931519, -0.0002526917669456452, -1.041137933731079, -0.5762217044830322, -1.31026291847229, -0.0006618693005293608, -2.2649508537142538e-05, -0.21407930552959442, -0.0007223857101053, -0.00029273517429828644, -4.31528314948082e-05, -0.00357916415669024, -0.009823078289628029, -0.010273550637066364, -1.8715683836489916e-05, -2.3841855067985307e-07, -0.0016415942227467895, -2.169585604860913e-05, -3.528532761265524e-05, -2.6225699912174605e-05, -0.166694775223732, -0.007578550837934017], "finish_reason": "stop"}, {"text": " save_path is not None:", "tokens": [" save", "_", "path", " is", " not", " None", ":", "\n"], "logprobs": [-0.02169600874185562, -3.158996332786046e-05, -1.4305104514278355e-06, -0.8588104248046875, -0.20795278251171112, -2.3245540432981215e-05, -0.0011044599814340472, -0.001965973060578108], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.007321786601096392, -0.0003181189822498709, -0.0002426806604489684, -0.008573628030717373, -7.033323527139146e-06, -5.483612312673358e-06, -0.1898319125175476, -0.006594443693757057], "finish_reason": "stop"}, {"text": "close()  # Optional, but recommended to close the figure after saving", "tokens": ["close", "()", "  ", "#", " Optional", ",", " but", " recommended", " to", " close", " the", " figure", " after", " saving", "\n"], "logprobs": [-0.17019793391227722, -0.08483172208070755, -2.6444742679595947, -0.0010917185572907329, -3.709474563598633, -1.5123134851455688, -1.6340898275375366, -1.0060595273971558, -0.982487142086029, -0.9223189949989319, -0.11962003260850906, -1.6868438720703125, -1.8656038045883179, -0.3138427734375, -0.3562568128108978], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.026162028312683105, -0.0582660436630249], "finish_reason": "stop"}, {"text": " FileNotFoundError as error:", "tokens": [" File", "NotFound", "Error", " as", " error", ":", "\n"], "logprobs": [-0.5295708179473877, -2.3364747903542593e-05, -6.556489552167477e-06, -0.21714510023593903, -3.2939364910125732, -0.013206391595304012, -0.004396653734147549], "finish_reason": "stop"}, {"text": " FileNotFoundError(", "tokens": [" File", "NotFound", "Error", "(", "\n"], "logprobs": [-0.2617301046848297, -0.00016258825780823827, -0.00026353701832704246, -0.02749316394329071, -1.1066569089889526], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.014108442701399326, -0.0667487308382988, -0.015107261948287487, -0.0006864098832011223, -0.0074394093826413155], "finish_reason": "stop"}, {"text": "e)", "tokens": ["e", ")", "\n"], "logprobs": [-2.859865188598633, -0.09471137821674347, -0.011925237253308296], "finish_reason": "stop"}, {"text": " None", "tokens": [" None", "\n"], "logprobs": [-0.019795361906290054, -0.9212871193885803], "finish_reason": "stop"}], "metrics": {"energy": 383.80854092788695, "energy_per_token": 1.6907865239113962, "time": 15.964425, "time_per_token": 0.07032786343612335}}
{"outputs": [{"text": " pd.read_csv(file_path)", "tokens": [" pd", ".", "read", "_", "csv", "(", "file", "_", "path", ")", "\n"], "logprobs": [-0.00498623214662075, -0.00015448330668732524, -0.0029444219544529915, -1.8954096958623268e-05, -0.001007764250971377, -0.0005876483046449721, -0.0081194331869483, -0.00022420754248742014, -2.8490614567999728e-05, -0.553931713104248, -0.030561480671167374], "finish_reason": "stop"}, {"text": " CountVectorizer(stop_words=STOP_WORDS)", "tokens": [" Count", "Vector", "izer", "(", "stop", "_", "words", "=", "ST", "OP", "_", "W", "OR", "DS", ")", "\n"], "logprobs": [-0.0002379134384682402, -6.6756979322235566e-06, -2.13382354559144e-05, -0.10027042031288147, -0.2961236834526062, -0.0002366024418734014, -7.283422019099817e-05, -0.11842232197523117, -0.029111698269844055, -3.576278118089249e-07, -0.010065983049571514, -7.390948667307384e-06, -5.483612312673358e-06, -1.645074735279195e-05, -0.2510663568973541, -0.028602328151464462], "finish_reason": "stop"}, {"text": " vectorizer.fit_transform(df['Text'])", "tokens": [" vector", "izer", ".", "fit", "_", "transform", "(", "df", "['", "Text", "'])", "\n"], "logprobs": [-0.006787103600800037, -1.2159273865108844e-05, -5.721882189391181e-05, -0.006773842498660088, -0.0004994813934899867, -0.00011050090688513592, -0.005885058548301458, -0.01904475875198841, -1.5006251335144043, -0.000570253818295896, -0.09031762927770615, -0.1585330069065094], "finish_reason": "stop"}, {"text": " np.sum(word_count.toarray(), axis=0)", "tokens": [" np", ".", "sum", "(", "word", "_", "count", ".", "to", "array", "()", ",", " axis", "=", "0", ")", "\n"], "logprobs": [-2.6623969078063965, -0.00025662468397058547, -0.6328282952308655, -0.003892703214660287, -0.01740749180316925, -4.649054244509898e-05, -0.00011395759065635502, -0.075892373919487, -0.04921146482229233, -0.0005054388311691582, -1.2489732503890991, -0.008562518283724785, -0.03959599882364273, -0.004744937177747488, -0.021921353414654732, -0.0036510254722088575, -0.03578752279281616], "finish_reason": "stop"}, {"text": " np.round(word_count.T.multiply(100 / sum_words), decimals=3)", "tokens": [" np", ".", "round", "(", "word", "_", "count", ".", "T", ".", "multip", "ly", "(", "1", "0", "0", " /", " sum", "_", "words", ")", ",", " dec", "imals", "=", "3", ")", "\n"], "logprobs": [-3.8921475410461426, -6.639736966462806e-05, -0.7968687415122986, -0.30580833554267883, -0.29982686042785645, -0.0006102845072746277, -1.3351351299206726e-05, -0.18791590631008148, -1.3332456350326538, -1.2813153266906738, -1.5642882585525513, -0.0332522951066494, -0.0032504366245120764, -0.07809998095035553, -0.03707030788064003, -0.0012622254434973001, -0.045078784227371216, -0.02899821847677231, -0.0004385939973872155, -8.583032467868179e-06, -0.20632301270961761, -0.579181969165802, -0.9063006639480591, -0.0017729768296703696, -0.004809834063053131, -1.9115393161773682, -0.005926654674112797, -0.16512355208396912], "finish_reason": "stop"}, {"text": "word, word_count[i])", "tokens": ["word", ",", " word", "_", "count", "[", "i", "])", "\n"], "logprobs": [-0.09179168194532394, -0.12332271039485931, -1.9761594533920288, -0.005092032253742218, -0.001817957148887217, -0.2518124580383301, -1.7134671211242676, -2.3648574352264404, -0.7277858257293701], "finish_reason": "stop"}, {"text": " sorted(words_freq, key=lambda x: -x[1])", "tokens": [" sorted", "(", "words", "_", "freq", ",", " key", "=", "lambda", " x", ":", " -", "x", "[", "1", "])", "\n"], "logprobs": [-0.09254245460033417, -0.00025650550378486514, -0.14475291967391968, -0.0008667526417411864, -5.054346183896996e-05, -0.0022977397311478853, -0.0204483512789011, -0.002778600202873349, -0.0016438555903732777, -0.024468334391713142, -0.0004451475979294628, -1.6323184967041016, -0.006914142053574324, -0.008850748650729656, -0.0005203323671594262, -0.002099335426464677, -0.1494860202074051], "finish_reason": "stop"}, {"text": " words_freq[:10]", "tokens": [" words", "_", "freq", "[:", "1", "0", "]", "\n"], "logprobs": [-0.3019956946372986, -0.0001311216183239594, -3.302042750874534e-05, -0.15678676962852478, -0.015582003630697727, -0.0034602549858391285, -0.0016213617054745555, -0.005026679486036301], "finish_reason": "stop"}, {"text": " pd.DataFrame(top_words, columns=[\"Word\", \"Frequency\"])", "tokens": [" pd", ".", "DataFrame", "(", "top", "_", "words", ",", " columns", "=[", "\"", "Word", "\"", ",", " \"", "F", "requency", "\"", "])", "\n"], "logprobs": [-0.01872224546968937, -0.004505126737058163, -0.002185458317399025, -0.07717365026473999, -0.1451137512922287, -8.177422569133341e-05, -9.059865078597795e-06, -0.05409220606088638, -0.02734760381281376, -0.04473993927240372, -0.005842394195497036, -0.2121744304895401, -0.00558186462149024, -0.00024387246230617166, -0.0021802245173603296, -0.5977280735969543, -0.09639420360326767, -0.004432496149092913, -0.005504332482814789, -0.030893143266439438], "finish_reason": "stop"}, {"text": " df_top.plot.bar(figsize=(10, 4), x=\"Word\", y=\"Count\", fontsize=8)", "tokens": [" df", "_", "top", ".", "plot", ".", "bar", "(", "fig", "size", "=(", "1", "0", ",", " ", "4", ")", ",", " x", "=", "\"", "Word", "\"", ",", " y", "=", "\"", "Count", "\"", ",", " fonts", "ize", "=", "8", ")", "\n"], "logprobs": [-0.1774572730064392, -0.0013667537132278085, -2.5629668016335927e-05, -0.014447485096752644, -0.12077701091766357, -0.6229106187820435, -0.005527094937860966, -0.45079946517944336, -2.9149258136749268, -5.9126061387360096e-05, -0.04699469357728958, -0.374068945646286, -0.6418132781982422, -0.003548992797732353, -0.0521288700401783, -1.923203945159912, -0.3196939527988434, -0.00016592556494288146, -2.5742149353027344, -0.06991611421108246, -0.0007868293323554099, -0.0006576997111551464, -0.00012516192509792745, -0.0021934278775006533, -0.014359239488840103, -0.003118534805253148, -0.00012587709352374077, -4.970903682988137e-05, -2.95634672511369e-05, -0.43475109338760376, -2.4988515377044678, -0.0001774868869688362, -0.006852460093796253, -1.239232063293457, -0.4887058734893799, -0.009408775717020035], "finish_reason": "stop"}, {"text": " save_path:", "tokens": [" save", "_", "path", ":", "\n"], "logprobs": [-0.02162286639213562, -3.302042750874534e-05, -1.1920922133867862e-06, -0.5179662108421326, -0.002541647292673588], "finish_reason": "stop"}, {"text": "savefig(save_path)", "tokens": ["save", "fig", "(", "save", "_", "path", ")", "\n"], "logprobs": [-0.009022537618875504, -0.0002989322238136083, -0.0002503081923350692, -0.0075185662135481834, -7.152531907195225e-06, -6.079655122448457e-06, -0.1328253298997879, -0.006091362796723843], "finish_reason": "stop"}, {"text": "close()", "tokens": ["close", "()", "\n"], "logprobs": [-0.15639902651309967, -0.09662432223558426, -0.07903086394071579], "finish_reason": "stop"}, {"text": " ax", "tokens": [" ax", "\n"], "logprobs": [-0.030408618971705437, -0.05607029050588608], "finish_reason": "stop"}, {"text": " Exception as e:", "tokens": [" Exception", " as", " e", ":", "\n"], "logprobs": [-1.085756778717041, -0.1517806500196457, -0.2383110523223877, -0.00034517052699811757, -0.006572060752660036], "finish_reason": "stop"}, {"text": " FileNotFoundError(f\"The file path {file_path} is invalid or does not exist.\") from exc", "tokens": [" File", "NotFound", "Error", "(", "f", "\"", "The", " file", " path", " {", "file", "_", "path", "}", " is", " invalid", " or", " does", " not", " exist", ".", "\"", ")", " from", " exc", "\n"], "logprobs": [-0.29870012402534485, -0.00016044282529037446, -0.00023815179883968085, -0.023126523941755295, -1.0268194675445557, -0.020558716729283333, -2.147641658782959, -0.6462935209274292, -1.429724931716919, -0.9051244258880615, -0.2851487696170807, -0.0003195490571670234, -6.758938252460212e-05, -0.019049670547246933, -3.1616928577423096, -1.3591612577438354, -1.7902107238769531, -1.0646110773086548, -0.003347272053360939, -0.015210587531328201, -0.2993597686290741, -0.3915077745914459, -0.028238268569111824, -0.32180920243263245, -0.003751385258510709, -0.019683275371789932], "finish_reason": "stop"}, {"text": " Exception as exc:", "tokens": [" Exception", " as", " exc", ":", "\n"], "logprobs": [-0.013488700613379478, -0.06052666902542114, -0.013316972181200981, -0.0006542449118569493, -0.006603799294680357], "finish_reason": "stop"}, {"text": "f\"An error occurred: {e}\")", "tokens": ["f", "\"", "An", " error", " occurred", ":", " {", "e", "}\"", ")", "\n"], "logprobs": [-0.5179478526115417, -0.005571906454861164, -0.9935845136642456, -0.10688579082489014, -0.02309507317841053, -0.15325117111206055, -0.007506971247494221, -0.38695651292800903, -0.1170821562409401, -0.05272173509001732, -0.021335843950510025], "finish_reason": "stop"}, {"text": " None", "tokens": [" None"], "logprobs": [-0.017791911959648132], "finish_reason": "stop"}], "metrics": {"energy": 400.35540667629215, "energy_per_token": 1.668147527817884, "time": 16.824833, "time_per_token": 0.07010347083333333}}
