{"outputs": [{"text": " re.sub(r'[^\\w]', ' ', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^\\", "w", "]", "'", ",", " '", " '", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7508039474487305, -0.002834947081282735, -1.8420201539993286, -0.03982800245285034, -0.00021240839851088822, -0.6256505250930786, -0.0007926659309305251, -0.00026890001026913524, -0.004996788688004017, -0.00022027450904715806, -6.258291978156194e-05, -0.024166300892829895, -0.2412741482257843], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 58.798840488433825, "energy_per_token": 1.4699710122108456, "time": 2.097157, "time_per_token": 0.052428925}}
{"outputs": [{"text": " re.sub(r'[^a-zA-Z0-9\\s]', '', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^", "a", "-", "z", "A", "-", "Z", "0", "-", "9", "\\", "s", "]", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7064714431762695, -0.11333071440458298, -3.6954195820726454e-05, -0.00011407678539399058, -0.25670966506004333, -3.0040289857424796e-05, -0.0008070787298493087, -0.4819363057613373, -4.768258077092469e-05, -0.00026008085114881396, -1.1551322937011719, -0.02546836994588375, -0.2130957841873169, -0.014676935039460659, -0.00013565097469836473, -0.03861963376402855, -0.00015829740732442588, -0.006436806637793779, -0.0001811817055568099, -6.83045873302035e-05, -0.020230619236826897, -0.1514565348625183], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 40.89222048759461, "energy_per_token": 0.8345351119917267, "time": 2.5028577, "time_per_token": 0.05107872857142857}}
{"outputs": [{"text": " re.sub(r'[^a-z\\s]', '', input_str.lower())", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^", "a", "-", "z", "\\", "s", "]", "'", ",", " ''", ",", " input", "_", "str", ".", "lower", "())", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7064714431762695, -0.11333071440458298, -3.6954195820726454e-05, -0.00011407678539399058, -2.592618465423584, -0.6427374482154846, -0.485635906457901, -0.014003238640725613, -0.00012051333033014089, -0.03389943763613701, -0.00015889335190877318, -0.0055796122178435326, -0.00020430385484360158, -7.235741941258311e-05, -0.6190772652626038, -0.027031471952795982, -0.009956576861441135, -0.07985742390155792], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 34.54938795471191, "energy_per_token": 0.7677641767713758, "time": 2.3275318, "time_per_token": 0.05172292888888889}}
{"outputs": [{"text": " re.sub(r\"[^\\w\\s]\", \"\", input_str)", "tokens": [" re", ".", "sub", "(", "r", "\"", "[", "^\\", "w", "\\", "s", "]\"", ",", " \"", "\"", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -1.855602502822876, -0.1296575516462326, -1.1124632358551025, -0.0019838192965835333, -0.22870409488677979, -0.008887377567589283, -0.22598566114902496, -0.00029130507027730346, -0.14218401908874512, -0.09265166521072388, -0.00042143522296100855, -0.007226874120533466, -0.00023326536756940186, -5.1973900554003194e-05, -0.025027133524417877, -0.1439169943332672], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 37.74232336997986, "energy_per_token": 0.9205444724385331, "time": 2.1203103, "time_per_token": 0.051714885365853655}}
{"outputs": [{"text": " re.sub(r'[^\\w\\s]', '', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^\\", "w", "\\", "s", "]", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7508039474487305, -0.002834947081282735, -0.2064153403043747, -0.015148123726248741, -0.11249706894159317, -0.04138290137052536, -0.00012408917245920748, -0.0375511571764946, -0.0002256377338198945, -0.005018732510507107, -0.00019560330838430673, -5.07818695041351e-05, -0.022776544094085693, -0.1258862316608429], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 32.29546346664429, "energy_per_token": 0.7876942308937632, "time": 2.1144516, "time_per_token": 0.051571990243902445}}
{"outputs": [{"text": " ''.join(re.findall(r'\\w+', input_str))", "tokens": [" ''", ".", "join", "(", "re", ".", "find", "all", "(", "r", "'\\", "w", "+'", ",", " input", "_", "str", "))", "\n"], "logprobs": [-2.675501585006714, -0.027645429596304893, -0.00032074074260890484, -0.06810947507619858, -1.1477428674697876, -0.0001919085334520787, -0.33700239658355713, -2.3841574147809297e-05, -0.25409671664237976, -0.05833655223250389, -1.0070972442626953, -0.00798734463751316, -0.026539266109466553, -0.00021944021864328533, -0.012028539553284645, -0.00022623363474849612, -0.0001045410826918669, -0.06525178998708725, -0.11183607578277588], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict<|endoftext|>from typing import List", "tokens": [" fre", "q", "_", "dict", "<", "|", "end", "of", "text", "|>", "from", " typing", " import", " List", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -1.1903016567230225, -1.6689286894688848e-06, -1.1920922133867862e-06, -0.00011252723925281316, -0.0001037067049765028, -0.09992518275976181, -1.1740202903747559, -2.1857423782348633, -0.0029818618204444647, -0.4358684718608856, -0.16752690076828003], "finish_reason": "stop"}], "metrics": {"energy": 81.30448234176635, "energy_per_token": 1.6592751498319662, "time": 2.5414429, "time_per_token": 0.05186618163265306}}
{"outputs": [{"text": " re.sub(r\"[^a-zA-Z0-9]+\", ' ', input_str)", "tokens": [" re", ".", "sub", "(", "r", "\"", "[", "^", "a", "-", "z", "A", "-", "Z", "0", "-", "9", "]+", "\"", ",", " '", " '", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -1.855602502822876, -0.1296575516462326, -0.45409226417541504, -0.13092085719108582, -3.790783375734463e-05, -0.00011169286881340668, -0.10589268058538437, -3.611976353568025e-05, -0.0005844315164722502, -0.33067935705184937, -3.540453326422721e-05, -0.0002636561985127628, -0.6393353343009949, -0.003996125888079405, -0.0002252801787108183, -2.961066246032715, -0.0013003236381337047, -0.0004981707315891981, -0.012720987200737, -0.0002811751910485327, -7.235741941258311e-05, -0.04195748269557953, -0.24797087907791138], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str.lower())", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ".", "lower", "())", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -1.5117485523223877, -0.03891206160187721, -0.0076943691819906235, -0.0033138857688754797], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict<|endoftext|>from collections import defaultdict", "tokens": [" fre", "q", "_", "dict", "<", "|", "end", "of", "text", "|>", "from", " collections", " import", " default", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -1.1903016567230225, -1.6689286894688848e-06, -1.1920922133867862e-06, -0.00011252723925281316, -0.0001037067049765028, -0.09992518275976181, -1.1740202903747559, -1.6037389039993286, -0.0055868434719741344, -1.2658970355987549, -2.706014311115723e-05, -0.1261177510023117], "finish_reason": "stop"}], "metrics": {"energy": 49.714901158332815, "energy_per_token": 0.8149983796448003, "time": 2.9586523, "time_per_token": 0.048502496721311475}}
{"outputs": [{"text": " re.sub(r'[^a-zA-Z]', '', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^", "a", "-", "z", "A", "-", "Z", "]", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7064714431762695, -0.11333071440458298, -3.6954195820726454e-05, -0.00011407678539399058, -0.25670966506004333, -3.0040289857424796e-05, -0.0008070787298493087, -3.289585828781128, -0.013645818457007408, -0.00026544384309090674, -0.18570508062839508, -0.00023672162205912173, -0.005025374703109264, -0.00018892886873800308, -8.11782301752828e-05, -0.029836272820830345, -0.17478667199611664], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict<|endoftext|>import pytest", "tokens": [" fre", "q", "_", "dict", "<", "|", "end", "of", "text", "|>", "import", " py", "test", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -1.1903016567230225, -1.6689286894688848e-06, -1.1920922133867862e-06, -0.00011252723925281316, -0.0001037067049765028, -0.09992518275976181, -1.2138934135437012, -3.7804994583129883, -0.0760713592171669, -0.0077939690090715885], "finish_reason": "stop"}], "metrics": {"energy": 63.75089580535887, "energy_per_token": 1.2028470906671485, "time": 2.7433093, "time_per_token": 0.051760552830188676}}
{"outputs": [{"text": " re.sub(r'[^a-zA-Z0-9]', '', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^", "a", "-", "z", "A", "-", "Z", "0", "-", "9", "]", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7064714431762695, -0.11333071440458298, -3.6954195820726454e-05, -0.00011407678539399058, -0.25670966506004333, -3.0040289857424796e-05, -0.0008070787298493087, -0.4819363057613373, -4.768258077092469e-05, -0.00026008085114881396, -1.3594112396240234, -0.03773036599159241, -0.00017677174764685333, -0.47598373889923096, -0.00024399164249189198, -0.006111979018896818, -0.0002455409849062562, -5.364274329622276e-05, -0.024952024221420288, -0.1436731368303299], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 76.40306579208374, "energy_per_token": 1.62559714451242, "time": 2.3270447, "time_per_token": 0.04951158936170213}}
{"outputs": [{"text": " re.sub(r\"[^a-zA-Z]+\", '', input_str)", "tokens": [" re", ".", "sub", "(", "r", "\"", "[", "^", "a", "-", "z", "A", "-", "Z", "]+", "\"", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -1.855602502822876, -0.1296575516462326, -0.45409226417541504, -0.13092085719108582, -3.790783375734463e-05, -0.00011169286881340668, -0.10589268058538437, -3.611976353568025e-05, -0.0005844315164722502, -2.840427875518799, -0.0035893793683499098, -0.0002727136597968638, -3.0224480628967285, -0.00020323118951637298, -0.006735360249876976, -0.00033778208307921886, -6.532455881824717e-05, -0.042092014104127884, -0.17011618614196777], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict<|endoftext|>import re", "tokens": [" fre", "q", "_", "dict", "<", "|", "end", "of", "text", "|>", "import", " re", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -1.1903016567230225, -1.6689286894688848e-06, -1.1920922133867862e-06, -0.00011252723925281316, -0.0001037067049765028, -0.09992518275976181, -1.2138934135437012, -0.8087073564529419, -0.02217579446732998], "finish_reason": "stop"}], "metrics": {"energy": 42.057584608078, "energy_per_token": 0.8087997040015, "time": 2.5385337, "time_per_token": 0.048817955769230766}}
{"outputs": [{"text": " re.sub(r'[^\\w]', '', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^\\", "w", "]", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7508039474487305, -0.002834947081282735, -1.8420201539993286, -0.03982800245285034, -0.00021240839851088822, -0.8263226747512817, -0.00029225845355540514, -0.0054030814208090305, -0.0001967951684491709, -7.045020902296528e-05, -0.030010394752025604, -0.1420617699623108], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str.lower())", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ".", "lower", "())", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -1.5117485523223877, -0.03891206160187721, -0.0076943691819906235, -0.0033138857688754797], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict<|endoftext|># -*- coding: utf-8 -*-", "tokens": [" fre", "q", "_", "dict", "<", "|", "end", "of", "text", "|>", "#", " -", "*-", " coding", ":", " utf", "-", "8", " -", "*-", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -1.1903016567230225, -1.6689286894688848e-06, -1.1920922133867862e-06, -0.00011252723925281316, -0.0001037067049765028, -0.09992518275976181, -1.4735121726989746, -2.7305521965026855, -0.008710011839866638, -0.016567744314670563, -0.00198643677867949, -0.022095808759331703, -0.0025497328024357557, -7.974783511599526e-05, -0.00580257223919034, -0.00330901425331831, -0.0012450808426365256], "finish_reason": "stop"}], "metrics": {"energy": 79.76773137664793, "energy_per_token": 1.3994338838008409, "time": 2.9637804, "time_per_token": 0.05199614736842106}}
{"outputs": [{"text": " ''.join(char for char in input_str if char.isalnum() or char == ' ')", "tokens": [" ''", ".", "join", "(", "char", " for", " char", " in", " input", "_", "str", " if", " char", ".", "isal", "num", "()", " or", " char", " ==", " '", " '", ")", "\n"], "logprobs": [-2.675501585006714, -0.027645429596304893, -0.00032074074260890484, -0.06810947507619858, -1.4996601343154907, -0.05645275115966797, -0.0004545609117485583, -0.00027414379292167723, -0.02413627877831459, -0.00012516192509792745, -6.389413465512916e-05, -0.010161688551306725, -0.1388559341430664, -0.0940692201256752, -0.026621105149388313, -0.00014530557382386178, -0.7901927828788757, -0.007091708015650511, -0.008073434233665466, -1.4167546033859253, -0.17439283430576324, -0.003063154872506857, -0.03111076168715954, -0.1005600318312645], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 80.56136955833435, "energy_per_token": 1.8309402172348717, "time": 2.3272305, "time_per_token": 0.052891602272727274}}
{"outputs": [{"text": " re.sub(r'[^\\w\\s]', '', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^\\", "w", "\\", "s", "]", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7508039474487305, -0.002834947081282735, -0.2064153403043747, -0.015148123726248741, -0.11249706894159317, -0.04138290137052536, -0.00012408917245920748, -0.0375511571764946, -0.0002256377338198945, -0.005018732510507107, -0.00019560330838430673, -5.07818695041351e-05, -0.022776544094085693, -0.1258862316608429], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 34.41511337089539, "energy_per_token": 0.839393009046229, "time": 2.1116784, "time_per_token": 0.0515043512195122}}
{"outputs": [{"text": " ''.join([char.lower() for char in input_str if char.isalnum()])", "tokens": [" ''", ".", "join", "([", "char", ".", "lower", "()", " for", " char", " in", " input", "_", "str", " if", " char", ".", "isal", "num", "()", "])", "\n"], "logprobs": [-2.675501585006714, -0.027645429596304893, -0.00032074074260890484, -2.7609519958496094, -0.7083957195281982, -2.4635086059570312, -0.06624724715948105, -0.0004104725376237184, -0.21584147214889526, -0.0007051127031445503, -0.000662703241687268, -0.10173085331916809, -5.674201020156033e-05, -0.00010072677832795307, -0.02441330999135971, -0.13060559332370758, -0.010126287117600441, -0.07475260645151138, -0.0001677133986959234, -0.0002503081923350692, -0.6133398413658142, -0.02459186688065529], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str.lower())", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ".", "lower", "())", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -1.5117485523223877, -0.03891206160187721, -0.0076943691819906235, -0.0033138857688754797], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 35.08150216579437, "energy_per_token": 0.7973068674044175, "time": 2.3303869, "time_per_token": 0.05296333863636364}}
{"outputs": [{"text": " re.sub(r'[^a-zA-Z0-9]', '', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^", "a", "-", "z", "A", "-", "Z", "0", "-", "9", "]", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7064714431762695, -0.11333071440458298, -3.6954195820726454e-05, -0.00011407678539399058, -0.25670966506004333, -3.0040289857424796e-05, -0.0008070787298493087, -0.4819363057613373, -4.768258077092469e-05, -0.00026008085114881396, -1.3594112396240234, -0.03773036599159241, -0.00017677174764685333, -0.47598373889923096, -0.00024399164249189198, -0.006111979018896818, -0.0002455409849062562, -5.364274329622276e-05, -0.024952024221420288, -0.1436731368303299], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict<|endoftext|>import re", "tokens": [" fre", "q", "_", "dict", "<", "|", "end", "of", "text", "|>", "import", " re", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -1.1903016567230225, -1.6689286894688848e-06, -1.1920922133867862e-06, -0.00011252723925281316, -0.0001037067049765028, -0.09992518275976181, -1.2138934135437012, -0.8087073564529419, -0.02217579446732998], "finish_reason": "stop"}], "metrics": {"energy": 53.53856491088866, "energy_per_token": 0.9734284529252484, "time": 2.7479734, "time_per_token": 0.049963152727272725}}
{"outputs": [{"text": " re.sub('[^a-zA-Z\\s]+', '', input_str)", "tokens": [" re", ".", "sub", "('", "[", "^", "a", "-", "z", "A", "-", "Z", "\\", "s", "]+", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -1.413030743598938, -0.0900479182600975, -0.18210521340370178, -0.19884589314460754, -2.90866428258596e-05, -0.00010561384988250211, -0.20175108313560486, -3.0517112463712692e-05, -0.000730247818864882, -2.0490660667419434, -0.11552494019269943, -0.7579620480537415, -0.004320691339671612, -0.00027021096320822835, -0.025639651343226433, -0.00017653337272349745, -0.005153941456228495, -0.00029583368450403214, -7.128461584215984e-05, -0.020278047770261765, -0.1473528891801834], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 36.17083128547668, "energy_per_token": 0.8220643473971972, "time": 2.3251321, "time_per_token": 0.05284391136363636}}
{"outputs": [{"text": " re.sub(r\"[^a-zA-Z]+\", \" \", input_str).strip()", "tokens": [" re", ".", "sub", "(", "r", "\"", "[", "^", "a", "-", "z", "A", "-", "Z", "]+", "\"", ",", " \"", " \"", ",", " input", "_", "str", ")", ".", "strip", "()", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -1.855602502822876, -0.1296575516462326, -0.45409226417541504, -0.13092085719108582, -3.790783375734463e-05, -0.00011169286881340668, -0.10589268058538437, -3.611976353568025e-05, -0.0005844315164722502, -2.840427875518799, -0.0035893793683499098, -0.0002727136597968638, -0.10578962415456772, -0.6079856753349304, -0.000196556793525815, -0.012071059085428715, -0.00021324267436284572, -6.139089964563027e-05, -0.04102747142314911, -1.792309045791626, -1.2281659841537476, -0.00367881846614182, -0.1450015753507614], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str.lower())", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ".", "lower", "())", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -1.5117485523223877, -0.03891206160187721, -0.0076943691819906235, -0.0033138857688754797], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict<|endoftext|>from collections import Counter", "tokens": [" fre", "q", "_", "dict", "<", "|", "end", "of", "text", "|>", "from", " collections", " import", " Counter", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -1.1903016567230225, -1.6689286894688848e-06, -1.1920922133867862e-06, -0.00011252723925281316, -0.0001037067049765028, -0.09992518275976181, -1.1740202903747559, -1.6037389039993286, -0.0055868434719741344, -1.0199081897735596, -0.07865682989358902], "finish_reason": "stop"}], "metrics": {"energy": 46.91627715015412, "energy_per_token": 0.7819379525025687, "time": 2.9614296, "time_per_token": 0.049357160000000004}}
{"outputs": [{"text": " re.sub(r'[^A-Za-z0-9\\s]', '', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^", "A", "-", "Z", "a", "-", "z", "0", "-", "9", "\\", "s", "]", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7064714431762695, -2.338020086288452, -2.2053474822314456e-05, -0.0022087718825787306, -0.0008755664457567036, -1.0251946150674485e-05, -1.1205610462639015e-05, -0.27291569113731384, -8.201262971851975e-05, -0.00022516099852509797, -1.5773959159851074, -0.08780574053525925, -0.36237138509750366, -0.020103858783841133, -9.822363062994555e-05, -0.03669506683945656, -0.00015233787416946143, -0.008940309286117554, -0.00021109737281221896, -5.507317473529838e-05, -0.054059453308582306, -0.22327305376529694], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict<|endoftext|>import re", "tokens": [" fre", "q", "_", "dict", "<", "|", "end", "of", "text", "|>", "import", " re", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -1.1903016567230225, -1.6689286894688848e-06, -1.1920922133867862e-06, -0.00011252723925281316, -0.0001037067049765028, -0.09992518275976181, -1.2138934135437012, -0.8087073564529419, -0.02217579446732998], "finish_reason": "stop"}], "metrics": {"energy": 48.64901600646973, "energy_per_token": 0.8534915088854338, "time": 2.953142, "time_per_token": 0.05180950877192983}}
{"outputs": [{"text": " re.sub(r'[^\\w\\s]', '', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^\\", "w", "\\", "s", "]", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7508039474487305, -0.002834947081282735, -0.2064153403043747, -0.015148123726248741, -0.11249706894159317, -0.04138290137052536, -0.00012408917245920748, -0.0375511571764946, -0.0002256377338198945, -0.005018732510507107, -0.00019560330838430673, -5.07818695041351e-05, -0.022776544094085693, -0.1258862316608429], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06], "finish_reason": "stop"}], "metrics": {"energy": 66.08872704696657, "energy_per_token": 1.652218176174164, "time": 2.121344, "time_per_token": 0.0530336}}
{"outputs": [{"text": " re.sub(r'[^a-zA-Z0-9]+', '', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^", "a", "-", "z", "A", "-", "Z", "0", "-", "9", "]+", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7064714431762695, -0.11333071440458298, -3.6954195820726454e-05, -0.00011407678539399058, -0.25670966506004333, -3.0040289857424796e-05, -0.0008070787298493087, -0.4819363057613373, -4.768258077092469e-05, -0.00026008085114881396, -1.3268795013427734, -0.0034746292512863874, -0.00014602071314584464, -0.9164153933525085, -0.00025197668583132327, -0.006937227211892605, -0.00026854246971197426, -5.066266385256313e-05, -0.02828972227871418, -0.1607985645532608], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str.lower())", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ".", "lower", "())", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -1.5117485523223877, -0.03891206160187721, -0.0076943691819906235, -0.0033138857688754797], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 59.70417801094055, "energy_per_token": 1.2184526124681745, "time": 2.5416245, "time_per_token": 0.05186988775510205}}
{"outputs": [{"text": " re.sub('[^a-zA-Z0-9]', '', input_str)", "tokens": [" re", ".", "sub", "('", "[", "^", "a", "-", "z", "A", "-", "Z", "0", "-", "9", "]", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -1.413030743598938, -0.0900479182600975, -0.18210521340370178, -0.19884589314460754, -2.90866428258596e-05, -0.00010561384988250211, -0.20175108313560486, -3.0517112463712692e-05, -0.000730247818864882, -0.37168648838996887, -4.684815212385729e-05, -0.00024875884992070496, -1.1505661010742188, -0.011616210453212261, -0.00025149996508844197, -0.3733857572078705, -0.00031394799589179456, -0.005105908960103989, -0.00021801002731081098, -5.638440416078083e-05, -0.02685532160103321, -0.1377614587545395], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 72.28055496025084, "energy_per_token": 1.606234554672241, "time": 2.3288593, "time_per_token": 0.05175242888888889}}
{"outputs": [{"text": " re.sub(r'[^a-zA-Z\\s]', '', input_str).lower()", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^", "a", "-", "z", "A", "-", "Z", "\\", "s", "]", "'", ",", " ''", ",", " input", "_", "str", ")", ".", "lower", "()", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7064714431762695, -0.11333071440458298, -3.6954195820726454e-05, -0.00011407678539399058, -0.25670966506004333, -3.0040289857424796e-05, -0.0008070787298493087, -1.3441017866134644, -0.1386745572090149, -0.41219696402549744, -0.006964337080717087, -0.00014184899919200689, -0.04118867218494415, -0.00016425691137555987, -0.004857524763792753, -0.00022206225548870862, -5.376194530981593e-05, -0.02033505216240883, -2.769280433654785, -0.1378551423549652, -0.0002884448622353375, -0.1290278285741806], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict<|endoftext|>import unittest", "tokens": [" fre", "q", "_", "dict", "<", "|", "end", "of", "text", "|>", "import", " un", "ittest", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -1.1903016567230225, -1.6689286894688848e-06, -1.1920922133867862e-06, -0.00011252723925281316, -0.0001037067049765028, -0.09992518275976181, -1.2138934135437012, -2.5157241821289062, -0.014424690045416355, -0.00875314511358738], "finish_reason": "stop"}], "metrics": {"energy": 53.750384453773506, "energy_per_token": 0.9267307664443708, "time": 2.964948, "time_per_token": 0.05111979310344828}}
{"outputs": [{"text": " re.sub(r'[^A-Za-z0-9]', ' ', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^", "A", "-", "Z", "a", "-", "z", "0", "-", "9", "]", "'", ",", " '", " '", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7064714431762695, -2.338020086288452, -2.2053474822314456e-05, -0.0022087718825787306, -0.0008755664457567036, -1.0251946150674485e-05, -1.1205610462639015e-05, -0.27291569113731384, -8.201262971851975e-05, -0.00022516099852509797, -2.427154064178467, -0.04131587594747543, -0.00013243274588603526, -1.2026550769805908, -0.0010852882405743003, -0.00025876989820972085, -0.007381665054708719, -0.0002613918040879071, -6.592056161025539e-05, -0.07628720998764038, -0.31380000710487366], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06], "finish_reason": "stop"}], "metrics": {"energy": 38.247861682891845, "energy_per_token": 0.8137842911253584, "time": 2.3265226, "time_per_token": 0.04950048085106383}}
{"outputs": [{"text": " re.sub('[^a-zA-Z0-9]', '', input_str)", "tokens": [" re", ".", "sub", "('", "[", "^", "a", "-", "z", "A", "-", "Z", "0", "-", "9", "]", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -1.413030743598938, -0.0900479182600975, -0.18210521340370178, -0.19884589314460754, -2.90866428258596e-05, -0.00010561384988250211, -0.20175108313560486, -3.0517112463712692e-05, -0.000730247818864882, -0.37168648838996887, -4.684815212385729e-05, -0.00024875884992070496, -1.1505661010742188, -0.011616210453212261, -0.00025149996508844197, -0.3733857572078705, -0.00031394799589179456, -0.005105908960103989, -0.00021801002731081098, -5.638440416078083e-05, -0.02685532160103321, -0.1377614587545395], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06], "finish_reason": "stop"}], "metrics": {"energy": 37.48427274322509, "energy_per_token": 0.8519152896187521, "time": 2.3315978, "time_per_token": 0.05299085909090909}}
{"outputs": [{"text": " re.sub('[\\W_]+', ' ', input_str)", "tokens": [" re", ".", "sub", "('", "[\\", "W", "_", "]+", "'", ",", " '", " '", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -1.413030743598938, -2.988229751586914, -0.022107934579253197, -0.17618398368358612, -0.26251542568206787, -0.007098454982042313, -0.00029416524921543896, -0.13778690993785858, -0.0005519058904610574, -0.0003228858404327184, -0.007689282298088074, -0.00019143179815728217, -5.280832192511298e-05, -0.01875465363264084, -0.33443301916122437], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 68.21770483016967, "energy_per_token": 1.7952027586886754, "time": 2.1127567, "time_per_token": 0.05559886052631578}}
{"outputs": [{"text": " re.sub(r\"[^a-zA-Z0-9]+\", \" \", input_str)", "tokens": [" re", ".", "sub", "(", "r", "\"", "[", "^", "a", "-", "z", "A", "-", "Z", "0", "-", "9", "]+", "\"", ",", " \"", " \"", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -1.855602502822876, -0.1296575516462326, -0.45409226417541504, -0.13092085719108582, -3.790783375734463e-05, -0.00011169286881340668, -0.10589268058538437, -3.611976353568025e-05, -0.0005844315164722502, -0.33067935705184937, -3.540453326422721e-05, -0.0002636561985127628, -0.6393353343009949, -0.003996125888079405, -0.0002252801787108183, -0.1586638242006302, -0.35496050119400024, -0.0002821285743266344, -0.010626280680298805, -0.0002127659390680492, -4.8040190449682996e-05, -0.036438316106796265, -0.2931601405143738], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 46.328841342926026, "energy_per_token": 0.9651841946442922, "time": 2.5418794, "time_per_token": 0.052955820833333334}}
{"outputs": [{"text": " re.sub(r'[^a-zA-Z0-9\\s]', '', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^", "a", "-", "z", "A", "-", "Z", "0", "-", "9", "\\", "s", "]", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7064714431762695, -0.11333071440458298, -3.6954195820726454e-05, -0.00011407678539399058, -0.25670966506004333, -3.0040289857424796e-05, -0.0008070787298493087, -0.4819363057613373, -4.768258077092469e-05, -0.00026008085114881396, -1.1551322937011719, -0.02546836994588375, -0.2130957841873169, -0.014676935039460659, -0.00013565097469836473, -0.03861963376402855, -0.00015829740732442588, -0.006436806637793779, -0.0001811817055568099, -6.83045873302035e-05, -0.020230619236826897, -0.1514565348625183], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict<|endoftext|>from typing import List", "tokens": [" fre", "q", "_", "dict", "<", "|", "end", "of", "text", "|>", "from", " typing", " import", " List", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -1.1903016567230225, -1.6689286894688848e-06, -1.1920922133867862e-06, -0.00011252723925281316, -0.0001037067049765028, -0.09992518275976181, -1.1740202903747559, -2.1857423782348633, -0.0029818618204444647, -0.4358684718608856, -0.16752690076828003], "finish_reason": "stop"}], "metrics": {"energy": 59.98330066871644, "energy_per_token": 1.0166661130290922, "time": 2.9603891, "time_per_token": 0.05017608644067797}}
{"outputs": [{"text": " re.sub(r'[^\\w\\s]', '', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^\\", "w", "\\", "s", "]", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7508039474487305, -0.002834947081282735, -0.2064153403043747, -0.015148123726248741, -0.11249706894159317, -0.04138290137052536, -0.00012408917245920748, -0.0375511571764946, -0.0002256377338198945, -0.005018732510507107, -0.00019560330838430673, -5.07818695041351e-05, -0.022776544094085693, -0.1258862316608429], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict<|endoftext|># https://codingcompetitions.withgoogle.com/kickstart/round/00000000000000b4/00000000001d5762", "tokens": [" fre", "q", "_", "dict", "<", "|", "end", "of", "text", "|>", "#", " https", "://", "c", "oding", "compet", "itions", ".", "with", "google", ".", "com", "/", "kick", "start", "/", "round", "/", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", "b", "4", "/", "0", "0", "0", "0", "0", "0", "0", "0", "0", "0", "1", "d", "5", "7", "6", "2", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -1.1903016567230225, -1.6689286894688848e-06, -1.1920922133867862e-06, -0.00011252723925281316, -0.0001037067049765028, -0.09992518275976181, -1.4735121726989746, -4.226233005523682, -0.0019063648069277406, -4.175938606262207, -0.3394736647605896, -1.5317736864089966, -0.01785491406917572, -4.029192859889008e-05, -0.008408619090914726, -0.00013863079948350787, -1.5616295058862306e-05, -1.1920928244535389e-07, -0.0048436447978019714, -1.1052840948104858, -0.012805729173123837, -0.004245435819029808, -0.03132891282439232, -0.0018243826925754547, -0.004043261986225843, -0.0011457790387794375, -0.005010192282497883, -0.0010413468116894364, -0.009857664816081524, -0.0013672299683094025, -0.08141102641820908, -0.0075547704473137856, -0.0025015748105943203, -0.03884280472993851, -1.5832300186157227, -1.7721805572509766, -1.1260225772857666, -0.2914469838142395, -2.3571555614471436, -2.0012593269348145, -0.007099520415067673, -0.00038842763751745224, -1.311301275563892e-06, -1.1920928244535389e-07, -7.152555099310121e-07, -7.152531907195225e-06, -2.5987286790041253e-05, -7.83174327807501e-05, -1.966933996300213e-05, -2.2053474822314456e-05, -1.4066597032069694e-05, -0.8511414527893066, -1.679140567779541, -0.37716320157051086, -2.4854445457458496, -2.4582364559173584, -2.1305274963378906, -0.03211122378706932], "finish_reason": "stop"}], "metrics": {"energy": 130.7802382469177, "energy_per_token": 1.3344922270093642, "time": 4.632124, "time_per_token": 0.04726657142857143}}
{"outputs": [{"text": " re.sub(r'[^a-zA-Z0-9 ]+', '', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^", "a", "-", "z", "A", "-", "Z", "0", "-", "9", " ]", "+'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7064714431762695, -0.11333071440458298, -3.6954195820726454e-05, -0.00011407678539399058, -0.25670966506004333, -3.0040289857424796e-05, -0.0008070787298493087, -0.4819363057613373, -4.768258077092469e-05, -0.00026008085114881396, -2.234760284423828, -1.0589215755462646, -0.00013851160474587232, -0.04950353130698204, -0.00021741411183029413, -0.005934831220656633, -0.0002208704245276749, -4.8874615458771586e-05, -0.01853187195956707, -0.13427238166332245], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 69.25961212539674, "energy_per_token": 1.4736087686254626, "time": 2.5410757, "time_per_token": 0.054065440425531915}}
{"outputs": [{"text": " re.sub(r'[^a-zA-Z0-9\\s]', '', input_str)", "tokens": [" re", ".", "sub", "(", "r", "'", "[", "^", "a", "-", "z", "A", "-", "Z", "0", "-", "9", "\\", "s", "]", "'", ",", " ''", ",", " input", "_", "str", ")", "\n"], "logprobs": [-0.11366348713636398, -6.437094270950183e-05, -0.017986759543418884, -0.2799283266067505, -0.04326525703072548, -0.2091715782880783, -0.058576278388500214, -0.7064714431762695, -0.11333071440458298, -3.6954195820726454e-05, -0.00011407678539399058, -0.25670966506004333, -3.0040289857424796e-05, -0.0008070787298493087, -0.4819363057613373, -4.768258077092469e-05, -0.00026008085114881396, -1.1551322937011719, -0.02546836994588375, -0.2130957841873169, -0.014676935039460659, -0.00013565097469836473, -0.03861963376402855, -0.00015829740732442588, -0.006436806637793779, -0.0001811817055568099, -6.83045873302035e-05, -0.020230619236826897, -0.1514565348625183], "finish_reason": "stop"}, {"text": " word_tokenize(cleaned_str)", "tokens": [" word", "_", "token", "ize", "(", "cleaned", "_", "str", ")", "\n"], "logprobs": [-0.03937472030520439, -6.139089964563027e-05, -2.1815061700181104e-05, -5.602820692729438e-06, -0.00021288513380568475, -0.0019358720164746046, -1.0013530300057027e-05, -1.1324817933200393e-05, -0.24957972764968872, -0.0031499075703322887], "finish_reason": "stop"}, {"text": " Counter(words)", "tokens": [" Counter", "(", "words", ")", "\n"], "logprobs": [-0.016111653298139572, -0.0018581758486106992, -0.00327467592433095, -0.0022166224662214518, -0.005389564670622349], "finish_reason": "stop"}, {"text": " freq_dict", "tokens": [" fre", "q", "_", "dict", "\n"], "logprobs": [-0.015132742002606392, -8.344646857949556e-07, -0.00012754580529872328, -6.079655122448457e-06, -0.5732858777046204], "finish_reason": "stop"}], "metrics": {"energy": 50.848229194641114, "energy_per_token": 1.0377189631559411, "time": 2.5369906, "time_per_token": 0.051775318367346945}}
