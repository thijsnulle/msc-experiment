{"outputs": [{"text": " RegexpTokenizer(r'$\\w+')", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "'", "$\\", "w", "+", "')", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -2.0277657508850098, -2.729586601257324, -0.07622116059064865, -0.4036823809146881, -0.053359005600214005, -0.17127908766269684], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if len(word) > 1 and word[1:].isalnum()]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " len", "(", "word", ")", " >", " ", "1", " and", " word", "[", "1", ":]", ".", "isal", "num", "()", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -1.2227665185928345, -0.00028200942324474454, -0.0016307639889419079, -0.1675470620393753, -0.03233261778950691, -0.0014455594355240464, -0.02093258872628212, -2.0524466037750244, -0.10575015842914581, -0.16852967441082, -0.04150424897670746, -0.1292870044708252, -0.005961138755083084, -0.06540410220623016, -1.1205610462639015e-05, -0.0012213874142616987, -0.0035036150366067886, -0.003177833277732134], "finish_reason": "stop"}, {"text": " [word[1:] if word.startswith('$') else word for word in dollar_prefixed_words]", "tokens": [" [", "word", "[", "1", ":]", " if", " word", ".", "start", "sw", "ith", "('", "$", "')", " else", " word", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.7551983594894409, -0.0016076747560873628, -0.0016214807983487844, -1.573312520980835, -0.07508508861064911, -0.3589309751987457, -0.016835158690810204, -1.1205610462639015e-05, -2.3841855067985307e-07, -0.4768051207065582, -0.16251644492149353, -0.00017736769223120064, -0.02192321978509426, -0.016267186030745506, -0.02665569633245468, -0.0003405229654163122, -0.0001911934232339263, -0.000739539333153516, -1.1920928244535389e-07, -1.5497195136049413e-06, -5.960462772236497e-07, -1.1920922133867862e-06, -4.768370445162873e-07, -0.01884356513619423, -0.016322309151291847], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.021463146433234215, -0.007004231214523315, -0.023815639317035675, -1.7881377516459906e-06, -1.1205610462639015e-05, -0.0008141063735820353, -0.13045723736286163], "finish_reason": "stop"}, {"text": " sorted([(word, count) for word, count in word_counts.items() if word != \"\"], key=lambda x: x[1], reverse=True)[:5]<|endoftext|>import re", "tokens": [" sorted", "([", "(", "word", ",", " count", ")", " for", " word", ",", " count", " in", " word", "_", "counts", ".", "items", "()", " if", " word", " ", "!", "=", " \"", "\"", "]", ",", " key", "=", "lambda", " x", ":", " x", "[", "1", "]", ",", " reverse", "=", "True", ")", "[:", "5", "]<", "|", "end", "of", "text", "|>", "import", " re", "\n"], "logprobs": [-2.737856388092041, -2.563716411590576, -0.1078638955950737, -0.21775414049625397, -0.03214874118566513, -0.03858683258295059, -0.000726316764485091, -0.003096311818808317, -0.0076600625179708, -3.635817120084539e-05, -0.0004766043566633016, -0.0001062098381225951, -0.005157499574124813, -8.344646857949556e-07, -1.1920928244535389e-07, -0.001262820791453123, -0.028597114607691765, -0.0007008241955190897, -0.5713574886322021, -0.450776606798172, -0.5179768204689026, -1.7762025890988298e-05, -0.0002847504511009902, -1.14349365234375, -0.46253320574760437, -0.08403557538986206, -0.0003398079425096512, -0.12171682715415955, -0.0014569868799299002, -0.0007453762227669358, -0.04500322788953781, -0.00031144535751082003, -0.2950688302516937, -0.0006445952458307147, -0.002478981390595436, -0.0035331938415765762, -6.48477507638745e-05, -0.13348689675331116, -0.001069212332367897, -0.0019971441943198442, -0.21159584820270538, -0.09732097387313843, -0.020516324788331985, -1.1038382053375244, -7.986990567587782e-06, -2.145764938177308e-06, -3.933898824470816e-06, -4.0531076592742465e-06, -0.1443435549736023, -1.3877476453781128, -2.1564526557922363, -0.016184262931346893], "finish_reason": "stop"}], "metrics": {"energy": 576.6589374828342, "energy_per_token": 4.303424906588314, "time": 14.870592, "time_per_token": 0.11097456716417911}}
{"outputs": [{"text": " RegexpTokenizer(r\"\\$\\w+\\b\")", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "\"", "\\", "$\\", "w", "+\\", "b", "\"", ")", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -1.064791202545166, -0.39815524220466614, -0.31417316198349, -0.03354894369840622, -2.3850269317626953, -1.129434585571289, -0.05166539549827576, -0.06307961791753769, -0.1553061306476593], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if word.startswith(\"$\") and word != '$']", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " word", ".", "start", "sw", "ith", "(", "\"", "$", "\"", ")", " and", " word", " ", "!", "=", " '$", "']", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -0.6267849206924438, -1.3537120819091797, -0.011074034497141838, -1.0132738680113107e-05, 0.0, -1.1721150875091553, -0.029114823788404465, -0.00302381650544703, -7.760223525110632e-05, -0.764987051486969, -0.025313563644886017, -0.4008100628852844, -0.46750837564468384, -1.311301275563892e-06, -0.0002628219372127205, -1.1054506301879883, -0.003642592579126358, -0.008647731505334377], "finish_reason": "stop"}, {"text": " [word[1:] for word in dollar_prefixed_words if word != '$']", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", " if", " word", " ", "!", "=", " '$", "']", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.7551983594894409, -0.0016076747560873628, -0.0016214807983487844, -0.38257384300231934, -0.0003418338019400835, -6.544376083184034e-05, -0.0004602803383022547, -1.1920928244535389e-07, -3.3378546504536644e-06, -7.510157047363464e-06, -3.2186455882765586e-06, -2.50339189733495e-06, -0.5047262907028198, -0.4751542806625366, -1.0273011922836304, -2.622600959512056e-06, -0.00011932138295378536, -0.507394015789032, -0.0011959074763581157, -0.06120495870709419], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.021463146433234215, -0.007004231214523315, -0.023815639317035675, -1.7881377516459906e-06, -1.1205610462639015e-05, -0.0008141063735820353, -0.13045723736286163], "finish_reason": "stop"}, {"text": " word_counts.most_common(3)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "3", ")", "\n"], "logprobs": [-0.31380322575569153, -1.3947389561508317e-05, -9.536697689327411e-06, -0.017802685499191284, -0.00013469743134919554, -2.109982233378105e-05, -0.0001174142598756589, -0.06182340160012245, -1.1866177320480347, -0.10877112299203873, -0.261724054813385], "finish_reason": "stop"}], "metrics": {"energy": 393.5137865524292, "energy_per_token": 4.32432732475197, "time": 11.366617, "time_per_token": 0.12490787912087911}}
{"outputs": [{"text": " RegexpTokenizer('[$]\\w+')  # Only words that start with \"$\"", "tokens": [" Re", "gex", "p", "Token", "izer", "('", "[$", "]\\", "w", "+", "')", "  ", "#", " Only", " words", " that", " start", " with", " \"", "$", "\"", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -2.585906505584717, -1.3339588642120361, -0.6150600910186768, -0.01095813512802124, -0.5408840179443359, -0.04068908095359802, -2.059361219406128, -0.00045253525604493916, -4.016908168792725, -2.942091226577759, -1.7653172016143799, -0.20805376768112183, -0.0036953275557607412, -0.8223695755004883, -0.0003251500893384218, -0.0007138088112697005, -0.6278566718101501], "finish_reason": "stop"}, {"text": " [word.lower().replace('$', '') for word in tokenizer.tokenize(text) if len(word) > 1]", "tokens": [" [", "word", ".", "lower", "()", ".", "replace", "('", "$'", ",", " '", "')", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " len", "(", "word", ")", " >", " ", "1", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.9864199757575989, -2.3837521076202393, -0.5115571022033691, -0.46919044852256775, -1.4050015211105347, -0.4485195577144623, -0.06593424826860428, -2.9682672902708873e-05, -0.017231984063982964, -0.00029583368450403214, -0.06341677904129028, -0.0005995621904730797, -0.0010794533882290125, -0.0126496572047472, -1.537788011773955e-05, -0.0002431573811918497, -0.00018070495571009815, -2.3841855067985307e-07, -0.00044741155579686165, -0.0034827073104679585, -0.2889438271522522, -0.13028155267238617, -1.4421911239624023, -0.0002649671514518559, -0.004140020813792944, -0.054129358381032944, -0.03248056769371033, -0.0005889588501304388, -0.035314686596393585, -0.011305555701255798, -0.002187599427998066], "finish_reason": "stop"}, {"text": " [word[1:] if word.startswith('$$') else word for word in dollar_prefixed_words]", "tokens": [" [", "word", "[", "1", ":]", " if", " word", ".", "start", "sw", "ith", "('", "$$", "')", " else", " word", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.7551983594894409, -0.0016076747560873628, -0.0016214807983487844, -1.573312520980835, -0.07508508861064911, -0.3589309751987457, -0.016835158690810204, -1.1205610462639015e-05, -2.3841855067985307e-07, -0.4768051207065582, -1.901549220085144, -0.015766017138957977, -0.048598457127809525, -0.001441036001779139, -0.11217158287763596, -0.0005489272880367935, -0.00026973424246534705, -0.000675807474181056, -1.1920928244535389e-07, -7.152555099310121e-07, -1.1920922133867862e-06, -9.536738616588991e-07, -3.576278118089249e-07, -0.022375619038939476, -0.025340180844068527], "finish_reason": "stop"}, {"text": " Counter(normalized_words).most_common()", "tokens": [" Counter", "(", "normalized", "_", "words", ")", ".", "most", "_", "common", "()", "\n"], "logprobs": [-0.021463146433234215, -0.007004231214523315, -0.023815639317035675, -1.7881377516459906e-06, -1.1205610462639015e-05, -0.0008141063735820353, -2.1452314853668213, -0.007500818464905024, -5.960462772236497e-07, -8.344646857949556e-07, -1.0694091320037842, -0.017245925962924957], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")"], "logprobs": [-0.31380322575569153, -1.3947389561508317e-05, -9.536697689327411e-06, -0.017802685499191284, -0.00013469743134919554, -2.109982233378105e-05, -0.0001174142598756589, -0.06182340160012245, -0.44775667786598206, -0.24642671644687653], "finish_reason": "stop"}], "metrics": {"energy": 456.82918077278117, "energy_per_token": 4.392588276661358, "time": 12.401959, "time_per_token": 0.11924960576923077}}
{"outputs": [{"text": " RegexpTokenizer(r'[$]\\w+')", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "'", "[$", "]\\", "w", "+", "')", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -2.0277657508850098, -0.7976294159889221, -0.5663504004478455, -0.009590976871550083, -0.4680459499359131, -0.029488172382116318, -0.14388912916183472], "finish_reason": "stop"}, {"text": " tokenizer.tokenize(text)", "tokens": [" token", "izer", ".", "token", "ize", "(", "text", ")", "\n"], "logprobs": [-2.154740333557129, -7.10462118149735e-05, -0.0001726001501083374, -0.00024637524620629847, 0.0, -0.001302585587836802, -0.005635445937514305, -0.02854347601532936, -0.006006760522723198], "finish_reason": "stop"}, {"text": " [word[1:] for word in dollar_prefixed_words if not re.match(r'^\\$\\$', word)]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", " if", " not", " re", ".", "match", "(", "r", "'^", "\\", "$\\", "$'", ",", " word", ")]", "\n"], "logprobs": [-0.09502872079610825, -0.05808248743414879, -0.7117553353309631, -0.0016098171472549438, -0.0013383012264966965, -0.373071551322937, -0.0003404037852305919, -7.533743337262422e-05, -0.0005013877525925636, -1.1920928244535389e-07, -2.3841830625315197e-06, -8.106198947643861e-06, -3.099436753473128e-06, -2.264974000354414e-06, -0.45563551783561707, -2.391611099243164, -1.8728699684143066, -4.0649541915627196e-05, -0.05836331844329834, -0.07854045927524567, -0.0060667176730930805, -0.6944561004638672, -0.005324824247509241, -0.4390852451324463, -2.1562156677246094, -0.0003233625029679388, -0.003449800657108426, -0.03252222761511803, -0.04232069477438927], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.021235598251223564, -0.007642672397196293, -0.023203516378998756, -1.6689286894688848e-06, -1.1444026313256472e-05, -0.0008515069494023919, -0.12573538720607758], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")", "\n"], "logprobs": [-0.2808639705181122, -1.2397689715726301e-05, -6.079655122448457e-06, -0.019382834434509277, -0.00012385078298393637, -1.490105023549404e-05, -8.844937838148326e-05, -0.0654238685965538, -0.43643850088119507, -0.24772869050502777, -0.23774345219135284], "finish_reason": "stop"}], "metrics": {"energy": 315.58705163574217, "energy_per_token": 4.508386451939174, "time": 9.262793, "time_per_token": 0.1323256142857143}}
{"outputs": [{"text": " RegexpTokenizer(r\"[$]\\w+\")", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "\"", "[$", "]\\", "w", "+", "\"", ")", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -1.064791202545166, -1.574981689453125, -0.7070456743240356, -0.010596085339784622, -0.15478895604610443, -0.11339137703180313, -0.07864603400230408, -0.11174141615629196], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if word[1:].isalnum()]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " word", "[", "1", ":]", ".", "isal", "num", "()", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -0.6267849206924438, -0.7294026017189026, -0.24066287279129028, -0.12729685008525848, -0.15129801630973816, -0.08109229803085327, -5.722029527532868e-06, -0.00048160876031033695, -0.031589288264513016, -0.008542661555111408], "finish_reason": "stop"}, {"text": " [word.lstrip(\"$\") for word in dollar_prefixed_words]", "tokens": [" [", "word", ".", "lst", "rip", "(", "\"", "$", "\"", ")", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -2.1227641105651855, -8.583032467868179e-06, -1.2958266735076904, -0.004805918782949448, -0.004316655918955803, -0.0017403707606717944, -0.00027640812913887203, -0.2885640561580658, -0.0008335214806720614, -0.00010930894495686516, -0.0008725888328626752, -3.576278118089249e-07, -9.536738616588991e-07, -8.129743218887597e-05, -1.1920922133867862e-06, -2.861018856492592e-06, -0.759345531463623, -0.009979120455682278], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.021231748163700104, -0.007705725263804197, -0.017180191352963448, -1.9073468138230965e-06, -9.775113539944869e-06, -0.0008025524439290166, -0.12247637659311295], "finish_reason": "stop"}, {"text": " word_counts.most_common(3)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "3", ")", "\n"], "logprobs": [-0.22913362085819244, -1.2636104656849056e-05, -5.8412379075889476e-06, -0.01955738104879856, -0.00010978573118336499, -1.8000440832111053e-05, -8.296622399939224e-05, -0.058542098850011826, -1.2348114252090454, -0.12879225611686707, -0.26558127999305725], "finish_reason": "stop"}], "metrics": {"energy": 377.325305185318, "energy_per_token": 4.658337101053308, "time": 10.306937, "time_per_token": 0.12724613580246913}}
{"outputs": [{"text": " RegexpTokenizer(r\"\\$\\w+\", gaps=False)", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "\"", "\\", "$\\", "w", "+", "\"", ",", " gaps", "=", "False", ")", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -1.064791202545166, -0.39815524220466614, -0.31417316198349, -0.03354894369840622, -0.1571749746799469, -0.03231807425618172, -2.9640614986419678, -0.061710771173238754, -0.0005858612130396068, -0.06911244243383408, -0.009601366706192493, -0.19685868918895721], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if word[1:].isalpha()]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " word", "[", "1", ":]", ".", "is", "alpha", "()", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -0.6267849206924438, -0.7294026017189026, -0.24066287279129028, -0.12729685008525848, -0.15129801630973816, -2.594329357147217, -0.01365816593170166, -0.0005343916127458215, -0.045730963349342346, -0.010757195763289928], "finish_reason": "stop"}, {"text": " [word.replace(\"$\", \"\") for word in dollar_prefixed_words if", "tokens": [" [", "word", ".", "replace", "(", "\"", "$", "\"", ",", " \"", "\"", ")", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", " if", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -1.1261801719665527, -1.122764229774475, -0.00835695955902338, -0.2894584834575653, -0.00030489088385365903, -7.247662142617628e-05, -0.03777318447828293, -0.0008466235012747347, -0.018531637266278267, -0.14280220866203308, -0.0007937379996292293, -0.00010573305189609528, -0.00048673225683160126, -3.576278118089249e-07, -2.264974000354414e-06, -1.0728830375228426e-06, -2.622600959512056e-06, -4.768360213347478e-06, -1.1916511058807373, -3.1809945106506348], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.02134821191430092, -0.008276568725705147, -0.01779027283191681, -1.6689286894688848e-06, -1.4185804502631072e-05, -0.0006183857913129032, -0.10062384605407715], "finish_reason": "stop"}, {"text": " sorted(word_counts.most_common(5), key=lambda x: (x[1], x[0]), reverse=True)", "tokens": [" sorted", "(", "word", "_", "counts", ".", "most", "_", "common", "(", "5", ")", ",", " key", "=", "lambda", " x", ":", " (", "x", "[", "1", "]", ",", " x", "[", "0", "])", ",", " reverse", "=", "True", ")", "\n"], "logprobs": [-3.0118894577026367, -0.06326371431350708, -0.04557857662439346, -2.50339189733495e-06, -5.960462772236497e-07, -0.0034319807309657335, -1.7074943780899048, -6.794906312279636e-06, -5.8412379075889476e-06, -0.3086107671260834, -0.4479772746562958, -0.014103623107075691, -0.0017987991450354457, -0.027872219681739807, -0.0009260656661354005, -0.0013455632142722607, -0.060778431594371796, -0.00031442465842701495, -2.774994373321533, -0.0071015325374901295, -0.002420236123725772, -0.013872513547539711, -0.004551764577627182, -0.0022436226718127728, -0.030734436586499214, -0.0008175606490112841, -0.000636255950666964, -0.051148928701877594, -0.0003502947511151433, -0.0006506709614768624, -0.0003980797773692757, -0.005637460853904486, -0.14394931495189667, -0.2326754480600357], "finish_reason": "stop"}], "metrics": {"energy": 468.0487651863099, "energy_per_token": 4.254988774420999, "time": 13.047159, "time_per_token": 0.11861053636363637}}
{"outputs": [{"text": " RegexpTokenizer(r'\\$\\w+')  # Matches words starting with \"$\"", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "'\\", "$\\", "w", "+", "')", "  ", "#", " Mat", "ches", " words", " starting", " with", " \"", "$", "\"", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -0.6923394203186035, -0.23499059677124023, -0.023577332496643066, -0.24047309160232544, -0.013485172763466835, -1.8491489887237549, -0.00025817399728111923, -2.6995840072631836, -0.00042524831951595843, -1.7339063882827759, -0.24963675439357758, -0.0010317008709535003, -0.8748635053634644, -0.00016080040950328112, -0.0005397531786002219, -0.5433391332626343], "finish_reason": "stop"}, {"text": " [word.replace('$', '') for word in tokenizer.tokenize(text) if re.match(r'\\$\\w+', word)]", "tokens": [" [", "word", ".", "replace", "('", "$'", ",", " '", "')", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " re", ".", "match", "(", "r", "'\\", "$\\", "w", "+'", ",", " word", ")]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.9864199757575989, -0.930428683757782, -0.3576599955558777, -0.0314282663166523, -4.279521817807108e-05, -0.011675243265926838, -0.00020668754586949944, -0.047286272048950195, -0.0005688241217285395, -0.0005870526074431837, -0.010897763073444366, -1.4543427823809907e-05, -0.00020251607929822057, -6.854299135738984e-05, -3.576278118089249e-07, -0.0006811682251282036, -0.001948483637534082, -0.09705433994531631, -0.04809176176786423, -2.764732599258423, -6.007967749610543e-05, -0.24727533757686615, -0.025082357227802277, -0.0021609545219689608, -1.0702507495880127, -0.12557947635650635, -0.3983522355556488, -0.08752923458814621, -3.0874729418428615e-05, -0.0010930284624919295, -0.007168525364249945, -0.0010484919184818864], "finish_reason": "stop"}, {"text": " [word.replace('$', '').lower() for word in dollar_prefixed_words]", "tokens": [" [", "word", ".", "replace", "('", "$'", ",", " '", "')", ".", "lower", "()", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -1.1261801719665527, -0.3952137529850006, -0.06077798455953598, -3.611976353568025e-05, -0.01644052006304264, -0.00042358008795417845, -1.725285530090332, -0.11484873294830322, -0.00011634149996098131, -0.07724890857934952, -0.0010976725025102496, -0.0002485204895492643, -0.0004086851258762181, -3.576278118089249e-07, -1.5497195136049413e-06, -1.1920922133867862e-06, -1.6689286894688848e-06, -4.172316494077677e-06, -0.4733477532863617, -0.00890368316322565], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.02134821191430092, -0.008276568725705147, -0.01779027283191681, -1.6689286894688848e-06, -1.4185804502631072e-05, -0.0006183857913129032, -0.10062384605407715], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")"], "logprobs": [-0.24036501348018646, -1.2278481335670222e-05, -7.510157047363464e-06, -0.019227784126996994, -0.00011491115583339706, -2.2053474822314456e-05, -6.913899414939806e-05, -0.06025407835841179, -0.4085839092731476, -0.2470511496067047], "finish_reason": "stop"}], "metrics": {"energy": 423.8082063722611, "energy_per_token": 4.369156766724341, "time": 11.777184, "time_per_token": 0.12141426804123712}}
{"outputs": [{"text": " RegexpTokenizer('\\$(\\w+)')", "tokens": [" Re", "gex", "p", "Token", "izer", "('", "\\", "$", "(\\", "w", "+)", "')", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -2.585906505584717, -0.6490623950958252, -1.8431695699691772, -0.6748924851417542, -0.031660664826631546, -0.8902643918991089, -0.16247843205928802, -0.15334627032279968], "finish_reason": "stop"}, {"text": " [word.lower()[1:] for word in tokenizer.tokenize(text) if len(word) > 1]", "tokens": [" [", "word", ".", "lower", "()[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " len", "(", "word", ")", " >", " ", "1", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.9864199757575989, -2.3837521076202393, -0.9153809547424316, -0.0006413786904886365, -0.0008500776602886617, -0.028454959392547607, -0.00046885941992513835, -0.0005220004240982234, -0.01226396206766367, -1.2874520507466514e-05, -0.0003424296446610242, -0.00012766500003635883, -1.1920928244535389e-07, -0.0008269704412668943, -0.003802452003583312, -0.16826333105564117, -0.031793590635061264, -0.8644269704818726, -0.00019631843315437436, -0.0029620127752423286, -0.1184515506029129, -0.02630625292658806, -0.0010669498005881906, -0.020837323740124702, -0.043641235679388046, -0.007232436444610357], "finish_reason": "stop"}, {"text": " [word[1:] for word in dollar_prefixed_words]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.7551983594894409, -0.0016076747560873628, -0.0016214807983487844, -0.38257384300231934, -0.0003418338019400835, -6.544376083184034e-05, -0.0004602803383022547, -1.1920928244535389e-07, -3.3378546504536644e-06, -7.510157047363464e-06, -3.2186455882765586e-06, -2.50339189733495e-06, -0.9890631437301636, -0.24459783732891083], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.021463146433234215, -0.007004231214523315, -0.023815639317035675, -1.7881377516459906e-06, -1.1205610462639015e-05, -0.0008141063735820353, -0.13045723736286163], "finish_reason": "stop"}, {"text": " word_counts.most_common(3)<|endoftext|>import time", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "3", ")<", "|", "end", "of", "text", "|>", "import", " time", "\n"], "logprobs": [-0.31380322575569153, -1.3947389561508317e-05, -9.536697689327411e-06, -0.017802685499191284, -0.00013469743134919554, -2.109982233378105e-05, -0.0001174142598756589, -0.06182340160012245, -1.1866177320480347, -2.3121440410614014, -6.079655122448457e-06, -1.4305104514278355e-06, -2.622600959512056e-06, -3.814689989667386e-06, -0.12926501035690308, -1.3040478229522705, -4.130066871643066, -0.09744739532470703], "finish_reason": "stop"}], "metrics": {"energy": 364.0783787269594, "energy_per_token": 4.439980228377554, "time": 10.526427, "time_per_token": 0.12837106097560977}}
{"outputs": [{"text": " RegexpTokenizer(r'\\b\\$[a-zA-Z0-9]+\\b')", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "'\\", "b", "\\", "$[", "a", "-", "z", "A", "-", "Z", "0", "-", "9", "]", "+\\", "b", "')", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -0.6923394203186035, -3.1973204612731934, -0.10079006105661392, -1.8299317359924316, -0.15281856060028076, -7.033100700937212e-05, -5.018585216021165e-05, -0.013030614703893661, -1.1205610462639015e-05, -0.003441247157752514, -0.0623798593878746, -7.986703712958843e-05, -3.969590397900902e-05, -0.15909349918365479, -0.018445156514644623, -0.0002337421028641984, -0.032012514770030975, -0.0939897894859314], "finish_reason": "stop"}, {"text": " [word.replace('$', '') for word in tokenizer.tokenize(text) if word.startswith('$')]", "tokens": [" [", "word", ".", "replace", "('", "$'", ",", " '", "')", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " word", ".", "start", "sw", "ith", "('", "$", "')", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.9864199757575989, -0.930428683757782, -0.3576599955558777, -0.0314282663166523, -4.279521817807108e-05, -0.011675243265926838, -0.00020668754586949944, -0.047286272048950195, -0.0005688241217285395, -0.0005870526074431837, -0.010897763073444366, -1.4543427823809907e-05, -0.00020251607929822057, -6.854299135738984e-05, -3.576278118089249e-07, -0.0006811682251282036, -0.001948483637534082, -0.09705433994531631, -0.04809176176786423, -0.6013148427009583, -0.6082108616828918, -0.06991499662399292, -9.65590606938349e-06, 0.0, -0.17183640599250793, -0.0019074357114732265, -5.018585216021165e-05, -0.07405500113964081, -0.0013803249457851052], "finish_reason": "stop"}, {"text": " [word.replace('$', '') for word in dollar_prefixed_words if not re.match(r'^\\$\\$$', word)]", "tokens": [" [", "word", ".", "replace", "('", "$'", ",", " '", "')", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", " if", " not", " re", ".", "match", "(", "r", "'^", "\\", "$\\", "$$", "'", ",", " word", ")]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -1.1261801719665527, -0.3952137529850006, -0.06077798455953598, -3.611976353568025e-05, -0.01644052006304264, -0.00042358008795417845, -0.2259683459997177, -0.0006162413046695292, -0.00010156115604331717, -0.0005932478234171867, -3.576278118089249e-07, -1.6689286894688848e-06, -5.340433563105762e-05, -1.9073468138230965e-06, -1.311301275563892e-06, -1.087281584739685, -1.4753153324127197, -1.979960560798645, -5.531158240046352e-05, -0.07754448056221008, -0.07691902667284012, -0.004748377948999405, -0.8396638631820679, -0.0028058229945600033, -0.45039016008377075, -0.3662063777446747, -0.0013865152141079307, -2.9205850296420977e-05, -0.0009615565068088472, -0.003599713556468487, -0.003571443259716034], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.02134821191430092, -0.008276568725705147, -0.01779027283191681, -1.6689286894688848e-06, -1.4185804502631072e-05, -0.0006183857913129032, -0.10062384605407715], "finish_reason": "stop"}, {"text": " [(k, v) for k, v in word_counts.most_common(5)]", "tokens": [" [(", "k", ",", " v", ")", " for", " k", ",", " v", " in", " word", "_", "counts", ".", "most", "_", "common", "(", "5", ")]", "\n"], "logprobs": [-2.364109992980957, -2.690052032470703, -0.01940271072089672, -0.06488831341266632, -0.0007226239540614188, -0.0032323752529919147, -0.013441654853522778, -0.00010513706365600228, -0.005567046348005533, -0.0002588890492916107, -0.03179601579904556, -3.4570634852570947e-06, -1.1920928244535389e-07, -0.00047505536349490285, -0.0007513322634622455, -1.1920922133867862e-06, -7.033323527139146e-06, -0.24676738679409027, -0.30239856243133545, -0.8445165157318115, -0.4709163010120392], "finish_reason": "stop"}], "metrics": {"energy": 472.16462425518046, "energy_per_token": 4.001395120806614, "time": 13.449678, "time_per_token": 0.11398032203389831}}
{"outputs": [{"text": " RegexpTokenizer('\\$[a-zA-Z0-9]+')", "tokens": [" Re", "gex", "p", "Token", "izer", "('", "\\", "$[", "a", "-", "z", "A", "-", "Z", "0", "-", "9", "]+", "')", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -2.585906505584717, -0.6490623950958252, -1.5167535543441772, -0.18872740864753723, -0.0006302992696873844, -0.00029416524921543896, -0.04551228880882263, -4.994744449504651e-05, -0.019920526072382927, -0.06679433584213257, -0.0002320735511602834, -9.97731985989958e-05, -0.31455767154693604, -0.08816872537136078, -0.13056229054927826], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if len(word) > 1]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " len", "(", "word", ")", " >", " ", "1", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -1.2227665185928345, -0.00028200942324474454, -0.0016307639889419079, -0.1675470620393753, -0.03233261778950691, -0.0014455594355240464, -0.02093258872628212, -0.1535055786371231, -0.018018020316958427], "finish_reason": "stop"}, {"text": " [word[1:] for word in dollar_prefixed_words]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.7551983594894409, -0.0016076747560873628, -0.0016214807983487844, -0.38257384300231934, -0.0003418338019400835, -6.544376083184034e-05, -0.0004602803383022547, -1.1920928244535389e-07, -3.3378546504536644e-06, -7.510157047363464e-06, -3.2186455882765586e-06, -2.50339189733495e-06, -0.9890631437301636, -0.24459783732891083], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.021463146433234215, -0.007004231214523315, -0.023815639317035675, -1.7881377516459906e-06, -1.1205610462639015e-05, -0.0008141063735820353, -0.13045723736286163], "finish_reason": "stop"}, {"text": " sorted(word_counts.most_common(5), key=lambda x: (-x[1], x[0]))", "tokens": [" sorted", "(", "word", "_", "counts", ".", "most", "_", "common", "(", "5", ")", ",", " key", "=", "lambda", " x", ":", " (-", "x", "[", "1", "]", ",", " x", "[", "0", "]))", "\n"], "logprobs": [-2.737856388092041, -0.09366169571876526, -0.04209773242473602, -2.861018856492592e-06, -3.576278118089249e-07, -0.004071400035172701, -1.6923245191574097, -5.245195097813848e-06, -5.364403477869928e-06, -0.3730250895023346, -0.44529837369918823, -0.012630823068320751, -0.0025015748105943203, -0.029638977721333504, -0.0009677494526840746, -0.0012359131360426545, -0.06881402432918549, -0.00027044929447583854, -0.241985484957695, -0.0009916870621964335, -0.0013630633475258946, -0.0010968389688059688, -0.0023641036823391914, -0.00019667598826345056, -0.023760344833135605, -0.0008432884933426976, -0.0001419681793777272, -0.0940212607383728, -0.3877641558647156], "finish_reason": "stop"}], "metrics": {"energy": 426.1236947364808, "energy_per_token": 4.3482009666987835, "time": 11.772219, "time_per_token": 0.12012468367346939}}
{"outputs": [{"text": " RegexpTokenizer(r'\\$\\w+')", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "'\\", "$\\", "w", "+", "')", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -0.6923394203186035, -0.23499059677124023, -0.023577332496643066, -0.24047309160232544, -0.013485172763466835, -0.18628044426441193], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if not word == '$$']", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " not", " word", " ==", " '", "$$", "']", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -3.1607470512390137, -0.2992088198661804, -2.196845293045044, -3.310014009475708, -0.011605252511799335, -0.6181660294532776, -0.027660157531499863], "finish_reason": "stop"}, {"text": " [word.lower() for word in dollar_prefixed_words if re.match(r'\\$\\w+', word)]", "tokens": [" [", "word", ".", "lower", "()", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", " if", " re", ".", "match", "(", "r", "'\\", "$\\", "w", "+'", ",", " word", ")]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -0.9513526558876038, -0.12223250418901443, -0.4120813012123108, -0.0013061572099104524, -0.0001438752660760656, -0.0007074952009133995, -8.344646857949556e-07, -3.6954811548639555e-06, -2.52720492426306e-05, -2.3841855067985307e-07, -7.152555099310121e-07, -1.1042513847351074, -3.520388126373291, -8.654219709569588e-05, -0.3144479990005493, -0.036117687821388245, -0.004182045813649893, -1.1517634391784668, -0.11015086621046066, -0.281573086977005, -0.08221794664859772, -2.658331868587993e-05, -0.0013378250878304243, -0.09656750410795212, -0.005678474437445402], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.02134821191430092, -0.008276568725705147, -0.01779027283191681, -1.6689286894688848e-06, -1.4185804502631072e-05, -0.0006183857913129032, -0.10062384605407715], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")", "\n"], "logprobs": [-0.24036501348018646, -1.2278481335670222e-05, -7.510157047363464e-06, -0.019227784126996994, -0.00011491115583339706, -2.2053474822314456e-05, -6.913899414939806e-05, -0.06025407835841179, -0.4085839092731476, -0.2470511496067047, -0.262347549200058], "finish_reason": "stop"}], "metrics": {"energy": 371.8461443672179, "energy_per_token": 4.480074028520698, "time": 10.519856, "time_per_token": 0.1267452530120482}}
{"outputs": [{"text": " RegexpTokenizer(r'\\$\\w+')  # Regex pattern to match \"$\" followed by one or more word characters", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "'\\", "$\\", "w", "+", "')", "  ", "#", " Re", "gex", " pattern", " to", " match", " \"", "$", "\"", " followed", " by", " one", " or", " more", " word", " characters", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -0.6923394203186035, -0.23499059677124023, -0.023577332496643066, -0.24047309160232544, -0.013485172763466835, -1.8491489887237549, -0.00025817399728111923, -2.7716150283813477, -0.00027724236133508384, -1.075721025466919, -0.3080526292324066, -0.19848263263702393, -3.3613173961639404, -0.0015866083558648825, -0.03244386985898018, -0.18543466925621033, -0.00044550508027896285, -0.5732447504997253, -0.00135925377253443, -0.0004363300104159862, -1.8211559057235718, -0.005283440463244915, -0.09817449003458023], "finish_reason": "stop"}, {"text": " [word.lstrip(\"$\") for word in tokenizer.tokenize(text) if word.startswith(\"$\")]", "tokens": [" [", "word", ".", "lst", "rip", "(", "\"", "$", "\"", ")", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " word", ".", "start", "sw", "ith", "(", "\"", "$", "\"", ")]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.9864199757575989, -1.2813084125518799, -2.861018856492592e-06, -1.5236101150512695, -0.016068367287516594, -0.0018773326883092523, -0.002069357316941023, -0.0001734344696160406, -0.0367305763065815, -0.0007671750499866903, -0.0006891497760079801, -0.008754090406000614, -2.3007127310847864e-05, -0.00014053787162993103, -0.00012110930401831865, -1.1920928244535389e-07, -0.00031931069679558277, -0.0020723312627524137, -0.0927748754620552, -0.02272026054561138, -0.445407897233963, -0.4843893349170685, -0.2036636471748352, -1.2278481335670222e-05, 0.0, -0.06804098188877106, -0.0016379047883674502, -0.0005224770284257829, -4.434487345861271e-05, -0.14955274760723114, -0.001799156074412167], "finish_reason": "stop"}, {"text": " [word.replace('$', '') for word in dollar_prefixed_words if not word.startswith('$$')]", "tokens": [" [", "word", ".", "replace", "('", "$'", ",", " '", "')", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", " if", " not", " word", ".", "start", "sw", "ith", "('", "$$", "')", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -1.1261801719665527, -0.3952137529850006, -0.06077798455953598, -3.611976353568025e-05, -0.01644052006304264, -0.00042358008795417845, -0.2259683459997177, -0.0006162413046695292, -0.00010156115604331717, -0.0005932478234171867, -3.576278118089249e-07, -1.6689286894688848e-06, -5.340433563105762e-05, -1.9073468138230965e-06, -1.311301275563892e-06, -1.087281584739685, -1.4753153324127197, -0.2056647539138794, -0.1752183735370636, -0.16377991437911987, -6.6756979322235566e-06, -1.1920928244535389e-07, -0.05212683230638504, -0.0093197301030159, -0.024406561627984047, -0.022991277277469635, -0.005739162210375071], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.02134821191430092, -0.008276568725705147, -0.01779027283191681, -1.6689286894688848e-06, -1.4185804502631072e-05, -0.0006183857913129032, -0.10062384605407715], "finish_reason": "stop"}, {"text": " word_counts.most_common(3)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "3", ")", "\n"], "logprobs": [-0.24036501348018646, -1.2278481335670222e-05, -7.510157047363464e-06, -0.019227784126996994, -0.00011491115583339706, -2.2053474822314456e-05, -6.913899414939806e-05, -0.06025407835841179, -1.292151689529419, -0.11540035903453827, -0.3120909035205841], "finish_reason": "stop"}], "metrics": {"energy": 464.5976599206926, "energy_per_token": 4.185564503790023, "time": 13.043136, "time_per_token": 0.11750572972972974}}
{"outputs": [{"text": " RegexpTokenizer(r\"\\b\\$[a-zA-Z0-9]+\\b\")", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "\"", "\\", "b", "\\", "$[", "a", "-", "z", "A", "-", "Z", "0", "-", "9", "]", "+\\", "b", "\"", ")", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -1.064791202545166, -0.39815524220466614, -3.2196011543273926, -0.11558866500854492, -1.5475043058395386, -0.19216546416282654, -9.536288416711614e-05, -4.851700214203447e-05, -0.029258854687213898, -9.65590606938349e-06, -0.0020060669630765915, -0.06735829263925552, -7.903263758635148e-05, -4.3987260141875595e-05, -0.1679462343454361, -0.021017571911215782, -0.0005134217790327966, -0.06104269251227379, -0.05492371693253517, -0.12174943834543228], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if len(word) > 1]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " len", "(", "word", ")", " >", " ", "1", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -1.2227665185928345, -0.00028200942324474454, -0.0016307639889419079, -0.1675470620393753, -0.03233261778950691, -0.0014455594355240464, -0.02093258872628212, -0.1535055786371231, -0.018018020316958427], "finish_reason": "stop"}, {"text": " [word.lower() for word in dollar_prefixed_words]", "tokens": [" [", "word", ".", "lower", "()", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -0.9513526558876038, -0.12223250418901443, -0.4120813012123108, -0.0013061572099104524, -0.0001438752660760656, -0.0007074952009133995, -8.344646857949556e-07, -3.6954811548639555e-06, -2.52720492426306e-05, -2.3841855067985307e-07, -7.152555099310121e-07, -0.4517741799354553, -0.010515520349144936], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.02134821191430092, -0.008276568725705147, -0.01779027283191681, -1.6689286894688848e-06, -1.4185804502631072e-05, -0.0006183857913129032, -0.10062384605407715], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")"], "logprobs": [-0.24036501348018646, -1.2278481335670222e-05, -7.510157047363464e-06, -0.019227784126996994, -0.00011491115583339706, -2.2053474822314456e-05, -6.913899414939806e-05, -0.06025407835841179, -0.4085839092731476, -0.2470511496067047], "finish_reason": "stop"}], "metrics": {"energy": 389.53122906303406, "energy_per_token": 4.529432896081792, "time": 10.946203, "time_per_token": 0.12728143023255814}}
{"outputs": [{"text": " RegexpTokenizer(\"\\\\$[\\w.-]+\")", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "\"", "\\\\", "$", "[\\", "w", ".", "-", "]+", "\"", ")", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -2.4700100421905518, -3.0029613971710205, -0.41880857944488525, -1.4670369625091553, -0.1309303641319275, -2.224515676498413, -1.539788842201233, -0.11443225294351578, -0.0641399621963501, -0.06403899937868118, -0.1518230438232422], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if word[0] == '$' and len(word) > 1]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " word", "[", "0", "]", " ==", " '", "$'", " and", " len", "(", "word", ")", " >", " ", "1", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -0.6267849206924438, -0.7294026017189026, -1.5467846393585205, -0.007389001548290253, -0.009230793453752995, -0.7414553761482239, -0.00043704494601115584, -0.014488374814391136, -2.064666986465454, -0.0001802282058633864, -0.0029391921125352383, -0.15747931599617004, -0.015616625547409058, -0.0009556017466820776, -0.012360282242298126, -0.012646596878767014, -0.00381860276684165], "finish_reason": "stop"}, {"text": " [word.lstrip('$') for word in dollar_prefixed_words if not word.lstrip('$') == \"\"]", "tokens": [" [", "word", ".", "lst", "rip", "('", "$", "')", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", " if", " not", " word", ".", "lst", "rip", "('", "$", "')", " ==", " \"", "\"", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -2.1227641105651855, -8.583032467868179e-06, -0.3211752772331238, -0.002140613505616784, -0.0008465044084005058, -0.32911059260368347, -0.0004961451631970704, -7.617183291586116e-05, -0.0006551980040967464, -2.3841855067985307e-07, -9.536738616588991e-07, -4.8636207793606445e-05, -1.6689286894688848e-06, -1.9073468138230965e-06, -0.6780285239219666, -1.9444475173950195, -0.1397765427827835, -0.17203013598918915, -0.8052446246147156, -8.702239938429557e-06, -0.028539884835481644, -0.0009447640040889382, -8.332382276421413e-05, -0.2557317614555359, -1.4410253763198853, -0.08062567561864853, -0.006575140170753002, -0.012803493067622185], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.02130666933953762, -0.010106697678565979, -0.01395163219422102, -1.7881377516459906e-06, -1.0371154530730564e-05, -0.0008244690834544599, -0.11252881586551666], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")", "\n"], "logprobs": [-0.21358616650104523, -9.894321920000948e-06, -8.583032467868179e-06, -0.0168895460665226, -0.00011836781777674332, -2.4914430468925275e-05, -9.572047565598041e-05, -0.05232449620962143, -0.42527076601982117, -0.26612260937690735, -0.23000283539295197], "finish_reason": "stop"}], "metrics": {"energy": 428.1750754604339, "energy_per_token": 4.281750754604339, "time": 11.986501, "time_per_token": 0.11986501000000001}}
{"outputs": [{"text": " RegexpTokenizer(r'\\$(\\w+\\d*\\D*|\\D*\\d+\\w*)')", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "'\\", "$", "(\\", "w", "+\\", "d", "*\\", "D", "*", "|\\", "D", "*\\", "d", "+\\", "w", "*)", "')", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -0.6923394203186035, -2.2739901542663574, -0.5830509662628174, -0.0176044050604105, -2.945230007171631, -1.4840527772903442, -2.780470848083496, -2.7836315631866455, -1.6769126653671265, -0.983184814453125, -0.8462469577789307, -0.43895861506462097, -0.04380464181303978, -0.3611736297607422, -0.18520736694335938, -0.2413279116153717, -0.14601296186447144, -0.0644117221236229], "finish_reason": "stop"}, {"text": " [word.strip(\"$\") for word in tokenizer.tokenize(text) if len(word.strip(\"$\")) > 0]", "tokens": [" [", "word", ".", "strip", "(", "\"", "$", "\"", ")", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " len", "(", "word", ".", "strip", "(", "\"", "$", "\"", "))", " >", " ", "0", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.9864199757575989, -1.5121395587921143, -1.1429643630981445, -0.00268503837287426, -0.0070288535207509995, -0.004759056027978659, -0.00015746307326480746, -0.026286164298653603, -0.0006587718962691724, -0.0006663962849415839, -0.013475763611495495, -1.9311717551317997e-05, -0.00018749863374978304, -8.475421054754406e-05, 0.0, -0.0004258441040292382, -0.00249182409606874, -0.12047439068555832, -0.020684951916337013, -1.6905819177627563, -0.00023648326168768108, -0.0026027634739875793, -1.5251579284667969, -0.04552800580859184, -0.021855924278497696, -0.00031275625224225223, -0.0013063953956589103, -0.0003305127320345491, -0.001320800743997097, -0.19350837171077728, -0.0004435985756572336, -0.0364375114440918, -0.006642996799200773, -0.004264784511178732], "finish_reason": "stop"}, {"text": " [word[1:] if word.startswith('$') else word for word in dollar_prefixed_words]", "tokens": [" [", "word", "[", "1", ":]", " if", " word", ".", "start", "sw", "ith", "('", "$", "')", " else", " word", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.7551983594894409, -0.0016076747560873628, -0.0016214807983487844, -1.573312520980835, -0.07508508861064911, -0.3589309751987457, -0.016835158690810204, -1.1205610462639015e-05, -2.3841855067985307e-07, -0.4768051207065582, -0.16251644492149353, -0.00017736769223120064, -0.02192321978509426, -0.016267186030745506, -0.02665569633245468, -0.0003405229654163122, -0.0001911934232339263, -0.000739539333153516, -1.1920928244535389e-07, -1.5497195136049413e-06, -5.960462772236497e-07, -1.1920922133867862e-06, -4.768370445162873e-07, -0.01884356513619423, -0.016322309151291847], "finish_reason": "stop"}, {"text": " Counter(normalized_words).most_common()", "tokens": [" Counter", "(", "normalized", "_", "words", ")", ".", "most", "_", "common", "()", "\n"], "logprobs": [-0.021463146433234215, -0.007004231214523315, -0.023815639317035675, -1.7881377516459906e-06, -1.1205610462639015e-05, -0.0008141063735820353, -2.1452314853668213, -0.007500818464905024, -5.960462772236497e-07, -8.344646857949556e-07, -1.0694091320037842, -0.017245925962924957], "finish_reason": "stop"}, {"text": " [(word, count) for word, count in word_counts.most_common(5) if len(word) > 0]", "tokens": [" [(", "word", ",", " count", ")", " for", " word", ",", " count", " in", " word", "_", "counts", ".", "most", "_", "common", "(", "5", ")", " if", " len", "(", "word", ")", " >", " ", "0", "]", "\n"], "logprobs": [-2.183523654937744, -0.20755784213542938, -0.05981827527284622, -0.028778864070773125, -0.0006017066189087927, -0.003316262038424611, -0.0048829116858541965, -3.85038583772257e-05, -0.00021026308240834624, -0.00019739109848160297, -0.014683984220027924, -2.0265558760002023e-06, -2.3841855067985307e-07, -0.0005857420619577169, -0.0010085977846756577, -1.1920922133867862e-06, -8.821448318485636e-06, -0.22615833580493927, -0.2745129466056824, -0.5163934826850891, -0.007198824547231197, -1.5763115882873535, -0.00026675479602999985, -0.0028846340719610453, -0.05813254043459892, -0.04013896733522415, -0.0003225283289793879, -0.019569655880331993, -0.31874552369117737, -0.22491276264190674], "finish_reason": "stop"}], "metrics": {"energy": 547.0062279491424, "energy_per_token": 4.207740214993403, "time": 14.731353, "time_per_token": 0.1133181}}
{"outputs": [{"text": " RegexpTokenizer(r'\\$\\w+\\w*')", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "'\\", "$\\", "w", "+\\", "w", "*", "')", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -0.6923394203186035, -0.23499059677124023, -0.023577332496643066, -2.0410330295562744, -1.3525357246398926, -1.4566419124603271, -0.12277079373598099, -0.12341786175966263], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if word.startswith('$') and word != '$']", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " word", ".", "start", "sw", "ith", "('", "$", "')", " and", " word", " ", "!", "=", " '$", "']", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -0.6267849206924438, -1.3537120819091797, -0.011074034497141838, -1.0132738680113107e-05, 0.0, -0.3708227276802063, -0.0026982349809259176, -8.320462075062096e-05, -0.5352336764335632, -0.48364126682281494, -0.5882577300071716, -7.152555099310121e-07, -0.0005970602505840361, -0.023291917517781258, -0.03148013353347778, -0.004549747332930565], "finish_reason": "stop"}, {"text": " [word.lower() for word in dollar_prefixed_words]", "tokens": [" [", "word", ".", "lower", "()", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -0.9513526558876038, -0.12223250418901443, -0.4120813012123108, -0.0013061572099104524, -0.0001438752660760656, -0.0007074952009133995, -8.344646857949556e-07, -3.6954811548639555e-06, -2.52720492426306e-05, -2.3841855067985307e-07, -7.152555099310121e-07, -0.4517741799354553, -0.010515520349144936], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.02134821191430092, -0.008276568725705147, -0.01779027283191681, -1.6689286894688848e-06, -1.4185804502631072e-05, -0.0006183857913129032, -0.10062384605407715], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")", "\n"], "logprobs": [-0.24036501348018646, -1.2278481335670222e-05, -7.510157047363464e-06, -0.019227784126996994, -0.00011491115583339706, -2.2053474822314456e-05, -6.913899414939806e-05, -0.06025407835841179, -0.4085839092731476, -0.2470511496067047, -0.262347549200058], "finish_reason": "stop"}], "metrics": {"energy": 368.9374553928376, "energy_per_token": 4.499237260888263, "time": 10.523104, "time_per_token": 0.12833053658536586}}
{"outputs": [{"text": " RegexpTokenizer(r\"\\$\\w+\")  # Tokenize words starting with \"$\"", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "\"", "\\", "$\\", "w", "+", "\"", ")", "  ", "#", " Token", "ize", " words", " starting", " with", " \"", "$", "\"", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -1.064791202545166, -0.39815524220466614, -0.31417316198349, -0.03354894369840622, -0.1571749746799469, -0.03231807425618172, -0.05304307863116264, -1.9151636362075806, -0.00018094333063345402, -1.5182565450668335, -0.24918481707572937, -0.8811669945716858, -0.48253577947616577, -0.0011838816571980715, -0.3886033594608307, -0.00013290952483657748, -0.0004938812926411629, -0.2455192655324936], "finish_reason": "stop"}, {"text": " [token[1:] for token in tokenizer.tokenize(text)]", "tokens": [" [", "token", "[", "1", ":]", " for", " token", " in", " token", "izer", ".", "token", "ize", "(", "text", ")]", "\n"], "logprobs": [-0.2378702163696289, -2.7280282974243164, -0.30826812982559204, -0.00031001531169749796, -0.0002208704245276749, -0.06937762349843979, -0.001077428925782442, -0.0012240068754181266, -0.008868827484548092, -1.1920858014491387e-05, -0.00025960413040593266, -6.174850568640977e-05, 0.0, -0.0005604841862805188, -0.0030853785574436188, -2.854356527328491, -0.021151568740606308], "finish_reason": "stop"}, {"text": " [word.replace('$', '') for word in dollar_prefixed_words]", "tokens": [" [", "word", ".", "replace", "('", "$'", ",", " '", "')", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -1.1261801719665527, -0.3952137529850006, -0.06077798455953598, -3.611976353568025e-05, -0.01644052006304264, -0.00042358008795417845, -0.2259683459997177, -0.0006162413046695292, -0.00010156115604331717, -0.0005932478234171867, -3.576278118089249e-07, -1.6689286894688848e-06, -5.340433563105762e-05, -1.9073468138230965e-06, -1.311301275563892e-06, -0.43786752223968506, -0.015430706553161144], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.02134821191430092, -0.008276568725705147, -0.01779027283191681, -1.6689286894688848e-06, -1.4185804502631072e-05, -0.0006183857913129032, -0.10062384605407715], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")", "\n"], "logprobs": [-0.24036501348018646, -1.2278481335670222e-05, -7.510157047363464e-06, -0.019227784126996994, -0.00011491115583339706, -2.2053474822314456e-05, -6.913899414939806e-05, -0.06025407835841179, -0.4085839092731476, -0.2470511496067047, -0.262347549200058], "finish_reason": "stop"}], "metrics": {"energy": 371.69917672729474, "energy_per_token": 4.6462397090911844, "time": 10.298431, "time_per_token": 0.12873038750000002}}
{"outputs": [{"text": " RegexpTokenizer(r\"\\$[\\w']+\")", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "\"", "\\", "$", "[\\", "w", "']", "+", "\"", ")", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -1.064791202545166, -0.39815524220466614, -2.0622010231018066, -1.1724421977996826, -0.06717628240585327, -1.718123435974121, -0.04150974005460739, -0.021313205361366272, -0.06202341243624687, -0.12639062106609344], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if word[1:].isalnum()]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " word", "[", "1", ":]", ".", "isal", "num", "()", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -0.6267849206924438, -0.7294026017189026, -0.24066287279129028, -0.12729685008525848, -0.15129801630973816, -0.08109229803085327, -5.722029527532868e-06, -0.00048160876031033695, -0.031589288264513016, -0.008542661555111408], "finish_reason": "stop"}, {"text": " [word[1:] if word.startswith('$$') else word for word in dollar_prefixed_words]", "tokens": [" [", "word", "[", "1", ":]", " if", " word", ".", "start", "sw", "ith", "('", "$$", "')", " else", " word", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.7551983594894409, -0.0016076747560873628, -0.0016214807983487844, -1.573312520980835, -0.07508508861064911, -0.3589309751987457, -0.016835158690810204, -1.1205610462639015e-05, -2.3841855067985307e-07, -0.4768051207065582, -1.901549220085144, -0.015766017138957977, -0.048598457127809525, -0.001441036001779139, -0.11217158287763596, -0.0005489272880367935, -0.00026973424246534705, -0.000675807474181056, -1.1920928244535389e-07, -7.152555099310121e-07, -1.1920922133867862e-06, -9.536738616588991e-07, -3.576278118089249e-07, -0.022375619038939476, -0.025340180844068527], "finish_reason": "stop"}, {"text": " Counter(normalized_words).most_common()", "tokens": [" Counter", "(", "normalized", "_", "words", ")", ".", "most", "_", "common", "()", "\n"], "logprobs": [-0.021463146433234215, -0.007004231214523315, -0.023815639317035675, -1.7881377516459906e-06, -1.1205610462639015e-05, -0.0008141063735820353, -2.1452314853668213, -0.007500818464905024, -5.960462772236497e-07, -8.344646857949556e-07, -1.0694091320037842, -0.017245925962924957], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)<|endoftext|>import random", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")<", "|", "end", "of", "text", "|>", "import", " random", "\n"], "logprobs": [-0.31380322575569153, -1.3947389561508317e-05, -9.536697689327411e-06, -0.017802685499191284, -0.00013469743134919554, -2.109982233378105e-05, -0.0001174142598756589, -0.06182340160012245, -0.44775667786598206, -1.537385106086731, -6.079655122448457e-06, -1.1920922133867862e-06, -3.099436753473128e-06, -5.602820692729438e-06, -0.16312634944915771, -1.357842206954956, -2.6908915042877197, -0.0317230299115181], "finish_reason": "stop"}], "metrics": {"energy": 430.2764697313308, "energy_per_token": 4.2601630666468395, "time": 11.985713, "time_per_token": 0.11867042574257426}}
{"outputs": [{"text": " RegexpTokenizer(\"[$](\\w+)\")", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "\"", "[$", "](", "\\", "w", "+", ")\"", ")", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -2.4700100421905518, -0.8187020421028137, -1.6483814716339111, -0.7106556296348572, -0.024346765130758286, -0.17162968218326569, -0.03556839004158974, -0.055408015847206116, -0.23505911231040955], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if word != '$']", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " word", " ", "!", "=", " '$", "']", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -0.6267849206924438, -1.4501781463623047, -6.198863957251888e-06, -0.0002619877050165087, -0.40623727440834045, -0.0006179092451930046, -0.018228158354759216], "finish_reason": "stop"}, {"text": " [word[1:].lower() for word in dollar_prefixed_words]", "tokens": [" [", "word", "[", "1", ":]", ".", "lower", "()", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.7551983594894409, -0.0016076747560873628, -0.0016214807983487844, -2.231637716293335, -0.07783082127571106, -9.321732068201527e-05, -0.13018496334552765, -0.0005168771021999419, -9.417090768693015e-05, -0.00047636605449952185, -1.1920928244535389e-07, -3.933898824470816e-06, -1.3470558769768104e-05, -9.536738616588991e-07, -4.768370445162873e-07, -0.9728546738624573, -0.09877826273441315], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.021463146433234215, -0.007004231214523315, -0.023815639317035675, -1.7881377516459906e-06, -1.1205610462639015e-05, -0.0008141063735820353, -0.13045723736286163], "finish_reason": "stop"}, {"text": " [(word, count) for word, count in word_counts.most_common() if word != \"$\"]", "tokens": [" [(", "word", ",", " count", ")", " for", " word", ",", " count", " in", " word", "_", "counts", ".", "most", "_", "common", "()", " if", " word", " ", "!", "=", " \"", "$", "\"", "]", "\n"], "logprobs": [-2.183523654937744, -0.20755784213542938, -0.05981827527284622, -0.028778864070773125, -0.0006017066189087927, -0.003316262038424611, -0.0048829116858541965, -3.85038583772257e-05, -0.00021026308240834624, -0.00019739109848160297, -0.014683984220027924, -2.0265558760002023e-06, -2.3841855067985307e-07, -0.0005857420619577169, -0.0010085977846756577, -1.1920922133867862e-06, -8.821448318485636e-06, -1.6133081912994385, -0.1417447328567505, -0.4832015335559845, -0.4893694818019867, -5.602820692729438e-06, -0.00019095504831057042, -0.6884863376617432, -0.5614490509033203, -0.0008704449282959104, -0.6962507367134094, -0.20302581787109375], "finish_reason": "stop"}], "metrics": {"energy": 401.8488387985228, "energy_per_token": 4.320955255898095, "time": 11.357463, "time_per_token": 0.12212325806451613}}
{"outputs": [{"text": " RegexpTokenizer(r\"\\$[\\w\\.-]+\")", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "\"", "\\", "$", "[\\", "w", "\\", ".", "-", "]+", "\"", ")", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -1.064791202545166, -0.39815524220466614, -2.0622010231018066, -1.1724421977996826, -0.06717628240585327, -2.1109628677368164, -0.6322863698005676, -2.237009286880493, -0.08741367608308792, -0.16229248046875, -0.05076069384813309, -0.17287598550319672], "finish_reason": "stop"}, {"text": " tokenizer.tokenize(text)", "tokens": [" token", "izer", ".", "token", "ize", "(", "text", ")", "\n"], "logprobs": [-2.154740333557129, -7.10462118149735e-05, -0.0001726001501083374, -0.00024637524620629847, 0.0, -0.001302585587836802, -0.005635445937514305, -0.02854347601532936, -0.006006760522723198], "finish_reason": "stop"}, {"text": " [word[1:] for word in dollar_prefixed_words if not re.match('^\\$+', word)]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", " if", " not", " re", ".", "match", "('", "^\\", "$", "+'", ",", " word", ")]", "\n"], "logprobs": [-0.09502872079610825, -0.05808248743414879, -0.7117553353309631, -0.0016098171472549438, -0.0013383012264966965, -0.373071551322937, -0.0003404037852305919, -7.533743337262422e-05, -0.0005013877525925636, -1.1920928244535389e-07, -2.3841830625315197e-06, -8.106198947643861e-06, -3.099436753473128e-06, -2.264974000354414e-06, -0.45563551783561707, -2.391611099243164, -1.8728699684143066, -4.0649541915627196e-05, -0.05836331844329834, -2.585845708847046, -0.15233254432678223, -0.4285702109336853, -2.126511812210083, -0.00029976642690598965, -0.004669357556849718, -0.03444826975464821, -0.043495725840330124], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.021235598251223564, -0.007642672397196293, -0.023203516378998756, -1.6689286894688848e-06, -1.1444026313256472e-05, -0.0008515069494023919, -0.12573538720607758], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)<|endoftext|>from typing import List", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")<", "|", "end", "of", "text", "|>", "from", " typing", " import", " List", "\n"], "logprobs": [-0.2808639705181122, -1.2397689715726301e-05, -6.079655122448457e-06, -0.019382834434509277, -0.00012385078298393637, -1.490105023549404e-05, -8.844937838148326e-05, -0.0654238685965538, -0.43643850088119507, -1.5326751470565796, -6.794906312279636e-06, -1.6689286894688848e-06, -2.50339189733495e-06, -8.702239938429557e-06, -0.13090191781520844, -1.776701807975769, -1.9131768941879272, -0.0006974886637181044, -0.4177030324935913, -0.1687883883714676], "finish_reason": "stop"}], "metrics": {"energy": 352.1671456050872, "energy_per_token": 4.294721287866917, "time": 10.310165, "time_per_token": 0.1257337195121951}}
{"outputs": [{"text": " RegexpTokenizer(r\"\\$\\w+\")", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "\"", "\\", "$\\", "w", "+", "\"", ")", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -1.064791202545166, -0.39815524220466614, -0.31417316198349, -0.03354894369840622, -0.1571749746799469, -0.03231807425618172, -0.05304307863116264, -0.16741810739040375], "finish_reason": "stop"}, {"text": " [word.replace('$', '') for word in tokenizer.tokenize(text) if word.startswith('$')]", "tokens": [" [", "word", ".", "replace", "('", "$'", ",", " '", "')", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " word", ".", "start", "sw", "ith", "('", "$", "')", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.9864199757575989, -0.930428683757782, -0.3576599955558777, -0.0314282663166523, -4.279521817807108e-05, -0.011675243265926838, -0.00020668754586949944, -0.047286272048950195, -0.0005688241217285395, -0.0005870526074431837, -0.010897763073444366, -1.4543427823809907e-05, -0.00020251607929822057, -6.854299135738984e-05, -3.576278118089249e-07, -0.0006811682251282036, -0.001948483637534082, -0.09705433994531631, -0.04809176176786423, -0.6013148427009583, -0.6082108616828918, -0.06991499662399292, -9.65590606938349e-06, 0.0, -0.17183640599250793, -0.0019074357114732265, -5.018585216021165e-05, -0.07405500113964081, -0.0013803249457851052], "finish_reason": "stop"}, {"text": " [word[1:] for word in dollar_prefixed_words if word[1:]]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", " if", " word", "[", "1", ":", "]]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.7551983594894409, -0.0016076747560873628, -0.0016214807983487844, -0.38257384300231934, -0.0003418338019400835, -6.544376083184034e-05, -0.0004602803383022547, -1.1920928244535389e-07, -3.3378546504536644e-06, -7.510157047363464e-06, -3.2186455882765586e-06, -2.50339189733495e-06, -0.5047262907028198, -0.4751542806625366, -0.7278932332992554, -0.025523336604237556, -0.9988305568695068, -0.00035529976594261825, -0.07428976893424988], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.021463146433234215, -0.007004231214523315, -0.023815639317035675, -1.7881377516459906e-06, -1.1205610462639015e-05, -0.0008141063735820353, -0.13045723736286163], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")", "\n"], "logprobs": [-0.31380322575569153, -1.3947389561508317e-05, -9.536697689327411e-06, -0.017802685499191284, -0.00013469743134919554, -2.109982233378105e-05, -0.0001174142598756589, -0.06182340160012245, -0.44775667786598206, -0.24642671644687653, -0.2693387269973755], "finish_reason": "stop"}], "metrics": {"energy": 382.16670791244525, "energy_per_token": 4.4960789166170025, "time": 10.926927, "time_per_token": 0.12855208235294116}}
{"outputs": [{"text": " RegexpTokenizer(r'\\$\\w+')", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "'\\", "$\\", "w", "+", "')", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -0.6923394203186035, -0.23499059677124023, -0.023577332496643066, -0.24047309160232544, -0.013485172763466835, -0.18628044426441193], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if word != \"$$\"]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " word", " ", "!", "=", " \"", "$$", "\"", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -0.6267849206924438, -1.4501781463623047, -6.198863957251888e-06, -0.0002619877050165087, -1.2012048959732056, -1.5489907264709473, -0.12170974910259247, -0.07433801889419556, -0.042074184864759445], "finish_reason": "stop"}, {"text": " [word.lower() for word in dollar_prefixed_words]", "tokens": [" [", "word", ".", "lower", "()", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -0.9513526558876038, -0.12223250418901443, -0.4120813012123108, -0.0013061572099104524, -0.0001438752660760656, -0.0007074952009133995, -8.344646857949556e-07, -3.6954811548639555e-06, -2.52720492426306e-05, -2.3841855067985307e-07, -7.152555099310121e-07, -0.4517741799354553, -0.010515520349144936], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.02134821191430092, -0.008276568725705147, -0.01779027283191681, -1.6689286894688848e-06, -1.4185804502631072e-05, -0.0006183857913129032, -0.10062384605407715], "finish_reason": "stop"}, {"text": " word_counts.most_common()[:5]", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "()", "[:", "5", "]", "\n"], "logprobs": [-0.24036501348018646, -1.2278481335670222e-05, -7.510157047363464e-06, -0.019227784126996994, -0.00011491115583339706, -2.2053474822314456e-05, -6.913899414939806e-05, -2.9010934829711914, -0.3586743474006653, -0.08044078946113586, -0.22376562654972076, -0.23473884165287018], "finish_reason": "stop"}], "metrics": {"energy": 358.27431610870354, "energy_per_token": 4.8415448122797775, "time": 9.879344, "time_per_token": 0.13350464864864864}}
{"outputs": [{"text": " RegexpTokenizer(r'\\$[\\w\\.]+')", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "'\\", "$", "[\\", "w", "\\", ".", "]+", "')", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -0.6923394203186035, -2.2739901542663574, -1.290543794631958, -0.04596621170639992, -1.5705111026763916, -0.4841960072517395, -0.27637720108032227, -0.1977318376302719, -0.21095003187656403], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if word[0] == '$' and word[1:].isalnum()]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " word", "[", "0", "]", " ==", " '", "$'", " and", " word", "[", "1", ":]", ".", "isal", "num", "()", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -0.6267849206924438, -0.7294026017189026, -1.5467846393585205, -0.007389001548290253, -0.009230793453752995, -0.7414553761482239, -0.00043704494601115584, -0.014488374814391136, -0.1970522403717041, -0.20238924026489258, -0.00455591781064868, -0.015563341788947582, -0.10238317400217056, -0.05222651734948158, -4.291525328881107e-06, -0.0009213017183355987, -0.0027001372072845697, -0.0026027634739875793], "finish_reason": "stop"}, {"text": " [word.strip(\"$\") for word in dollar_prefixed_words]", "tokens": [" [", "word", ".", "strip", "(", "\"", "$", "\"", ")", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -1.845731258392334, -0.6788519620895386, -0.0018756669014692307, -0.01118756178766489, -0.008824753575026989, -0.0002506657037883997, -0.19669879972934723, -0.000551310193259269, -9.297892393078655e-05, -0.000730128725990653, -3.576278118089249e-07, -1.6689286894688848e-06, -2.312633478140924e-05, -2.0265558760002023e-06, -2.9802276912960224e-06, -0.4285133481025696, -0.00923091173171997], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.02134821191430092, -0.008276568725705147, -0.01779027283191681, -1.6689286894688848e-06, -1.4185804502631072e-05, -0.0006183857913129032, -0.10062384605407715], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")", "\n"], "logprobs": [-0.24036501348018646, -1.2278481335670222e-05, -7.510157047363464e-06, -0.019227784126996994, -0.00011491115583339706, -2.2053474822314456e-05, -6.913899414939806e-05, -0.06025407835841179, -0.4085839092731476, -0.2470511496067047, -0.262347549200058], "finish_reason": "stop"}], "metrics": {"energy": 390.8042825183869, "energy_per_token": 4.391059354139179, "time": 11.14995, "time_per_token": 0.1252803370786517}}
{"outputs": [{"text": " RegexpTokenizer(r'\\$\\w+\\S*')  # Regex pattern to match words starting with \"$\"", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "'\\", "$\\", "w", "+\\", "S", "*", "')", "  ", "#", " Re", "gex", " pattern", " to", " match", " words", " starting", " with", " \"", "$", "\"", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -0.6923394203186035, -0.23499059677124023, -0.023577332496643066, -2.0410330295562744, -0.9254441261291504, -0.521331250667572, -0.1848769634962082, -2.0163989067077637, -0.00024423000286333263, -2.288527488708496, -0.0003924791526515037, -1.1928199529647827, -0.31236186623573303, -0.346539169549942, -0.6647961139678955, -0.15179498493671417, -0.0008662762120366096, -0.5190999507904053, -0.0001805857609724626, -0.0008351890719495714, -0.34969255328178406], "finish_reason": "stop"}, {"text": " [word.lower().replace('$', '') for word in tokenizer.tokenize(text)]", "tokens": [" [", "word", ".", "lower", "()", ".", "replace", "('", "$'", ",", " '", "')", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.9864199757575989, -2.3837521076202393, -0.5115571022033691, -0.46919044852256775, -1.4050015211105347, -0.4485195577144623, -0.06593424826860428, -2.9682672902708873e-05, -0.017231984063982964, -0.00029583368450403214, -0.06341677904129028, -0.0005995621904730797, -0.0010794533882290125, -0.0126496572047472, -1.537788011773955e-05, -0.0002431573811918497, -0.00018070495571009815, -2.3841855067985307e-07, -0.00044741155579686165, -0.0034827073104679585, -1.5470614433288574, -0.012155620381236076], "finish_reason": "stop"}, {"text": " [word.lstrip('$') for word in dollar_prefixed_words]", "tokens": [" [", "word", ".", "lst", "rip", "('", "$", "')", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -2.1227641105651855, -8.583032467868179e-06, -0.3211752772331238, -0.002140613505616784, -0.0008465044084005058, -0.32911059260368347, -0.0004961451631970704, -7.617183291586116e-05, -0.0006551980040967464, -2.3841855067985307e-07, -9.536738616588991e-07, -4.8636207793606445e-05, -1.6689286894688848e-06, -1.9073468138230965e-06, -0.7569851279258728, -0.01158557366579771], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.02130666933953762, -0.010106697678565979, -0.01395163219422102, -1.7881377516459906e-06, -1.0371154530730564e-05, -0.0008244690834544599, -0.11252881586551666], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)<|endoftext|>#!/usr/bin/env python3", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")<", "|", "end", "of", "text", "|>", "#", "!", "/", "usr", "/", "bin", "/", "env", " python", "3", "\n"], "logprobs": [-0.21358616650104523, -9.894321920000948e-06, -8.583032467868179e-06, -0.0168895460665226, -0.00011836781777674332, -2.4914430468925275e-05, -9.572047565598041e-05, -0.05232449620962143, -0.42527076601982117, -1.469196081161499, -7.510157047363464e-06, -1.4305104514278355e-06, -2.9802276912960224e-06, -4.0531076592742465e-06, -0.15506809949874878, -1.1810246706008911, -1.5813881158828735, -0.06837981939315796, -0.1051408126950264, -7.819823804311454e-05, -0.006048944313079119, -0.0005841932725161314, -0.09667032212018967, -0.003989476710557938, -0.6078096032142639, -0.015402534045279026], "finish_reason": "stop"}], "metrics": {"energy": 430.47377710533164, "energy_per_token": 4.1391709337051115, "time": 12.188176, "time_per_token": 0.117194}}
{"outputs": [{"text": " RegexpTokenizer(r'\\$\\w+')", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "'\\", "$\\", "w", "+", "')", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -0.6923394203186035, -0.23499059677124023, -0.023577332496643066, -0.24047309160232544, -0.013485172763466835, -0.18628044426441193], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if word.startswith(\"$\") and not word[1:].isalpha()]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " word", ".", "start", "sw", "ith", "(", "\"", "$", "\"", ")", " and", " not", " word", "[", "1", ":]", ".", "is", "alpha", "()", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -0.6267849206924438, -1.3537120819091797, -0.011074034497141838, -1.0132738680113107e-05, 0.0, -1.1721150875091553, -0.029114823788404465, -0.00302381650544703, -7.760223525110632e-05, -0.764987051486969, -0.025313563644886017, -1.9062573909759521, -0.0951012372970581, -0.7259459495544434, -0.00695889163762331, -0.0010917185572907329, -0.05176478624343872, -0.5238823294639587, -1.9116692543029785, -0.0012834176886826754, -0.016740556806325912, -0.011970235034823418], "finish_reason": "stop"}, {"text": " [word.replace('$', '') for word in dollar_prefixed_words]", "tokens": [" [", "word", ".", "replace", "('", "$'", ",", " '", "')", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -1.1261801719665527, -0.3952137529850006, -0.06077798455953598, -3.611976353568025e-05, -0.01644052006304264, -0.00042358008795417845, -0.2259683459997177, -0.0006162413046695292, -0.00010156115604331717, -0.0005932478234171867, -3.576278118089249e-07, -1.6689286894688848e-06, -5.340433563105762e-05, -1.9073468138230965e-06, -1.311301275563892e-06, -0.43786752223968506, -0.015430706553161144], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.02134821191430092, -0.008276568725705147, -0.01779027283191681, -1.6689286894688848e-06, -1.4185804502631072e-05, -0.0006183857913129032, -0.10062384605407715], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")", "\n"], "logprobs": [-0.24036501348018646, -1.2278481335670222e-05, -7.510157047363464e-06, -0.019227784126996994, -0.00011491115583339706, -2.2053474822314456e-05, -6.913899414939806e-05, -0.06025407835841179, -0.4085839092731476, -0.2470511496067047, -0.262347549200058], "finish_reason": "stop"}], "metrics": {"energy": 419.04483384895303, "energy_per_token": 4.656053709432811, "time": 11.151737, "time_per_token": 0.1239081888888889}}
{"outputs": [{"text": " RegexpTokenizer(r\"\\$\\w+\\S\\w+\")", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "\"", "\\", "$\\", "w", "+\\", "S", "\\", "w", "+", "\"", ")", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -1.064791202545166, -0.39815524220466614, -0.31417316198349, -0.03354894369840622, -2.3850269317626953, -1.5071525573730469, -3.3970437049865723, -0.04211419075727463, -0.660035252571106, -0.16929003596305847, -0.07309465855360031, -0.16045381128787994], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if len(word[1:]) > 0]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " len", "(", "word", "[", "1", ":", "])", " >", " ", "0", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -1.2227665185928345, -0.00028200942324474454, -0.0016307639889419079, -1.9909189939498901, -0.0007110689766705036, -0.053156573325395584, -9.369411418447271e-05, -0.21832333505153656, -0.0009242791566066444, -0.04213990643620491, -0.03200835734605789, -0.011253456585109234], "finish_reason": "stop"}, {"text": " [word.lower() for word in dollar_prefixed_words if word[1:].isalnum()]", "tokens": [" [", "word", ".", "lower", "()", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", " if", " word", "[", "1", ":]", ".", "isal", "num", "()", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -0.9513526558876038, -0.12223250418901443, -0.4120813012123108, -0.0013061572099104524, -0.0001438752660760656, -0.0007074952009133995, -8.344646857949556e-07, -3.6954811548639555e-06, -2.52720492426306e-05, -2.3841855067985307e-07, -7.152555099310121e-07, -1.1042513847351074, -0.6834207773208618, -2.150639772415161, -0.2313465029001236, -0.01952371373772621, -0.18222513794898987, -0.1801704317331314, -1.9311717551317997e-05, -0.000350175570929423, -0.04389774054288864, -0.02772381529211998], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.02134821191430092, -0.008276568725705147, -0.01779027283191681, -1.6689286894688848e-06, -1.4185804502631072e-05, -0.0006183857913129032, -0.10062384605407715], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")", "\n"], "logprobs": [-0.24036501348018646, -1.2278481335670222e-05, -7.510157047363464e-06, -0.019227784126996994, -0.00011491115583339706, -2.2053474822314456e-05, -6.913899414939806e-05, -0.06025407835841179, -0.4085839092731476, -0.2470511496067047, -0.262347549200058], "finish_reason": "stop"}], "metrics": {"energy": 403.56894407176964, "energy_per_token": 4.434823561228238, "time": 11.362785, "time_per_token": 0.12486576923076924}}
{"outputs": [{"text": " RegexpTokenizer(r\"[$]\\w+\")", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "\"", "[$", "]\\", "w", "+", "\"", ")", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -1.064791202545166, -1.574981689453125, -0.7070456743240356, -0.010596085339784622, -0.15478895604610443, -0.11339137703180313, -0.07864603400230408, -0.11174141615629196], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if not word.startswith(\"$$\")]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " not", " word", ".", "start", "sw", "ith", "(", "\"", "$$", "\"", ")]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -3.1607470512390137, -0.2992088198661804, -0.258471816778183, -0.033253561705350876, -6.770858453819528e-05, -2.3841855067985307e-07, -0.8838722705841064, -0.008541951887309551, -0.009202918969094753, -0.010399202816188335, -0.08855634927749634, -0.018073398619890213], "finish_reason": "stop"}, {"text": " [word[1:] for word in dollar_prefixed_words if word != '$']", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", " if", " word", " ", "!", "=", " '$", "']", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.7551983594894409, -0.0016076747560873628, -0.0016214807983487844, -0.38257384300231934, -0.0003418338019400835, -6.544376083184034e-05, -0.0004602803383022547, -1.1920928244535389e-07, -3.3378546504536644e-06, -7.510157047363464e-06, -3.2186455882765586e-06, -2.50339189733495e-06, -0.5047262907028198, -0.4751542806625366, -1.0273011922836304, -2.622600959512056e-06, -0.00011932138295378536, -0.507394015789032, -0.0011959074763581157, -0.06120495870709419], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.021463146433234215, -0.007004231214523315, -0.023815639317035675, -1.7881377516459906e-06, -1.1205610462639015e-05, -0.0008141063735820353, -0.13045723736286163], "finish_reason": "stop"}, {"text": " [pair for pair in word_counts.most_common(5) if pair[0] != \"\"]", "tokens": [" [", "pair", " for", " pair", " in", " word", "_", "counts", ".", "most", "_", "common", "(", "5", ")", " if", " pair", "[", "0", "]", " ", "!", "=", " \"", "\"", "]", "\n"], "logprobs": [-3.073263645172119, -3.286914348602295, -0.02175106666982174, -0.002107186708599329, -0.0010224120924249291, -0.018747635185718536, -1.4305104514278355e-06, -3.576278118089249e-07, -0.0007974305190145969, -0.0013188959565013647, -1.9073468138230965e-06, -1.3112935448589269e-05, -0.23315170407295227, -0.33981233835220337, -0.17849262058734894, -0.007019501645117998, -0.20640671253204346, -0.004502041265368462, -0.06884206831455231, -0.2205970585346222, -0.3580567240715027, -3.099436753473128e-06, -0.00012575789878610522, -1.2087469100952148, -0.5679186582565308, -0.1472589671611786, -0.21470195055007935], "finish_reason": "stop"}], "metrics": {"energy": 434.11647173309314, "energy_per_token": 4.341164717330932, "time": 12.20222, "time_per_token": 0.12202220000000001}}
{"outputs": [{"text": " RegexpTokenizer(r\"[$]\\w+\")", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "\"", "[$", "]\\", "w", "+", "\"", ")", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -1.064791202545166, -1.574981689453125, -0.7070456743240356, -0.010596085339784622, -0.15478895604610443, -0.11339137703180313, -0.07864603400230408, -0.11174141615629196], "finish_reason": "stop"}, {"text": " [word.replace(\"$\", \"\") for word in tokenizer.tokenize(text) if \"$\" in word]", "tokens": [" [", "word", ".", "replace", "(", "\"", "$", "\"", ",", " \"", "\"", ")", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " \"", "$", "\"", " in", " word", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.9864199757575989, -0.930428683757782, -1.2032792568206787, -0.01279890350997448, -0.052038002759218216, -0.00029881304362788796, -5.340433563105762e-05, -0.04941163212060928, -0.00036399890086613595, -0.023670705035328865, -0.05947304144501686, -0.0008911690674722195, -0.000651147507596761, -0.01048308052122593, -1.8715683836489916e-05, -0.0002076410164590925, -0.00011681827891152352, -9.536738616588991e-07, -0.0003597089380491525, -0.0023889592848718166, -0.0938708484172821, -0.035426873713731766, -2.745795726776123, -0.22810083627700806, -0.000321336614433676, -0.008170749992132187, -0.0005209281225688756, -0.09214213490486145, -0.0027583905030041933], "finish_reason": "stop"}, {"text": " [word[1:] for word in dollar_prefixed_words]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.7551983594894409, -0.0016076747560873628, -0.0016214807983487844, -0.38257384300231934, -0.0003418338019400835, -6.544376083184034e-05, -0.0004602803383022547, -1.1920928244535389e-07, -3.3378546504536644e-06, -7.510157047363464e-06, -3.2186455882765586e-06, -2.50339189733495e-06, -0.9890631437301636, -0.24459783732891083], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.021463146433234215, -0.007004231214523315, -0.023815639317035675, -1.7881377516459906e-06, -1.1205610462639015e-05, -0.0008141063735820353, -0.13045723736286163], "finish_reason": "stop"}, {"text": " word_counts.most_common()[:5]", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "()", "[:", "5", "]", "\n"], "logprobs": [-0.31380322575569153, -1.3947389561508317e-05, -9.536697689327411e-06, -0.017802685499191284, -0.00013469743134919554, -2.109982233378105e-05, -0.0001174142598756589, -2.882235050201416, -0.4313064515590668, -0.06695779412984848, -0.22864946722984314, -0.29283207654953003], "finish_reason": "stop"}], "metrics": {"energy": 371.4700461549758, "energy_per_token": 4.586049952530566, "time": 10.524924, "time_per_token": 0.12993733333333335}}
{"outputs": [{"text": " RegexpTokenizer('\\w+|\\$?\\w+\\$?\\w*')", "tokens": [" Re", "gex", "p", "Token", "izer", "('", "\\", "w", "+", "|\\", "$", "?", "\\", "w", "+\\", "$", "?", "\\", "w", "*", "')", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -2.585906505584717, -0.6490623950958252, -2.8605895042419434, -0.6100983619689941, -0.4954814612865448, -0.007006598636507988, -0.6133331060409546, -0.005651211366057396, -0.25907349586486816, -1.104296088218689, -0.002052940195426345, -0.04558529704809189, -1.0833487510681152, -0.04517814517021179, -0.12840797007083893, -0.2919815480709076, -0.09013234823942184], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if word != '$']", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " word", " ", "!", "=", " '$", "']", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -0.6267849206924438, -1.4501781463623047, -6.198863957251888e-06, -0.0002619877050165087, -0.40623727440834045, -0.0006179092451930046, -0.018228158354759216], "finish_reason": "stop"}, {"text": " [word.lstrip('$') for word in dollar_prefixed_words if word.lstrip('$')]", "tokens": [" [", "word", ".", "lst", "rip", "('", "$", "')", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", " if", " word", ".", "lst", "rip", "('", "$", "')", "]", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.6684521436691284, -2.1227641105651855, -8.583032467868179e-06, -0.3211752772331238, -0.002140613505616784, -0.0008465044084005058, -0.32911059260368347, -0.0004961451631970704, -7.617183291586116e-05, -0.0006551980040967464, -2.3841855067985307e-07, -9.536738616588991e-07, -4.8636207793606445e-05, -1.6689286894688848e-06, -1.9073468138230965e-06, -0.6780285239219666, -0.4322710335254669, -0.7034615278244019, -0.1403416246175766, -1.2874520507466514e-05, -0.03650325536727905, -0.000811366830021143, -3.8265450712060556e-05, -0.23704874515533447, -0.03316649794578552], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.02130666933953762, -0.010106697678565979, -0.01395163219422102, -1.7881377516459906e-06, -1.0371154530730564e-05, -0.0008244690834544599, -0.11252881586551666], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")", "\n"], "logprobs": [-0.21358616650104523, -9.894321920000948e-06, -8.583032467868179e-06, -0.0168895460665226, -0.00011836781777674332, -2.4914430468925275e-05, -9.572047565598041e-05, -0.05232449620962143, -0.42527076601982117, -0.26612260937690735, -0.23000283539295197], "finish_reason": "stop"}], "metrics": {"energy": 404.723214416504, "energy_per_token": 4.447507850730813, "time": 11.365125, "time_per_token": 0.12489148351648352}}
{"outputs": [{"text": " RegexpTokenizer(r'(\\$\\w+)', gaps=False)", "tokens": [" Re", "gex", "p", "Token", "izer", "(", "r", "'", "(\\", "$\\", "w", "+", ")'", ",", " gaps", "=", "False", ")", "\n"], "logprobs": [-0.012801139615476131, -5.960462772236497e-07, -5.6265202147187665e-05, -1.156323378381785e-05, -2.145764938177308e-06, -0.07929947972297668, -0.10012170672416687, -2.0277657508850098, -2.14798641204834, -0.5114877223968506, -0.04153638333082199, -1.5029877424240112, -0.5422366261482239, -0.0018264055252075195, -0.040569011121988297, -0.0014071096666157246, -0.020215781405568123, -0.016608312726020813, -0.14547353982925415], "finish_reason": "stop"}, {"text": " [word[1:] for word in tokenizer.tokenize(text) if word[1:].isalnum()]", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " token", "izer", ".", "token", "ize", "(", "text", ")", " if", " word", "[", "1", ":]", ".", "isal", "num", "()", "]", "\n"], "logprobs": [-0.2378702163696289, -0.12257097661495209, -0.5215113759040833, -0.0003995097358711064, -0.0007039214833639562, -0.03667932376265526, -0.00021598390594590455, -0.00037067217635922134, -0.012222510762512684, -8.702239938429557e-06, -0.0003190723655279726, -7.70062324590981e-05, -2.3841855067985307e-07, -0.0004748170613311231, -0.0026207170449197292, -0.0686040148139, -0.027372077107429504, -0.6267849206924438, -0.7294026017189026, -0.24066287279129028, -0.12729685008525848, -0.15129801630973816, -0.08109229803085327, -5.722029527532868e-06, -0.00048160876031033695, -0.031589288264513016, -0.008542661555111408], "finish_reason": "stop"}, {"text": " [word[1:] for word in dollar_prefixed_words if word != '$']", "tokens": [" [", "word", "[", "1", ":]", " for", " word", " in", " dollar", "_", "pref", "ixed", "_", "words", " if", " word", " ", "!", "=", " '$", "']", "\n"], "logprobs": [-0.08038128167390823, -0.051200009882450104, -0.7551983594894409, -0.0016076747560873628, -0.0016214807983487844, -0.38257384300231934, -0.0003418338019400835, -6.544376083184034e-05, -0.0004602803383022547, -1.1920928244535389e-07, -3.3378546504536644e-06, -7.510157047363464e-06, -3.2186455882765586e-06, -2.50339189733495e-06, -0.5047262907028198, -0.4751542806625366, -1.0273011922836304, -2.622600959512056e-06, -0.00011932138295378536, -0.507394015789032, -0.0011959074763581157, -0.06120495870709419], "finish_reason": "stop"}, {"text": " Counter(normalized_words)", "tokens": [" Counter", "(", "normalized", "_", "words", ")", "\n"], "logprobs": [-0.021463146433234215, -0.007004231214523315, -0.023815639317035675, -1.7881377516459906e-06, -1.1205610462639015e-05, -0.0008141063735820353, -0.13045723736286163], "finish_reason": "stop"}, {"text": " word_counts.most_common(5)", "tokens": [" word", "_", "counts", ".", "most", "_", "common", "(", "5", ")", "\n"], "logprobs": [-0.31380322575569153, -1.3947389561508317e-05, -9.536697689327411e-06, -0.017802685499191284, -0.00013469743134919554, -2.109982233378105e-05, -0.0001174142598756589, -0.06182340160012245, -0.44775667786598206, -0.24642671644687653, -0.2693387269973755], "finish_reason": "stop"}], "metrics": {"energy": 408.7997082080842, "energy_per_token": 4.75348497916377, "time": 10.949821, "time_per_token": 0.1273235}}
