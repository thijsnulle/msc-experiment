{"code": "json_file_list = []\n\n    # Get all file names from directory\n    for root, dirs, files in os.walk(json_dir_path):\n        for filename in files:\n            if \".json\" in filename:\n                json_file_list.append(os.path.join(root, filename))\n\n    df_list = []\n    for json_file in json_file_list:\n        with open(json_file) as f:\n            data = json.load(f)\n        df_list.append(data['text'])\n    df = pd.DataFrame(df_list)\n    text_column = df[0]\n    text_column = text_column.astype(str)\n    text_column = text_column.str.replace(r'\\W+', ' ')\n    text_column = text_column.str.replace(r'\\d+', '')\n    text_column = text_column.str.split()\n    text_column = text_column.explode()\n    text_column = text_column.apply(lambda x: x.strip())\n", "compilation_passed": true, "time": 0.0034401416778564453, "tests_passed": false, "error": "TypeError"}
{"code": "json_dir = os.fsencode(json_dir_path)\n\n    counter_obj = Counter()\n    for json_file in os.listdir(json_dir):\n        path = os.path.join(json_dir, json_file)\n        if os.path.isfile(path):\n            with open(path, \"rb\") as json_file_obj:\n                json_data = json.load(json_file_obj)\n                text_list = json_data.get(\"text\").split()\n                for word in text_list:\n                    counter_obj.update([word])\n\n    # Use the most common method to get the top n frequent words and their counts\n    most_common = counter_obj.most_common(word_count)\n\n    return most_common", "compilation_passed": true, "time": 0.010133743286132812, "tests_passed": true, "error": null}
{"code": "# create a list to store the text content of each JSON file\n    text_list = []\n\n    # loop through all the JSON files in the directory\n    for file_name in os.listdir(json_dir_path):\n        # check if the file is a JSON file\n        if file_name.endswith(\".json\"):\n            # read the JSON file\n            with open(os.path.join(json_dir_path, file_name), \"r\") as f:\n                json_data = json.load(f)\n            # get the text content from the JSON data\n            text = json_data[\"text\"]\n            # add the text content to the list\n            text_list.append(text)\n\n    # concatenate all the text contents into a single string\n    text_concatenated = \" \".join(text_list)\n\n    # split the concatenated text into a list of words\n    # this is done by separating the words at the whitespace characters\n    words = text_concatenated.split()\n\n    # count the occurrence of each word using Counter from collections\n", "compilation_passed": true, "time": 0.0026831626892089844, "tests_passed": false, "error": "TypeError"}
{"code": "df = pd.DataFrame()\n    for file in os.listdir(json_dir_path):\n        if file.endswith(\".json\"):\n            with open(json_dir_path + '/' + file, \"r\", encoding=\"UTF-8\") as f:\n                json_data = json.load(f)\n                df = pd.concat([df, pd.DataFrame.from_records(json_data)])\n    word_counter = Counter()\n    for word in df.text.str.split(expand=True).unstack():\n        word_counter[word] += 1\n    return word_counter.most_common(word_count)", "compilation_passed": true, "time": 0.002928018569946289, "tests_passed": false, "error": "ValueError"}
{"code": "df = pd.DataFrame()\n\n    for root, dirs, files in os.walk(json_dir_path):\n        for file in files:\n            if file.endswith('.json'):\n                json_path = os.path.join(root, file)\n                with open(json_path) as f:\n                    data = json.load(f)\n                    text = data['text']\n                    df = df.append(pd.Series([text], index=['text']), ignore_index=True)\n\n    all_text = ' '.join(df['text'].tolist())\n    all_words = all_text.split(' ')\n\n    counter = Counter(all_words)\n\n    most_common_words = counter.most_common(word_count)\n\n    return most_common_words", "compilation_passed": true, "time": 0.0029969215393066406, "tests_passed": false, "error": "AttributeError"}
{"code": "words = []\n    for file in os.listdir(json_dir_path):\n        if file.endswith(\".json\"):\n            with open(os.path.join(json_dir_path, file)) as f:\n                data = json.load(f)\n                words.extend(data[\"text\"].split())\n    word_counts = Counter(words)\n    most_common = word_counts.most_common(word_count)\n    return most_common", "compilation_passed": true, "time": 0.00941610336303711, "tests_passed": true, "error": null}
{"code": "words_counter = Counter()\n\n    for root, dirs, files in os.walk(json_dir_path, topdown=True):\n        for file in files:\n            if not file.endswith(\".json\"):\n                continue\n\n            file_path = os.path.join(root, file)\n            with open(file_path) as json_file:\n                data = json.load(json_file)\n                text = data.get(\"text\")\n\n                if not text:\n                    continue\n\n                for word in text.split():\n                    words_counter.update([word])\n\n    return words_counter.most_common(word_count)", "compilation_passed": true, "time": 0.009623050689697266, "tests_passed": true, "error": null}
{"code": "# Load all JSON files in the directory\n    all_json = []\n    for filename in os.listdir(json_dir_path):\n        if filename.endswith('.json'):\n            with open(os.path.join(json_dir_path, filename), 'r') as f:\n                all_json.append(json.load(f))\n\n    # Extract text content from each JSON object\n    all_text = [item[\"text\"] for item in all_json]\n\n    # Join the text content into a single string\n    combined_text = \" \".join(all_text)\n\n    # Split text into words\n    words = combined_text.split()\n\n    # Count occurrences of each word\n    word_counts = Counter(words)\n\n    # Get the most common words\n    most_common = word_counts.most_common(word_count)\n\n    return most_common", "compilation_passed": true, "time": 0.009737968444824219, "tests_passed": true, "error": null}
{"code": "# Get all JSON files in the specified directory\n    json_files = [f for f in os.listdir(json_dir_path) if f.endswith(\".json\")]\n    print(\"Total json files:\", len(json_files))\n\n    # Create an empty Counter object to store the word frequencies\n    word_counter = Counter()\n\n    # Loop through each JSON file and extract the text content\n    for json_file in json_files:\n        with open(os.path.join(json_dir_path, json_file)) as f:\n            data = json.load(f)\n            text = data.get(\"text\", \"\")\n            # Update the counter with the words from the text content\n            word_counter.update(text.split())\n\n    # Return the most common words and their counts\n    return word_counter.most_common(word_count)", "compilation_passed": true, "time": 0.009335041046142578, "tests_passed": true, "error": null}
{"code": "all_texts = []\n    for file in os.listdir(json_dir_path):\n        if file.endswith(\".json\"):\n            with open(os.path.join(json_dir_path, file)) as f:\n                all_texts.append(json.load(f)['text'])\n    df = pd.DataFrame(columns = ['text'])\n    df['text'] = all_texts\n    df['tokenized_text'] = df['text'].apply(lambda x: x.split())\n    all_tokens = []\n    for tokens in df['tokenized_text']:\n        all_tokens.extend(tokens)\n    freq_counter = Counter(all_tokens)\n    top_freq_words = freq_counter.most_common(word_count)\n    return top_freq_words", "compilation_passed": true, "time": 0.011697053909301758, "tests_passed": true, "error": null}
{"code": "json_file_list = [json_file for json_file in os.listdir(json_dir_path) if json_file.endswith('.json')]\n    json_file_path_list = [os.path.join(json_dir_path, file_name) for file_name in json_file_list]\n    json_file_content_list = []\n    for path in json_file_path_list:\n        with open(path) as f:\n            content = json.load(f)\n        json_file_content_list.append(content)\n\n    df = pd.DataFrame(json_file_content_list)\n    text_content = df['text'].astype(str).str.cat(sep=' ')\n    text_content = text_content.split(' ')\n    c = Counter(text_content)\n    top_words = c.most_common(word_count)\n    return top_words", "compilation_passed": true, "time": 0.010616064071655273, "tests_passed": true, "error": null}
{"code": "all_json_data = []\n    for file in os.listdir(json_dir_path):\n        if file.endswith('.json'):\n            with open(os.path.join(json_dir_path, file), 'r') as json_file:\n                data = json.load(json_file)\n                all_json_data.append(data)\n\n    df = pd.DataFrame(all_json_data)\n    word_list = df['text'].str.split(expand=True).stack().value_counts()\n\n    word_counts = [(word, count) for word, count in Counter(word_list).items()]\n\n    most_common_words = sorted(word_counts, key=lambda x: x[1], reverse=True)\n    most_common_words = most_common_words[:word_count]\n    return most_common_words", "compilation_passed": true, "time": 0.004230976104736328, "tests_passed": true, "error": null}
{"code": "# Initialize an empty list to store the text content from JSON files\n    text_list = []\n\n    # Iterate through all the files in the specified directory\n    for file in os.listdir(json_dir_path):\n        # If the file is a JSON file\n        if file.endswith(\".json\"):\n            # Open the file in read mode\n            with open(f\"{json_dir_path}/{file}\", \"r\") as f:\n                # Load the data from the file as Python objects\n                data = json.load(f)\n                # Extract the text content from the data\n                text = data['text']\n                # Append the extracted text to the text_list\n                text_list.append(text)\n\n    # Concatenate all the extracted text into a single string\n    full_text = \" \".join(text_list)\n\n    # Split the full text into individual words, accounting for punctuation marks and apostrophes\n    words = re.findall(r'\\w+|[^\\w\\s]', full_text)\n\n    # Count the occurrence of", "compilation_passed": true, "time": 0.0026788711547851562, "tests_passed": false, "error": "NameError"}
{"code": "file_paths = [os.path.join(json_dir_path, file_name) for file_name in os.listdir(json_dir_path)]\n\n    if len(file_paths) > 1000:\n        print(f\"Too many files in the directory: {json_dir_path}\")\n\n    df = pd.DataFrame({'text': [json.load(open(path))['text'] for path in file_paths]})\n\n    text_str = df['text'].str.cat(sep=' ')\n\n    words_list = text_str.split()\n    word_count_dict = Counter(words_list)\n\n    return word_count_dict.most_common(word_count)", "compilation_passed": true, "time": 0.009752988815307617, "tests_passed": true, "error": null}
{"code": "# Read all the JSON files from the specified directory\n    json_files = [f for f in os.listdir(json_dir_path) if f.endswith('.json')]\n    all_text_data = []\n    for file in json_files:\n        with open(os.path.join(json_dir_path, file), 'r') as f:\n            json_data = json.load(f)\n            all_text_data.extend(json_data['text'])\n\n    # Count the number of occurrences of each word\n    word_counts = Counter(word for text in all_text_data for word in text.split())\n\n    # Get the word_count most common words and their counts\n    most_common_words = word_counts.most_common(word_count)\n\n    return most_common_words", "compilation_passed": true, "time": 0.003103971481323242, "tests_passed": true, "error": null}
{"code": "json_file_paths = [os.path.join(json_dir_path, file_name)\n                    for file_name in os.listdir(json_dir_path) if file_name.endswith('.json')]\n    json_files = [json.load(open(json_path)) for json_path in json_file_paths]\n    texts = [json_file['text'] for json_file in json_files]\n    words = [word for text in texts for word in text.split()]\n    most_common_words = Counter(words).most_common(word_count)\n    return most_common_words", "compilation_passed": true, "time": 0.009104251861572266, "tests_passed": true, "error": null}
{"code": "file_list = os.listdir(json_dir_path)\n    total_text = []\n\n    # read and extract text\n    for i in range(len(file_list)):\n        if file_list[i].endswith('json'):\n            with open(json_dir_path + '/' + file_list[i]) as f:\n                text_data = pd.read_json(f)\n                text = text_data['text']\n                total_text.append(text.tolist())\n\n    total_text = sum(total_text, [])\n    total_text = \"\".join(total_text)\n\n    # tokenize words\n    tokens = total_text.split()\n    tokens = [t for t in tokens if len(t) > 3] # only keep tokens with a length greater than 3\n\n    # count words\n    counter = Counter(tokens)\n    most_common_words = counter.most_common(word_count)\n\n    return most_common_words", "compilation_passed": true, "time": 0.002863168716430664, "tests_passed": false, "error": "ValueError"}
{"code": "word_counter = Counter()\n    for filename in os.listdir(json_dir_path):\n        if filename.endswith('.json'):\n            with open(os.path.join(json_dir_path, filename), 'r') as f:\n                data = json.load(f)\n                for sentence in data.values():\n                    words = sentence.split()\n                    word_counter.update(words)\n    most_common_words = word_counter.most_common(word_count)\n    return most_common_words", "compilation_passed": true, "time": 0.008960962295532227, "tests_passed": true, "error": null}
{"code": "all_texts = []\n    all_text_words = []\n    all_files = os.listdir(json_dir_path)\n\n    for json_file in all_files:\n        if json_file.endswith(\".json\"):\n            file_path = os.path.join(json_dir_path, json_file)\n            with open(file_path, 'r') as f:\n                data = json.load(f)\n                text = data.get('text')\n                all_texts.append(text)\n\n    for text in all_texts:\n        if text is not None:\n            text_words = text.split()\n            all_text_words.extend(text_words)\n\n    if all_text_words:\n        counts = Counter(all_text_words)\n        most_common = counts.most_common(word_count)\n        return most_common\n\n    return []", "compilation_passed": true, "time": 0.010732889175415039, "tests_passed": true, "error": null}
{"code": "# Check if the provided path exists\n    if not os.path.exists(json_dir_path):\n        raise FileNotFoundError(f\"Directory or file not found: {json_dir_path}\")\n\n    # Initialize an empty counter\n    counter = Counter()\n\n    # Read all JSON files in the given directory\n    for file in os.listdir(json_dir_path):\n        if file.endswith('.json'):\n            file_path = os.path.join(json_dir_path, file)\n            with open(file_path, 'r') as json_file:\n                data = json.load(json_file)\n\n            # Extract text content from the JSON and count words\n            if 'text' in data:\n                text = data['text']\n                words = text.split()\n                counter.update(words)\n\n    # Determine the most common words and their counts\n    most_common = counter.most_common(word_count)\n\n    return most_common", "compilation_passed": true, "time": 0.009464740753173828, "tests_passed": true, "error": null}
{"code": "# Initialize a dictionary to store the word counts\n    word_count_dict = {}\n\n    # Loop through all the files in the directory\n    for filename in os.listdir(json_dir_path):\n        # Check if the file is a JSON file\n        if filename.endswith(\".json\"):\n            # Read the JSON file\n            with open(os.path.join(json_dir_path, filename), \"r\") as f:\n                json_data = json.load(f)\n\n            # Extract the text content from the JSON file\n            text = json_data[\"text\"]\n\n            # Split the text into words\n            words = text.split()\n\n            # Count the occurrences of each word\n            for word in words:\n                if word in word_count_dict:\n                    word_count_dict[word] += 1\n                else:\n                    word_count_dict[word] = 1\n\n    # Get the most common words\n    most_common_words = Counter(word_count_dict).most_common(word_count)\n\n    ", "compilation_passed": true, "time": 0.0027577877044677734, "tests_passed": false, "error": "TypeError"}
{"code": "word_counter = Counter()\n    for filename in os.listdir(json_dir_path):\n        if filename.endswith('.json'):\n            with open(f'{json_dir_path}/{filename}') as f:\n                data = json.load(f)\n                word_counter.update(data[\"text\"].split())\n    return word_counter.most_common(word_count)", "compilation_passed": true, "time": 0.009147167205810547, "tests_passed": true, "error": null}
{"code": "word_list = []\n    for file in os.listdir(json_dir_path):\n        with open(os.path.join(json_dir_path, file), \"r\") as f:\n            content = json.load(f)\n            word_list += content[\"text\"].split()\n    c = Counter(word_list)\n    most_common_words = c.most_common(word_count)\n    return most_common_words", "compilation_passed": true, "time": 0.009060859680175781, "tests_passed": true, "error": null}
{"code": "# Initialize a dictionary to store all the words from the JSON files\n    all_words = Counter()\n\n    # Initialize a list of valid file extensions to process\n    valid_ext = [\".json\"]\n\n    # Loop over all the files in the specified directory\n    for file in os.listdir(json_dir_path):\n        # If the file is not a JSON file, skip it\n        if os.path.splitext(file)[1] not in valid_ext:\n            continue\n\n        # Open the JSON file and read the data\n        with open(os.path.join(json_dir_path, file), \"r\") as f:\n            data = json.load(f)\n\n        # Extract the text content from the JSON data\n        text = data[\"text\"]\n\n        # Split the text into words\n        words = text.split()\n\n        # Update the dictionary of all words\n        all_words.update(words)\n\n    # Sort the dictionary by the count of words and take the specified number of words\n    most_common_words = all_words.most_common", "compilation_passed": true, "time": 0.0028929710388183594, "tests_passed": false, "error": "TypeError"}
{"code": "all_files_list = os.listdir(json_dir_path)\n\n    text_list = []\n    for file in all_files_list:\n        file_path = f\"{json_dir_path}/{file}\"\n        df = pd.read_json(file_path)\n        text_list.extend(df['text'].values.tolist())\n\n    words_counter = Counter()\n    for text in text_list:\n        words_counter.update(text.split(' '))\n\n    most_common_words = words_counter.most_common(word_count)\n    most_common_words = [(word, count) for word, count in most_common_words if word != '']\n    return most_common_words", "compilation_passed": true, "time": 0.003108978271484375, "tests_passed": false, "error": "ValueError"}
{"code": "all_json = [json.loads(open(os.path.join(json_dir_path, file), 'r').read()) for file in os.listdir(json_dir_path)]\n    text_content = [content['text'] for content in all_json]\n\n    total_text = ''.join([text for text in text_content])\n    total_text_words = total_text.split()\n\n    words_count = Counter(total_text_words)\n    most_common_words = words_count.most_common(word_count)\n\n    return most_common_words", "compilation_passed": true, "time": 0.009595155715942383, "tests_passed": true, "error": null}
{"code": "# Check if the input directory path is valid\n    if not os.path.isdir(json_dir_path):\n        raise ValueError(f\"Invalid directory path: {json_dir_path}\")\n\n    # Create an empty list to store all the words from the JSON files\n    all_words = []\n\n    # Iterate through each JSON file in the directory\n    for filename in os.listdir(json_dir_path):\n        if filename.endswith(\".json\"):\n            with open(os.path.join(json_dir_path, filename), 'r') as f:\n                # Load the content of the JSON file\n                content = json.load(f)\n\n                # Extract the text content from the dictionary and split it into words\n                words = content.get('text', '').split()\n\n                # Add the extracted words to the 'all_words' list\n                all_words.extend(words)\n\n    # Count the occurrences of each word using the Counter class from collections\n    word_counts = Counter(all_words)\n\n    # Get the 'word_count", "compilation_passed": true, "time": 0.0027217864990234375, "tests_passed": false, "error": "TypeError"}
{"code": "files = os.listdir(json_dir_path)\n    words_list = []\n    for file in files:\n        file_path = os.path.join(json_dir_path, file)\n        if os.path.isfile(file_path):\n            with open(file_path, 'r') as f:\n                try:\n                    json_file = json.load(f)\n                    if 'text' in json_file:\n                        words = json_file['text'].split()\n                        for word in words:\n                            words_list.append(word)\n                except json.JSONDecodeError:\n                    print(f\"Error decoding JSON in file {file_path}\")\n    word_counts = Counter(words_list)\n    most_common_words = word_counts.most_common(word_count)\n    return most_common_words", "compilation_passed": true, "time": 0.009205102920532227, "tests_passed": true, "error": null}
{"code": "json_files = [pos_json for pos_json in os.listdir(json_dir_path)]\n    texts = []\n    for json_file in json_files:\n        with open(os.path.join(json_dir_path, json_file)) as f:\n            data = json.load(f)\n            texts.append(data['text'])\n    df = pd.DataFrame(data={'text': texts})\n    df = df['text'].str.split(expand=True).stack().value_counts().to_frame('Count')\n    df = df.sort_values('Count', ascending=False)\n    df['Count'] = df['Count'].astype(int)\n    df = df.reset_index()\n    return df[['index', 'Count']].head(word_count).to_dict('records')", "compilation_passed": true, "time": 0.0047261714935302734, "tests_passed": false, "error": "KeyError"}
{"code": "# Get list of all files in json_dir_path\n    files = os.listdir(json_dir_path)\n\n    # Initialize empty list to store all text content\n    all_text = []\n\n    # Loop through each file in the directory and append its text content to all_text\n    for file in files:\n        # Construct the full path to the file\n        file_path = os.path.join(json_dir_path, file)\n\n        # Open the file and load its JSON data into a dictionary\n        with open(file_path, 'r') as f:\n            json_data = json.load(f)\n\n        # Extract the text content from the dictionary and append it to all_text\n        # if 'text' key is present in the dictionary, otherwise skip the file\n        if 'text' in json_data.keys():\n            all_text.append(json_data['text'])\n\n    # Combine all the text content into a single string\n    all_text = ' '.join(all_text)\n\n    # Split the text string into words, creating a list of all the words in", "compilation_passed": true, "time": 0.002692699432373047, "tests_passed": false, "error": "TypeError"}
