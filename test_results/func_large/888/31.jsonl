{"code": "if not csv_files:\n        return pd.DataFrame()\n\n    # Initialize an empty list to store the data frames\n    dfs = []\n\n    for file_name in csv_files:\n        file_path = os.path.join(data_dir, file_name)\n        dfs.append(pd.read_csv(file_path))\n\n    # Concatenate the data frames together\n    return pd.concat(dfs, axis=0, ignore_index=True)", "compilation_passed": true, "time": 0.011282205581665039, "tests_passed": true, "error": null}
{"code": "if not csv_files:\n        return pd.DataFrame()\n    data = pd.concat([pd.read_csv(os.path.join(data_dir, file)) for file in csv_files], ignore_index=True)\n    return data", "compilation_passed": true, "time": 0.010869979858398438, "tests_passed": true, "error": null}
{"code": "# Initialize an empty DataFrame to store the merged data\n    data = pd.DataFrame()\n    \n    # Check if the CSV file list is not empty\n    if csv_files:\n        # Iterate over the CSV files\n        for filename in csv_files:\n            # Construct the file path\n            filepath = os.path.join(data_dir, filename)\n            # Read the CSV file into a DataFrame\n            df = pd.read_csv(filepath)\n            # Append the data of the current DataFrame to the existing data\n            data = pd.concat([data, df], ignore_index=True)\n\n    return data", "compilation_passed": true, "time": 0.01189422607421875, "tests_passed": true, "error": null}
{"code": "if not csv_files:\n        return pd.DataFrame()\n    else:\n        data_list = []\n        for file in csv_files:\n            data = pd.read_csv(os.path.join(data_dir, file))\n            data_list.append(data)\n        return pd.concat(data_list, ignore_index=True)", "compilation_passed": true, "time": 0.01085209846496582, "tests_passed": true, "error": null}
{"code": "if len(csv_files) == 0:\n        return pd.DataFrame()\n    else:\n        return pd.concat([pd.read_csv(os.path.join(data_dir, csv)) for csv in csv_files])", "compilation_passed": true, "time": 0.0059740543365478516, "tests_passed": true, "error": null}
{"code": "try:\n        if len(csv_files) == 0:\n            return pd.DataFrame()\n        else:\n            return pd.concat([pd.read_csv(os.path.join(data_dir, file)) for file in csv_files], ignore_index=True)\n    except Exception as e:\n        print(f\"Error concatenating CSV files: {e}\")\n        return None", "compilation_passed": true, "time": 0.011058807373046875, "tests_passed": true, "error": null}
{"code": "# Initialize an empty DataFrame to store the merged data\n    merged_data = pd.DataFrame()\n\n    # Check if the CSV files list is not empty\n    if csv_files:\n        # Iterate over each CSV file in the list\n        for csv_file in csv_files:\n            # Construct the full path to the CSV file\n            file_path = os.path.join(data_dir, csv_file)\n\n            # Read the CSV file into a DataFrame\n            df = pd.read_csv(file_path)\n\n            # Concatenate the current DataFrame to the merged_data DataFrame\n            merged_data = pd.concat([merged_data, df], ignore_index=True)\n\n    # Return the merged DataFrame\n    return merged_data", "compilation_passed": true, "time": 0.012006998062133789, "tests_passed": true, "error": null}
{"code": "# Initialize an empty list to store DataFrames\n    dfs = []\n\n    # Iterate over the list of CSV files\n    for file in csv_files:\n        # Create the full path of the CSV file\n        file_path = os.path.join(data_dir, file)\n\n        # Read the CSV file as a DataFrame and append it to the list\n        dfs.append(pd.read_csv(file_path))\n\n    # Concatenate the DataFrames in the list, vertically, into a single DataFrame\n    merged_df = pd.concat(dfs, axis=0)\n\n    return merged_df", "compilation_passed": true, "time": 0.006663084030151367, "tests_passed": true, "error": null}
{"code": "data = []\n    for f in csv_files:\n        df = pd.read_csv(os.path.join(data_dir, f))\n        data.append(df)\n    return pd.concat(data, axis=0, sort=False, ignore_index=True)", "compilation_passed": true, "time": 0.008391857147216797, "tests_passed": false, "error": "ValueError"}
{"code": "if not csv_files:\n        return pd.DataFrame()\n\n    csv_list = [pd.read_csv(os.path.join(data_dir, csv)) for csv in csv_files]\n    csv_merged = pd.concat(csv_list)\n\n    return csv_merged", "compilation_passed": true, "time": 0.006429910659790039, "tests_passed": true, "error": null}
{"code": "# Check for an empty list\n    if len(csv_files) == 0:\n        return pd.DataFrame()\n\n    # Read and concatenate data from the specified CSV files\n    data = pd.concat([pd.read_csv(os.path.join(data_dir, file)) for file in csv_files], axis=0)\n    return data", "compilation_passed": true, "time": 0.006201028823852539, "tests_passed": true, "error": null}
{"code": "if not csv_files:\n        return pd.DataFrame()\n\n    result = pd.DataFrame()\n    for csv in csv_files:\n        csv_path = os.path.join(data_dir, csv)\n        df = pd.read_csv(csv_path)\n        result = pd.concat([result, df], axis=0, ignore_index=True)\n\n    return result", "compilation_passed": true, "time": 0.012314796447753906, "tests_passed": true, "error": null}
{"code": "# Return an empty DataFrame if the list is empty\n    if not csv_files:\n        return pd.DataFrame()\n\n    # Create full paths of CSV files\n    csv_file_paths = [os.path.join(data_dir, file) for file in csv_files]\n\n    # Load CSV files using pandas and concatenate them\n    dfs = [pd.read_csv(file) for file in csv_file_paths]\n\n    # Concatenate the DataFrames into one\n    result_df = pd.concat(dfs, ignore_index=True)\n\n    return result_df", "compilation_passed": true, "time": 0.010764837265014648, "tests_passed": true, "error": null}
{"code": "if not csv_files:\n        return pd.DataFrame()\n\n    dataframes = [pd.read_csv(os.path.join(data_dir, csv_file)) for csv_file in csv_files]\n    return pd.concat(dataframes, ignore_index=True)", "compilation_passed": true, "time": 0.011184930801391602, "tests_passed": true, "error": null}
{"code": "if not csv_files:\n        return pd.DataFrame()\n    all_data = [pd.read_csv(os.path.join(data_dir, filename)) for filename in csv_files]\n    merged_data = pd.concat(all_data, axis=0, ignore_index=True)\n    return merged_data", "compilation_passed": true, "time": 0.0107879638671875, "tests_passed": true, "error": null}
{"code": "df = pd.DataFrame()\n\n    if not csv_files:\n        return df\n\n    # Create list with full path to all csv files.\n    full_path_file_list = [os.path.join(data_dir, csv) for csv in csv_files]\n    \n    # Loop over all full path csv files.\n    for file in full_path_file_list:\n        df = pd.concat([df, pd.read_csv(file)], ignore_index=True)\n\n    return df", "compilation_passed": true, "time": 0.011120080947875977, "tests_passed": true, "error": null}
{"code": "if not csv_files:\n        return pd.DataFrame()\n\n    dfs = []\n    for filename in csv_files:\n        file_path = os.path.join(data_dir, filename)\n        df = pd.read_csv(file_path)\n        dfs.append(df)\n\n    return pd.concat(dfs, ignore_index=True)", "compilation_passed": true, "time": 0.01070094108581543, "tests_passed": true, "error": null}
{"code": "if csv_files:\n        # If there are files in the list, concatenate them into a single DataFrame\n        return pd.concat([pd.read_csv(os.path.join(data_dir, csv_file)) for csv_file in csv_files],\n                          ignore_index=True)\n    else:\n        # If the list is empty, return an empty DataFrame\n        return pd.DataFrame()", "compilation_passed": true, "time": 0.011592864990234375, "tests_passed": true, "error": null}
{"code": "# Return empty DataFrame if an empty list of CSV files is provided\n    if not csv_files:\n        return pd.DataFrame()\n\n    # Initialize an empty list to hold the DataFrames\n    dataframes = []\n\n    # Loop over the provided CSV files\n    for file in csv_files:\n        # Construct the full path to the CSV file\n        full_path = os.path.join(data_dir, file)\n\n        # Read the CSV file into a DataFrame and append it to the list\n        dataframes.append(pd.read_csv(full_path))\n\n    # Concatenate the DataFrames into a single DataFrame\n    df = pd.concat(dataframes)\n\n    return df", "compilation_passed": true, "time": 0.006402015686035156, "tests_passed": true, "error": null}
{"code": "# Check if the list of files is empty\n    if not csv_files:\n        # Return an empty DataFrame if the list of files is empty\n        return pd.DataFrame()\n\n    # Initialize an empty list to store the DataFrames\n    dfs = []\n\n    # Loop through each file in the list\n    for file in csv_files:\n        # Read the CSV file as a DataFrame\n        df = pd.read_csv(os.path.join(data_dir, file))\n        # Append the DataFrame to the list of DataFrames\n        dfs.append(df)\n\n    # Concatenate the DataFrames in the list into a single DataFrame\n    result = pd.concat(dfs, ignore_index=True)\n\n    # Return the merged DataFrame\n    return result", "compilation_passed": true, "time": 0.011015176773071289, "tests_passed": true, "error": null}
{"code": "# Check if the list of CSV files is empty\n    if not csv_files:\n        return pd.DataFrame()\n\n    # Use list comprehension to read each CSV file and store the resulting DataFrames in a list\n    dfs = [pd.read_csv(os.path.join(data_dir, csv)) for csv in csv_files]\n\n    # Use pd.concat() to concatenate the DataFrames into a single DataFrame\n    df = pd.concat(dfs, ignore_index=True)\n    return df", "compilation_passed": true, "time": 0.01096796989440918, "tests_passed": true, "error": null}
{"code": "if not csv_files:\n        return pd.DataFrame()\n    else:\n        return pd.concat([pd.read_csv(os.path.join(data_dir, csv_file)) for csv_file in csv_files],\n                         ignore_index=True)", "compilation_passed": true, "time": 0.01088094711303711, "tests_passed": true, "error": null}
{"code": "if not csv_files:\n        return pd.DataFrame()\n    csv_paths = [os.path.join(data_dir, csv_file) for csv_file in csv_files]\n    return pd.concat([pd.read_csv(path) for path in csv_paths], ignore_index=True)", "compilation_passed": true, "time": 0.01065206527709961, "tests_passed": true, "error": null}
{"code": "if len(csv_files) == 0:\n        return pd.DataFrame()\n\n    full_paths = [os.path.join(data_dir, filename) for filename in csv_files]\n    dataframes = [pd.read_csv(path) for path in full_paths]\n\n    return pd.concat(dataframes, ignore_index=True)", "compilation_passed": true, "time": 0.011023998260498047, "tests_passed": true, "error": null}
{"code": "# Check for an empty list\n    if not csv_files:\n        # Return an empty DataFrame if the list is empty\n        return pd.DataFrame()\n\n    # Loop over the CSV files in the list\n    for i, file in enumerate(csv_files):\n        # Use os.path.join() to create a complete file path\n        file_path = os.path.join(data_dir, file)\n\n        # If it is the first file, read it as a DataFrame\n        if i == 0:\n            df = pd.read_csv(file_path)\n        # Otherwise, concatenate the next DataFrames\n        else:\n            df = pd.concat([df, pd.read_csv(file_path)])\n\n    return df", "compilation_passed": true, "time": 0.0064313411712646484, "tests_passed": true, "error": null}
{"code": "if not csv_files:\n        return pd.DataFrame()\n\n    data = []\n    for csv_file in csv_files:\n        file_path = os.path.join(data_dir, csv_file)\n        df = pd.read_csv(file_path)\n        data.append(df)\n\n    return pd.concat(data, ignore_index=True)", "compilation_passed": true, "time": 0.010965108871459961, "tests_passed": true, "error": null}
{"code": "# If empty list of files, return empty dataframe\n    if not csv_files:\n        return pd.DataFrame()\n\n    # Initialize empty list to store dataframes\n    df_list = []\n\n    # Loop through CSV file list\n    for file in csv_files:\n        # Get full file path\n        file_path = os.path.join(data_dir, file)\n        # Read CSV file and append to list\n        df_list.append(pd.read_csv(file_path))\n\n    # Concatenate dataframes into single dataframe\n    df = pd.concat(df_list)\n    return df", "compilation_passed": true, "time": 0.006256103515625, "tests_passed": true, "error": null}
{"code": "if not csv_files:\n        return pd.DataFrame()\n\n    dfs = [pd.read_csv(os.path.join(data_dir, f)) for f in csv_files]\n    return pd.concat(dfs, ignore_index=True)", "compilation_passed": true, "time": 0.010987997055053711, "tests_passed": true, "error": null}
{"code": "try:\n        if csv_files:\n            # Create a list of file paths to all CSV files in the specified directory\n            file_paths = [os.path.join(data_dir, f) for f in csv_files]\n\n            # Read each file into a DataFrame and concatenate them all together\n            df = pd.concat([pd.read_csv(f) for f in file_paths], ignore_index=True)\n\n        # If csv_files list is empty, return an empty DataFrame\n        else:\n            df = pd.DataFrame()\n\n        # Print the number of rows in the DataFrame\n        print(f\"\\n\\nNumber of rows in merged DataFrame: {len(df)}\\n\\n{df.head()}\\n\\n{df.tail()}\\n\\n\")\n\n        return df\n\n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\n        raise e", "compilation_passed": true, "time": 0.017915725708007812, "tests_passed": true, "error": null}
{"code": "if len(csv_files) == 0:\n        return pd.DataFrame()\n\n    csv_paths = [os.path.join(data_dir, file) for file in csv_files]\n    dfs = [pd.read_csv(file_path) for file_path in csv_paths]\n    return pd.concat(dfs, ignore_index=True)", "compilation_passed": true, "time": 0.011054277420043945, "tests_passed": true, "error": null}
