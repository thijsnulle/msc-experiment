{"code": "hashes = {}\n\n    for root, _, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            with open(file_path, 'rb') as f:\n                hashes[file_path] = hashlib.sha256(f.read()).hexdigest()\n\n    json_filename = 'hashes.json'\n    json_file = os.path.join(directory, json_filename)\n    with open(json_file, 'w') as f:\n        json.dump(hashes, f)\n\n    return json_file", "compilation_passed": true, "time": 0.003804922103881836, "tests_passed": true, "error": null}
{"code": "hash_dict = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            with open(os.path.join(root, file), 'rb') as f:\n                hash = hashlib.sha256(f.read()).hexdigest()\n                hash_dict[os.path.join(root, file)] = hash\n\n    json_path = Path(directory) / 'hashes.json'\n    with open(json_path, 'w') as f:\n        json.dump(hash_dict, f)\n\n    return json_path", "compilation_passed": true, "time": 0.0037152767181396484, "tests_passed": true, "error": null}
{"code": "file_hashes = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            with open(file_path, 'rb') as file_obj:\n                file_hash = hashlib.sha256()\n                file_hash.update(file_obj.read())\n            file_hashes[file] = file_hash.hexdigest()\n\n    json_file_path = os.path.join(directory, 'hashes.json')\n    with open(json_file_path, 'w') as json_file:\n        json.dump(file_hashes, json_file)\n\n    return json_file_path", "compilation_passed": true, "time": 0.0019099712371826172, "tests_passed": false, "error": "KeyError"}
{"code": "hashes = {}\n\n    for dirpath, dirnames, filenames in os.walk(directory):\n        for filename in filenames:\n            file_path = os.path.join(dirpath, filename)\n\n            with open(file_path, 'rb') as f:\n                file_hash = hashlib.sha256(f.read()).hexdigest()\n                hashes[file_path] = file_hash\n\n    json_path = Path(directory) / 'hashes.json'\n\n    with open(json_path, 'w') as f:\n        json.dump(hashes, f, indent=4)\n\n    return json_path.resolve().absolute()", "compilation_passed": true, "time": 0.0037078857421875, "tests_passed": true, "error": null}
{"code": "hashes = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            with open(file_path, \"rb\") as f:\n                file_hash = hashlib.sha256()\n                while chunk := f.read(8192):\n                    file_hash.update(chunk)\n            hashes[file_path] = file_hash.hexdigest()\n    json_file = str(Path(directory) / \"hashes.json\")\n    with open(json_file, \"w\") as f:\n        json.dump(hashes, f)\n    return json_file", "compilation_passed": true, "time": 0.0037348270416259766, "tests_passed": true, "error": null}
{"code": "# Initialize an empty dictionary to store file hashes\n    hashes = {}\n\n    # Iterate over files in the directory and its subdirectories\n    for path, dirs, files in os.walk(directory):\n        for file in files:\n            # Create an absolute path to the file\n            file_path = os.path.join(path, file)\n\n            # Create an absolute path to the directory\n            abs_directory = Path(directory).absolute()\n\n            # Create an absolute path to the hashes.json file\n            json_path = os.path.join(abs_directory, 'hashes.json')\n\n            # Calculate hash for the file\n            hash = hashlib.sha256()\n            with open(file_path, 'rb') as f:\n                for chunk in iter(lambda: f.read(4096), b''):\n                    hash.update(chunk)\n\n            # Store file path and hash in the dictionary\n            hashes[file_path] = hash.hexdigest()\n\n    # Write file hashes to the hashes.json file\n    with open", "compilation_passed": false, "time": 0.00021314620971679688, "tests_passed": false, "error": "SyntaxError"}
{"code": "path_dir = Path(directory).resolve()\n    hashes = {}\n    for root, _, filenames in os.walk(directory):\n        for filename in filenames:\n            with open(os.path.join(root, filename), 'rb') as f:\n                file_hash = hashlib.sha256()\n                while chunk := f.read(4096):\n                    file_hash.update(chunk)\n            hashes[filename] = file_hash.hexdigest()\n\n    with open(path_dir / \"hashes.json\", \"w\") as f:\n        json.dump(hashes, f)\n\n    return str(path_dir / \"hashes.json\")", "compilation_passed": true, "time": 0.0017931461334228516, "tests_passed": false, "error": "KeyError"}
{"code": "hashes = {}\n\n    for path, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(path, file)\n            with open(file_path, \"rb\") as f:\n                data = f.read()\n                hash_object = hashlib.sha256(data)\n                hashes[file_path] = hash_object.hexdigest()\n\n    json_file = Path(directory, \"hashes.json\")\n    with open(json_file, \"w\") as f:\n        json.dump(hashes, f)\n\n    return json_file.as_posix()", "compilation_passed": true, "time": 0.004148960113525391, "tests_passed": true, "error": null}
{"code": "hashes = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            with open(file_path, 'rb') as f:\n                data = f.read()\n                hash_obj = hashlib.sha256(data)\n                hash_value = hash_obj.hexdigest()\n                hashes[file_path] = hash_value\n    with open('hashes.json', 'w') as f:\n        json.dump(hashes, f)\n    return Path('hashes.json').resolve()", "compilation_passed": true, "time": 0.003900766372680664, "tests_passed": true, "error": null}
{"code": "hash_dict = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            hash = hashlib.sha256()\n            with open(file_path, \"rb\") as f:\n                for chunk in iter(lambda: f.read(4096), b\"\"):\n                    hash.update(chunk)\n            hash_dict[file] = hash.hexdigest()\n    json_file = str(Path(directory) / 'hashes.json')\n    with open(json_file, 'w') as f:\n        json.dump(hash_dict, f)\n    return json_file", "compilation_passed": true, "time": 0.0019168853759765625, "tests_passed": false, "error": "KeyError"}
{"code": "path = Path(directory).resolve()  # Resolve the path to get the absolute path\n\n    file_hashes = {}\n\n    for dirpath, dirnames, filenames in os.walk(directory):\n        for filename in filenames:\n            file_path = Path(dirpath, filename)\n            with open(file_path, \"rb\") as f:\n                file_hash = hashlib.sha256()\n                while chunk := f.read(4096):\n                    file_hash.update(chunk)\n            file_hashes[str(file_path.relative_to(path))] = file_hash.hexdigest()\n\n    hashes_file = Path(path, \"hashes.json\")\n    with open(hashes_file, \"w\") as f:\n        json.dump(file_hashes, f)\n\n    return str(hashes_file.resolve())", "compilation_passed": true, "time": 0.002389192581176758, "tests_passed": false, "error": "ValueError"}
{"code": "hashes = {}\n    for root, dirs, files in os.walk(directory):\n        for filename in files:\n            file_path = os.path.join(root, filename)\n            with open(file_path, 'rb') as f:\n                contents = f.read()\n                hash_object = hashlib.sha256(contents)\n                hash_value = hash_object.hexdigest()\n            hashes[file_path] = hash_value\n    with open(os.path.join(directory, 'hashes.json'), 'w') as f:\n        json.dump(hashes, f)\n    return os.path.abspath(f.name)", "compilation_passed": true, "time": 0.0038268566131591797, "tests_passed": true, "error": null}
{"code": "path = Path(directory)\n    hashes = {}\n\n    for file_path in path.rglob('*'):\n        if file_path.is_file():\n            with open(file_path, \"rb\") as f:\n                hash_obj = hashlib.sha256()\n                hash_obj.update(f.read())\n                file_hash = hash_obj.hexdigest()\n                hashes[file_path.relative_to(path)] = file_hash\n\n    with open(path / 'hashes.json', 'w') as f:\n        json.dump(hashes, f)\n\n    return path / 'hashes.json'", "compilation_passed": true, "time": 0.0019428730010986328, "tests_passed": false, "error": "TypeError"}
{"code": "hashes = {}\n\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            hash_ = hashlib.sha256()\n            with open(file_path, 'rb') as f:\n                for chunk in iter(lambda: f.read(4096), b\"\"):\n                    hash_.update(chunk)\n            hashes[file_path] = hash_.hexdigest()\n\n    json_file = Path(directory) / 'hashes.json'\n    with open(json_file, 'w') as f:\n        json.dump(hashes, f)\n\n    return json_file.resolve().as_posix()", "compilation_passed": true, "time": 0.003929853439331055, "tests_passed": true, "error": null}
{"code": "hashes = {}\n    for dirpath, dirnames, filenames in os.walk(directory):\n        for filename in filenames:\n            file_path = os.path.join(dirpath, filename)\n            with open(file_path, \"rb\") as f:\n                contents = f.read()\n                hash = hashlib.sha256(contents).hexdigest()\n                hashes[file_path] = hash\n\n    json_filename = \"hashes.json\"\n    json_file_path = os.path.join(directory, json_filename)\n    with open(json_file_path, \"w\") as f:\n        json.dump(hashes, f)\n\n    return os.path.abspath(json_file_path)", "compilation_passed": true, "time": 0.0036742687225341797, "tests_passed": true, "error": null}
{"code": "# Convert the directory path to an absolute path\n    directory_path = os.path.abspath(directory)\n\n    # Create an empty dictionary to store the hashes\n    hash_dict = {}\n\n    # Iterate through all files and directories in the given directory\n    for root, dirs, files in os.walk(directory_path):\n        for file in files:\n            # Create a path to the file\n            file_path = os.path.join(root, file)\n\n            # Calculate the SHA256 hash of the file\n            with open(file_path, 'rb') as f:\n                file_hash = hashlib.sha256(f.read()).hexdigest()\n\n            # Store the hash with the file path as the key in the dictionary\n            hash_dict[file_path] = file_hash\n\n    # Create a JSON file to store the hashes\n    json_path = Path(directory) / \"hashes.json\"\n\n    # Ensure that the parent directory of the JSON file exists\n    json_path.parent.mkdir(parents=True, exist_ok", "compilation_passed": false, "time": 0.00019788742065429688, "tests_passed": false, "error": "SyntaxError"}
{"code": "file_hashes = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            with open(file_path, 'rb') as f:\n                file_hash = hashlib.sha256(f.read()).hexdigest()\n                file_hashes[file_path] = file_hash\n\n    hashes_json = json.dumps(file_hashes, indent=4)\n    json_path = Path(directory, 'hashes.json')\n    json_path.write_text(hashes_json)\n\n    return json_path.resolve()", "compilation_passed": true, "time": 0.00394892692565918, "tests_passed": true, "error": null}
{"code": "hashes = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            with open(file_path, \"rb\") as f:\n                content = f.read()\n                hash = hashlib.sha256(content).hexdigest()\n                hashes[file_path] = hash\n    json_path = os.path.join(directory, \"hashes.json\")\n    with open(json_path, \"w\") as json_file:\n        json.dump(hashes, json_file)\n    return os.path.abspath(json_path)", "compilation_passed": true, "time": 0.003559112548828125, "tests_passed": true, "error": null}
{"code": "# Initialize empty dictionary to hold hash values\n    hash_dict = {}\n\n    # Iterate through each file in directory and all subdirectories\n    for root, dirs, files in os.walk(directory):\n        for name in files:\n            # Create absolute path to file\n            file_path = os.path.join(root, name)\n\n            # Calculate SHA256 hash value\n            with open(file_path, 'rb') as f:\n                file_hash = hashlib.sha256()\n                while chunk := f.read(8192):\n                    file_hash.update(chunk)\n\n            # Add hash value to dictionary along with absolute path to file\n            hash_dict[file_path] = file_hash.hexdigest()\n\n    # Create absolute path to output JSON file\n    output_path = os.path.join(directory, 'hashes.json')\n\n    # Convert hash dictionary to JSON file\n    with open(output_path, 'w') as f:\n        json.dump(hash_dict, f, indent=4)\n\n    # Return absolute", "compilation_passed": true, "time": 0.0017311573028564453, "tests_passed": false, "error": "TypeError"}
{"code": "hashes = {}\n    for current_dir, directories, files in os.walk(directory):\n        for file_name in files:\n            file_path = os.path.join(current_dir, file_name)\n            with open(file_path, 'rb') as file:\n                content = file.read()\n                hash_ = hashlib.sha256(content).hexdigest()\n                hashes[file_path] = hash_\n    json_path = os.path.join(directory, 'hashes.json')\n    with open(json_path, 'w') as json_file:\n        json.dump(hashes, json_file)\n    return json_path", "compilation_passed": true, "time": 0.003673076629638672, "tests_passed": true, "error": null}
{"code": "path = Path(directory)\n    hashes = []\n    for file in path.glob('**/*'):\n        if file.is_file():\n            with open(file, 'rb') as f:\n                hashes.append((file.stem, hashlib.sha256(f.read()).hexdigest()))\n    json_file = json.dumps(hashes)\n    json_path = os.path.join(path, 'hashes.json')\n    with open(json_path, 'w') as f:\n        json.dump(hashes, f)\n    return json_path", "compilation_passed": true, "time": 0.001955747604370117, "tests_passed": false, "error": "TypeError"}
{"code": "hashes = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            with open(os.path.join(root, file), 'rb') as f:\n                data = f.read()\n                hash = hashlib.sha256(data).hexdigest()\n                hashes[file] = hash\n    json_file = Path(directory) / 'hashes.json'\n    with open(json_file, 'w') as f:\n        json.dump(hashes, f)\n    return str(json_file.absolute())", "compilation_passed": true, "time": 0.001889944076538086, "tests_passed": false, "error": "KeyError"}
{"code": "path = Path(directory)\n    hashes = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            with open(Path(root, file), \"rb\") as f:\n                hash = hashlib.sha256(f.read()).hexdigest()\n                hashes[file] = hash\n    json_file = Path(path, \"hashes.json\")\n    with open(json_file, \"w\") as f:\n        json.dump(hashes, f)\n    return str(json_file.resolve())", "compilation_passed": true, "time": 0.0018019676208496094, "tests_passed": false, "error": "KeyError"}
{"code": "file_hashes = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            with open(file_path, \"rb\") as f:\n                file_content = f.read()\n                file_hash = hashlib.sha256(file_content).hexdigest()\n                file_hashes[file_path] = file_hash\n    json_file = os.path.join(directory, \"hashes.json\")\n    with open(json_file, \"w\") as f:\n        json.dump(file_hashes, f)\n    return os.path.abspath(json_file)", "compilation_passed": true, "time": 0.003622770309448242, "tests_passed": true, "error": null}
{"code": "# Get the absolute path of the given directory.\n    abs_dir = Path(directory).absolute()\n\n    # Initialize an empty dictionary to store the file names and their hashes.\n    hashes = {}\n\n    # Iterate over all files in the directory and its subdirectories.\n    for root, _, files in os.walk(directory):\n        for file in files:\n            # Get the absolute path of each file.\n            file_path = Path(root, file).absolute()\n\n            # Generate the hash for the current file.\n            file_hash = hashlib.sha256()\n            with open(file_path, 'rb') as f:\n                while True:\n                    # Read a chunk of data from the file.\n                    chunk = f.read(8192)\n                    if not chunk:\n                        # If we've read all data, break the loop.\n                        break\n                    # Update the hash with the current chunk.\n                    file_hash.update(chunk)\n\n            # Store the hash in the 'hashes' dictionary with the file name as the", "compilation_passed": true, "time": 0.0015850067138671875, "tests_passed": false, "error": "TypeError"}
{"code": "hash_dict = {}\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            with open(file_path, \"rb\") as f:\n                data = f.read()\n                file_hash = hashlib.sha256(data).hexdigest()\n                hash_dict[file_path] = file_hash\n\n    json_file = \"hashes.json\"\n    with open(json_file, \"w\") as f:\n        json.dump(hash_dict, f, indent=4)\n    return Path(json_file).absolute()", "compilation_passed": true, "time": 0.0034449100494384766, "tests_passed": true, "error": null}
{"code": "file_hashes = {}\n    for root, _, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            hash_object = hashlib.sha256()\n            with open(file_path, 'rb') as f:\n                for chunk in iter(lambda: f.read(4096), b''):\n                    hash_object.update(chunk)\n            file_hashes[file_path] = hash_object.hexdigest()\n\n    json_file = os.path.join(directory, 'hashes.json')\n    with open(json_file, 'w') as f:\n        json.dump(file_hashes, f, indent=4)\n\n    return json_file", "compilation_passed": true, "time": 0.003657102584838867, "tests_passed": true, "error": null}
{"code": "# Construct absolute path for the JSON file\n    json_path = os.path.join(os.path.abspath(directory), 'hashes.json')\n\n    # Create empty dictionary to store file hashes\n    hashes = {}\n\n    # Use pathlib to traverse directory structure\n    for file in Path(directory).rglob('*'):\n        if file.is_file():\n            # Read file content\n            with open(file, 'rb') as f:\n                content = f.read()\n\n            # Compute SHA256 hash\n            h = hashlib.sha256()\n            h.update(content)\n            sha256_hash = h.hexdigest()\n\n            # Add file hash to dictionary\n            hashes[file.absolute()] = sha256_hash\n\n    # Save file hashes in a JSON file\n    with open(json_path, 'w') as jf:\n        json.dump(hashes, jf)\n\n    # Return the absolute path of the JSON file containing the hashes\n    return json_path", "compilation_passed": true, "time": 0.0019502639770507812, "tests_passed": false, "error": "TypeError"}
{"code": "# Initialize a dictionary to store the file hashes\n    file_hashes = {}\n\n    # Iterate over the files in the directory and its subdirectories\n    for root, _, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n\n            # Ignore any files ending with \".json\" or are hidden\n            if file.endswith(\".json\") or file.startswith(\".\"):\n                continue\n\n            # Calculate the hash of the file\n            try:\n                with open(file_path, 'rb') as file:\n                    file_bytes = file.read()\n                    file_hash = hashlib.sha256(file_bytes).hexdigest()\n                    file_hashes[file_path] = file_hash\n            except Exception as e:\n                print(f\"Error calculating hash for file: {file_path} - {e}\")\n\n    # Save the hashes to a JSON file\n    json_file = os.path.join(directory, 'hashes", "compilation_passed": false, "time": 0.00010395050048828125, "tests_passed": false, "error": "SyntaxError"}
{"code": "# Initialize an empty dictionary to store file hashes\n    file_hashes = {}\n\n    # Iterate over all files in the directory and its subdirectories\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            # Construct the absolute path of the file\n            file_path = os.path.join(root, file)\n\n            # Calculate the hash of the file\n            file_hash = hashlib.sha256()\n            with open(file_path, 'rb') as f:\n                # Read chunks of the file at a time to avoid memory issues\n                for chunk in iter(lambda: f.read(4096), b''):\n                    file_hash.update(chunk)\n\n            # Store the file hash in the dictionary\n            file_hashes[file_path] = file_hash.hexdigest()\n\n    # Construct the absolute path of the JSON file\n    json_file = os.path.join(directory, 'hashes.json')\n\n    # Save the hashes to the JSON file\n    with open(json_file, '", "compilation_passed": false, "time": 8.20159912109375e-05, "tests_passed": false, "error": "SyntaxError"}
