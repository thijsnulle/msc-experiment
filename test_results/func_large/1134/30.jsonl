{"code": "try:\n        if not os.path.exists(source_dir):\n            raise FileNotFoundError(f\"Source directory '{source_dir}' not found.\")\n        os.makedirs(target_dir, exist_ok=True)\n\n        def hash_file(filepath):\n            with open(filepath, 'r') as f:\n                content = f.read()\n            hashed_content = f\"{prefix}{hashlib.md5(content.encode('utf-8')).hexdigest()}\\n{content}\"\n            return hashed_content\n\n        processed_files = []\n        for filename in glob.glob(os.path.join(source_dir, '*')):\n            hashed_content = hash_file(filename)\n            new_filename = os.path.join(target_dir, os.path.basename(filename))\n            with open(new_filename, 'w') as f:\n                f.write(hashed_content)\n            processed_files.append(new_filename)\n\n        return processed_files\n    except FileNotFoundError as e:\n", "compilation_passed": false, "time": 0.0003879070281982422, "tests_passed": false, "error": "IndentationError"}
{"code": "if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Source directory '{source_dir}' does not exist.\")\n\n    os.makedirs(target_dir, exist_ok=True)\n    processed_files = []\n\n    for filename in os.listdir(source_dir):\n        filepath = os.path.join(source_dir, filename)\n        if os.path.isfile(filepath):\n            with open(filepath, 'rb') as f:\n                content = f.read()\n                hashed_content = prefix + hashlib.md5(content).hexdigest() + content.decode('utf-8')\n                target_filepath = os.path.join(target_dir, filename)\n                with open(target_filepath, 'w', encoding='utf-8') as outf:\n                    outf.write(hashed_content)\n                processed_files.append(target_filepath)\n\n    return processed_files", "compilation_passed": true, "time": 0.003777027130126953, "tests_passed": true, "error": null}
{"code": "os.makedirs(target_dir, exist_ok=True)\n\n    processed_files = []\n\n    for file_path in glob.glob(os.path.join(source_dir, '*.txt')):\n        file_name = os.path.basename(file_path)\n        target_file_path = os.path.join(target_dir, file_name)\n\n        with open(file_path, 'r') as infile:\n            content = infile.read()\n            hash_object = hashlib.md5(content.encode())\n            md5_hash = hash_object.hexdigest()\n\n            with open(target_file_path, 'w') as outfile:\n                outfile.write(prefix + md5_hash + '\\n' + content)\n\n        processed_files.append(target_file_path)\n\n    return processed_files", "compilation_passed": true, "time": 0.004392147064208984, "tests_passed": true, "error": null}
{"code": "if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Source directory '{source_dir}' does not exist\")\n\n    os.makedirs(target_dir, exist_ok=True)\n\n    new_files = []\n\n    for file_path in glob.glob(os.path.join(source_dir, '*')):\n        file_name = os.path.basename(file_path)\n        new_file_path = os.path.join(target_dir, file_name)\n\n        with open(file_path, 'r') as source_file:\n            content = source_file.read()\n            md5_hash = hashlib.md5(content.encode()).hexdigest()\n\n        with open(new_file_path, 'w') as target_file:\n            target_file.write(prefix + md5_hash + '\\n' + content)\n            new_files.append(new_file_path)\n\n    return new_files", "compilation_passed": true, "time": 0.00503993034362793, "tests_passed": true, "error": null}
{"code": "if not os.path.isdir(source_dir):\n        raise FileNotFoundError(f\"Source directory {source_dir} does not exist.\")\n\n    if not os.path.isdir(target_dir):\n        os.makedirs(target_dir)\n\n    paths = []\n    for file in glob.glob(os.path.join(source_dir, '*')):\n        with open(file, 'r') as f:\n            content = f.read()\n\n        hasher = hashlib.md5()\n        hasher.update(content.encode('utf-8'))\n        hash_val = hasher.hexdigest()\n\n        new_content = prefix + hash_val + '\\n\\n' + content\n\n        filename = os.path.basename(file)\n        new_path = os.path.join(target_dir, filename)\n\n        with open(new_path, 'w') as f:\n            f.write(new_content)\n\n        paths.append(new_path)\n\n    return paths", "compilation_passed": true, "time": 0.004583835601806641, "tests_passed": true, "error": null}
{"code": "# Ensure the source directory exists\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"The source directory '{source_dir}' does not exist.\")\n\n    # Create the target directory if it does not exist\n    os.makedirs(target_dir, exist_ok=True)\n\n    # Initialize an empty list to store the file names of the hashed files\n    hashed_files = []\n\n    # Iterate over all files in the source directory\n    for file in glob.glob(os.path.join(source_dir, '*')):\n        with open(file, 'r') as f:\n            # Read the file content and compute its MD5 hash\n            content = f.read()\n            hashed_content = hashlib.md5(content.encode()).hexdigest()\n\n        # Append the prefix and hash to the content\n        updated_content = f\"{prefix}{hashed_content}\\n{content}\"\n\n        # Construct the name of the hashed file\n        file_name = os.path.basename(file)\n        h", "compilation_passed": true, "time": 0.0017371177673339844, "tests_passed": false, "error": "NameError"}
{"code": "os.makedirs(target_dir, exist_ok=True)\n\n    target_files = []\n    for filename in glob.glob(os.path.join(source_dir, '*')):\n        with open(filename, 'r') as f:\n            content = f.read()\n            md5_hash = hashlib.md5(content.encode()).hexdigest()\n            with open(os.path.join(target_dir, os.path.basename(filename)), 'w') as g:\n                g.write(f'{prefix}{md5_hash}\\n{content}')\n                target_files.append(os.path.join(target_dir, os.path.basename(filename)))\n\n    return target_files", "compilation_passed": true, "time": 0.00385284423828125, "tests_passed": true, "error": null}
{"code": "# Create the target directory if it doesn't exist\n    if not os.path.isdir(target_dir):\n        os.makedirs(target_dir)\n\n    # Loop through each file in the source directory\n    for file_path in glob.iglob(source_dir + '/**/*', recursive=True):\n        if os.path.isfile(file_path):\n            # Read the file's content\n            with open(file_path, 'r') as f:\n                content = f.read()\n\n            # Compute the MD5 hash of the content\n            hashed_content = hashlib.md5(content.encode()).hexdigest()\n\n            # Create a new file in the target directory with the hash prepended to the content\n            target_file_path = os.path.join(target_dir, os.path.basename(file_path))\n            with open(target_file_path, 'w') as f:\n                f.write(prefix + hashed_content + '\\n' + content)\n\n    # Return the list of paths to the created files\n    return", "compilation_passed": true, "time": 0.0019102096557617188, "tests_passed": false, "error": "TypeError"}
{"code": "# Check if the source directory exists\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Source directory '{source_dir}' does not exist.\")\n\n    # Create the target directory if it does not exist\n    os.makedirs(target_dir, exist_ok=True)\n\n    # Find all files in the source directory\n    files = glob.glob(os.path.join(source_dir, '*'))\n\n    # Process each file\n    new_files = []\n    for file_path in files:\n        # Read the file's contents\n        with open(file_path, 'r') as file:\n            content = file.read()\n\n        # Compute the hash of the content\n        hash = hashlib.md5(content.encode()).hexdigest()\n\n        # Prepend the hash to the content\n        content = f\"{prefix}{hash}\\n{content}\"\n\n        # Write the modified content to a new file in the target directory\n        new_file_name = os.path.basename(file_path)\n        new_", "compilation_passed": true, "time": 0.0016431808471679688, "tests_passed": false, "error": "NameError"}
{"code": "if not os.path.exists(source_dir):\n        raise FileNotFoundError(f'Source directory does not exist: {source_dir}')\n\n    os.makedirs(target_dir, exist_ok=True)\n    file_paths = glob.glob(os.path.join(source_dir, '*'))\n    hash_prepended_file_paths = []\n\n    for file_path in file_paths:\n        with open(file_path, 'r') as file:\n            content = file.read()\n            file_hash = hashlib.md5(content.encode()).hexdigest()\n\n        new_content = prefix + file_hash + content\n\n        file_name = os.path.basename(file_path)\n        hash_prepended_file_path = os.path.join(target_dir, file_name)\n        with open(hash_prepended_file_path, 'w') as file:\n            file.write(new_content)\n\n        hash_prepended_file_paths.append(hash_prepended_file_", "compilation_passed": false, "time": 0.0002467632293701172, "tests_passed": false, "error": "SyntaxError"}
{"code": "os.makedirs(target_dir, exist_ok=True)\n    files = glob.glob(os.path.join(source_dir, '*'))\n    processed_files = []\n    for file in files:\n        with open(file, 'rb') as f:\n            data = f.read()\n            md5_hash = hashlib.md5(data).hexdigest()\n            new_data = prefix.encode('utf-8') + md5_hash.encode('utf-8') + b'\\n' + data\n        target_path = os.path.join(target_dir, os.path.basename(file))\n        with open(target_path, 'wb') as f:\n            f.write(new_data)\n        processed_files.append(target_path)\n    return processed_files", "compilation_passed": true, "time": 0.0036683082580566406, "tests_passed": true, "error": null}
{"code": "# Ensure source_dir exists\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(\"Source directory '{}' does not exist.\".format(source_dir))\n\n    # Create target_dir if it does not exist\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    # Find all files in source_dir\n    files = glob.glob(os.path.join(source_dir, '*'))\n\n    new_files = []\n    for file_path in files:\n        # Compute MD5 hash of file's content\n        md5_hash = hashlib.md5()\n        with open(file_path, 'rb') as f:\n            for chunk in iter(lambda: f.read(4096), b''):\n                md5_hash.update(chunk)\n        hash_str = md5_hash.hexdigest()\n\n        # Prepend hash to file's content\n        with open(file_path, 'rb') as f_in, open(os.path.", "compilation_passed": false, "time": 0.0002238750457763672, "tests_passed": false, "error": "SyntaxError"}
{"code": "# Create the target directory if it doesn't exist\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    # Initialize the list of file paths in the target directory\n    target_files = []\n\n    # Loop through all files in the source directory\n    for file_path in glob.glob(os.path.join(source_dir, \"*\")):\n        # Read the contents of the file\n        with open(file_path, \"rb\") as f:\n            content = f.read()\n\n        # Compute the MD5 hash of the file's content\n        hash_object = hashlib.md5(content)\n        md5_hash = hash_object.hexdigest()\n\n        # Extract the file name from the file path\n        file_name = os.path.basename(file_path)\n\n        # Create the path of the new file in the target directory\n        target_file = os.path.join(target_dir, file_name)\n        target_files.append(target_file)\n\n        # Open the", "compilation_passed": true, "time": 0.0015578269958496094, "tests_passed": false, "error": "TypeError"}
{"code": "if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Directory {source_dir} does not exist\")\n\n    os.makedirs(target_dir, exist_ok=True)\n    files = glob.glob(os.path.join(source_dir, '*'))\n    hash_files = []\n\n    for file in files:\n        with open(file, 'rb') as f:\n            data = f.read()\n            hash = hashlib.md5(data).hexdigest()\n            file_name = os.path.basename(file)\n            target_file = os.path.join(target_dir, file_name)\n            with open(target_file, 'w') as new_file:\n                new_file.write(prefix + hash + os.linesep + data.decode('utf-8'))\n            hash_files.append(target_file)\n\n    return hash_files", "compilation_passed": true, "time": 0.004207134246826172, "tests_passed": true, "error": null}
{"code": "os.makedirs(target_dir, exist_ok=True)  # Create the target directory if it doesn't exist\n\n    file_paths = glob.glob(os.path.join(source_dir, '*.txt'))  # Get the list of .txt files in the source directory\n\n    result_paths = []  # List to store the paths to the created files in the target directory\n\n    for file_path in file_paths:\n        filename = os.path.basename(file_path)  # Get the base filename without the directory\n        target_file_path = os.path.join(target_dir, filename)  # Generate the path for the new file in target directory\n\n        # Compute the MD5 hash of the file's content\n        md5_hash = hashlib.md5()\n        with open(file_path, 'rb') as f:\n            for chunk in iter(lambda: f.read(4096), b''):\n                md5_hash.update(chunk)\n\n        # Prepend the hash and prefix to the file's content\n        hash_prefix", "compilation_passed": true, "time": 0.0017080307006835938, "tests_passed": false, "error": "NameError"}
{"code": "os.makedirs(target_dir, exist_ok=True)\n    file_paths = glob.glob(os.path.join(source_dir, '*'))\n    target_paths = []\n    for file_path in file_paths:\n        with open(file_path, 'r') as file:\n            content = file.read()\n            hash_object = hashlib.md5(content.encode())\n            hash_value = hash_object.hexdigest()\n            prepended_content = prefix + hash_value + content\n        target_path = os.path.join(target_dir, os.path.basename(file_path))\n        target_paths.append(target_path)\n        with open(target_path, 'w') as file:\n            file.write(prepended_content)\n    return target_paths", "compilation_passed": true, "time": 0.0029571056365966797, "tests_passed": true, "error": null}
{"code": "# Ensure the source directory exists\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Source directory {source_dir} does not exist.\")\n\n    # Create the target directory if it does not exist\n    if not os.path.exists(target_dir):\n        os.mkdir(target_dir)\n\n    # Process each file in the source directory\n    files_processed = []\n    for filename in glob.glob(os.path.join(source_dir, \"*\")):\n        with open(filename, \"r\", encoding=\"utf-8\") as input_file:\n            # Read the file content\n            content = input_file.read()\n\n            # Compute the MD5 hash\n            hash_obj = hashlib.md5()\n            hash_obj.update(content.encode())\n            file_hash = hash_obj.hexdigest()\n\n            # Prepend the hash with the prefix\n            modified_content = prefix + file_hash + \"\\n\" + content\n\n            # Get the filename without the full path\n            _, file_", "compilation_passed": true, "time": 0.0016121864318847656, "tests_passed": false, "error": "NameError"}
{"code": "source_files = glob.glob(f\"{source_dir}/*.txt\")\n    os.makedirs(target_dir, exist_ok=True)\n\n    new_file_paths = []\n\n    for source_file in source_files:\n        file_name = os.path.basename(source_file)\n        target_file = f\"{target_dir}/{file_name}\"\n\n        with open(source_file, 'r') as sf, open(target_file, 'w') as tf:\n            content = sf.read()\n            content_bytes = content.encode('utf-8')\n            hash_object = hashlib.md5(content_bytes)\n            hash_str = hash_object.hexdigest()\n\n            tf.write(f\"{prefix}{hash_str}\\n{content}\")\n\n        new_file_paths.append(target_file)\n\n    return new_file_paths", "compilation_passed": true, "time": 0.0037131309509277344, "tests_passed": true, "error": null}
{"code": "if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Source directory '{source_dir}' does not exist.\")\n\n    os.makedirs(target_dir, exist_ok=True)\n\n    # Get a list of file paths in the source directory\n    file_paths = glob.glob(os.path.join(source_dir, '*'))\n\n    # Process each file\n    new_files = []\n    for file_path in file_paths:\n        with open(file_path, 'rb') as infile:\n            content = infile.read()\n            hash_obj = hashlib.md5(content)\n            md5_hash = hash_obj.hexdigest()\n\n            new_content = prefix.encode('ascii') + md5_hash.encode('ascii') + b'\\n' + content\n\n            file_name = os.path.basename(file_path)\n            new_file_path = os.path.join(target_dir, file_name)\n            with open(new_file_path, 'wb') as out", "compilation_passed": false, "time": 0.00024509429931640625, "tests_passed": false, "error": "SyntaxError"}
{"code": "if not os.path.isdir(source_dir):\n        raise FileNotFoundError(f\"Source directory '{source_dir}' does not exist.\")\n\n    if not os.path.isdir(target_dir):\n        os.makedirs(target_dir)\n\n    file_paths = []\n    for file in glob.glob(os.path.join(source_dir, '*')):\n        if os.path.isfile(file):\n            with open(file, 'r') as f:\n                content = f.read()\n\n            hash_object = hashlib.md5(content.encode())\n            hash = hash_object.hexdigest()\n\n            hashed_content = prefix + hash + '\\n' + content\n\n            new_file = os.path.join(target_dir, os.path.basename(file))\n            with open(new_file, 'w') as f:\n                f.write(hashed_content)\n\n            file_paths.append(new_file)\n\n    return file_paths", "compilation_passed": true, "time": 0.0042819976806640625, "tests_passed": true, "error": null}
{"code": "os.makedirs(target_dir, exist_ok=True)  # ensure target directory exists\n    paths = []\n    for source_path in glob.iglob(os.path.join(source_dir, '*')):  # iterate over all files in source_dir\n        filename = os.path.basename(source_path)  # get filename\n        with open(source_path, 'r') as in_file:\n            content = in_file.read()  # read file content\n        hash_ = hashlib.md5(content.encode('utf-8')).hexdigest()  # compute MD5 hash of file content\n        new_content = prefix + hash_ + content  # prepend hash and prefix to file content\n        new_path = os.path.join(target_dir, filename)  # construct target path\n        with open(new_path, 'w') as out_file:  # write new file content to target directory\n            out_file.write(new_content)\n        paths.append(new_path)  # append target path to list\n    return paths", "compilation_passed": true, "time": 0.0031359195709228516, "tests_passed": true, "error": null}
{"code": "# Check if the source directory exists\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Directory '{source_dir}' does not exist.\")\n\n    # Create the target directory if it doesn't exist\n    os.makedirs(target_dir, exist_ok=True)\n\n    # Get a list of all files in the source directory\n    files = glob.glob(os.path.join(source_dir, '*'))\n\n    # Process each file\n    result_paths = []\n    for file in files:\n        with open(file, 'r') as infile:\n            content = infile.read()\n\n        # Compute the hash\n        hash_obj = hashlib.md5()\n        hash_obj.update(content.encode('utf-8'))\n        hash_value = hash_obj.hexdigest()\n\n        # Prepend the hash and the prefix to the content\n        prepended_content = f'{prefix}{hash_value}\\n\\n{content}'\n\n        # Get the filename without extension and create the new file path in target", "compilation_passed": true, "time": 0.0016651153564453125, "tests_passed": false, "error": "TypeError"}
{"code": "if not os.path.isdir(source_dir):\n        raise FileNotFoundError(f\"The source directory '{source_dir}' does not exist.\")\n\n    os.makedirs(target_dir, exist_ok=True)\n\n    processed_files = []\n    for filename in glob.glob(os.path.join(source_dir, '*')):\n        with open(filename, 'r') as f:\n            content = f.read()\n\n        md5_hash = hashlib.md5(content.encode()).hexdigest()\n\n        new_content = prefix + md5_hash + content\n\n        target_filename = os.path.join(target_dir, os.path.basename(filename))\n\n        with open(target_filename, 'w') as f:\n            f.write(new_content)\n\n        processed_files.append(target_filename)\n\n    return processed_files", "compilation_passed": true, "time": 0.0028989315032958984, "tests_passed": true, "error": null}
{"code": "# Check that source_dir exists\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Directory '{source_dir}' does not exist.\")\n\n    # Create target_dir if it doesn't exist\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    # Find all files in source_dir and its subdirectories\n    files = glob.glob(os.path.join(source_dir, '**/*'), recursive=True)\n    result_files = []\n\n    # Process each file and write to target_dir\n    for file_path in files:\n        if os.path.isfile(file_path):\n            file_name = os.path.basename(file_path)\n            with open(file_path, 'r') as source_file, open(os.path.join(target_dir, file_name), 'w') as target_file:\n                # Compute hash\n                with open(file_path, 'rb') as f:\n                    h = hashlib.", "compilation_passed": false, "time": 0.00022673606872558594, "tests_passed": false, "error": "SyntaxError"}
{"code": "os.makedirs(target_dir, exist_ok=True)\n    # Iterate over all text files in the source directory\n    file_paths = glob.glob(f\"{source_dir}/*.txt\")\n    created_file_paths = []\n    for file_path in file_paths:\n        # Read the content of the file\n        with open(file_path, 'r', encoding=\"utf-8\") as file:\n            content = file.read()\n            # Compute the MD5 hash of the file's content\n            hash_md5 = hashlib.md5(content.encode('utf-8')).hexdigest()\n            # Prepend the hash to the content and write it to a new file\n            modified_content = f\"{prefix}{hash_md5}\\n{content}\"\n            target_file_path = f\"{target_dir}/{os.path.basename(file_path)}\"\n            with open(target_file_path, 'w', encoding=\"utf-8\") as target_file:\n                target_file.write(modified_content)", "compilation_passed": true, "time": 0.0019528865814208984, "tests_passed": false, "error": "TypeError"}
{"code": "# Create target directory if it doesn't exist\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    # Find all text files in the source directory\n    file_paths = glob.glob(os.path.join(source_dir, \"*.txt\"))\n\n    # Create a list to store the paths to the modified files\n    modified_files = []\n\n    for file_path in file_paths:\n        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n            # Read the file content\n            content = file.read()\n\n            # Calculate MD5 hash of the content\n            md5_hash = hashlib.md5(content.encode()).hexdigest()\n\n            # Prepend hash and prefix to the content\n            new_content = f\"{prefix}{md5_hash}\\n\\n{content}\"\n\n            # Generate the modified file name\n            modified_file_name = os.path.basename(file_path)\n\n            # Write the modified content to a new file in the", "compilation_passed": true, "time": 0.0017590522766113281, "tests_passed": false, "error": "TypeError"}
{"code": "# Create the target directory if it doesn't exist\n    os.makedirs(target_dir, exist_ok=True)\n\n    # Get a list of files in the source directory\n    files = glob.glob(os.path.join(source_dir, '*'))\n\n    # Process each file\n    processed_files = []\n    for file_path in files:\n        with open(file_path, 'r') as f:\n            # Read the content of the file\n            content = f.read()\n\n            # Compute the MD5 hash of the content\n            md5 = hashlib.md5()\n            md5.update(content.encode())\n            hash_value = md5.hexdigest()\n\n            # Prepend the hash with the prefix\n            new_content = prefix + hash_value + '\\n' + content\n\n            # Write the new content to a new file in the target directory\n            file_name = os.path.basename(file_path)\n            new_file_path = os.path.join(target_dir, file_name)\n            with open(new_file", "compilation_passed": false, "time": 0.0002110004425048828, "tests_passed": false, "error": "SyntaxError"}
{"code": "if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Directory {source_dir} does not exist.\")\n\n    os.makedirs(target_dir, exist_ok=True)\n\n    files = glob.glob(os.path.join(source_dir, '*'))\n\n    for file in files:\n        with open(file, 'rb') as f:\n            content = f.read()\n            md5 = hashlib.md5(content).hexdigest()\n\n        with open(os.path.join(target_dir, os.path.basename(file)), 'wb') as f:\n            f.write(f'{prefix}{md5}\\n'.encode('utf-8'))\n            f.write(content)\n\n    return [os.path.join(target_dir, os.path.basename(file)) for file in files]", "compilation_passed": true, "time": 0.0044400691986083984, "tests_passed": true, "error": null}
{"code": "if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Source directory '{source_dir}' does not exist.\")\n\n    os.makedirs(target_dir, exist_ok=True)\n\n    files = glob.glob(f\"{source_dir}/*\")\n\n    target_files = []\n    for file in files:\n        with open(file, \"r\") as f:\n            content = f.read()\n            md5_hash = hashlib.md5(content.encode()).hexdigest()\n            new_content = prefix + md5_hash + \"\\n\" + content\n            target_file = os.path.join(target_dir, os.path.basename(file))\n            with open(target_file, \"w\") as target_f:\n                target_f.write(new_content)\n            target_files.append(target_file)\n\n    return target_files", "compilation_passed": true, "time": 0.0044097900390625, "tests_passed": true, "error": null}
{"code": "# Ensure source_dir exists\n    if not os.path.exists(source_dir):\n        raise FileNotFoundError(f\"Source directory {source_dir} not found\")\n\n    # Get list of source files\n    source_files = glob.glob(os.path.join(source_dir, \"*.txt\"))\n\n    # Create target directory if it doesn't exist\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    # Process each source file\n    output_files = []\n    for filepath in source_files:\n        filename = os.path.basename(filepath)\n        target_path = os.path.join(target_dir, filename)\n\n        # Read and hash the file content\n        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n            content = f.read()\n            hashed_content = f\"{prefix}{hashlib.md5(content.encode()).hexdigest()}\\n{content}\"\n\n        # Write the modified content to a new file", "compilation_passed": true, "time": 0.0016298294067382812, "tests_passed": false, "error": "TypeError"}
