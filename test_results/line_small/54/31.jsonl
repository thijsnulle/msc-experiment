{"code": " CountVectorizer(strip_accents=None)", "compilation_passed": true, "time": 0.0073490142822265625, "tests_passed": true, "error": null}
{"code": " CountVectorizer(analyzer='word')", "compilation_passed": true, "time": 0.004851102828979492, "tests_passed": true, "error": null}
{"code": " CountVectorizer(tokenizer=lambda x: x.split())", "compilation_passed": true, "time": 0.005678892135620117, "tests_passed": true, "error": null}
{"code": " CountVectorizer()", "compilation_passed": true, "time": 0.004843235015869141, "tests_passed": true, "error": null}
{"code": " CountVectorizer(analyzer=\"word\")", "compilation_passed": true, "time": 0.004682064056396484, "tests_passed": true, "error": null}
{"code": " CountVectorizer(stop_words=\"english\")", "compilation_passed": true, "time": 0.005384922027587891, "tests_passed": true, "error": null}
{"code": " CountVectorizer(stop_words=[\".\"])", "compilation_passed": true, "time": 0.0049550533294677734, "tests_passed": true, "error": null}
{"code": " CountVectorizer(analyzer='word', tokenizer=None, ngram_range=(1, 1), preprocessor=None, stop_words=None,", "compilation_passed": false, "time": 0.000286102294921875, "tests_passed": false, "error": "SyntaxError"}
{"code": " CountVectorizer(", "compilation_passed": false, "time": 0.00017905235290527344, "tests_passed": false, "error": "SyntaxError"}
{"code": " CountVectorizer(vocabulary={\"contains\": 0, \"is\": 1, \"sample\": 2, \"sentence\": 3, \"this\": 4, \"words\": 5})", "compilation_passed": true, "time": 0.006061077117919922, "tests_passed": true, "error": null}
{"code": " CountVectorizer(token_pattern=\"\\\\w+\")", "compilation_passed": true, "time": 0.005280971527099609, "tests_passed": true, "error": null}
