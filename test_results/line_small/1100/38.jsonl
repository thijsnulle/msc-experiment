{"code": " TfidfVectorizer(stop_words='english')", "compilation_passed": true, "time": 0.006433963775634766, "tests_passed": true, "error": null}
{"code": " TfidfVectorizer()", "compilation_passed": true, "time": 0.005384206771850586, "tests_passed": true, "error": null}
{"code": " TfidfVectorizer(analyzer='char', char_wb=2, tokenizer=lambda x: x.split(), dtype=float, preprocessor=None, stop_words=None, max_df=1.0, max_features=None, use_idf=True, norm='l2', smooth_idf=True, sublinear_tf=False)", "compilation_passed": true, "time": 0.008839845657348633, "tests_passed": false, "error": "TypeError"}
{"code": " TfidfVectorizer(use_idf=False)", "compilation_passed": true, "time": 0.005401134490966797, "tests_passed": true, "error": null}
{"code": " TfidfVectorizer(tokenizer=lambda x: x.split(), lowercase=True)", "compilation_passed": true, "time": 0.005257129669189453, "tests_passed": true, "error": null}
{"code": " TfidfVectorizer(analyzer='word', strip_accents='unicode')", "compilation_passed": true, "time": 0.006621837615966797, "tests_passed": true, "error": null}
{"code": " TfidfVectorizer(analyzer=\"word\", stop_words=\"english\", max_features=1000)", "compilation_passed": true, "time": 0.006468772888183594, "tests_passed": true, "error": null}
{"code": " TfidfVectorizer(analyzer=\"word\", dtype=float)", "compilation_passed": true, "time": 0.005299806594848633, "tests_passed": true, "error": null}
{"code": " TfidfVectorizer(analyzer=\"word\", stop_words='english')", "compilation_passed": true, "time": 0.006544828414916992, "tests_passed": true, "error": null}
{"code": " TfidfVectorizer(analyzer='word')", "compilation_passed": true, "time": 0.005271196365356445, "tests_passed": true, "error": null}
