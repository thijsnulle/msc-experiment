{"code": "if not text:\n        return []\n    regex = re.compile(r'(?:(?:(?:https?|ftp(?:s)?)\\:\\/\\/)?[\\w\\-\\.@]+\\.(?:[a-z]+))')\n    cleaned_text = re.sub(regex, '', text)\n    cleaned_text = re.sub(r'\\s{2,}', ' ', cleaned_text)\n    cleaned_text = re.sub(r'\\n', ' ', cleaned_text)\n    cleaned_text = re.sub(r',', '', cleaned_text)\n    cleaned_text = cleaned_text.lower()\n    word_list = cleaned_text.split()\n    stopwords = Counter([i for i in PREDEFINED_STOPWORDS])\n    result_list = []\n    for word in word_list:\n        if stopwords[word] > 0:\n            stopwords[word] = 0\n        else:\n            result_list.append((word, 1))\n    return result_list", "compilation_passed": true, "time": 0.001331329345703125, "tests_passed": true, "error": null}
{"code": "# Remove URLS\n    text = re.sub('http\\S+', '', text, flags=re.MULTILINE)\n    # Split by whitespaces\n    words = text.split()\n    # Remove stopwords\n    stopwords_list = [word for word in PREDEFINED_STOPWORDS]\n    # Counter\n    word_count = Counter(words)\n    # Remove stopwords from word count\n    filtered_count = [word for word, count in word_count.items() if not word.lower() in stopwords_list]\n    return filtered_count", "compilation_passed": true, "time": 0.0009961128234863281, "tests_passed": true, "error": null}
{"code": "text = re.sub(r'http.*', ' ', text)\n    text = text.replace('\\n', ' ')\n    text = text.replace('\\r', ' ')\n    text = text.replace(',', ', ')\n    text = text.replace('\\'', '')\n    words_freq = Counter(text.split(' '))\n    words_freq = [word for word in words_freq if word.strip() and not word in PREDEFINED_STOPWORDS]\n    return sorted(words_freq.items(), key=lambda x: x[1], reverse=True)", "compilation_passed": true, "time": 0.0009610652923583984, "tests_passed": false, "error": "AttributeError"}
{"code": "# Get list of stop words\n    stopwords_list = list(PREDEFINED_STOPWORDS)\n\n    # Create a regular expression to match urls\n    url_regex = re.compile(r'https?://(www\\.)?(\\w+)\\.(com|org|net|edu)')\n    # Split text into words using regex and remove urls\n    words_list = re.findall(r'[A-Za-z]+', text)\n\n    # Remove urls from words list\n    words_list = [word for word in words_list if word not in url_regex.findall(text)]\n\n    # Count words and return a list of tuples\n    word_counts = Counter(words_list)\n    stopwords_list = list(word_counts.keys())\n    stopwords_list = [word for word in stopwords_list if word in stopwords_list and word not in stopwords_list[:len(PREDEFINED_STOPWORDS)]]\n    return [ (word, count) for word, count in word_counts.most_", "compilation_passed": false, "time": 0.0003390312194824219, "tests_passed": false, "error": "SyntaxError"}
{"code": "# remove the urls\n    text = re.sub(r'(http|https):\\/\\/[\\w\\-_]+(\\.[\\w\\-_]+)+([\\w\\-\\.,@?^=%&;:/~\\+#]*[\\w\\-\\@?^=%&/~\\+#])?', \"\", text, flags=re.MULTILINE)\n\n    # count the stopwords\n    return Counter(re.findall(r\"[\\w']+\", text.lower())).most_common(5)", "compilation_passed": true, "time": 0.0013420581817626953, "tests_passed": true, "error": null}
{"code": "if isinstance(text, str):\n        text = text.lower().strip()\n        text = re.sub(r\"http\\S+\", \"\", text)\n        text = re.sub(r\"\\s+\", \" \", text)\n        text = re.split(\" \", text)\n        counter = Counter(text)\n        counter = counter.most_common()\n        counter = [key for (key, value) in counter]\n        return counter\n    else:\n        raise TypeError(\"Input must be a string.\")", "compilation_passed": true, "time": 0.0011668205261230469, "tests_passed": true, "error": null}
{"code": "stop_words = list(PREDEFINED_STOPWORDS)\n    pattern = re.compile(\"http(s)?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\'(\" + r\"\\\\)]|[^&;\" + r\"\\\\]])*\\r?\\n?\")\n    url_removed_text = pattern.sub('', text)\n    url_removed_stopwords = [i.lower() for i in url_removed_text.split() if i not in stop_words]\n    return Counter(url_removed_stopwords).most_common()", "compilation_passed": true, "time": 0.001081228256225586, "tests_passed": true, "error": null}
{"code": "text_without_url = re.sub(r\"https?://\\S*\", \" \", text)\n    text_without_url = re.sub(r\"http?://\\S*\", \" \", text_without_url)\n    stopwords = [PREDEFINED_STOPWORDS[s] for s in list(PREDEFINED_STOPWORDS.keys())]\n    words = text_without_url.split()\n    clean_words = [word.lower() for word in words if word.lower() not in stopwords]\n\n    counter = Counter(clean_words)\n    return list(counter.items())", "compilation_passed": true, "time": 0.0010182857513427734, "tests_passed": false, "error": "AttributeError"}
{"code": "words = []\n    text = re.sub(r\"https?://\\S+|&|.\", \"\", text)\n    # Convert text into a list of words\n    words = text.split()\n    # Remove stopwords\n    stop_words = [word.lower() for word in words if word.lower() not in PREDEFINED_STOPWORDS]\n    # Count the occurance of each word\n    return Counter(stop_words).most_common(None)", "compilation_passed": true, "time": 0.0009350776672363281, "tests_passed": true, "error": null}
{"code": "# Remove urls\n    text = re.sub(r\"(?<![\\w-])((http|https)://[\\w-]+(?:[\\w-.]+/[\\w-./?%&=]*)?).(?![\\w-])\", \"\", text)\n\n    # Remove stopwords\n    for stopword in PREDEFINED_STOPWORDS:\n        text = text.replace(stopword, \"\")\n\n    # Tokenize text\n    words = text.split()\n\n    # Count the words\n    counter = Counter(words)\n\n    return list(counter.items())", "compilation_passed": true, "time": 0.0020868778228759766, "tests_passed": false, "error": "re.error"}
{"code": "cleaned_text = re.sub(r\"\\bhttp.*|https.*\", \"\", text).lower()\n    counter = Counter()\n\n    for word in cleaned_text.split():\n        if word in PREDEFINED_STOPWORDS:\n            counter[word] += 1\n\n    return sorted(counter.items(), key=lambda x: x[1], reverse=True)", "compilation_passed": true, "time": 0.0009620189666748047, "tests_passed": true, "error": null}
{"code": "# remove all urls\n    text_no_url = re.sub(r'http\\S+', ' ', text)\n\n    # remove all punctuations\n    punctuations = [\",\", \";\", \".\", \":\", \"(\", \")\", \"{\", \"}\", \"[\", \"]\", \"'\", \"\\\"\", \"\\/\", \"/\", \"\\\\\"]\n    for punctuation in punctuations:\n        text_no_url = text_no_url.replace(punctuation, \" \")\n\n    # Remove all special characters\n    text_no_url = re.sub('[^a-zA-Z0-9 ]', '', text_no_url)\n\n    # remove all special characters\n    for word in text:\n        if not word.isalnum():\n            text_no_url = text_no_url.replace(word, ' ')\n\n    # Remove all numbers\n    text_no_url = re.sub('[0-9]', ' ', text_no_url)\n\n    # Remove all", "compilation_passed": true, "time": 0.0009541511535644531, "tests_passed": true, "error": null}
{"code": "# Remove the urls from the text\n    text = re.sub(r'(http|https|ftp)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '', text, flags=re.MULTILINE)\n\n    # Remove all punctuation except for .\n    punctuations = set(string.punctuation)\n    text = ''.join(character for character in text if character not in punctuations or character == '.')\n\n    # Remove all the whitespaces from the text\n    text = text.strip().replace(\"   \", \" \").replace(\"  \", \" \")\n\n    # Remove all the predefined stopwords from the text\n    text = ' '.join([word for word in text.split() if word.lower() not in PREDEFINED_STOPWORDS])\n\n    # Remove all the common english words from the text\n    common_english_words = set(stopwords.words('english'))\n    text", "compilation_passed": true, "time": 0.0010449886322021484, "tests_passed": false, "error": "NameError"}
{"code": "return list(Counter(re.sub(r\"http.*\", \"\", text).strip().split()).items())", "compilation_passed": true, "time": 0.0008699893951416016, "tests_passed": true, "error": null}
{"code": "word_freq = Counter()\n    for sentence in text:\n        words = re.findall(r\"[\\w']+\", sentence.lower())\n\n        for word in words:\n            if word.lower() in PREDEFINED_STOPWORDS:\n                word_freq[word] += 1\n\n    return [ (word, freq) for word, freq in word_freq.items() ]", "compilation_passed": true, "time": 0.0008988380432128906, "tests_passed": true, "error": null}
{"code": "# remove URL\n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*#?]|[^/\n                |\"<>\\[\\]]{,1024}|[^/]\"<>]{0,1024})+', '', text)\n    # convert to lowercase\n    text = text.lower()\n    # remove special char\n    text = re.sub(r\"[^a-z0-9]+\", ' ', text)\n    # remove multiple spaces\n    text = ' '.join(text.split())\n    # remove stopwords\n    text = [w for w in text.split() if w not in PREDEFINED_STOPWORDS]\n    # Count the occurence of each word\n    word_counts = Counter(text)\n    # Create a list of tuples\n    stopwords_list = [\n        (w, word_counts[w]) for w in word_counts if w in PREDEFINED_STOPW", "compilation_passed": false, "time": 0.00011706352233886719, "tests_passed": false, "error": "SyntaxError"}
{"code": "stopwords_list = []\n\n    url_regex = re.compile(\"https?://.*\")\n    text = re.sub(url_regex, \"\", text)\n\n    for word in text.split():\n        if word not in stopwords_list:\n            stopwords_list.append(word)\n\n    return Counter(stopwords_list).most_common()", "compilation_passed": true, "time": 0.0009200572967529297, "tests_passed": true, "error": null}
{"code": "text = text.lower()\n    stopwords = list(PREDEFINED_STOPWORDS.union(\n        {word for word in re.findall(\n            r\"[\\w']+|[^\\w\\s]+\", text\n        ) if word != ''}))\n\n    text = re.sub(r\"https?:\\/\\/[^/]*\", \"\", text)\n\n    text_tokens = nltk.word_tokenize(text)\n\n    counter = Counter(\n        [\n            word.capitalize()\n            for word in text_tokens\n            if word.lower() not in stopwords\n        ]\n    )\n\n    return [\n        (word, counter[word])\n        for word in counter.keys()\n        if word not in stopwords\n    ]", "compilation_passed": true, "time": 0.0010700225830078125, "tests_passed": false, "error": "NameError"}
{"code": "# Remove URLs\n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\\\(\\\\),]|(?:\\\\\\|))+', '', text)\n\n    # Remove stopwords from predefined list\n    stopwords = PREDEFINED_STOPWORDS\n\n    # Remove stopwords from text\n    stopwords_removed_text = \" \".join([word for word in text.split() if word.lower() not in stopwords])\n\n    # Count the stopwords\n    stopwords_count = Counter(stopwords_removed_text.split())\n\n    # Convert the count to a list of tuples\n    stopwords_count_list = [(word, count) for word, count in stopwords_count.items()]\n\n    return stopwords_count_list", "compilation_passed": true, "time": 0.0009911060333251953, "tests_passed": true, "error": null}
{"code": "counter = Counter()\n    url_pattern = re.compile(r'https?://\\S+')\n    text = url_pattern.sub('', text)\n    for word in text.split():\n        if word.lower() not in PREDEFINED_STOPWORDS:\n            counter[word] += 1\n    return list(counter.items())", "compilation_passed": true, "time": 0.0009810924530029297, "tests_passed": true, "error": null}
{"code": "if not text:\n        return []\n\n    cleaned_text = re.sub(r\"http\\S+\", \"\", text).strip()\n    stopwords_list = [word for word in cleaned_text.split(\" \") if word not in PREDEFINED_STOPWORDS]\n\n    return Counter(stopwords_list).most_common(100)", "compilation_passed": true, "time": 0.0008628368377685547, "tests_passed": true, "error": null}
{"code": "words = re.split(r\"\\W+\", text)\n    return Counter(w.lower() for w in words if w.lower() not in PREDEFINED_STOPWORDS).most_common()", "compilation_passed": true, "time": 0.0009391307830810547, "tests_passed": true, "error": null}
{"code": "def is_url(url):\n        return True if re.search(r'^https?://', url) else False\n\n    url = is_url(text)\n    text_list = text.split()\n\n    if url:\n        text_list = [word for word in text_list if is_url(word) is False]\n    text_list = [word.lower() for word in text_list]\n    text_list = [word for word in text_list if word not in PREDEFINED_STOPWORDS]\n\n    return [\n        (word, text_list.count(word))\n        for word in set(text_list)\n    ]", "compilation_passed": true, "time": 0.0009920597076416016, "tests_passed": true, "error": null}
{"code": "# Remove URLs\n    text = re.sub(\"\\s*(?:https?://\\S+|[#][\\w]+\\S+)\\s*\", \"\", text)\n\n    # Split by white spaces\n    tokens = text.split()\n\n    # Remove stopwords\n    tokens = [token for token in tokens if token.lower() not in PREDEFINED_STOPWORDS]\n\n    # Count the frequency of tokens\n    counter = Counter(tokens)\n\n    # Return the list of tuples\n    result = []\n    for word in counter:\n        result.append((word, counter[word]))\n\n    return result", "compilation_passed": true, "time": 0.0009789466857910156, "tests_passed": true, "error": null}
{"code": "return []", "compilation_passed": true, "time": 0.0007653236389160156, "tests_passed": true, "error": null}
{"code": "text = re.sub(r'\\s*(https?|ftp|file)://?\\S+', \" \", text).strip()\n    # text = text.strip()\n    text = text.lower().split()\n    text = [word for word in text if word not in PREDEFINED_STOPWORDS]\n\n    return Counter(text).most_common()", "compilation_passed": true, "time": 0.0009300708770751953, "tests_passed": true, "error": null}
{"code": "counter = Counter()\n    # Remove URL\n    text = re.sub(r\"https?://\\S+\", \"\", text)\n    # Remove punctuation\n    text = re.sub(r\"\\W+\", \" \", text)\n    # Convert to lowercase\n    text = text.lower()\n    # Remove stop words\n    # Predefined list of stopwords\n    stopwords = re.sub(r\"\\W+\", \"\", list(PREDEFINED_STOPWORDS))\n    counter.update(stopwords)\n\n    counter.update(re.sub(r\"\\W+\", \" \", text).split())\n\n    return counter.most_common()", "compilation_passed": true, "time": 0.00092315673828125, "tests_passed": false, "error": "TypeError"}
{"code": "# Split the text into words\n    words = text.lower().split()\n\n    # Remove all URLs from the text\n    words = [word for word in words if not re.match(r'^https?:\\/\\/\\S+', word)]\n\n    # Remove all special characters and stopwords\n    words = [word for word in words if word.isalnum() or word in PREDEFINED_STOPWORDS]\n\n    # Count the number of occurences of each word\n    counter = Counter(words)\n\n    return counter.most_common()", "compilation_passed": true, "time": 0.0009357929229736328, "tests_passed": true, "error": null}
{"code": "result = []\n\n    def clean_string(text: str) -> str:\n        \"\"\"\n        Remove URLs, HTML tags, and special characters from the text.\n        \"\"\"\n        return re.sub(r'(http|https)?://[a-zA-Z]*\\.\\w*\\.*\\w*', '', text)\n\n    def remove_stopwords(text: str) -> str:\n        \"\"\"\n        Remove stopwords from the text.\n        \"\"\"\n        return re.sub(r'\\b(?:{})\\b'.format(\"|\".join(PREDEFINED_STOPWORDS)), '', text)\n\n    text = clean_string(text)\n    text = remove_stopwords(text)\n\n    # Split the text by whitespace\n    words = [word.lower() for word in text.split()]\n\n    # Create a Counter object\n    word_count = Counter(words)\n\n    # Iterate over the Counter object\n    for word, count in word_count.items():\n        result.append((word,", "compilation_passed": false, "time": 0.0003819465637207031, "tests_passed": false, "error": "SyntaxError"}
{"code": "text = re.sub(\"https?://\\S+|&|#\", '', text)\n    words = re.findall(r'\\w+', text)\n    counter = Counter(words)\n    return [word.lower() for word in counter.most_common() if word[0] not in PREDEFINED_STOPWORDS]", "compilation_passed": true, "time": 0.0009112358093261719, "tests_passed": false, "error": "AttributeError"}
