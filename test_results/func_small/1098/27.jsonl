{"code": "url = re.compile(r'https?://(www\\.)?(?P<domain>[a-zA-Z0-9][a-zA-Z0-9\\-]*[a-zA-Z0-9]*\\.[a-zA-Z]{2,63})')\n    # remove url from the text\n    text = url.sub(' ', text)\n\n    # Count the words\n    words = Counter(text.split())\n\n    # Sort the words by frequency\n    most_common = words.most_common(top_n)\n\n    return most_common", "compilation_passed": true, "time": 0.0007450580596923828, "tests_passed": true, "error": null}
{"code": "words = re.findall(r'[\\w]+', text)\n    counts = Counter(words)\n    return counts.most_common(top_n)", "compilation_passed": true, "time": 0.0006811618804931641, "tests_passed": true, "error": null}
{"code": "words = re.findall(r'\\w+', text.lower())\n    counter = Counter(words)\n    return counter.most_common(top_n)", "compilation_passed": true, "time": 0.0006129741668701172, "tests_passed": true, "error": null}
{"code": "# Remove URL's\n    words = [word for word in re.sub(r'http\\S+|@\\S+', '', text).split()]\n    # Count occurrences of each word\n    count = Counter(words).most_common(top_n)\n    # Return result\n    return count", "compilation_passed": true, "time": 0.0007717609405517578, "tests_passed": true, "error": null}
{"code": "url_regex = re.compile(r'https?://(www\\.)?\\S+', re.I)\n    text_no_urls = url_regex.sub(\"\", text)\n    word_counts = Counter(text_no_urls.split())\n    word_counts_list = word_counts.most_common(top_n)\n    return word_counts_list", "compilation_passed": true, "time": 0.0006709098815917969, "tests_passed": true, "error": null}
{"code": "# Remove URLs from text\n    text_without_url = re.sub(r'http\\S+|https\\S+', '', text)\n\n    # Tokenize text into words\n    words = text_without_url.split()\n\n    # Create a Counter object to count the words\n    word_counter = Counter(words)\n\n    # Return top_n most common words and their frequencies\n    return word_counter.most_common(top_n)", "compilation_passed": true, "time": 0.000659942626953125, "tests_passed": true, "error": null}
{"code": "# remove URLs\n    url_regex = re.compile(r'(http|https)://\\S+|[\\w.+-]*\\.[a-z]+')\n    text = re.sub(url_regex, ' ', text)\n\n    # tokenize\n    words = [word.lower() for word in text.split()]\n\n    # remove punctuation\n    punctuation = re.compile(r'[^\\w\\s]')\n    words = [word.strip(punctuation) for word in words]\n\n    # count the frequency of each word\n    word_counts = Counter(words)\n\n    # sort the words by frequency\n    ordered_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n\n    # return top N words\n    return ordered_words[:top_n]", "compilation_passed": true, "time": 0.0007758140563964844, "tests_passed": false, "error": "TypeError"}
{"code": "if text == '':\n        return []\n    # re.sub() function is used to remove any URLs present in the text.\n    # The \"^\" character at the beginning of the pattern is used to indicate that the pattern should only match the beginning of a string.\n    # The \"$\" character at the end of the pattern is used to indicate that the pattern should only match the end of a string.\n    # The pattern is combined with the \"*\" character to indicate that the pattern should match 0 or more repetitions of the previous part of the pattern.\n    # This way, the pattern matches any combination of 0 or more characters, starting at the beginning and ending at the end, without affecting the length.\n    # For example, if the input string is \"http://www.python.org\", the pattern will match the entire string and remove all URLs from the text.\n    text = re.sub(\"\\S*http\\S*|\\S*https\\S*|\\S*www\\S*|\\S*python\\S*\", \" \", text).lower()\n\n    # Create a Counter object with text as the input and split it into individual", "compilation_passed": true, "time": 0.0006132125854492188, "tests_passed": true, "error": null}
{"code": "url_regex = r'\\b((http|https):\\/\\/)?[a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,63}(\\/\\S*)?'\n    cleaned_text = re.sub(url_regex, \" \", text)\n\n    # split text into words\n    words = cleaned_text.split()\n\n    # count occurrences of each word in the text\n    word_counts = Counter(words)\n\n    # get the top N most common words\n    top_words = word_counts.most_common(top_n)\n\n    return top_words", "compilation_passed": true, "time": 0.0007147789001464844, "tests_passed": true, "error": null}
{"code": "regex = re.compile('http|ftp|https')\n    words = [word.lower() for word in text.split() if not regex.search(word)]\n    word_count = Counter(words)\n    sorted_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\n    return sorted_words[:top_n]", "compilation_passed": true, "time": 0.0007650852203369141, "tests_passed": true, "error": null}
{"code": "pattern = re.compile(r'https?://\\S+|#')\n    text = pattern.sub(\"\", text)\n    words = [word.strip(string.punctuation).lower() for word in text.split()]\n\n    counter = Counter(words)\n    return list(counter.most_common(top_n))", "compilation_passed": true, "time": 0.0006299018859863281, "tests_passed": false, "error": "NameError"}
{"code": "# regex pattern for valid urls\n    regex_url = re.compile(r\"(?i)\\b((?:https?:)?//|(?:www\\.)?((?!@))[-\\w.+&@#/%?=]*[^\\W_.+&@#])((?!@).)*\")\n    # remove urls from text\n    cleaned_text = regex_url.sub('', text)\n\n    # split text into words\n    words = cleaned_text.split()\n\n    # count occurrences of words\n    word_counts = Counter(words).most_common(top_n)\n\n    return word_counts", "compilation_passed": true, "time": 0.0006902217864990234, "tests_passed": true, "error": null}
{"code": "regex_url = re.compile(r'https?://(www\\.)?[\\w-]+(\\.[\\w-]+)+')\n    text = regex_url.sub(' ', text)\n\n    words = [word.lower() for word in text.split()]\n    return Counter(words).most_common(top_n)", "compilation_passed": true, "time": 0.0006792545318603516, "tests_passed": true, "error": null}
{"code": "# Remove URLs\n    text = re.sub(r'https?://\\S+', '', text)\n\n    # Split text into words\n    words = re.split(r'\\W+', text)\n\n    # Count the frequency of words\n    counts = Counter(words)\n\n    # Sort the words by frequency and return the top n\n    return counts.most_common(top_n)", "compilation_passed": true, "time": 0.0007009506225585938, "tests_passed": true, "error": null}
{"code": "# remove URLs\n    regex = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*#%]|(?:[\\(\\),]|@|&|;=))+', re.IGNORECASE)\n    text = re.sub(regex, '', text)\n\n    # remove stopwords\n    stopwords = set(stopwords.words('english'))\n    text = [word for word in text.split() if word.lower() not in stopwords]\n\n    # count words\n    count_words = Counter(text)\n\n    # sort words by frequency\n    words = list(count_words.items())\n    words = sorted(words, key=lambda x: x[1], reverse=True)\n\n    # return top N words\n    top_words = words[:top_n]\n    return top_words", "compilation_passed": true, "time": 0.0009021759033203125, "tests_passed": false, "error": "UnboundLocalError"}
{"code": "url_regex = re.compile(r\"(http|https)://[\\w/\\.]+\")\n    text_no_url = url_regex.sub('', text).split()\n    count_dict = Counter(text_no_url)\n    return count_dict.most_common(top_n)", "compilation_passed": true, "time": 0.0006630420684814453, "tests_passed": true, "error": null}
{"code": "# 1. remove http\n    # 2. split by ,\n    # 3. remove http\n    # 4. count frequency\n\n    # url = re.compile(r'http\\S+')\n    # text = url.sub('', text)\n\n    # url = re.compile(r'https\\S+')\n    # text = url.sub('', text)\n\n    text = re.sub(r'https?://\\S+', '', text)\n\n    words = [word for word in text.split() if word]\n    word_freqs = Counter(words)\n\n    top_words = word_freqs.most_common(top_n)\n    return top_words", "compilation_passed": true, "time": 0.0006389617919921875, "tests_passed": true, "error": null}
{"code": "# Convert text to lowercase and remove URL markers\n    text = re.sub(r'http\\S+|https\\S+|www\\S+', ' ', text)\n\n    # Convert text to list of words\n    words = text.split()\n\n    # Remove words containing only special characters (e.g. punctuations, numbers, etc.)\n    words = [word.strip(string.punctuation) for word in words if not word.isdigit()]\n\n    # Count word frequencies\n    word_counts = Counter(words)\n\n    # Sort word counts in descending order by word count\n    words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n\n    # Return top N most frequent words\n    return words[:top_n]", "compilation_passed": true, "time": 0.0006620883941650391, "tests_passed": false, "error": "NameError"}
{"code": "pattern = re.compile(r\"http\\S+|www.\\S+\")\n    words = pattern.sub(\" \", text).split()\n    words_freq = Counter(words).most_common(top_n)\n    return words_freq", "compilation_passed": true, "time": 0.000659942626953125, "tests_passed": true, "error": null}
{"code": "# Use regex to remove urls\n    text = re.sub(r'http\\S+|www\\S+|@\\S+', '', text)\n    # Use Counter to count the top words\n    words = Counter(text.split()).most_common(top_n)\n    # Return the top N words\n    return words", "compilation_passed": true, "time": 0.0006501674652099609, "tests_passed": true, "error": null}
{"code": "# Remove URLs from the text\n    url_pattern = re.compile(r\"(http|https)\\:\\/\\/[A-Za-z0-9\\-\\.\\/\\?\\=&\\%\\$\\#;:\\@\\~\\+\\,\\*]+\")\n    text = url_pattern.sub('', text)\n\n    # Remove all special characters and punctuation\n    cleaned_text = ''.join(char for char in text if char.isalnum() or char.isspace())\n\n    # Split the text into a list of words\n    words = cleaned_text.split()\n\n    # Count the occurrences of each word\n    word_counts = Counter(words)\n\n    # Sort the counts in descending order\n    sorted_counts = word_counts.most_common(top_n)\n\n    # Return the list of top N words and their counts\n    return sorted_counts", "compilation_passed": true, "time": 0.0007481575012207031, "tests_passed": true, "error": null}
{"code": "pattern = re.compile(r'\\b(?:\\w+://)?\\w+(?::\\d+)?')\n    text = pattern.sub('', text)\n    words = Counter(text.lower().split()).most_common(top_n)\n    return words", "compilation_passed": true, "time": 0.0006263256072998047, "tests_passed": true, "error": null}
{"code": "text = re.sub(r'http|https', ' ', text)\n\n    words = text.split()\n    word_freq = Counter(words)\n\n    top_freq_words = []\n    for word in word_freq:\n        if word_freq[word] > 1:\n            top_freq_words.append((word, word_freq[word]))\n\n    top_freq_words.sort(key=lambda x: x[1], reverse=True)\n\n    if len(top_freq_words) < top_n:\n        top_n = len(top_freq_words)\n\n    return top_freq_words[:top_n]", "compilation_passed": true, "time": 0.0006909370422363281, "tests_passed": true, "error": null}
{"code": "regex = \"http\"\n    text = re.sub(regex, '', text)\n    return Counter(text.lower().split()).most_common(top_n)", "compilation_passed": true, "time": 0.0006210803985595703, "tests_passed": true, "error": null}
{"code": "# remove urls\n    text = re.sub('(https|http)://[^\\s]+\\s?', '', text)\n\n    # remove punctuations\n    text = re.sub('[^\\w\\s]', '', text)\n\n    # remove stop words\n    stops = ['I', 'a', 'about', 'an', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'have', 'he', 'in', 'into', 'is', 'it', 'of', 'on', 'that', 'the', 'this', 'to', 'was', 'we', 'were', 'what', 'when', 'where', 'who', 'will', 'with', 'www', 'www.python', 'org']\n    text = ' '.join([w for w in text.split() if w not in stops])\n\n    # count words\n    word_counts = Counter(text.split())\n    print(", "compilation_passed": false, "time": 0.0001971721649169922, "tests_passed": false, "error": "SyntaxError"}
{"code": "# TODO: Your code here\n    text = text.split()\n    text_clean = ''.join(text)\n\n    clean_text = re.findall(r\"\\w+\", text_clean)\n\n    # text = Counter(clean_text).most_common(2)\n    text = Counter(clean_text)\n\n    return text[:top_n]", "compilation_passed": true, "time": 0.0006163120269775391, "tests_passed": false, "error": "TypeError"}
{"code": "# remove urls\n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*#?]|[^`\"<>[:]])*', '', text)\n    # remove punctuation\n    text = text.replace(',', '').replace('.', '').replace('?', '').replace('!', '').replace(':', '').replace(';', '').replace('_', '')\n    # lowercase\n    text = text.lower()\n\n    # remove non-alpha characters\n    text = re.sub(r'[^\\w\\s]', ' ', text)\n    # split by whitespace\n    words = text.split()\n\n    # count occurrences of each word\n    word_counts = Counter(words)\n\n    # sort words by count and return top n\n    return word_counts.most_common(top_n)", "compilation_passed": true, "time": 0.0007588863372802734, "tests_passed": true, "error": null}
{"code": "result = []\n\n    words = re.findall(r\"\\b\\w+\\b\", text)\n\n    for word in Counter(words).most_common(top_n):\n        result.append(word)\n\n    return result", "compilation_passed": true, "time": 0.0006489753723144531, "tests_passed": true, "error": null}
{"code": "# Write your code below this line\n    # Task\n    # Count the N most common words in a text after removing URLs.\n\n    # Requirements:\n    # - re\n    # - collections.Counter\n    # - You should not remove words that are urls.\n\n    # Example:\n    # >>> task_func('Visit https://www.python.org for more info. Python is great. I love Python.', 2)\n    # [('Python', 2), ('Visit', 1)]\n\n    # Note:\n    # - Valid url is start with http or https\n\n    # Hints:\n    # 1. You will need to use regex to identify valid urls and then remove them.\n    # 2. You will need to use re.split to split the text into words.\n    # 3. You will need to use the Counter class from the collections library to count the words.\n\n    # YOUR CODE GOES HERE\n    import re\n    from collections import Counter\n    # regex for urls\n    url_regex = re.compile(r'http[s]?://", "compilation_passed": false, "time": 3.409385681152344e-05, "tests_passed": false, "error": "SyntaxError"}
{"code": "cleaned_text = ''.join(\n        [char for char in text if re.match('[\\w-]+', char) is not None])\n\n    top_words = Counter(cleaned_text.split()).most_common(top_n)\n\n    return top_words", "compilation_passed": true, "time": 0.0006432533264160156, "tests_passed": true, "error": null}
