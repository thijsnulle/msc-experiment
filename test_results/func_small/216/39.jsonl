{"code": "counts = []\n\n    for file_path in os.listdir(json_dir_path):\n        with open(f\"{json_dir_path}/{file_path}\", 'r') as f:\n            data = json.load(f)\n            counts.append((data['text'], data['text'].split()))\n\n    counts = Counter(word for text, words in counts for word in words)\n\n    return counts.most_common(word_count)", "compilation_passed": true, "time": 0.010182857513427734, "tests_passed": true, "error": null}
{"code": "if not json_dir_path.endswith(\"/\"):\n        json_dir_path = f\"{json_dir_path}/\"\n    if not os.path.exists(json_dir_path):\n        raise FileNotFoundError(f\"No such file or directory: {json_dir_path}\")\n\n    text_data = []\n    for file_path in os.listdir(json_dir_path):\n        if file_path.endswith(\".json\"):\n            with open(f\"{json_dir_path}{file_path}\", \"r\") as f:\n                file_data = json.load(f)\n            text_data.append(file_data[\"text\"])\n\n    words = Counter()\n\n    for text in text_data:\n        words.update(text.split())\n\n    most_common = words.most_common(word_count)\n\n    return most_common", "compilation_passed": true, "time": 0.00958395004272461, "tests_passed": true, "error": null}
{"code": "# Read all JSON files in the directory\n    file_paths = [os.path.join(json_dir_path, f) for f in os.listdir(json_dir_path) if f.endswith('.json')]\n    json_objects = []\n\n    for file_path in file_paths:\n        with open(file_path, 'r') as f:\n            json_objects.append(json.load(f))\n\n    # Create a list of all text contents\n    texts = [j['text'] for j in json_objects]\n    texts = ' '.join(texts)\n\n    # Use Counter to find most common words\n    c = Counter(texts.split()).most_common(word_count)\n\n    return c", "compilation_passed": true, "time": 0.009274959564208984, "tests_passed": true, "error": null}
{"code": "word_count_list = []\n    json_files = os.listdir(json_dir_path)\n    for json_file in json_files:\n        with open(os.path.join(json_dir_path, json_file), \"r\") as f:\n            data = json.load(f)\n            word_list = data[\"text\"].split()\n            word_count_list.extend(Counter(word_list).most_common(word_count))\n    return word_count_list[:word_count]", "compilation_passed": true, "time": 0.002936124801635742, "tests_passed": true, "error": null}
{"code": "most_common_words = []\n    with os.scandir(json_dir_path) as files:\n        for file in files:\n            if file.path.endswith(\".json\"):\n                with open(file.path, 'r') as f:\n                    data = json.load(f)\n                    text = data.get(\"text\", \"\")\n                    words = text.split()\n                    counts = Counter(words)\n                    most_common_words += counts.most_common(word_count)\n\n    return most_common_words", "compilation_passed": true, "time": 0.0031239986419677734, "tests_passed": true, "error": null}
{"code": "most_common_words = []\n    # Open all JSON files in the directory and extract the text content.\n    for dir_path, subdir_list, file_list in os.walk(json_dir_path):\n        for file in file_list:\n            json_path = os.path.join(dir_path, file)\n            with open(json_path, 'r') as f:\n                json_content = json.load(f)\n                most_common_words.append((json_content[\"text\"], len(json_content[\"text\"].split())))\n    # Create a Counter object to count the occurrences of words in the text content.\n    word_counter = Counter(word for _, word in most_common_words)\n    # Return the top N most frequent words and their counts.\n    return word_counter.most_common(word_count)", "compilation_passed": true, "time": 0.0028290748596191406, "tests_passed": true, "error": null}
{"code": "results = []\n\n    with os.scandir(json_dir_path) as files:\n        for file in files:\n            if file.name.endswith('.json'):\n                with open(os.path.join(json_dir_path, file.name)) as f:\n                    data = json.load(f)\n                    text = data[\"text\"]\n                    words = text.split()\n\n                    counter = Counter(words)\n\n                    results.extend(counter.most_common(word_count))\n\n    return results", "compilation_passed": true, "time": 0.0027761459350585938, "tests_passed": true, "error": null}
{"code": "most_common_words = Counter()\n    for filename in os.listdir(json_dir_path):\n        with open(os.path.join(json_dir_path, filename)) as f:\n            json_data = json.load(f)\n            text = json_data['text']\n            words = text.split()\n            most_common_words.update(Counter(words).most_common(word_count))\n    return most_common_words", "compilation_passed": true, "time": 0.0025899410247802734, "tests_passed": false, "error": "TypeError"}
{"code": "most_common_words = []\n    for dir_path, _, files in os.walk(json_dir_path):\n        for filename in files:\n            json_path = os.path.join(dir_path, filename)\n            with open(json_path) as file:\n                data = json.load(file)\n                text = data.get(\"text\")\n                if text:\n                    words = text.split()\n                    word_counts = Counter(words)\n                    most_common_words.extend(word_counts.most_common(word_count))\n\n    return most_common_words", "compilation_passed": true, "time": 0.002627849578857422, "tests_passed": true, "error": null}
{"code": "result = []\n\n    for json_file in os.listdir(json_dir_path):\n        json_file_path = os.path.join(json_dir_path, json_file)\n\n        with open(json_file_path, 'r') as f:\n            json_data = json.load(f)\n\n        text = json_data.get('text')\n\n        if not text:\n            continue\n\n        text = text.split()\n        words = Counter(text)\n\n        result.extend([(word, count) for word, count in words.most_common()])\n\n        if len(result) == word_count:\n            break\n\n    return result", "compilation_passed": true, "time": 0.0027658939361572266, "tests_passed": true, "error": null}
{"code": "json_files = []\n    json_paths = []\n    for path, dirs, files in os.walk(json_dir_path):\n        for file in files:\n            if file.endswith(\".json\"):\n                json_files.append(os.path.join(path, file))\n                json_paths.append(file)\n\n    words_counts = []\n    for file_path in json_files:\n        with open(file_path) as f:\n            data = json.load(f)\n            text = data[\"text\"]\n            word_counts = Counter(text.split())\n            words_counts.append((word, word_counts[word]) for word in word_counts)\n\n    words_counts = sorted(words_counts, key=lambda x: x[1], reverse=True)\n    return words_counts[:word_count]", "compilation_passed": true, "time": 0.0026907920837402344, "tests_passed": false, "error": "TypeError"}
{"code": "files = [os.path.join(json_dir_path, file_name) for file_name in os.listdir(json_dir_path)]\n\n    texts = []\n    for file_path in files:\n        with open(file_path, \"r\") as f:\n            data = json.load(f)\n            texts.append(data[\"text\"])\n\n    most_common = Counter(texts).most_common(word_count)\n\n    return most_common", "compilation_passed": true, "time": 0.0024881362915039062, "tests_passed": true, "error": null}
{"code": "# Create a list to store the most common words and their counts\n    most_common_words = []\n\n    # Create a list to store all the JSON files in the specified directory\n    files_list = os.listdir(json_dir_path)\n\n    # Loop through each file in the files_list and extract the text content\n    for file_path in files_list:\n        with open(os.path.join(json_dir_path, file_path), \"r\") as file:\n            json_data = json.load(file)\n            text = json_data[\"text\"]\n\n        # Split the text content into words and add the counts of each word to most_common_words\n        words = text.split(\" \")\n        word_counts = Counter(words)\n        for word, count in word_counts.items():\n            if len(most_common_words) < word_count:\n                most_common_words.append((word, count))\n            else:\n                max_count = max(word_counts.values())\n                if max_count > most_common_words[", "compilation_passed": false, "time": 0.00024509429931640625, "tests_passed": false, "error": "SyntaxError"}
{"code": "counter = Counter()\n    for file in os.listdir(json_dir_path):\n        path = os.path.join(json_dir_path, file)\n        if os.path.isfile(path) and path.endswith(\".json\"):\n            with open(path, 'r') as f:\n                data = json.load(f)\n                if \"text\" in data:\n                    counter.update(data[\"text\"].split())\n    return counter.most_common(word_count)", "compilation_passed": true, "time": 0.00900888442993164, "tests_passed": true, "error": null}
{"code": "counts = Counter()\n    for file_name in os.listdir(json_dir_path):\n        file_path = os.path.join(json_dir_path, file_name)\n        with open(file_path) as f:\n            data = json.load(f)\n            counts.update(data['text'].split())\n    return counts.most_common(word_count)", "compilation_passed": true, "time": 0.008783817291259766, "tests_passed": true, "error": null}
{"code": "words = []\n    for file_name in os.listdir(json_dir_path):\n        with open(os.path.join(json_dir_path, file_name)) as f:\n            file_data = json.load(f)\n            words.append((file_data['text'], 1))\n\n    word_counts = Counter(word for sentence, _ in words for word in sentence.split())\n\n    return word_counts.most_common(word_count)", "compilation_passed": true, "time": 0.009598970413208008, "tests_passed": true, "error": null}
{"code": "with pd.option_context('display.max_rows', 5):\n        # Read all the JSON files in the specified directory\n        files = []\n        for file in os.listdir(json_dir_path):\n            if file.endswith(\".json\"):\n                with open(os.path.join(json_dir_path, file), \"r\") as f:\n                    files.append(json.load(f))\n\n        # Extract text content from all the JSON files\n        texts = []\n        for file in files:\n            texts.append(file[\"text\"])\n\n        # Determine the most frequent words using the Counter class from the collections library\n        word_counts = Counter(\n            word for text in texts for word in text.split()).most_common(word_count)\n\n        return word_counts", "compilation_passed": true, "time": 0.009693145751953125, "tests_passed": true, "error": null}
{"code": "result = []\n    for filename in os.listdir(json_dir_path):\n        file_path = os.path.join(json_dir_path, filename)\n        with open(file_path, 'r') as f:\n            text = json.load(f)['text']\n            words = text.split()\n            result.append(Counter(words).most_common(word_count))\n\n    return result", "compilation_passed": true, "time": 0.002576112747192383, "tests_passed": true, "error": null}
{"code": "files = []\n    for root, _, files in os.walk(json_dir_path):\n        for file_name in files:\n            file_path = os.path.join(root, file_name)\n            files.append(file_path)\n\n    text_data = []\n    for file_path in files:\n        with open(file_path, 'r') as f:\n            data = json.load(f)\n            text = data['text'].split()\n            text_data.extend(text)\n\n    # Get the most common words\n    word_counts = Counter(text_data).most_common(word_count)\n\n    return word_counts", "compilation_passed": true, "time": 1.0079758167266846, "tests_passed": false, "error": "TimeoutError"}
{"code": "counter = Counter()\n    for json_file_path in os.listdir(json_dir_path):\n        with open(f\"{json_dir_path}/{json_file_path}\", \"r\") as f:\n            data = json.load(f)\n            text = data[\"text\"]\n            counter.update(text.split())\n\n    return counter.most_common(word_count)", "compilation_passed": true, "time": 0.00993490219116211, "tests_passed": true, "error": null}
{"code": "most_common_words = []\n    with os.scandir(json_dir_path) as files:\n        for file in files:\n            if file.is_file() and file.name.endswith(\".json\"):\n                with open(file.path, \"r\") as f:\n                    json_data = json.load(f)\n                    text = json_data[\"text\"]\n                    words = text.split()\n                    word_count_list = Counter(words).most_common(word_count)\n                    most_common_words.extend(word_count_list)\n    return most_common_words", "compilation_passed": true, "time": 0.003148794174194336, "tests_passed": true, "error": null}
{"code": "files = [f for f in os.listdir(json_dir_path) if f.endswith(\".json\")]\n    contents = [json.load(open(f\"{json_dir_path}/{f}\"))[\"text\"] for f in files]\n    words = [word for content in contents for word in content.lower().split()]\n    most_common = Counter(words).most_common(word_count)\n    return most_common", "compilation_passed": true, "time": 0.0030641555786132812, "tests_passed": true, "error": null}
{"code": "files = []\n    for root, dirs, files_ in os.walk(json_dir_path):\n        for filename in files_:\n            if filename.endswith(\".json\"):\n                filepath = os.path.join(root, filename)\n                with open(filepath, 'r') as f:\n                    files.append(f.read())\n\n    words = []\n    for file in files:\n        words.extend([word.lower() for word in file.split()])\n\n    word_count = Counter(words)\n    return word_count.most_common(word_count.__len__())[:word_count]", "compilation_passed": true, "time": 0.002989053726196289, "tests_passed": false, "error": "TypeError"}
{"code": "# Create an empty list to store the word counts\n    word_counts = []\n\n    # Iterate over all files in the JSON directory\n    for root, _, files in os.walk(json_dir_path):\n        # Iterate over files\n        for file in files:\n            # Open the file in read mode\n            with open(os.path.join(root, file), \"r\") as f:\n                # Read the JSON content as a dictionary\n                json_content = json.load(f)\n                # Access the text content from the JSON dictionary and split it into words\n                words = json_content[\"text\"].split()\n                # Iterate over words\n                for word in words:\n                    # If word is not in the word_counts list, add it\n                    if not word_counts:\n                        word_counts.append(word)\n                    # If word is already in the word_counts list, increment its count\n                    else:\n                        # Find the index of the word in the list\n                        index = word_counts.index(word)\n                        # Increment the count", "compilation_passed": true, "time": 0.002508878707885742, "tests_passed": false, "error": "ValueError"}
{"code": "json_files_path = os.listdir(json_dir_path)\n\n    texts = []\n    for file in json_files_path:\n        with open(f\"{json_dir_path}/{file}\", \"r\") as f:\n            texts.append(json.load(f)[\"text\"])\n\n    counter = Counter(texts)\n\n    most_common = counter.most_common(word_count)\n\n    return most_common", "compilation_passed": true, "time": 0.0027239322662353516, "tests_passed": true, "error": null}
{"code": "word_list = []\n    json_files = os.listdir(json_dir_path)\n    for file_name in json_files:\n        with open(f\"{json_dir_path}/{file_name}\", 'r') as f:\n            content = json.load(f)\n            text = content['text']\n            word_list.extend(text.split())\n    word_list = list(map(lambda word: word.lower(), word_list))\n    most_common_words = Counter(word_list).most_common(word_count)\n    return most_common_words", "compilation_passed": true, "time": 0.0027561187744140625, "tests_passed": true, "error": null}
{"code": "# Initialize a dictionary to store the word count\n    word_counts = {}\n\n    # Iterate through all files in the specified directory\n    for file in os.listdir(json_dir_path):\n        # Load the contents of each JSON file\n        with open(os.path.join(json_dir_path, file), 'r') as f:\n            data = json.load(f)\n\n        # Extract the text content from each file and count the words\n        words = [word.strip() for word in data[\"text\"].split()]\n        word_counts.update(Counter(words))\n\n    # Sort the word counts in descending order\n    word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n\n    # Return a list of the most common words\n    return word_counts[:word_count]", "compilation_passed": true, "time": 0.0027289390563964844, "tests_passed": true, "error": null}
{"code": "result = []\n    for file in os.listdir(json_dir_path):\n        if file.endswith(\".json\"):\n            with open(os.path.join(json_dir_path, file), \"r\") as f:\n                data = json.load(f)\n                text = data[\"text\"]\n                for word in text.split():\n                    if word in Counter(text.split()):\n                        result.append((word, Counter(text.split())[word]))\n                    else:\n                        result.append((word, 1))\n    return sorted(result, key=lambda x: -x[1])[:word_count]", "compilation_passed": true, "time": 0.008758068084716797, "tests_passed": true, "error": null}
{"code": "with open(json_dir_path) as f:\n        json_data = json.load(f)\n\n    texts = []\n    for row in json_data:\n        texts.append(row['text'])\n\n    words = [word.lower()\n            for sentence in texts\n            for word in sentence.split()]\n    word_counts = Counter(words)\n\n    return word_counts.most_common(word_count)", "compilation_passed": true, "time": 0.002270221710205078, "tests_passed": false, "error": "IsADirectoryError"}
{"code": "with os.scandir(json_dir_path) as contents:\n        most_common_words = Counter()\n\n        for entry in contents:\n            if entry.path.endswith(\".json\"):\n                with open(entry.path) as f:\n                    data = json.load(f)\n                    most_common_words.update(Counter(data[\"text\"].split()))\n\n        return most_common_words.most_common(word_count)", "compilation_passed": true, "time": 0.009300947189331055, "tests_passed": true, "error": null}
