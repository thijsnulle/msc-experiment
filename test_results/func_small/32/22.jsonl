{"code": "try:\n        res = requests.get(url)\n        res.raise_for_status()\n        soup = BeautifulSoup(res.content, \"html.parser\")\n        tag_content = soup.find(tag).text.strip()\n        return tag_content\n    except requests.exceptions.RequestException:\n        return None\n    except AttributeError:\n        return None", "compilation_passed": true, "time": 0.0038080215454101562, "tests_passed": false, "error": "TypeError"}
{"code": "response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    tag = soup.find(tag)\n    return tag.text if tag else None", "compilation_passed": true, "time": 0.0011830329895019531, "tests_passed": true, "error": null}
{"code": "response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    tag_text = soup.find_all(tag)\n    if tag_text:\n        return tag_text[0].get_text().strip()\n    return None", "compilation_passed": true, "time": 0.0010809898376464844, "tests_passed": true, "error": null}
{"code": "response = requests.get(url)\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    tag = soup.select_one(tag)\n    if tag:\n        return tag.get_text()\n    else:\n        return None", "compilation_passed": true, "time": 0.0012769699096679688, "tests_passed": false, "error": "TypeError"}
{"code": "try:\n        response = requests.get(url)\n        if response.status_code != 200:\n            raise Exception(f\"Failed to get data from URL: {url}\")\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        element = soup.find(tag)\n        if element is None:\n            raise Exception(f\"Tag '{tag}' not found in HTML\")\n        else:\n            return element.text\n    except Exception as e:\n        return None", "compilation_passed": true, "time": 0.0011179447174072266, "tests_passed": true, "error": null}
{"code": "response = requests.get(url)\n    response.raise_for_status()\n    soup = BeautifulSoup(response.text, \"html.parser\")\n    tag = soup.find(tag)\n    return tag.text if tag else None", "compilation_passed": true, "time": 0.0011279582977294922, "tests_passed": true, "error": null}
{"code": "try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.text, 'html.parser')\n\n        tag_element = soup.find(tag)\n\n        if tag_element:\n            return tag_element.text\n        else:\n            return None\n    except Exception as e:\n        raise Exception(f\"Error while scraping website: {e}\")", "compilation_passed": true, "time": 0.0011031627655029297, "tests_passed": true, "error": null}
{"code": "try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.content, \"html.parser\")\n        return soup.find(tag).get_text()\n    except Exception as e:\n        print(f\"Task failed: {e}\")", "compilation_passed": true, "time": 0.0011761188507080078, "tests_passed": true, "error": null}
{"code": "try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        return soup.select_one(tag).text\n    except requests.exceptions.RequestException:\n        return None", "compilation_passed": true, "time": 0.0012068748474121094, "tests_passed": true, "error": null}
{"code": "response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    tag_elements = soup.find_all(tag)\n\n    if tag_elements:\n        return tag_elements[0].text\n    return None", "compilation_passed": true, "time": 0.001415252685546875, "tests_passed": false, "error": "TypeError"}
{"code": "try:\n        r = requests.get(url)\n        soup = BeautifulSoup(r.text, \"html.parser\")\n        tag_element = soup.find(tag)\n        if tag_element:\n            return tag_element.get_text()\n        else:\n            return None\n    except:\n        return None", "compilation_passed": true, "time": 0.0010640621185302734, "tests_passed": true, "error": null}
{"code": "if tag != \"\":\n        try:\n            page = requests.get(url)\n            soup = BeautifulSoup(page.content, 'html.parser')\n            element = soup.select(tag)[0].text\n            return element\n        except:\n            return None\n    else:\n        return None", "compilation_passed": true, "time": 0.0011749267578125, "tests_passed": true, "error": null}
{"code": "try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        tag_content = soup.find(tag)\n        if tag_content:\n            return tag_content.text\n        else:\n            return None\n    except Exception as e:\n        print(\"Error:\", str(e))\n        return None", "compilation_passed": true, "time": 0.0011658668518066406, "tests_passed": true, "error": null}
{"code": "try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.text, 'html.parser')\n        tag = soup.find(tag)\n        if tag is None:\n            return None\n        return tag.text\n    except Exception as e:\n        print(f\"Error: {str(e)}\")\n        return None", "compilation_passed": true, "time": 0.0011739730834960938, "tests_passed": true, "error": null}
{"code": "response = requests.get(url)\n    soup = BeautifulSoup(response.text, \"html.parser\")\n    tag_found = soup.find(tag)\n    if tag_found:\n        return tag_found.text\n    else:\n        return None", "compilation_passed": true, "time": 0.0010371208190917969, "tests_passed": true, "error": null}
{"code": "if not isinstance(url, str) or not isinstance(tag, str):\n        raise TypeError(\"URL and tag must be strings.\")\n    try:\n        html_data = requests.get(url).content\n    except requests.RequestException as e:\n        print(f\"Error accessing URL {url}: {e}\")\n        return None\n\n    try:\n        soup = BeautifulSoup(html_data, \"html.parser\")\n    except (TypeError, ValueError) as e:\n        print(f\"Error parsing HTML: {e}\")\n        return None\n\n    tag_obj = soup.find(tag)\n    if tag_obj:\n        tag_text = tag_obj.text\n        print(tag_text)\n        return tag_text\n    else:\n        print(\"HTML tag not found.\")\n        return None", "compilation_passed": true, "time": 0.0012710094451904297, "tests_passed": true, "error": null}
{"code": "try:\n        response = requests.get(url)\n        if response.status_code == 200:\n            soup = BeautifulSoup(response.text, \"html.parser\")\n            tag_content = soup.find(tag).text\n            print(tag_content)\n        else:\n            print(\"Error: Cannot scrape web page.\")\n    except:\n        print(\"Error: Unable to scrape web page.\")", "compilation_passed": true, "time": 0.0010492801666259766, "tests_passed": true, "error": null}
{"code": "response = requests.get(url)\n    if response.status_code != 200:\n        raise Exception(\"Failed to fetch data.\")\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    tag = soup.find(tag)\n    if tag:\n        return tag.text\n    else:\n        return None", "compilation_passed": true, "time": 0.0010459423065185547, "tests_passed": false, "error": "Exception"}
{"code": "try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        tag_element = soup.select(tag)[0]\n        tag_text = tag_element.text\n    except (requests.exceptions.RequestException, IndexError):\n        return None\n    else:\n        return tag_text", "compilation_passed": true, "time": 0.0011670589447021484, "tests_passed": true, "error": null}
{"code": "try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except Exception as e:\n        print(f\"Error fetching URL: {url}\", e)\n    else:\n        soup = BeautifulSoup(response.content, \"html.parser\")\n        tag_elem = soup.find(tag)\n        if tag_elem:\n            return tag_elem.text\n    return None", "compilation_passed": true, "time": 0.0013458728790283203, "tests_passed": false, "error": "TypeError"}
{"code": "r = requests.get(url)\n    soup = BeautifulSoup(r.content, \"html.parser\")\n    tag = soup.find(tag)\n\n    if tag is None:\n        return None\n\n    return tag.text", "compilation_passed": true, "time": 0.0012760162353515625, "tests_passed": false, "error": "TypeError"}
{"code": "r = requests.get(url)\n    soup = BeautifulSoup(r.text, \"html.parser\")\n    tags = soup.find_all(tag)\n    if tags:\n        return tags[0].text\n    return None", "compilation_passed": true, "time": 0.001093149185180664, "tests_passed": true, "error": null}
{"code": "try:\n        html = requests.get(url)\n        html.raise_for_status()\n        soup = BeautifulSoup(html.content, \"html.parser\")\n        tag = soup.find(tag)\n        if tag is not None:\n            return tag.text\n    except requests.exceptions.RequestException:\n        return None", "compilation_passed": true, "time": 0.001318216323852539, "tests_passed": false, "error": "TypeError"}
{"code": "response = requests.get(url)\n    response.raise_for_status()\n\n    soup = BeautifulSoup(response.text, \"html.parser\")\n    tag_element = soup.find(tag)\n\n    return tag_element.text if tag_element else None", "compilation_passed": true, "time": 0.0011119842529296875, "tests_passed": true, "error": null}
{"code": "try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.content, \"html.parser\")\n        tag_text = soup.find_all(tag)\n        if tag_text:\n            return tag_text[0].get_text().strip()\n        else:\n            return None\n    except (requests.RequestException, AttributeError):\n        return None", "compilation_passed": true, "time": 0.0012629032135009766, "tests_passed": false, "error": "TypeError"}
{"code": "try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.text, 'html.parser')\n        tag = soup.find(tag)\n        if tag:\n            return tag.text\n    except (requests.exceptions.ConnectionError, requests.exceptions.Timeout):\n        return None", "compilation_passed": true, "time": 0.001058816909790039, "tests_passed": true, "error": null}
{"code": "try:\n        html = requests.get(url)\n        soup = BeautifulSoup(html.text, \"html.parser\")\n        tag = soup.find(tag)\n        if tag:\n            return tag.text\n    except:\n        return None", "compilation_passed": true, "time": 0.0010402202606201172, "tests_passed": true, "error": null}
{"code": "try:\n        html = requests.get(url)\n        html.raise_for_status()\n        soup = BeautifulSoup(html.text, \"html.parser\")\n\n        tag_element = soup.find(tag)\n        if tag_element is None:\n            return None\n        else:\n            return tag_element.text\n    except Exception as e:\n        print(f\"An error occurred while scraping the web page: {e}\")\n        return None", "compilation_passed": true, "time": 0.0011560916900634766, "tests_passed": true, "error": null}
{"code": "try:\n        r = requests.get(url)\n        html = r.text\n        soup = BeautifulSoup(html, \"html.parser\")\n        return soup.find(tag).text\n    except AttributeError:\n        return None", "compilation_passed": true, "time": 0.0010280609130859375, "tests_passed": true, "error": null}
{"code": "try:\n        response = requests.get(url)\n        if response.status_code == 200:\n            soup = BeautifulSoup(response.text, \"html.parser\")\n            element = soup.find(tag)\n            if element:\n                return element.text\n\n    except requests.exceptions.ConnectionError:\n        print(\"Error connecting to {url}.\".format(url=url))\n        return None\n    except AttributeError:\n        print(\"Tag {tag} not found in {url}.\".format(tag=tag, url=url))\n        return None\n    return None", "compilation_passed": true, "time": 0.0010907649993896484, "tests_passed": true, "error": null}
