{"code": "result = {}\n    for url in re.findall(r'https?://(?:[a-z0-9]|[$-_@.&+]|[!*\\\\'\"'(),]|[^/:<>#@\\\\[\\\\\\\\\\\\]|])*\\\\.(?:[a-z]|[0-9])*', myString):\n        # url.replace(\"/\", \"\").replace(\"/\", \"\").replace(\"/\", \"\")\n        parsed_url = urllib.parse.urlparse(url)\n        domain = parsed_url.netloc.lower()\n        if \".\" in parsed_url.netloc:\n            domain = re.sub(r'([^a-z0-9.-])+$', '', parsed_url.netloc.lower())\n        if not domain:\n            domain = parsed_url.path\n        if not domain:\n            domain = parsed_url.netloc\n        if domain == \"www.\":\n            domain = \"\"\n        if domain == \"www\":\n            domain = \"\"\n        if domain", "compilation_passed": false, "time": 4.482269287109375e-05, "tests_passed": false, "error": "SyntaxError"}
{"code": "# Extract all URLs from the string\n    urls = extract_urls(myString)\n\n    # Initialize an empty dictionary to store the geolocation data\n    geolocation_data = {}\n\n    # Loop through the URLs\n    for url in urls:\n        # Parse the URL and extract the hostname and port\n        parsed_url = urllib.parse.urlparse(url)\n        hostname = parsed_url.netloc or parsed_url.path\n        port = parsed_url.port or None\n\n        # Construct the URL to use with the IP API service\n        api_url = \"https://api.ipapi.org/{}.{}:{}/json?access_key={}\".format(\n            parsed_url.netloc, parsed_url.scheme, port, API_KEY\n        )\n\n        # Send a GET request to the IP API service\n        response = requests.get(api_url)\n\n        # Parse the response and extract the status code, country, city, etc.\n        if response.status_code == 200:\n            data = json.loads(response.", "compilation_passed": false, "time": 0.00017404556274414062, "tests_passed": false, "error": "SyntaxError"}
{"code": "result = {}\n    for url in re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*,;:&]|#|%[0-9a-fA-F][0-9a-fA-F])+', myString):\n        domain = urllib.parse.urlparse(url).netloc\n        try:\n            response = requests.get(f'http://api.ipapi.com/{domain}/json?api_key={API_KEY}')\n            result[domain] = response.json()\n        except:\n            result[domain] = None\n    return result", "compilation_passed": true, "time": 0.0012471675872802734, "tests_passed": true, "error": null}
{"code": "myString = myString.replace(\"http://\", \"\").replace(\"https://\", \"\").replace(\"www.\", \"\")\n    urls = re.findall(r\"(http|https)://([\\w.-]+)\", myString)\n    res = []\n    for i in range(len(urls)):\n        try:\n            url = urllib.parse.urlparse(urls[i][1])\n            hostname = url.netloc\n            res.append(json.loads(requests.get(f\"https://ipapi.co/{hostname}/json?api_key={API_KEY}\").text))\n        except Exception as e:\n            res.append({\"status\": \"failure\", \"msg\": str(e)})\n    return res", "compilation_passed": true, "time": 0.0013530254364013672, "tests_passed": true, "error": null}
{"code": "regex = re.compile(r\"(http|https)://[^\\s<>()[\\]]+[\\s<>]*\")\n    result = regex.findall(myString)\n    if not result:\n        return None\n\n    results = []\n    for i in result:\n        url = i.strip(\"'\\\"\")\n        url = url.lstrip('http://')\n        url = url.lstrip('https://')\n        url = url.rstrip('/')\n        url = urllib.parse.urlparse(url)\n        hostname = url.netloc\n        if hostname == '':\n            hostname = url.path\n            if hostname == '':\n                hostname = \"/\"\n            hostname = url.scheme + '://' + url.geturl().split('/', 1)[0]\n        url = urllib.parse.urlparse('https://' + hostname)\n        hostname = url.netloc\n\n        try:\n            results.append(url_info(hostname, API_KEY))\n        except Exception as e:\n            results.append", "compilation_passed": true, "time": 0.001432657241821289, "tests_passed": true, "error": null}
{"code": "# Create a regular expression pattern for URLs\n    pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\'\n                         r'(),]|[#]){1,65535}', re.I)\n\n    # Use the re.finditer function to extract all URLs from myString\n    results = re.finditer(pattern, myString)\n\n    # Initialize a dictionary to store URLs and their geolocation data\n    url_info = {}\n\n    # Iterate through the results\n    for match in results:\n        try:\n            # Extract the URL using the match object\n            url = match.group(0)\n\n            # Parse the URL using the urllib.parse.urlparse function\n            parsed_url = urllib.parse.urlparse(url)\n\n            # Split the netloc into its components\n            domain_name = parsed_url.netloc.split(':')[0]\n            host_name = parsed_url.netloc.split", "compilation_passed": false, "time": 0.00015306472778320312, "tests_passed": false, "error": "SyntaxError"}
{"code": "urls = re.findall(r'https?://[^\\s<>\"\\',]+\\.[^\\s<>\"\\',]+', myString)\n    result = {}\n    for url in urls:\n        if url.startswith(\"http\"):\n            url = urllib.parse.unquote(url)\n        else:\n            url = urllib.parse.unquote(urllib.parse.urlparse(url).path)\n        url = url.lstrip(\"/\")\n        url = url.strip(\"/\")\n        if not url:\n            continue\n        response = requests.get(f\"https://api.ipapi.co/{url}/?api_key={API_KEY}\", timeout=5)\n        if response.status_code == 200:\n            data = json.loads(response.text)\n            if data[\"country\"]:\n                result[url] = data\n    return result", "compilation_passed": true, "time": 0.0015079975128173828, "tests_passed": true, "error": null}
{"code": "url_regex = re.compile(r'(([a-zA-Z0-9]{2,63}\\.)*[a-zA-Z0-9]{2,63})')\n    domains = set()\n    matches = url_regex.findall(myString)\n    for match in matches:\n        parsed_url = urllib.parse.urlparse(match)\n        domain = parsed_url.netloc or parsed_url.path.split('/')[0]\n        domains.add(domain)\n\n    result = {}\n    for domain in domains:\n        api_url = 'https://ipapi.co/{0}/json?api_key={1}'.format(domain, API_KEY)\n        try:\n            response = requests.get(api_url)\n            response.raise_for_status()\n            json_data = json.loads(response.content)\n            result[domain] = json_data\n        except requests.exceptions.RequestException as e:\n            result[domain] = None\n        except json.JSONDecodeError as e:\n            result", "compilation_passed": true, "time": 0.001486063003540039, "tests_passed": false, "error": "AttributeError"}
{"code": "urls = re.findall(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", myString)\n\n    geolocation = []\n\n    for url in urls:\n        try:\n            result = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n            if result.status_code == 200:\n                json_data = json.loads(result.text)\n                domain = urllib.parse.urlparse(url).netloc\n                country = json_data.get(\"country\")\n                region = json_data.get(\"region\")\n                city = json_data.get(\"city\")\n                zip_code = json_data.get(\"zip\")\n                latitude = json_data.get(\"lat\")\n                longitude = json_data.get(\"", "compilation_passed": false, "time": 8.916854858398438e-05, "tests_passed": false, "error": "SyntaxError"}
{"code": "urls = re.findall(r'http[s]?:\\/\\/|https:\\/\\/|www.|[a-z]+\\.[a-z]+', myString, re.I)\n    ip_api = requests.get(f'https://ipapi.co/json?api_key={API_KEY}')\n    response = json.loads(ip_api.text)\n    if response['error']:\n        print('Error: ', response['error'])\n        exit(0)\n    for url in urls:\n        url_parse = urllib.parse.urlparse(url)\n        domain = url_parse.netloc.split(\".\")[0]\n        url = domain + '.com' if domain not in [\"www\", \"\"] else domain\n        yield(url, response)", "compilation_passed": true, "time": 0.0012683868408203125, "tests_passed": true, "error": null}
{"code": "# regex pattern for URLs\n    regex = re.compile(\n        r'https?://(?:[a-z0-9.-]+/[a-z0-9-]+(?:.[a-z0-9]{2,7})+)*(?:/)?')\n\n    # find all URLs in the input string using regex pattern\n    matches = regex.findall(myString)\n\n    # initialize an empty dict to store geolocation data for each domain\n    geolocation_data = {}\n\n    # iterate over all URLs\n    for url in matches:\n\n        # extract the domain using urlparse module\n        domain = urlparse(url).netloc.split(':')[0]\n\n        # check if domain is already present in geolocation_data dict\n        if domain in geolocation_data:\n            # if present, check if its status is success\n            if geolocation_data[domain]['status'] == 'success':\n                # if so, skip this url as we already have all data for it\n                continue\n            else:\n                # if status is not success, update data by making", "compilation_passed": false, "time": 0.00014710426330566406, "tests_passed": false, "error": "IndentationError"}
{"code": "try:\n        # Split the provided string into individual URLs using re.split() and remove empty values.\n        urls = re.split(r'[\\s,]+', myString)\n        urls = [url for url in urls if url]\n        # Initialize a dictionary to store results.\n        results = {}\n        # Iterate over the URLs using a for loop.\n        for url in urls:\n            # Use the urlparse module to parse the URL.\n            parsed_url = urllib.parse.urlparse(url)\n            # Use the IP API to get geolocation data.\n            response = requests.get(f\"https://ipapi.co/json?api_key={API_KEY}\", params={\"domain\": parsed_url.netloc})\n            # If the API request is successful, parse the response and add the result to the dictionary.\n            if response.status_code == 200:\n                response_json = json.loads(response.text)\n                results[parsed_url.netloc] = response_json\n            else:\n                # If the API request fails, add a", "compilation_passed": false, "time": 0.0001671314239501953, "tests_passed": false, "error": "IndentationError"}
{"code": "URL_REGEX = '(?:[a-zA-Z]{3,9}:(?:\\/\\/)?)(?:[-;:&=+$,\\w]+@)?[A-Z0-9.-]+(?:\\:[\\d]+)?(?:/(?:[-\\w@&;+,.#/%?=~_|:]]|[^!:@&;+,.#/%=~_])*)'\n\n    urls = re.findall(URL_REGEX, myString)\n    URL_REGEX2 = '(?:https?|ftp):\\/\\/[\\n\\S]*'\n    urls2 = re.findall(URL_REGEX2, myString)\n\n    if len(urls) == 0:\n        return None\n\n    url_set = set(urls + urls2)\n\n    url_dict = {}\n    for url in url_set:\n        url = urllib.parse.urlparse(url)\n        domain = urllib.parse.parse_qsl(url.query)\n        ip_api_url = 'http://api", "compilation_passed": false, "time": 8.0108642578125e-05, "tests_passed": false, "error": "SyntaxError"}
{"code": "# Extract all URLs from myString\n    url_regex = re.compile(r'(http|https)://([\\w.-]*)')\n    urls = url_regex.findall(myString)\n    url_dict = {}\n    for url in urls:\n        domain = url[1]\n        url_dict[domain] = None\n        try:\n            response = requests.get(f\"http://api.ip2location.com/{API_KEY}/?format=json&ip={domain}\")\n            url_dict[domain] = response.json()\n        except Exception as e:\n            print(f\"Error getting geolocation data for {domain}: {e}\")\n    return url_dict", "compilation_passed": true, "time": 0.0013120174407958984, "tests_passed": true, "error": null}
{"code": "# Initialize the result dictionary\n    result = {}\n\n    # Extract URLs from the provided string\n    url_regex = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*(),]|{}|:|\\\"|/)*')\n    url_matches = url_regex.finditer(myString)\n\n    for url in url_matches:\n        # Get the URL string\n        url_str = url.group()\n        # Parse the URL\n        parsed_url = urllib.parse.urlparse(url_str)\n\n        # Try to fetch geolocation data for the domain\n        try:\n            ip_url = requests.get(parsed_url.netloc)\n            if ip_url.status_code == 200:\n                geolocation = json.loads(ip_url.text)\n                result[parsed_url.netloc] = geolocation\n            else:\n                result[parsed_url.netloc] = None\n        except:\n", "compilation_passed": false, "time": 0.00017595291137695312, "tests_passed": false, "error": "IndentationError"}
{"code": "# Split myString into individual URLs and store them in a list\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', myString)\n    # Initialize an empty dictionary to store geolocation data\n    geolocation_data = {}\n    # Loop through each URL in the list\n    for url in urls:\n        try:\n            # Parse the URL using the urllib.parse library\n            parsed_url = urllib.parse.urlparse(url)\n            # Get the domain name and port from the parsed URL\n            hostname = parsed_url.netloc\n            # Get the path from the parsed URL\n            path = parsed_url.path\n            # Construct the URL to make a request to the IP API\n            url_for_api = 'http://ip-api.com/json/%s%s?fields=status,country,country", "compilation_passed": false, "time": 5.626678466796875e-05, "tests_passed": false, "error": "SyntaxError"}
{"code": "# Initialize the dictionary to store results\n    result = {}\n\n    # Parse the input string and find all URLs\n    pattern = r'https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b(?:[-a-zA-Z0-9()@:%_\\+.~#?&//=]*)'\n    urls = re.findall(pattern, myString)\n\n    # Iterate through the URLs\n    for url in urls:\n        # Parse the URL\n        parsed_url = urllib.parse.urlparse(url)\n\n        # Extract the domain name\n        domain = parsed_url.netloc\n\n        # Check if the domain is already in the result dictionary\n        if domain not in result:\n            # Send an HTTP request to the IP API with the domain as the payload\n            response = requests.get(f\"http://api.ipdata.co/{domain}?api-key={API_KEY}\"", "compilation_passed": false, "time": 0.00014591217041015625, "tests_passed": false, "error": "SyntaxError"}
{"code": "# Extract URLs from the provided string\n    url_pattern = re.compile(r'http(s)?://(www\\.)?[a-zA-Z0-9\\.]+\\.[a-z]{2,10}(/.*)?')\n    urls = url_pattern.findall(myString)\n\n    # Create a dictionary to store URL-domain mappings\n    domain_map = {}\n\n    # Loop through URLs and perform requests\n    for url in urls:\n        parsed_url = urllib.parse.urlparse(url)\n        hostname = parsed_url.netloc\n        domain = parsed_url.hostname.split('.')\n\n        # Check for custom domain\n        if len(domain) > 1:\n            if domain[0] == 'www' or domain[1] == 'google' or domain[1] == 'amazon':\n                domain[0] = domain[1]\n            domain = domain[0] + '.' + domain[1]\n        else:\n            domain = domain[0]\n        ip_api_url = 'http", "compilation_passed": false, "time": 8.296966552734375e-05, "tests_passed": false, "error": "SyntaxError"}
{"code": "try:\n        # Extract all URLs from the input string\n        urls = re.findall('(?:https?\\:\\/\\/)?(?:www\\.)?[\\w\\-\\.]+(?:\\:\\d+)?', myString)\n        results = {}\n        for url in urls:\n            # Analyze each URL for IP, domain, country, etc.\n            if not url.startswith('http'):\n                url = 'http://' + url\n            domain = urllib.parse.urlparse(url).netloc\n            parsed_url = urllib.parse.urlparse(url)\n            ip_request = requests.get(f'https://ipapi.co/{domain}/json?api_key={API_KEY}')\n            if ip_request.status_code != 200:\n                results[domain] = None\n            else:\n                ip_response = ip_request.json()\n                # print(ip_response)\n                results[domain] = ip_response\n        return results\n    except Exception as e:\n        print(f\"", "compilation_passed": false, "time": 8.702278137207031e-05, "tests_passed": false, "error": "SyntaxError"}
{"code": "try:\n        result = {}\n        matches = re.findall(r'https?://(www\\.)?([a-zA-Z0-9.-]+)(/.*)?', myString)\n        for match in matches:\n            domain = match[1]\n            url = 'https://api.ip.sb/geoip?query=' + domain + '&api_key=' + API_KEY\n            resp = requests.get(url)\n            data = resp.json()\n            result[domain] = data\n        return result\n    except Exception as e:\n        return {'error': str(e)}", "compilation_passed": true, "time": 0.0012040138244628906, "tests_passed": true, "error": null}
{"code": "# 1. Extract all URLs from the string\n    urls = [\n        url.strip()\n        for url in re.findall(\n            r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\'#]|\"\n            r\"(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\n            myString\n        )\n    ]\n    # 2. Check whether the string is empty\n    if len(urls) == 0:\n        return {}\n\n    # 3. Get the geolocation data for each URL\n    results = {}\n    for url in urls:\n        # 4. Use the IP API to get the geolocation data for the domain\n        try:\n            url = urllib.parse.urlparse(url).netloc or urllib.parse.urlparse(\n                url\n            ).path\n            url = url.encode(\"idna\").decode(\"ascii\")\n            url =", "compilation_passed": false, "time": 0.000164031982421875, "tests_passed": false, "error": "SyntaxError"}
{"code": "try:\n        result = json.loads(urllib.parse.urlparse(myString).query)\n\n        domain_list = []\n        for item in result:\n            domain = item.get('query').split('.')\n            domain_list.append(domain[len(domain)-2] + '.' + domain[len(domain)-1])\n\n        api_url = \"https://api.ipapi.co/%s/json?api_key=%s\" % (domain, API_KEY)\n        response = requests.get(api_url)\n        data = response.json()\n        return data\n    except Exception as e:\n        return None", "compilation_passed": true, "time": 0.0013041496276855469, "tests_passed": true, "error": null}
{"code": "result_dict = dict()\n    for url in re.findall(r'https?://(?:[a-zA-Z]+\\.)*[a-zA-Z]+(?:\\/[^\"\\']*)*', myString):\n        domain = urllib.parse.urlparse(url).netloc.lower()\n        try:\n            res = requests.get('https://api.ipapi.org/{}?api_key={}'.format(domain, API_KEY))\n            json_response = json.loads(res.text)\n            result_dict[domain] = json_response\n        except requests.exceptions.RequestException as e:\n            result_dict[domain] = None\n    return result_dict", "compilation_passed": true, "time": 0.0017960071563720703, "tests_passed": true, "error": null}
{"code": "# Define the regex pattern for matching URLs\n    pattern = re.compile(r\"(http|https):\\/\\/([^ \\n]+\\.)*[^ \\n]+\")\n    urls = pattern.findall(myString)\n\n    # Iterate over the list of URLs\n    url_to_ip = dict()\n    for url in urls:\n        # Convert the URL to a full URL\n        url_with_netloc = urllib.parse.urlparse(url)\n        url_with_netloc = url_with_netloc._replace(netloc=f\"{url_with_netloc.hostname}:{url_with_netloc.port}\")\n        url_with_netloc = urllib.parse.urlunparse(url_with_netloc)\n        # Fetch the URL's data using the requests library\n        response = requests.get(url_with_netloc)\n        # Parse the response\n        response_json = json.loads(response.text)\n        # Extract the geolocation data from the response\n        geolocation_data = response_json", "compilation_passed": true, "time": 0.0012867450714111328, "tests_passed": true, "error": null}
{"code": "myString = myString.replace(\"\\r\",\"\") # Removes line breaks and replaces carriage returns to prevent unexpected line breaks\n    myString = myString.replace(\"\\n\",\"\")\n    # 1. Separate out the URLs from the provided string\n    myString = myString.split(\",\")\n    myUrls = []\n    for myUrl in myString:\n        # Removes spaces from the URL\n        myUrl = myUrl.strip()\n        # Removes any query string from the URL\n        myUrl = myUrl.split(\"?\")[0]\n        # Removes any HTTP, HTTPS, FTP, or WWW prefixes from the URL\n        if re.match(r\"^http|https|ftp|www\\d\\d\\d\\d\\d\\d\\d\\d\", myUrl):\n            myUrl = myUrl.split(\"http://\")[1]\n            myUrl = myUrl.split(\"https://\")[1]\n            myUrl = myUrl.split(\"ftp://\")[1]\n            myUrl = myUrl", "compilation_passed": true, "time": 0.0012829303741455078, "tests_passed": true, "error": null}
{"code": "url_regex = re.compile(\n        r\"\"\"(?i)\\b((?:[a-z][\\w-]*://)?(?:www\\.)?[\\w-]+(?:.[\\w-]+)+/((?:\\w+\\/)*[\\w-]+(?:/\\w+)*)?.(?:[\\w-]+(?:.[\\w-]+)?/)*[\\w-]+(?:/\\w+)*(/.*)?)\"\"\")\n\n    url_list = url_regex.findall(myString)\n\n    result = {}\n    for domain in url_list:\n        try:\n            url = urllib.parse.urlparse(domain)\n\n            # API request to get IP data\n            response = requests.get(f\"https://api.ipapi.co/{url.hostname}/json?api_key={API_KEY}\", timeout=3)\n\n            if response.status_code == 200:\n                ip_data = json.loads(response.text)\n                result[domain] = ip_data\n            else", "compilation_passed": false, "time": 0.00010609626770019531, "tests_passed": false, "error": "SyntaxError"}
{"code": "result = {}\n\n    # Extract URLs\n    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*(),]|\"|:|;|=|%7E|#)+', myString)\n\n    # Loop through URLs\n    for url in urls:\n        try:\n            # Parse URL\n            parsed = urllib.parse.urlparse(url)\n\n            # Extract hostname from parsed URL\n            hostname = parsed.netloc\n\n            # Strip trailing dots if present\n            if hostname.endswith('.'):\n                hostname = hostname.rstrip('.')\n\n            # Extract domain name\n            domain = hostname\n\n            # Strip www prefix if present\n            if domain.startswith('www.'):\n                domain = domain[4:]\n\n            # Get IP API URL\n            ip_url = f\"https://api.ipapi.co/{domain}/json?api_key={API_KEY}\"\n\n            ", "compilation_passed": false, "time": 0.00016498565673828125, "tests_passed": false, "error": "SyntaxError"}
{"code": "def get_ip_api_data(ip_address):\n        #url = f'http://api.ipapi.co/{ip_address}/json?api_key={API_KEY}'\n        url = f'https://ipapi.co/json?api_key={API_KEY}'\n        try:\n            response = requests.get(url)\n            if response.status_code == 200:\n                return response.json()\n            else:\n                return None\n        except requests.exceptions.RequestException:\n            return None\n\n    def get_domain_name(url):\n        return urllib.parse.urlparse(url).netloc.lower()\n\n    def extract_urls(myString):\n        regex = r'(http|ftp|https)://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n        urls = re.findall(regex, myString)\n        return url", "compilation_passed": true, "time": 0.0012531280517578125, "tests_passed": true, "error": null}
{"code": "# Regular expression to match URLs in the given string\n    url_regex = r\"(?i)\\b((?:https?|ftp):\\/\\/|www\\.)[-a-zA-Z0-9+&@#\\/%?!_|~#]*\"\n\n    # Find all URLs in the string\n    urls = re.findall(url_regex, myString)\n\n    # Loop through each URL and make a request to the IP API service\n    results = {}\n    for url in urls:\n        try:\n            parsed_url = urllib.parse.urlparse(url)\n            domain_name = parsed_url.netloc or parsed_url.path.split('/')[0]\n            if domain_name.startswith('www.'):\n                domain_name = domain_name[4:]\n            domain = parsed_url.scheme + '://' + domain_name\n            req = requests.get(domain)\n            ip = req.headers.get('X-Real-IP') or req.headers.get('X-Forwarded-For')\n\n            # if no X-", "compilation_passed": false, "time": 0.0001709461212158203, "tests_passed": false, "error": "SyntaxError"}
{"code": "regex = re.compile(\n        r\"((http|https)://)(www\\.)?([a-zA-Z0-9\\-])+((\\.[a-zA-Z0-9\\-]+)+)(/[a-zA-Z0-9\\-\\._\\?\\,\\/\\\\\\+\\&amp;%#;=\\$!:@]*)?\")\n    myMatches = regex.findall(myString)\n\n    geoloc_dict = {}\n\n    for domain in myMatches:\n        url = urllib.parse.urlparse(domain[0])\n        domain = url.netloc.split(\".\")[-1]\n        try:\n            res = requests.get(\"https://api.ipapi.co/\" + domain + \"?api_key=\" + API_KEY)\n            data = json.loads(res.content)\n            geoloc_dict[domain] = data\n        except:\n            print(domain, \"failed\")\n            geoloc_dict[domain] = None\n\n    return geoloc_dict", "compilation_passed": true, "time": 0.0013208389282226562, "tests_passed": true, "error": null}
