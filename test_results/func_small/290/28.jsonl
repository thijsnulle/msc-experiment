{"code": "file_list = []\n    total_count = 0\n    for (dir_path, _, files) in os.walk(directory_path):\n        for file in files:\n            if file.endswith('.txt'):\n                file_path = os.path.join(dir_path, file)\n                file_list.append(file_path)\n    for file_path in file_list:\n        with open(file_path, 'r') as file:\n            data = file.read().split()\n            for word in data:\n                if not word in STOPWORDS:\n                    total_count += 1\n    return total_count", "compilation_passed": true, "time": 0.0021140575408935547, "tests_passed": true, "error": null}
{"code": "word_count = 0\n\n    files = [os.path.join(directory_path, f) for f in os.listdir(directory_path) if f.endswith('.txt')]\n    for file in files:\n        with open(file) as f:\n            words = nltk.word_tokenize(f.read())\n            word_count += len(Counter(word for word in words if word.lower() not in STOPWORDS))\n    return word_count", "compilation_passed": true, "time": 0.0016179084777832031, "tests_passed": false, "error": ""}
{"code": "# Find all '.txt' files in the specified directory\n    text_files = [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith('.txt')]\n    # Extract non-stop words from all files using Counter()\n    non_stop_words = Counter()\n    for file in text_files:\n        with open(file, encoding='utf-8', errors='ignore') as f:\n            text = f.read()\n            for word in text.split():\n                if word.lower() not in STOPWORDS:\n                    non_stop_words[word.lower()] += 1\n\n    # Sum up all the non-stop words\n    unique_non_stop_words = sum(non_stop_words.values())\n\n    return unique_non_stop_words", "compilation_passed": true, "time": 0.0019519329071044922, "tests_passed": true, "error": null}
{"code": "counter = Counter()\n    for file_name in os.listdir(directory_path):\n        if file_name.endswith(\".txt\"):\n            file_path = os.path.join(directory_path, file_name)\n            with open(file_path, 'r') as file:\n                contents = file.read()\n                words = contents.split()\n                unique_words = [word for word in words if word.lower() not in STOPWORDS]\n                counter.update(unique_words)\n    return len(counter)", "compilation_passed": true, "time": 0.001931905746459961, "tests_passed": true, "error": null}
{"code": "count = 0\n\n    # Use os.walk() to iterate through all subdirectories and files in the specified directory\n    for subdir, dirs, files in os.walk(directory_path):\n        for file in files:\n            if file.endswith('txt'):\n                # Read the file using the with statement, split the file contents into words,\n                # filter out stopwords, count unique words, and sum them up\n                with open(os.path.join(subdir, file)) as f:\n                    text = f.read()\n                    words = nltk.wordpunct_tokenize(text)\n                    words = [word.lower() for word in words if word not in STOPWORDS]\n                    unique_words = len(Counter(words))\n                    count += unique_words\n\n    return count", "compilation_passed": true, "time": 0.0012547969818115234, "tests_passed": true, "error": null}
{"code": "# Define the path to the directory and the file extension\n    directory_path = directory_path.strip('/')\n    file_extension = '.txt'\n\n    # Check if the directory exists and has files\n    if not os.path.exists(directory_path) or not os.listdir(directory_path):\n        return None\n\n    # Initialize variables to store the count of unique non-stop words\n    word_count = 0\n    word_counter = Counter()\n\n    # Iterate over the files in the directory\n    for file_name in os.listdir(directory_path):\n        if file_name.endswith(file_extension):\n            file_path = os.path.join(directory_path, file_name)\n\n            # Open the file in read mode\n            with open(file_path, 'r') as file:\n                # Iterate over the lines in the file\n                for line in file:\n                    # Split the line into words and remove non-letter characters\n                    words = [word for word in re.findall(r'\\w+', line.lower()) if word not in", "compilation_passed": false, "time": 0.0002048015594482422, "tests_passed": false, "error": "SyntaxError"}
{"code": "# TODO: Write code here\n    counter = Counter()\n    for file_name in os.listdir(directory_path):\n        file_path = os.path.join(directory_path, file_name)\n        if os.path.isfile(file_path) and file_name.endswith('.txt'):\n            with open(file_path, 'r', encoding='utf-8') as file:\n                contents = file.read()\n                words = contents.split()\n                for word in words:\n                    if word not in STOPWORDS:\n                        counter[word] += 1\n    return sum(counter.values())", "compilation_passed": true, "time": 0.0020470619201660156, "tests_passed": true, "error": null}
{"code": "counter = Counter()\n    for file_name in os.listdir(directory_path):\n        if file_name.endswith('.txt'):\n            with open(os.path.join(directory_path, file_name), encoding='utf-8') as f:\n                words = nltk.word_tokenize(f.read())\n                non_stop_words = [word for word in words if word not in STOPWORDS]\n                counter.update(non_stop_words)\n    return len(counter)", "compilation_passed": true, "time": 0.0015742778778076172, "tests_passed": false, "error": ""}
{"code": "# Read all '.txt' files in the directory into a list\n    file_paths = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f)) and f.endswith('.txt')]\n    all_texts = []\n    for file_path in file_paths:\n        with open(os.path.join(directory_path, file_path), 'r') as file:\n            all_texts.append(file.read())\n\n    # Create a set of all non-stop words found in all texts\n    all_words = Counter()\n    for text in all_texts:\n        words = text.split()\n        non_stop_words = set(words) - STOPWORDS\n        all_words.update(non_stop_words)\n\n    return len(all_words)", "compilation_passed": true, "time": 0.002238035202026367, "tests_passed": true, "error": null}
{"code": "count = 0\n    for file in os.listdir(directory_path):\n        if file.endswith('.txt'):\n            with open(os.path.join(directory_path, file), 'r') as file:\n                text = file.read()\n                words = nltk.wordpunct_tokenize(text)\n                words = [word for word in words if not word.lower() in STOPWORDS]\n                count += len(Counter(words))\n    return count", "compilation_passed": true, "time": 0.0020551681518554688, "tests_passed": true, "error": null}
{"code": "total_unique_words = 0\n    files_counter = 0\n    directory_path = os.path.expanduser(directory_path)\n\n    for file in os.listdir(directory_path):\n        if file.endswith('.txt'):\n            files_counter += 1\n            with open(os.path.join(directory_path, file), encoding='utf8') as f:\n                # Load the file data as a string\n                content = f.read()\n\n                # Tokenize the content using nltk\n                tokens = nltk.word_tokenize(content)\n\n                # Remove stop words\n                filtered_tokens = [word for word in tokens if word not in STOPWORDS]\n\n                # Count the occurrence of each unique word\n                word_count = Counter(filtered_tokens)\n\n                total_unique_words += len(word_count)\n\n                print(f\"Processed file {file}, {files_counter} files\")\n\n    print(f\"Total unique words: {total_unique_words}\")\n    return total_unique_words", "compilation_passed": true, "time": 0.0016617774963378906, "tests_passed": false, "error": ""}
{"code": "# Initializing counters and total count\n    stop_word_count = 0\n    non_stop_word_count = 0\n    total_count = 0\n\n    # Looping through all files in the directory\n    for file in os.listdir(directory_path):\n        if file.endswith(\".txt\"):\n            filepath = os.path.join(directory_path, file)\n            with open(filepath, encoding='utf-8') as f:\n                contents = f.read()\n                words = nltk.word_tokenize(contents)\n                for word in words:\n                    # Checking if the word is a stopword or not\n                    if word not in STOPWORDS:\n                        non_stop_word_count += 1\n                        # Counting the total number of non-stop words\n                        total_count += 1\n                    else:\n                        stop_word_count += 1\n\n    # Calculating the total number of non-stop words\n    total_count += stop_word_count\n\n    # Print the result\n    print", "compilation_passed": true, "time": 0.0015568733215332031, "tests_passed": false, "error": ""}
{"code": "counter = Counter()\n    for file_name in os.listdir(directory_path):\n        if file_name.endswith('.txt'):\n            with open(os.path.join(directory_path, file_name)) as f:\n                text = f.read()\n                words = text.split()\n                counter.update(set(words))\n    return len(counter)", "compilation_passed": true, "time": 0.0016169548034667969, "tests_passed": true, "error": null}
{"code": "# Fetch all files from the directory\n    files = [os.path.join(directory_path, f) for f in os.listdir(directory_path) if f.endswith(\".txt\")]\n\n    # Process each file\n    counter = Counter()\n    for file_path in files:\n        with open(file_path, 'r') as f:\n            for line in f.readlines():\n                for word in line.split():\n                    # Ignore stopwords and non-alphabetic characters\n                    if word not in STOPWORDS and word.isalpha():\n                        counter[word.lower()] += 1\n    return sum(counter.values())", "compilation_passed": true, "time": 0.0020401477813720703, "tests_passed": true, "error": null}
{"code": "# TODO: Implement me\n    return 0", "compilation_passed": true, "time": 0.0009930133819580078, "tests_passed": true, "error": null}
{"code": "# TODO: Implement your solution here\n    file_count = 0\n    word_count = 0\n    total_words = 0\n\n    for root, dirs, files in os.walk(directory_path):\n        for file in files:\n            if file.endswith(\".txt\"):\n                file_path = os.path.join(root, file)\n                with open(file_path, 'r', encoding='utf-8') as file:\n                    content = file.read()\n                    tokens = nltk.tokenize.word_tokenize(content)\n                    tokens = [word.lower() for word in tokens if word.isalnum()]\n                    tokens = [word for word in tokens if not word in STOPWORDS]\n                    word_count += len(tokens)\n                    file_count += 1\n\n    total_words = word_count / file_count\n    return total_words", "compilation_passed": true, "time": 0.0016160011291503906, "tests_passed": false, "error": ""}
{"code": "count = 0\n\n    for root, dirs, files in os.walk(directory_path):\n        for filename in files:\n            if filename.endswith(\".txt\"):\n                file_path = os.path.join(root, filename)\n                with open(file_path, \"r\") as file:\n                    text = file.read()\n                    words = text.split()\n                    non_stop_words = [word for word in words if word.lower() not in STOPWORDS]\n                    word_counts = Counter(non_stop_words)\n                    count += sum(word_counts.values())\n\n    return count", "compilation_passed": true, "time": 0.0018928050994873047, "tests_passed": true, "error": null}
{"code": "# Count non-stop words across files\n    word_counter = Counter()\n    for filename in os.listdir(directory_path):\n        if filename.endswith('.txt'):\n            with open(os.path.join(directory_path, filename), 'r') as file:\n                words = nltk.word_tokenize(file.read())\n                non_stop_words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n                word_counter.update(non_stop_words)\n\n    # Count total number of non-stop words\n    total_count = sum([count for count, word in word_counter.items() if count > 1])\n    return total_count", "compilation_passed": true, "time": 0.0015943050384521484, "tests_passed": false, "error": ""}
{"code": "total_words = 0\n    for file in os.listdir(directory_path):\n        if file.endswith('.txt'):\n            with open(os.path.join(directory_path, file)) as f:\n                words = nltk.word_tokenize(f.read())\n                words = [w.lower() for w in words if w not in STOPWORDS]\n                total_words += len(words)\n    return total_words", "compilation_passed": true, "time": 0.0015480518341064453, "tests_passed": false, "error": ""}
{"code": "# Your code goes here\n    # print(os.listdir(directory_path))\n    result = 0\n    for file in os.listdir(directory_path):\n        if file.endswith(\".txt\"):\n            with open(directory_path+file, 'r') as f:\n                data = f.read()\n            word = data.split()\n            # print(word)\n            new_word = []\n            for item in word:\n                # print(item)\n                item = item.strip(\".,;:'[]\")\n                item = item.lower()\n                if item not in STOPWORDS:\n                    new_word.append(item)\n\n            # print(new_word)\n            result += len(new_word)\n            # print(result)\n\n    return result", "compilation_passed": true, "time": 0.0011818408966064453, "tests_passed": false, "error": "FileNotFoundError"}
{"code": "total_words = 0\n\n    # Use Counter to find the most common word in each file\n    for filename in os.listdir(directory_path):\n        if filename.endswith(\".txt\"):\n            file_path = os.path.join(directory_path, filename)\n            with open(file_path, 'r') as file:\n                words = file.read().split()\n                word_counts = Counter(words)\n                common_word = word_counts.most_common(1)[0]\n                total_words += common_word[1]\n\n    return total_words", "compilation_passed": true, "time": 0.0011501312255859375, "tests_passed": true, "error": null}
{"code": "unique_words = Counter()\n\n    for root, _, filenames in os.walk(directory_path):\n        for filename in filenames:\n            filepath = os.path.join(root, filename)\n            if not filename.endswith('.txt'):\n                continue\n\n            with open(filepath, 'r') as file:\n                lines = file.readlines()\n                for line in lines:\n                    words = line.split()\n                    for word in words:\n                        word = word.strip().lower()\n                        if word not in STOPWORDS:\n                            unique_words[word] += 1\n\n    return sum(unique_words.values())", "compilation_passed": true, "time": 0.0021278858184814453, "tests_passed": true, "error": null}
{"code": "# Count unique non-stop words in all '.txt' files in the specified directory\n    count = 0\n    for dirname, _, files in os.walk(directory_path):\n        for filename in files:\n            if filename.endswith('.txt'):\n                with open(os.path.join(dirname, filename)) as file:\n                    text = file.read()\n                    words = nltk.word_tokenize(text)\n                    words = [word for word in words if word not in STOPWORDS]\n                    count += len(Counter(words))\n    return count", "compilation_passed": true, "time": 0.0016541481018066406, "tests_passed": false, "error": ""}
{"code": "# Step 1: Check if the directory path exists and is a valid directory\n    if not os.path.exists(directory_path) or not os.path.isdir(directory_path):\n        print('Error: Directory does not exist or is not a valid directory')\n        return None\n\n    # Step 2: Initialize variables to track the total count of unique non-stop words\n    word_counts = Counter()\n\n    # Step 3: Loop through all '.txt' files in the directory\n    for file in os.listdir(directory_path):\n        if file.endswith('.txt'):\n            # Step 3.1: Read the file and extract the words\n            with open(directory_path + file, 'r', encoding='utf-8') as f:\n                words = f.read().split()\n\n            # Step 3.2: Remove stopwords from the words\n            words = [word for word in words if word not in STOPWORDS]\n\n            # Step 3.3: Add the words to the Counter object and keep track of their frequency\n            word_counts.update", "compilation_passed": true, "time": 0.0013158321380615234, "tests_passed": false, "error": "FileNotFoundError"}
{"code": "stopwords = set(stopwords.words('english'))\n\n    total = 0\n\n    for file in os.listdir(directory_path):\n        if file.endswith('.txt'):\n            with open(os.path.join(directory_path, file), 'r', encoding='utf-8') as f:\n                text = f.read()\n                words = nltk.word_tokenize(text)\n                non_stopwords = [word.lower() for word in words if word.lower() not in stopwords]\n                count = Counter(non_stopwords)\n                total += sum(count.values())\n    return total", "compilation_passed": true, "time": 0.0012652873992919922, "tests_passed": false, "error": "UnboundLocalError"}
{"code": "counter = Counter()\n\n    for file_name in os.listdir(directory_path):\n        if file_name.endswith('.txt'):\n            try:\n                with open(os.path.join(directory_path, file_name), 'r', encoding='utf-8') as file:\n                    lines = file.readlines()\n                    words = [word.strip(\"'\").lower() for word in nltk.word_tokenize(' '.join(lines))]\n                    counter.update(Counter(words))\n            except UnicodeDecodeError:\n                continue\n\n    return sum([1 for word, count in counter.items() if word not in STOPWORDS and count > 1])", "compilation_passed": true, "time": 0.0016710758209228516, "tests_passed": false, "error": ""}
{"code": "stopwords = STOPWORDS\n\n    # Check if the directory exists and if it's a valid path\n    if os.path.isdir(directory_path):\n        # Loop over all '.txt' files in the specified directory\n        for file_name in os.listdir(directory_path):\n            # Check if the file is an '.txt' file\n            if file_name.endswith('.txt'):\n                file_path = os.path.join(directory_path, file_name)\n                # Open the file for reading\n                with open(file_path, 'r', encoding='utf-8') as file:\n                    text = file.read()\n\n                # Split the text into words\n                words = text.split()\n                # Remove the stopwords from the words list\n                filtered_words = [word for word in words if word.lower() not in stopwords]\n\n                # Count the unique non-stop words\n                unique_words = Counter(filtered_words)\n\n                # Display the number of unique non-stop words\n                print(\"Unique non-stop words in\"", "compilation_passed": false, "time": 0.00019669532775878906, "tests_passed": false, "error": "SyntaxError"}
{"code": "# Fetch all '.txt' files in the directory\n    file_paths = [os.path.join(directory_path, f) for f in os.listdir(directory_path) if f.endswith('.txt')]\n\n    # Count the number of unique non-stop words across all '.txt' files\n    total_words = 0\n    for file_path in file_paths:\n        with open(file_path, 'r') as f:\n            text = f.read()\n            words = nltk.word_tokenize(text)\n            words = [w.lower() for w in words if w.isalnum()]\n            words = [w for w in words if w not in STOPWORDS]\n            total_words += len(set(words))\n\n    return total_words", "compilation_passed": true, "time": 0.0015840530395507812, "tests_passed": false, "error": ""}
{"code": "# TODO: Count the total number of non-stop words across all '.txt' files in the specified directory\n\n    total = 0\n    for filename in os.listdir(directory_path):\n        if filename.endswith(\".txt\"):\n            file_path = os.path.join(directory_path, filename)\n            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                text = f.read()\n                words = text.split()\n                words_lower = [word.lower() for word in words if word not in STOPWORDS]\n                total += len(words_lower)\n\n    return total", "compilation_passed": true, "time": 0.0019500255584716797, "tests_passed": true, "error": null}
{"code": "# Check if the directory exists.\n    if os.path.isdir(directory_path):\n        # List all files in the directory.\n        files = [file for file in os.listdir(directory_path) if file.endswith('.txt')]\n        # Initialize a Counter for the total number of unique non-stop words.\n        total_unique_words = Counter()\n\n        # Loop through each file and count the total number of unique words.\n        for file in files:\n            with open(os.path.join(directory_path, file), encoding='utf-8') as f:\n                # Split the file into words using the nltk.word_tokenize() function.\n                words = nltk.word_tokenize(f.read())\n                # Remove stop words from the words.\n                words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n                # Update the total number of unique words.\n                total_unique_words.update(Counter(words))\n\n        return len(total_unique_words)\n    else:\n        raise", "compilation_passed": true, "time": 0.001619100570678711, "tests_passed": false, "error": ""}
