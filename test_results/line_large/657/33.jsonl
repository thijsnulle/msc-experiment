{"code": " [word_tokenize(text) for text in cleaned_texts]", "compilation_passed": true, "time": 0.003245115280151367, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}
{"code": " [word for text in cleaned_texts for word in text.split() if word not in stopwords]", "compilation_passed": true, "time": 0.0031270980834960938, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}
{"code": " [nltk.word_tokenize(text) for text in cleaned_texts]", "compilation_passed": true, "time": 0.0023899078369140625, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}
{"code": " [text.split() for text in cleaned_texts]", "compilation_passed": true, "time": 0.005257844924926758, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}
{"code": " [[word for word in nltk.word_tokenize(text) if word not in stopwords] for text in cleaned_texts]", "compilation_passed": true, "time": 0.0025179386138916016, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}
