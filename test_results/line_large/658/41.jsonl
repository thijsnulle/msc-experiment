{"code": " vectorizer.fit_transform(tokenized_texts)", "compilation_passed": true, "time": 0.002171754837036133, "tests_passed": true, "error": null}
{"code": " vectorizer.fit_transform(tokenized_texts).todense()", "compilation_passed": true, "time": 0.0011241436004638672, "tests_passed": false, "error": "AttributeError"}
{"code": " pd.DataFrame(vectorizer.fit_transform(tokenized_texts).todense(), columns=vectorizer.get_feature_names_out())", "compilation_passed": true, "time": 0.0011119842529296875, "tests_passed": false, "error": "AttributeError"}
{"code": " pd.DataFrame(vectorizer.fit_transform(tokenized_texts).toarray(), columns=vectorizer.get_feature_names_out())", "compilation_passed": true, "time": 0.0013489723205566406, "tests_passed": false, "error": "AttributeError"}
{"code": " vectorizer.fit_transform(tokenized_texts).toarray()", "compilation_passed": true, "time": 0.0010747909545898438, "tests_passed": false, "error": "AttributeError"}
{"code": " pd.DataFrame(vectorizer.fit_transform(tokenized_texts).todense(),", "compilation_passed": false, "time": 0.00018715858459472656, "tests_passed": false, "error": "SyntaxError"}
{"code": " pd.DataFrame(vectorizer.fit_transform(tokenized_texts).toarray())", "compilation_passed": true, "time": 0.0011467933654785156, "tests_passed": false, "error": "AttributeError"}
