{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 25, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002778768539428711, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 30, 27, 29, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 30, 27, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 31, 28, 29, 30, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 30, 31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 27, 28, 29, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 26, 29, 31, 25, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0032439231872558594, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 26, 31, 25, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 30, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002009868621826172, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 31, 28, 30, 27, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 28, 27, 31, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 30, 25, 28, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 28, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 29, 28, 31, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 26, 31, 27, 29, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 31, 29, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 25, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 25, 26, 27, 30, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 31, 30, 27, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 31, 29, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 28, 25, 27, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 30, 29, 28, 26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.004307270050048828, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 26, 28, 29, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 27, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 29, 27, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 25, 29, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25, 31, 28, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 27, 29, 30, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 25, 31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 28, 30, 27, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 30, 26, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 26, 25, 29, 30, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29, 30, 28, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 29, 28, 26, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 31, 28, 26, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 27, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002009868621826172, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 31, 29, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 30, 26, 27, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 29, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 30, 25, 28, 26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002076387405395508, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 30, 31, 29, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 29, 30, 25, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 30, 26, 28, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 25, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 29, 28, 25, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 30, 25, 26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 30, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 29, 26, 28, 30, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 31, 28, 27, 29, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0048291683197021484, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 26, 29, 25, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 31, 29, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 29, 28, 30, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 29, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 25, 27, 29, 30, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002173900604248047, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 27, 25, 26, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 27, 29, 26, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002009868621826172, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0025682449340820312, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 27, 28, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 27, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002009868621826172, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0032439231872558594, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 27, 26, 28, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023512840270996094, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002317190170288086, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 25, 27, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 26, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 27, 25, 28, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 27, 29, 30, 26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 28, 26, 31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = {}\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 30, 29, 31, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 25, 27, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 27, 31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 30, 26, 29, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.004508018493652344, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 30, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 28, 26, 27, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 25, 28, 31, 26, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = {}\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 28, 31, 25, 29, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 29, 25, 26, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 26, 28, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023512840270996094, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 29, 25, 27, 28, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 29, 27, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 30, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 27, 29, 25, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 25, 26, 29, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 28, 30, 25, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023512840270996094, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 30, 31, 29, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 28, 29, 30, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 31, 28, 26, 25, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002009868621826172, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002279996871948242, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 28, 27, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 28, 29, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002173900604248047, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002778768539428711, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 31, 28, 26, 29, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 27, 29, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 30, 29, 31, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 29, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 28, 25, 29, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002076387405395508, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 31, 29, 28, 27, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 31, 30, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 31, 29, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 25, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 26, 29, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002778768539428711, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 26, 29, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 28, 25, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 28, 27, 29, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 30, 26, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 25, 27, 30, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 25, 30, 26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 26, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 30, 26, 27, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 31, 25, 28, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25, 27, 30, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0032439231872558594, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 30, 28, 29, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 25, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 29, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 25, 26, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 31, 27, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 30, 27, 31, 28, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 27, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 29, 27, 31, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 26, 25, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 26, 29, 28, 31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 25, 27, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002009868621826172, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002863168716430664, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 29, 26, 30, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 29, 30, 28, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 31, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023169517517089844, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 25, 31, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 29, 27, 30, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29, 30, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 25, 29, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 27, 26, 30, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 31, 25, 27, 30, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 31, 30, 29, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 31, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 30, 26, 25, 27, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 27, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0029811859130859375, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0025682449340820312, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 30, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 30, 29, 31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 25, 29, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 31, 28, 25, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.004508018493652344, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 27, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0029811859130859375, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 31, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 30, 27, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 26, 29, 30, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 31, 30, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = {}\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 30, 29, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 30, 29, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 30, 27, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 27, 26, 29, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023512840270996094, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0020890235900878906, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 25, 26, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 27, 26, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 28, 27, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 25, 31, 28, 30, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 25, 28, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 31, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002279996871948242, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 28, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 27, 25, 30, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 26, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 25, 28, 27, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 30, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 26, 29, 27, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 28, 31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 27, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 28, 25, 29, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 28, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 28, 26, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 25, 27, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 31, 28, 29, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023169517517089844, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.004307270050048828, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023512840270996094, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 26, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002279996871948242, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 27, 31, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 27, 28, 31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 31, 27, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 30, 27, 29, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [w for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023169517517089844, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 25, 30, 31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 31, 25, 28, 27, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 26, 27, 31, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [w.lower() for w in words]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 26, 25, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 31, 29, 27, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 30, 27, 29, 26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 29, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0025682449340820312, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 30, 25, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 25, 26, 30, 29, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = {}\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 28, 25, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 30, 29, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 26, 27, 31, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 29, 25, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 26, 28, 25, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0030171871185302734, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 25, 26, 28, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 25, 30, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 27, 26, 29, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0032949447631835938, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 27, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29, 27, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0025682449340820312, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 26, 29, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 28, 25, 29, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 27, 28, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023169517517089844, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 27, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 25, 30, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 31, 27, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0029811859130859375, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 26, 29, 27, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002279996871948242, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 31, 30, 25, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002317190170288086, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002863168716430664, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0025682449340820312, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 28, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 27, 30, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 25, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 27, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 26, 28, 27, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002076387405395508, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 28, 27, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.004508018493652344, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 26, 29, 27, 31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.004508018493652344, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 28, 25, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 27, 31, 26, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0021009445190429688, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 25, 26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 25, 26, 29, 30, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0020890235900878906, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 29, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 25, 30, 27, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 29, 27, 25, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 29, 27, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 31, 27, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002279996871948242, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 27, 29, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 28, 26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 27, 26, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 26, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 27, 29, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 27, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 30, 27, 29, 26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 30, 31, 25, 29, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002279996871948242, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 30, 27, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0020890235900878906, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023512840270996094, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 27, 30, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 25, 27, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023512840270996094, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0030171871185302734, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 26, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 30, 25, 29, 28, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 30, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 25, 26, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023512840270996094, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 29, 27, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 29, 28, 31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0029811859130859375, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 29, 26, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 25, 31, 28, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 30, 28, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002009868621826172, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 30, 28, 25, 26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 31, 29, 30, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 30, 25, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 30, 29, 31, 27, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 30, 26, 29, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 31, 29, 28, 27, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29, 28, 26, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 26, 29, 28, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 29, 30, 27, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 27, 28, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.004307270050048828, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 28, 26, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 28, 26, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 29, 31, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 26, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 29, 25, 28, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 29, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 29, 27, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 29, 27, 30, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 28, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0032949447631835938, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 25, 28, 29, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 29, 31, 28, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 28, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 30, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002454996109008789, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 26, 31, 27, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 31, 26, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002173900604248047, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003239870071411133, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 30, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 31, 30, 28, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 29, 27, 28, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29, 28, 26, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 31, 26, 27, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 25, 26, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 26, 25, 28, 30, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 27, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [word.lower() for word in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 30, 27, 26, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 26, 31, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29, 30, 25, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 26, 28, 29, 31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002196073532104492, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 30, 31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25, 28, 31, 27, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 30, 31, 27, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 25, 26, 29, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25, 30, 26, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 31, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 31, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023169517517089844, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 30, 25, 27, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 29, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 28, 25, 31, 26, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 26, 29, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 27, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25, 28, 31, 30, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 26, 30, 27, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 27, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 31, 29, 26, 27, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 29, 25, 26, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 27, 31, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 28, 27, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 31, 28, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 30, 29, 28, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 31, 27, 28, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 27, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 27, 29, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 27, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 26, 31, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 26, 30, 25, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 25, 30, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 28, 26, 31, 29, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 26, 27, 28, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 30, 31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 29, 30, 25, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0030171871185302734, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 28, 29, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 28, 31, 25, 29, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 30, 25, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023512840270996094, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 25, 31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 30, 28, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 31, 26, 27, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 26, 29, 31, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 28, 27, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 27, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 28, 31, 30, 25, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 26, 31, 27, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0033140182495117188, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 31, 29, 30, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 26, 29, 27, 31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 28, 27, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 30, 26, 29, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 25, 28, 27, 31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 29, 31, 27, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023169517517089844, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 28, 30, 27, 26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 29, 31, 27, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 29, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 30, 27, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 30, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 26, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 29, 25, 30, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 30, 26, 29, 28, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 27, 30, 31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 27, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 28, 31, 26, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 31, 27, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 31, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 29, 31, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 31, 25, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003239870071411133, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 25, 31, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 27, 29, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 30, 27, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 29, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 29, 28, 25, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002009868621826172, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 27, 31, 26, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 26, 27, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 25, 31, 29, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 25, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 27, 31, 29, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002279996871948242, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 30, 26, 29, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = {}\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29, 26, 25, 27, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 31, 26, 28, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002009868621826172, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 29, 25, 27, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 27, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002279996871948242, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 26, 25, 27, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 25, 28, 29, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 26, 31, 27, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002076387405395508, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 30, 25, 28, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25, 28, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 31, 29, 30, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 27, 29, 31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 29, 27, 30, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 26, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 25, 31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29, 28, 30, 27, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 29, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 25, 27, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 29, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 26, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 27, 26, 30, 31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 28, 29, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 29, 30, 28, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002279996871948242, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 26, 28, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 26, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 27, 31, 30, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0021009445190429688, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002076387405395508, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 29, 28, 26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 27, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 30, 31, 25, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 25, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 28, 31, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 27, 26, 30, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 27, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 25, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 28, 31, 29, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 31, 26, 27, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0029811859130859375, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 28, 29, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 29, 27, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023169517517089844, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002279996871948242, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 26, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 29, 31, 30, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 30, 25, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 31, 28, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 27, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 30, 25, 28, 27, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 29, 28, 26, 27, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 26, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 30, 31, 28, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 28, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0029811859130859375, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002009868621826172, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 25, 29, 27, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002009868621826172, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 29, 26, 31, 30, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 27, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 27, 29, 26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 30, 31, 27, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 31, 27, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 29, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 25, 26, 30, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 25, 28, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0025682449340820312, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023512840270996094, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 27, 31, 26, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 30, 29, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 29, 27, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 30, 31, 26, 25, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 30, 29, 28, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 29, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 26, 25, 27, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 29, 31, 25, 27, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002076387405395508, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 30, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 26, 27, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 29, 31, 27, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 28, 26, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 30, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 30, 25, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0029811859130859375, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 30, 27, 28, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023512840270996094, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 29, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 31, 28, 30, 27, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29, 28, 30, 25, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 30, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023512840270996094, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003239870071411133, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 26, 29, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 25, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 25, 26, 28, 29, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 27, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 30, 27, 31, 28, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub(\"\\n{2,}\", \"\\n\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 28, 31, 27, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 28, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 30, 26, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 27, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 31, 26, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 31, 28, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 27, 25, 31, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 26, 27, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 29, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 27, 31, 29, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 28, 26, 30, 31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 28, 27, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 29, 28, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 30, 28, 29, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 31, 25, 27, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 26, 29, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 28, 26, 25, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 29, 27, 31, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 25, 26, 31, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 29, 31, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 29, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0025682449340820312, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 27, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 30, 26, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0023109912872314453, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 28, 31, 27, 29, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 27, 28, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 30, 29, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 29, 30, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0033140182495117188, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 29, 27, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 29, 27, 31, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 27, 28, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = {}\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 27, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 28, 26, 27, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 29, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0033140182495117188, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 29, 30, 31, 28, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 27, 29, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 27, 31, 25, 30, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 28, 31, 27, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 26, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 29, 27, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 29, 31, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29, 30, 27, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 26, 28, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 27, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 25, 28, 26, 27, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002076387405395508, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 29, 26, 31, 27, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 28, 26, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 28, 27, 29, 31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002778768539428711, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 28, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 30, 29, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0021009445190429688, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [30, 26, 28, 31, 25, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 27, 25, 29, 31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002026081085205078, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 26, 31, 30, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 30, 25, 28, 31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 31, 25, 27, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 30, 25, 29, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 27, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 25, 26, 29, 30, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 31, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 26, 30, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 27, 28, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 28, 25, 29, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 30, 25, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002076387405395508, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 31, 30, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003239870071411133, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r\"\\n{2,}\", input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0025789737701416016, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 26, 28, 30, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 30, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 27, 30, 29, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [w.lower() for w in words]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 31, 27, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0048291683197021484, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 30, 27, 25, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 26, 31, 29, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 26, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 31, 26, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29, 27, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002778768539428711, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w.lower() for w in re.findall(r'\\w+', line) if w.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0032439231872558594, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 29, 27, 30, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 25, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002009868621826172, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 31, 27, 29, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 27, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 27, 28, 25, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 30, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 30, 28, 26, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 27, 25, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 27, 25, 29, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 25, 26, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002454996109008789, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 26, 25, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 29, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 31, 29, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 28, 29, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 25, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = [line.strip() for line in input_string.split('\\n') if line.strip()]\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [26, 30, 27, 31, 29, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 29, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25, 28, 30, 26, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall('\\n.*', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in line.split() if word.lower() not in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002863168716430664, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 28, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25, 27, 28, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split('[\\n\\r]+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 29, 26, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 29, 31, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 26, 29, 30, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 26, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS and len(w) > 1]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 25, 29, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 25, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0020890235900878906, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 30, 25, 28, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29, 26, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 28, 31, 29, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.sub('\\W+', ' ', input_string).split(' ')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.003503084182739258, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003239870071411133, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 26, 31, 29, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 27, 26, 25, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0029811859130859375, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 29, 30, 26, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 28, 30, 31, 29, 27], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 28, 30, 27, 26], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 27, 29, 31, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 29, 26, 28, 31, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002090930938720703, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [27, 29, 31, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word.lower() for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line.lower())\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002279996871948242, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28, 29, 30, 26, 31, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'(.*\\n)', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(Counter(words))\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [30, 26, 28, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [25, 27, 31, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split(\"\\n\")\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 27, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [w for w in line.split() if not w.lower() in STOPWORDS]\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 25, 29, 31, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\\\n')\n    word_count = {}\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [31, 27, 28, 30, 29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = [word for word in re.findall(r'\\w+', line) if word not in STOPWORDS]\n        words = [w for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [26, 29, 30, 25, 28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.split(r'\\n+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word.lower() for word in words if word.lower() not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.002225160598754883, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [28], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.003468036651611328, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = re.findall(r'\\S+', input_string)\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0032949447631835938, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 27, 29, 30, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = []\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [28, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = line.split()\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0035588741302490234, "tests_passed": false, "error": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"}}
{"selected_lines": [25, 29, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [27, 28, 30], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\w+', line)\n        words = [word for word in words if word not in STOPWORDS]\n        word_count.update(Counter(words))\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [31, 26, 27, 29, 30, 25], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.split('\\n')\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words if w.lower() not in STOPWORDS]\n        word_count.update(words)\n    return word_count", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
{"selected_lines": [29, 25, 31], "result": {"code": "import re\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\nSTOPWORDS = set(stopwords.words('english'))\n\ndef task_func(input_string):\n    \"\"\"\n    Divide a multi-line string into individual lines, remove stopwords, and count the frequency of each word.\n\n    Parameters:\n    - input_string (str): The multi-line string.\n\n    Returns:\n    - dict: A dictionary with word frequencies where each key is a unique word and the value is its frequency.\n\n    Requirements:\n    - re\n    - nltk.corpus\n    - collections\n\n    Example:\n    >>> task_func('line a\\\\nfollows by line b\\\\n...bye\\\\n')\n    {'line': 2, 'follows': 1, 'b': 1, 'bye': 1}\n    \"\"\"\n    lines = input_string.splitlines()\n    word_count = Counter()\n    for line in lines:\n        words = re.findall(r'\\b\\w+\\b', line)\n        words = [w.lower() for w in words]\n        word_count.update(words)\n    return dict(word_count)", "compilation_passed": true, "time": 0.0, "tests_passed": false, "error": null}}
